  
{'loss': 0.6651, 'learning_rate': 0.0002699720149253731, 'epoch': 1.41}                                                                                                       
{'loss': 0.5324, 'learning_rate': 0.0002696921641791044, 'epoch': 1.42}                                                                                                       
{'loss': 0.5247, 'learning_rate': 0.0002694123134328358, 'epoch': 1.43}                                                                                                       
 14%|██████████████████▎                                                                                                             | 1600/11220 [1:35:38<2:00:58,  1.33it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.43157875537872314, 'eval_wer': 0.51970430705522, 'eval_cer': 0.16521425912080662, 'eval_runtime': 296.2394, 'eval_samples_per_second': 29.328, 'eval_steps_per_second': 3.666, 'epoch': 1.43}                                                                                                                                               
{'loss': 0.5554, 'learning_rate': 0.00026913246268656717, 'epoch': 1.43}                                                                                                      
{'loss': 0.5545, 'learning_rate': 0.0002688526119402985, 'epoch': 1.44}                                                                                                       
{'loss': 0.5444, 'learning_rate': 0.0002685727611940298, 'epoch': 1.45}                                                                                                       
{'loss': 0.482, 'learning_rate': 0.0002682929104477612, 'epoch': 1.46}                                                                                                        
{'loss': 0.5003, 'learning_rate': 0.0002680130597014925, 'epoch': 1.47}                                                                                                       
{'loss': 0.6197, 'learning_rate': 0.0002677332089552238, 'epoch': 1.48}                                                                                                       
{'loss': 0.7591, 'learning_rate': 0.0002674533582089552, 'epoch': 1.49}                                                                                                       
{'loss': 0.7685, 'learning_rate': 0.00026717350746268656, 'epoch': 1.5}                                                                                                       
 15%|███████████████████▏                                                                                                            | 1683/11220 [1:41:43<2:50:53,  1.08s/it]Saving model checkpoint to ./portu_clean/checkpoint-1683
Configuration saved in ./portu_clean/checkpoint-1683/config.json
Model weights saved in ./portu_clean/checkpoint-1683/pytorch_model.bin
Feature extractor saved in ./portu_clean/checkpoint-1683/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.48, 'learning_rate': 0.0002668936567164179, 'epoch': 1.51}                                                                                                         
{'loss': 0.5615, 'learning_rate': 0.00026661380597014925, 'epoch': 1.51}                                                                                                      
 15%|███████████████████▍                                                                                                            | 1700/11220 [1:42:01<2:05:27,  1.26it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.38416746258735657, 'eval_wer': 0.4838720717329181, 'eval_cer': 0.15439611830336197, 'eval_runtime': 296.7943, 'eval_samples_per_second': 29.273, 'eval_steps_per_second': 3.659, 'epoch': 1.51}                                                                                                                                             
{'loss': 0.5385, 'learning_rate': 0.00026633395522388057, 'epoch': 1.52}                                                                                                      
{'loss': 0.5116, 'learning_rate': 0.0002660541044776119, 'epoch': 1.53}                                                                                                       
{'loss': 0.49, 'learning_rate': 0.00026577425373134326, 'epoch': 1.54}                                                                                                        
{'loss': 0.541, 'learning_rate': 0.00026549440298507463, 'epoch': 1.55}                                                                                                       
{'loss': 0.6308, 'learning_rate': 0.0002652425373134328, 'epoch': 1.56}                                                                                                       
{'loss': 0.5328, 'learning_rate': 0.00026496268656716417, 'epoch': 1.57}                                                                                                      
{'loss': 0.6426, 'learning_rate': 0.0002646828358208955, 'epoch': 1.58}                                                                                                       
{'loss': 0.532, 'learning_rate': 0.00026440298507462686, 'epoch': 1.59}                                                                                                       
{'loss': 0.534, 'learning_rate': 0.0002641231343283582, 'epoch': 1.6}                                                                                                         
{'loss': 0.6545, 'learning_rate': 0.0002638712686567164, 'epoch': 1.6}                                                                                                        
 16%|████████████████████▌                                                                                                           | 1800/11220 [1:48:20<1:59:35,  1.31it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3948425054550171, 'eval_wer': 0.4936258320642037, 'eval_cer': 0.1619996912561938, 'eval_runtime': 296.8121, 'eval_samples_per_second': 29.271, 'eval_steps_per_second': 3.659, 'epoch': 1.6}                                                                                                                                                
{'loss': 0.5505, 'learning_rate': 0.00026359141791044776, 'epoch': 1.61}                                                                                                      
{'loss': 0.5879, 'learning_rate': 0.0002633115671641791, 'epoch': 1.62}                                                                                                       
{'loss': 0.6485, 'learning_rate': 0.0002630317164179104, 'epoch': 1.63}                                                                                                       
{'loss': 0.7092, 'learning_rate': 0.00026275186567164177, 'epoch': 1.64}                                                                                                      
{'loss': 0.5061, 'learning_rate': 0.0002624720149253731, 'epoch': 1.65}                                                                                                       
{'loss': 0.5049, 'learning_rate': 0.00026219216417910446, 'epoch': 1.66}                                                                                                      
{'loss': 0.5512, 'learning_rate': 0.00026191231343283583, 'epoch': 1.67}                                                                                                      
{'loss': 0.5341, 'learning_rate': 0.00026163246268656715, 'epoch': 1.68}                                                                                                      
{'loss': 0.5124, 'learning_rate': 0.00026135261194029847, 'epoch': 1.68}                                                                                                      
{'loss': 0.4724, 'learning_rate': 0.00026107276119402984, 'epoch': 1.69}                                                                                                      
 17%|█████████████████████▋                                                                                                          | 1900/11220 [1:54:40<1:58:49,  1.31it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3808515667915344, 'eval_wer': 0.48010746248224645, 'eval_cer': 0.15670866994984425, 'eval_runtime': 297.1799, 'eval_samples_per_second': 29.235, 'eval_steps_per_second': 3.654, 'epoch': 1.69}                                                                                                                                             
{'loss': 0.4766, 'learning_rate': 0.00026079291044776116, 'epoch': 1.7}                                                                                                       
{'loss': 0.6268, 'learning_rate': 0.0002605130597014925, 'epoch': 1.71}                                                                                                       
{'loss': 0.7952, 'learning_rate': 0.00026023320895522385, 'epoch': 1.72}                                                                                                      
{'loss': 0.5203, 'learning_rate': 0.0002599533582089552, 'epoch': 1.73}                                                                                                       
{'loss': 0.442, 'learning_rate': 0.00025967350746268654, 'epoch': 1.74}                                                                                                       
{'loss': 0.6266, 'learning_rate': 0.00025939365671641786, 'epoch': 1.75}                                                                                                      
{'loss': 0.5775, 'learning_rate': 0.00025911380597014923, 'epoch': 1.76}                                                                                                      
{'loss': 0.5046, 'learning_rate': 0.00025883395522388055, 'epoch': 1.76}                                                                                                      
{'loss': 0.5646, 'learning_rate': 0.0002585541044776119, 'epoch': 1.77}                                                                                                       
{'loss': 0.4939, 'learning_rate': 0.0002582742537313433, 'epoch': 1.78}                                                                                                       
 18%|██████████████████████▊                                                                                                         | 2000/11220 [2:00:59<1:56:35,  1.32it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.38156187534332275, 'eval_wer': 0.47548726022005855, 'eval_cer': 0.15458681300719493, 'eval_runtime': 297.0414, 'eval_samples_per_second': 29.248, 'eval_steps_per_second': 3.656, 'epoch': 1.78}                                                                                                                                            
{'loss': 0.4916, 'learning_rate': 0.0002579944029850746, 'epoch': 1.79}                                                                                                       
{'loss': 0.5471, 'learning_rate': 0.00025771455223880593, 'epoch': 1.8}                                                                                                       
{'loss': 0.5226, 'learning_rate': 0.0002574347014925373, 'epoch': 1.81}                                                                                                       
{'loss': 0.4971, 'learning_rate': 0.0002571548507462686, 'epoch': 1.82}                                                                                                       
{'loss': 0.5319, 'learning_rate': 0.00025687499999999994, 'epoch': 1.83}                                                                                                      
{'loss': 0.5097, 'learning_rate': 0.0002565951492537313, 'epoch': 1.84}                                                                                                       
{'loss': 0.52, 'learning_rate': 0.0002563152985074627, 'epoch': 1.84}                                                                                                         
{'loss': 0.5322, 'learning_rate': 0.000256035447761194, 'epoch': 1.85}                                                                                                        
{'loss': 0.5162, 'learning_rate': 0.0002557555970149254, 'epoch': 1.86}                                                                                                       
{'loss': 0.5038, 'learning_rate': 0.0002554757462686567, 'epoch': 1.87}                                                                                                       
 19%|███████████████████████▉                                                                                                        | 2100/11220 [2:07:19<1:54:09,  1.33it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3708235025405884, 'eval_wer': 0.4627047006280053, 'eval_cer': 0.14885083739190183, 'eval_runtime': 298.4442, 'eval_samples_per_second': 29.111, 'eval_steps_per_second': 3.639, 'epoch': 1.87}                                                                                                                                              
{'loss': 0.5763, 'learning_rate': 0.000255195895522388, 'epoch': 1.88}                                                                                                        
{'loss': 0.6186, 'learning_rate': 0.0002549160447761194, 'epoch': 1.89}                                                                                                       
{'loss': 0.4785, 'learning_rate': 0.00025463619402985076, 'epoch': 1.9}                                                                                                       
{'loss': 0.4725, 'learning_rate': 0.0002543563432835821, 'epoch': 1.91}                                                                                                       
{'loss': 0.4983, 'learning_rate': 0.0002540764925373134, 'epoch': 1.92}                                                                                                       
{'loss': 0.4688, 'learning_rate': 0.00025379664179104477, 'epoch': 1.92}                                                                                                      
{'loss': 0.5342, 'learning_rate': 0.0002535167910447761, 'epoch': 1.93}                                                                                                       
{'loss': 0.4556, 'learning_rate': 0.0002532369402985074, 'epoch': 1.94}                                                                                                       
{'loss': 0.4362, 'learning_rate': 0.0002529570895522388, 'epoch': 1.95}                                                                                                       
{'loss': 0.4897, 'learning_rate': 0.00025267723880597015, 'epoch': 1.96}                                                                                                      
 20%|█████████████████████████                                                                                                       | 2200/11220 [2:13:40<1:54:19,  1.31it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.35247376561164856, 'eval_wer': 0.461797772035798, 'eval_cer': 0.1492049846990202, 'eval_runtime': 296.3896, 'eval_samples_per_second': 29.313, 'eval_steps_per_second': 3.664, 'epoch': 1.96}                                                                                                                                               
{'loss': 0.5243, 'learning_rate': 0.00025239738805970147, 'epoch': 1.97}                                                                                                      
{'loss': 0.5114, 'learning_rate': 0.00025211753731343284, 'epoch': 1.98}                                                                                                      
{'loss': 0.6122, 'learning_rate': 0.00025183768656716416, 'epoch': 1.99}                                                                                                      
{'loss': 0.5116, 'learning_rate': 0.0002515578358208955, 'epoch': 2.0}                                                                                                        
 20%|█████████████████████████▌                                                                                                      | 2244/11220 [2:19:08<1:23:21,  1.79it/s]Saving model checkpoint to ./portu_clean/checkpoint-2244
Configuration saved in ./portu_clean/checkpoint-2244/config.json
Model weights saved in ./portu_clean/checkpoint-2244/pytorch_model.bin
Feature extractor saved in ./portu_clean/checkpoint-2244/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4767, 'learning_rate': 0.00025127798507462685, 'epoch': 2.01}                                                                                                      
{'loss': 0.3881, 'learning_rate': 0.0002509981343283582, 'epoch': 2.01}                                                                                                       
{'loss': 0.4298, 'learning_rate': 0.00025071828358208954, 'epoch': 2.02}                                                                                                      
{'loss': 0.3989, 'learning_rate': 0.00025043843283582086, 'epoch': 2.03}                                                                                                      
{'loss': 0.423, 'learning_rate': 0.00025015858208955223, 'epoch': 2.04}                                                                                                       
{'loss': 0.4782, 'learning_rate': 0.00024987873134328355, 'epoch': 2.05}                                                                                                      
 20%|██████████████████████████▏                                                                                                     | 2300/11220 [2:20:00<2:51:04,  1.15s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3609195351600647, 'eval_wer': 0.45840962371019356, 'eval_cer': 0.1479700094741972, 'eval_runtime': 295.5537, 'eval_samples_per_second': 29.396, 'eval_steps_per_second': 3.674, 'epoch': 2.05}                                                                                                                                              
{'loss': 0.3902, 'learning_rate': 0.00024959888059701487, 'epoch': 2.06}                                                                                                      
{'loss': 0.4176, 'learning_rate': 0.00024931902985074624, 'epoch': 2.07}                                                                                                      
{'loss': 0.4333, 'learning_rate': 0.0002490391791044776, 'epoch': 2.08}                                                                                                       
{'loss': 0.4736, 'learning_rate': 0.00024875932835820893, 'epoch': 2.09}                                                                                                      
{'loss': 0.3724, 'learning_rate': 0.0002484794776119403, 'epoch': 2.09}                                                                                                       
{'loss': 0.3996, 'learning_rate': 0.0002481996268656716, 'epoch': 2.1}                                                                                                        
{'loss': 0.3768, 'learning_rate': 0.00024794776119402984, 'epoch': 2.11}                                                                                                      
{'loss': 0.4097, 'learning_rate': 0.00024766791044776115, 'epoch': 2.12}                                                                                                      
{'loss': 0.4452, 'learning_rate': 0.0002473880597014925, 'epoch': 2.13}                                                                                                       
{'loss': 0.522, 'learning_rate': 0.00024710820895522384, 'epoch': 2.14}                                                                                                       
 21%|███████████████████████████▍                                                                                                    | 2400/11220 [2:26:17<2:56:14,  1.20s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3731658458709717, 'eval_wer': 0.46600728965245813, 'eval_cer': 0.15304914777628786, 'eval_runtime': 295.3351, 'eval_samples_per_second': 29.417, 'eval_steps_per_second': 3.677, 'epoch': 2.14}                                                                                                                                             
{'loss': 0.3794, 'learning_rate': 0.0002468283582089552, 'epoch': 2.15}                                                                                                       
{'loss': 0.398, 'learning_rate': 0.00024654850746268653, 'epoch': 2.16}                                                                                                       
{'loss': 0.4022, 'learning_rate': 0.0002462686567164179, 'epoch': 2.17}                                                                                                       
{'loss': 0.4777, 'learning_rate': 0.0002459888059701492, 'epoch': 2.17}                                                                                                       
{'loss': 0.466, 'learning_rate': 0.0002457089552238806, 'epoch': 2.18}                                                                                                        
{'loss': 0.3519, 'learning_rate': 0.0002454291044776119, 'epoch': 2.19}                                                                                                       
{'loss': 0.4195, 'learning_rate': 0.00024514925373134323, 'epoch': 2.2}                                                                                                       
{'loss': 0.4345, 'learning_rate': 0.0002448694029850746, 'epoch': 2.21}                                                                                                       
{'loss': 0.3817, 'learning_rate': 0.000244589552238806, 'epoch': 2.22}                                                                                                        
{'loss': 0.4786, 'learning_rate': 0.0002443097014925373, 'epoch': 2.23}                                                                                                       
 22%|████████████████████████████▌                                                                                                   | 2500/11220 [2:32:34<2:47:12,  1.15s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.35530176758766174, 'eval_wer': 0.4505895035849347, 'eval_cer': 0.14926249580017617, 'eval_runtime': 295.8477, 'eval_samples_per_second': 29.366, 'eval_steps_per_second': 3.671, 'epoch': 2.23}                                                                                                                                             
{'loss': 0.4106, 'learning_rate': 0.00024402985074626864, 'epoch': 2.24}                                                                                                      
{'loss': 0.4261, 'learning_rate': 0.00024375, 'epoch': 2.25}                                                                                                                  
{'loss': 0.4431, 'learning_rate': 0.0002434701492537313, 'epoch': 2.25}                                                                                                       
{'loss': 0.4028, 'learning_rate': 0.00024319029850746265, 'epoch': 2.26}                                                                                                      
{'loss': 0.4083, 'learning_rate': 0.000242910447761194, 'epoch': 2.27}                                                                                                        
{'loss': 0.3559, 'learning_rate': 0.00024263059701492537, 'epoch': 2.28}                                                                                                      
{'loss': 0.3691, 'learning_rate': 0.00024235074626865672, 'epoch': 2.29}                                                                                                      
{'loss': 0.4019, 'learning_rate': 0.00024207089552238803, 'epoch': 2.3}                                                                                                       
{'loss': 0.384, 'learning_rate': 0.00024179104477611938, 'epoch': 2.31}                                                                                                       
{'loss': 0.6234, 'learning_rate': 0.00024151119402985072, 'epoch': 2.32}                                                                                                      
 23%|█████████████████████████████▋                                                                                                  | 2600/11220 [2:38:52<2:51:56,  1.20s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.33844324946403503, 'eval_wer': 0.4572973527952224, 'eval_cer': 0.14950767470510426, 'eval_runtime': 297.6868, 'eval_samples_per_second': 29.185, 'eval_steps_per_second': 3.648, 'epoch': 2.32}                                                                                                                                             
{'loss': 0.3878, 'learning_rate': 0.00024123134328358207, 'epoch': 2.33}                                                                                                      
{'loss': 0.3988, 'learning_rate': 0.0002409514925373134, 'epoch': 2.33}                                                                                                       
{'loss': 0.4395, 'learning_rate': 0.00024067164179104476, 'epoch': 2.34}                                                                                                      
{'loss': 0.4489, 'learning_rate': 0.0002403917910447761, 'epoch': 2.35}                                                                                                       
{'loss': 0.5028, 'learning_rate': 0.00024011194029850745, 'epoch': 2.36}                                                                                                      
{'loss': 0.4167, 'learning_rate': 0.00023983208955223877, 'epoch': 2.37}                                                                                                      
{'loss': 0.4037, 'learning_rate': 0.00023955223880597012, 'epoch': 2.38}                                                                                                      
{'loss': 0.4172, 'learning_rate': 0.00023927238805970146, 'epoch': 2.39}                                                                                                      
{'loss': 0.3926, 'learning_rate': 0.00023899253731343283, 'epoch': 2.4}                                                                                                       
{'loss': 0.4444, 'learning_rate': 0.00023871268656716418, 'epoch': 2.41}                                                                                                      
 24%|██████████████████████████████▊                                                                                                 | 2700/11220 [2:45:14<2:49:29,  1.19s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3360731899738312, 'eval_wer': 0.43921011653176817, 'eval_cer': 0.14457685450599478, 'eval_runtime': 298.1974, 'eval_samples_per_second': 29.135, 'eval_steps_per_second': 3.642, 'epoch': 2.41}                                                                                                                                             
{'loss': 0.4619, 'learning_rate': 0.0002384328358208955, 'epoch': 2.42}                                                                                                       
{'loss': 0.4005, 'learning_rate': 0.00023815298507462684, 'epoch': 2.42}                                                                                                      
{'loss': 0.4417, 'learning_rate': 0.0002378731343283582, 'epoch': 2.43}                                                                                                       
{'loss': 0.4528, 'learning_rate': 0.00023759328358208953, 'epoch': 2.44}                                                                                                      
{'loss': 0.4531, 'learning_rate': 0.00023731343283582085, 'epoch': 2.45}                                                                                                      
{'loss': 0.4075, 'learning_rate': 0.00023703358208955222, 'epoch': 2.46}                                                                                                      
{'loss': 0.3785, 'learning_rate': 0.00023675373134328357, 'epoch': 2.47}                                                                                                      
{'loss': 0.4082, 'learning_rate': 0.00023647388059701491, 'epoch': 2.48}                                                                                                      
{'loss': 0.4054, 'learning_rate': 0.00023619402985074626, 'epoch': 2.49}                                                                                                      
{'loss': 0.5009, 'learning_rate': 0.00023591417910447758, 'epoch': 2.5}                                                                                                       
 25%|███████████████████████████████▉                                                                                                | 2800/11220 [2:51:34<2:49:05,  1.20s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3452422320842743, 'eval_wer': 0.4464313215489656, 'eval_cer': 0.14497640531402575, 'eval_runtime': 297.0281, 'eval_samples_per_second': 29.25, 'eval_steps_per_second': 3.656, 'epoch': 2.5}                                                                                                                                                
 25%|███████████████████████████████▊                                                                                               | 2805/11220 [2:56:36<52:34:02, 22.49s/it]Saving model checkpoint to ./portu_clean/checkpoint-2805                                                                                                                      
Configuration saved in ./portu_clean/checkpoint-2805/config.json
Model weights saved in ./portu_clean/checkpoint-2805/pytorch_model.bin
Feature extractor saved in ./portu_clean/checkpoint-2805/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3954, 'learning_rate': 0.00023563432835820892, 'epoch': 2.5}                                                                                                       
{'loss': 0.3771, 'learning_rate': 0.00023535447761194027, 'epoch': 2.51}                                                                                                      
{'loss': 0.4408, 'learning_rate': 0.00023507462686567164, 'epoch': 2.52}                                                                                                      
{'loss': 0.4161, 'learning_rate': 0.00023479477611940296, 'epoch': 2.53}                                                                                                      
{'loss': 0.4238, 'learning_rate': 0.0002345149253731343, 'epoch': 2.54}                                                                                                       
{'loss': 0.4221, 'learning_rate': 0.00023423507462686565, 'epoch': 2.55}                                                                                                      
{'loss': 0.4105, 'learning_rate': 0.000233955223880597, 'epoch': 2.56}                                                                                                        
{'loss': 0.3742, 'learning_rate': 0.00023367537313432831, 'epoch': 2.57}                                                                                                      
{'loss': 0.4422, 'learning_rate': 0.0002333955223880597, 'epoch': 2.58}                                                                                                       
{'loss': 0.3531, 'learning_rate': 0.00023311567164179103, 'epoch': 2.58}                                                                                                      
 26%|█████████████████████████████████                                                                                               | 2900/11220 [2:57:57<2:54:24,  1.26s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.34361618757247925, 'eval_wer': 0.43318674173069355, 'eval_cer': 0.14220376485829567, 'eval_runtime': 297.4675, 'eval_samples_per_second': 29.207, 'eval_steps_per_second': 3.651, 'epoch': 2.58}                                                                                                                                            
{'loss': 0.3902, 'learning_rate': 0.00023283582089552238, 'epoch': 2.59}                                                                                                      
{'loss': 0.3835, 'learning_rate': 0.00023255597014925372, 'epoch': 2.6}                                                                                                       
{'loss': 0.4396, 'learning_rate': 0.00023227611940298504, 'epoch': 2.61}                                                                                                      
{'loss': 0.4656, 'learning_rate': 0.00023199626865671639, 'epoch': 2.62}                                                                                                      
{'loss': 0.429, 'learning_rate': 0.00023171641791044773, 'epoch': 2.63}                                                                                                       
{'loss': 0.3916, 'learning_rate': 0.0002314365671641791, 'epoch': 2.64}                                                                                                       
{'loss': 0.3772, 'learning_rate': 0.00023115671641791045, 'epoch': 2.65}                                                                                                      
{'loss': 0.3893, 'learning_rate': 0.00023087686567164177, 'epoch': 2.66}                                                                                                      
{'loss': 0.409, 'learning_rate': 0.0002305970149253731, 'epoch': 2.66}                                                                                                        
{'loss': 0.4802, 'learning_rate': 0.00023031716417910446, 'epoch': 2.67}                                                                                                      
 27%|██████████████████████████████████▏                                                                                             | 3000/11220 [3:04:17<2:42:05,  1.18s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3182152807712555, 'eval_wer': 0.4262906620578723, 'eval_cer': 0.13902249289435212, 'eval_runtime': 297.1602, 'eval_samples_per_second': 29.237, 'eval_steps_per_second': 3.655, 'epoch': 2.67}                                                                                                                                              
{'loss': 0.3372, 'learning_rate': 0.00023003731343283578, 'epoch': 2.68}                                                                                                      
{'loss': 0.3798, 'learning_rate': 0.00022975746268656712, 'epoch': 2.69}                                                                                                      
{'loss': 0.3362, 'learning_rate': 0.0002294776119402985, 'epoch': 2.7}                                                                                                        
{'loss': 0.4509, 'learning_rate': 0.00022919776119402984, 'epoch': 2.71}                                                                                                      
{'loss': 0.4068, 'learning_rate': 0.00022891791044776119, 'epoch': 2.72}                                                                                                      
{'loss': 0.4321, 'learning_rate': 0.0002286380597014925, 'epoch': 2.73}                                                                                                       
{'loss': 0.4358, 'learning_rate': 0.00022835820895522385, 'epoch': 2.74}                                                                                                      
{'loss': 0.4209, 'learning_rate': 0.0002280783582089552, 'epoch': 2.74}                                                                                                       
{'loss': 0.3899, 'learning_rate': 0.00022779850746268657, 'epoch': 2.75}                                                                                                      
{'loss': 0.4502, 'learning_rate': 0.0002275186567164179, 'epoch': 2.76}                                                                                                       
 28%|███████████████████████████████████▎                                                                                            | 3100/11220 [3:10:38<2:41:02,  1.19s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.31378260254859924, 'eval_wer': 0.4165882373072777, 'eval_cer': 0.13651319274391518, 'eval_runtime': 297.5516, 'eval_samples_per_second': 29.198, 'eval_steps_per_second': 3.65, 'epoch': 2.76}                                                                                                                                              
{'loss': 0.3398, 'learning_rate': 0.00022723880597014923, 'epoch': 2.77}                                                                                                      
{'loss': 0.385, 'learning_rate': 0.00022695895522388058, 'epoch': 2.78}                                                                                                       
{'loss': 0.4487, 'learning_rate': 0.00022667910447761192, 'epoch': 2.79}                                                                                                      
{'loss': 0.4373, 'learning_rate': 0.00022639925373134327, 'epoch': 2.8}                                                                                                       
{'loss': 0.3888, 'learning_rate': 0.00022611940298507459, 'epoch': 2.81}                                                                                                      
{'loss': 0.3925, 'learning_rate': 0.00022583955223880596, 'epoch': 2.82}                                                                                                      
{'loss': 0.3901, 'learning_rate': 0.00022558768656716414, 'epoch': 2.82}                                                                                                      
{'loss': 0.3881, 'learning_rate': 0.0002253078358208955, 'epoch': 2.83}                                                                                                       
{'loss': 0.4169, 'learning_rate': 0.00022502798507462686, 'epoch': 2.84}                                                                                                      
{'loss': 0.4647, 'learning_rate': 0.0002247481343283582, 'epoch': 2.85}                                                                                                       
 29%|████████████████████████████████████▌                                                                                           | 3200/11220 [3:16:58<2:39:55,  1.20s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3151502013206482, 'eval_wer': 0.4279334006399836, 'eval_cer': 0.1418102678503864, 'eval_runtime': 297.3675, 'eval_samples_per_second': 29.216, 'eval_steps_per_second': 3.652, 'epoch': 2.85}                                                                                                                                               
{'loss': 0.3359, 'learning_rate': 0.00022446828358208953, 'epoch': 2.86}                                                                                                      
{'loss': 0.4078, 'learning_rate': 0.00022418843283582087, 'epoch': 2.87}                                                                                                      
{'loss': 0.4185, 'learning_rate': 0.00022390858208955222, 'epoch': 2.88}                                                                                                      
{'loss': 0.443, 'learning_rate': 0.00022362873134328356, 'epoch': 2.89}                                                                                                       
{'loss': 0.3561, 'learning_rate': 0.00022334888059701488, 'epoch': 2.9}                                                                                                       
{'loss': 0.3815, 'learning_rate': 0.00022306902985074625, 'epoch': 2.91}                                                                                                      
{'loss': 0.3748, 'learning_rate': 0.0002227891791044776, 'epoch': 2.91}                                                                                                       
{'loss': 0.3528, 'learning_rate': 0.00022250932835820894, 'epoch': 2.92}                                                                                                      
{'loss': 0.4665, 'learning_rate': 0.0002222294776119403, 'epoch': 2.93}                                                                                                       
{'loss': 0.4879, 'learning_rate': 0.0002219496268656716, 'epoch': 2.94}                                                                                                       
 29%|█████████████████████████████████████▋                                                                                          | 3300/11220 [3:23:18<2:42:37,  1.23s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3041604161262512, 'eval_wer': 0.4228682900118072, 'eval_cer': 0.13931307530019282, 'eval_runtime': 298.8064, 'eval_samples_per_second': 29.076, 'eval_steps_per_second': 3.634, 'epoch': 2.94}                                                                                                                                              
{'loss': 0.3554, 'learning_rate': 0.00022166977611940295, 'epoch': 2.95}                                                                                                      
{'loss': 0.3857, 'learning_rate': 0.00022138992537313432, 'epoch': 2.96}                                                                                                      
{'loss': 0.3742, 'learning_rate': 0.00022111007462686567, 'epoch': 2.97}                                                                                                      
{'loss': 0.4117, 'learning_rate': 0.000220830223880597, 'epoch': 2.98}                                                                                                        
{'loss': 0.4126, 'learning_rate': 0.00022055037313432833, 'epoch': 2.99}                                                                                                      
{'loss': 0.3957, 'learning_rate': 0.00022027052238805968, 'epoch': 2.99}                                                                                                      
 30%|██████████████████████████████████████▍                                                                                         | 3366/11220 [3:29:11<1:15:11,  1.74it/s]Saving model checkpoint to ./portu_clean/checkpoint-3366
Configuration saved in ./portu_clean/checkpoint-3366/config.json
Model weights saved in ./portu_clean/checkpoint-3366/pytorch_model.bin
Feature extractor saved in ./portu_clean/checkpoint-3366/preprocessor_config.json
Deleting older checkpoint [portu_clean/checkpoint-561] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4188, 'learning_rate': 0.00021999067164179102, 'epoch': 3.0}                                                                                                       
{'loss': 0.3036, 'learning_rate': 0.00021971082089552234, 'epoch': 3.01}                                                                                                      
{'loss': 0.2905, 'learning_rate': 0.00021943097014925372, 'epoch': 3.02}                                                                                                      
{'loss': 0.324, 'learning_rate': 0.00021915111940298506, 'epoch': 3.03}                                                                                                       
 30%|██████████████████████████████████████▊                                                                                         | 3400/11220 [3:29:46<1:29:45,  1.45it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.318766325712204, 'eval_wer': 0.42137955817176886, 'eval_cer': 0.14115948433730563, 'eval_runtime': 297.0733, 'eval_samples_per_second': 29.245, 'eval_steps_per_second': 3.656, 'epoch': 3.03}                                                                                                                                              
{'loss': 0.3659, 'learning_rate': 0.0002188712686567164, 'epoch': 3.04}                                                                                                       
{'loss': 0.3748, 'learning_rate': 0.00021859141791044775, 'epoch': 3.05}                                                                                                      
{'loss': 0.3355, 'learning_rate': 0.00021831156716417907, 'epoch': 3.06}                                                                                                      
{'loss': 0.2929, 'learning_rate': 0.00021803171641791042, 'epoch': 3.07}                                                                                                      
{'loss': 0.2987, 'learning_rate': 0.00021775186567164176, 'epoch': 3.07}                                                                                                      
{'loss': 0.3343, 'learning_rate': 0.00021747201492537313, 'epoch': 3.08}                                                                                                      
{'loss': 0.4091, 'learning_rate': 0.00021719216417910448, 'epoch': 3.09}                                                                                                      
{'loss': 0.2976, 'learning_rate': 0.0002169123134328358, 'epoch': 3.1}                                                                                                        
{'loss': 0.3255, 'learning_rate': 0.00021663246268656714, 'epoch': 3.11}                                                                                                      
{'loss': 0.3086, 'learning_rate': 0.0002163526119402985, 'epoch': 3.12}                                                                                                       
 31%|███████████████████████████████████████▉                                                                                        | 3500/11220 [3:36:05<1:25:21,  1.51it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3274012804031372, 'eval_wer': 0.4160919933605982, 'eval_cer': 0.13677047924908664, 'eval_runtime': 298.0763, 'eval_samples_per_second': 29.147, 'eval_steps_per_second': 3.643, 'epoch': 3.12}                                                                                                                                              
{'loss': 0.3488, 'learning_rate': 0.00021607276119402983, 'epoch': 3.13}                                                                                                      
{'loss': 0.4167, 'learning_rate': 0.00021579291044776118, 'epoch': 3.14}                                                                                                      
{'loss': 0.3062, 'learning_rate': 0.00021551305970149252, 'epoch': 3.15}                                                                                                      
{'loss': 0.2907, 'learning_rate': 0.00021523320895522387, 'epoch': 3.16}                                                                                                      
{'loss': 0.3751, 'learning_rate': 0.00021495335820895521, 'epoch': 3.16}                                                                                                      
{'loss': 0.4127, 'learning_rate': 0.00021467350746268653, 'epoch': 3.17}                                                                                                      
{'loss': 0.4954, 'learning_rate': 0.00021439365671641788, 'epoch': 3.18}                                                                                                      
{'loss': 0.3302, 'learning_rate': 0.00021411380597014922, 'epoch': 3.19}                                                                                                      
{'loss': 0.3263, 'learning_rate': 0.0002138339552238806, 'epoch': 3.2}                                                                                                        
{'loss': 0.3234, 'learning_rate': 0.00021355410447761194, 'epoch': 3.21}                                                                                                      
 32%|█████████████████████████████████████████                                                                                       | 3600/11220 [3:42:25<1:24:06,  1.51it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.30638620257377625, 'eval_wer': 0.40914457810708604, 'eval_cer': 0.1324753080627537, 'eval_runtime': 299.0357, 'eval_samples_per_second': 29.053, 'eval_steps_per_second': 3.632, 'epoch': 3.21}                                                                                                                                             
{'loss': 0.3914, 'learning_rate': 0.00021327425373134326, 'epoch': 3.22}                                                                                                      
{'loss': 0.4103, 'learning_rate': 0.0002129944029850746, 'epoch': 3.23}                                                                                                       
{'loss': 0.3191, 'learning_rate': 0.00021271455223880595, 'epoch': 3.24}                                                                                                      
{'loss': 0.3343, 'learning_rate': 0.0002124347014925373, 'epoch': 3.24}                                                                                                       
{'loss': 0.3338, 'learning_rate': 0.00021215485074626861, 'epoch': 3.25}                                                                                                      
{'loss': 0.3443, 'learning_rate': 0.000211875, 'epoch': 3.26}                                                                                                                 
{'loss': 0.4024, 'learning_rate': 0.00021159514925373133, 'epoch': 3.27}                                                                                                      
{'loss': 0.3177, 'learning_rate': 0.00021131529850746268, 'epoch': 3.28}                                                                                                      
{'loss': 0.2584, 'learning_rate': 0.00021103544776119402, 'epoch': 3.29}                                                                                                      
{'loss': 0.3979, 'learning_rate': 0.00021075559701492534, 'epoch': 3.3}                                                                                                       
 33%|██████████████████████████████████████████▏                                                                                     | 3700/11220 [3:48:47<1:25:07,  1.47it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.31217727065086365, 'eval_wer': 0.41354232618627973, 'eval_cer': 0.13698236225334548, 'eval_runtime': 299.2941, 'eval_samples_per_second': 29.028, 'eval_steps_per_second': 3.629, 'epoch': 3.3}                                                                                                                                             
{'loss': 0.3555, 'learning_rate': 0.00021047574626865669, 'epoch': 3.31}                                                                                                      
{'loss': 0.3436, 'learning_rate': 0.00021019589552238803, 'epoch': 3.32}                                                                                                      
{'loss': 0.2757, 'learning_rate': 0.0002099160447761194, 'epoch': 3.32}                                                                                                       
{'loss': 0.3463, 'learning_rate': 0.0002096641791044776, 'epoch': 3.33}                                                                                                       
{'loss': 0.3056, 'learning_rate': 0.00020938432835820896, 'epoch': 3.34}                                                                                                      
{'loss': 0.3868, 'learning_rate': 0.00020910447761194028, 'epoch': 3.35}                                                                                                      
{'loss': 0.3438, 'learning_rate': 0.00020882462686567163, 'epoch': 3.36}                                                                                                      
{'loss': 0.3042, 'learning_rate': 0.00020854477611940297, 'epoch': 3.37}                                                                                                      
{'loss': 0.2994, 'learning_rate': 0.00020826492537313432, 'epoch': 3.38}                                                                                                      
{'loss': 0.3351, 'learning_rate': 0.00020798507462686564, 'epoch': 3.39}                                                                                                      
 34%|███████████████████████████████████████████▎                                                                                    | 3800/11220 [3:55:10<1:25:00,  1.45it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.2917274832725525, 'eval_wer': 0.4088707883434008, 'eval_cer': 0.1336588259865424, 'eval_runtime': 299.164, 'eval_samples_per_second': 29.041, 'eval_steps_per_second': 3.63, 'epoch': 3.39}                                                                                                                                                 
{'loss': 0.3367, 'learning_rate': 0.00020770522388059698, 'epoch': 3.4}                                                                                                       
{'loss': 0.3669, 'learning_rate': 0.00020742537313432835, 'epoch': 3.4}                                                                                                       
{'loss': 0.2488, 'learning_rate': 0.0002071455223880597, 'epoch': 3.41}                                                                                                       
{'loss': 0.2967, 'learning_rate': 0.00020686567164179104, 'epoch': 3.42}                                                                                                      
{'loss': 0.3739, 'learning_rate': 0.00020658582089552236, 'epoch': 3.43}                                                                                                      
{'loss': 0.4133, 'learning_rate': 0.0002063059701492537, 'epoch': 3.44}                                                                                                       
{'loss': 0.3258, 'learning_rate': 0.00020602611940298505, 'epoch': 3.45}                                                                                                      
{'loss': 0.3092, 'learning_rate': 0.00020574626865671637, 'epoch': 3.46}                                                                                                      
{'loss': 0.3069, 'learning_rate': 0.00020546641791044774, 'epoch': 3.47}                                                                                                      
{'loss': 0.3117, 'learning_rate': 0.0002051865671641791, 'epoch': 3.48}                                                                                                       
 35%|████████████████████████████████████████████▍                                                                                   | 3900/11220 [4:01:32<1:24:22,  1.45it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3098316192626953, 'eval_wer': 0.4049521723506562, 'eval_cer': 0.1322149946575214, 'eval_runtime': 299.2143, 'eval_samples_per_second': 29.036, 'eval_steps_per_second': 3.63, 'epoch': 3.48}                                                                                                                                                
{'loss': 0.3464, 'learning_rate': 0.00020490671641791044, 'epoch': 3.48}                                                                                                      
{'loss': 0.3248, 'learning_rate': 0.00020462686567164178, 'epoch': 3.49}                                                                                                      
 35%|████████████████████████████████████████████▊                                                                                   | 3927/11220 [4:06:54<2:12:24,  1.09s/it]Saving model checkpoint to ./portu_clean/checkpoint-3927
Configuration saved in ./portu_clean/checkpoint-3927/config.json
Model weights saved in ./portu_clean/checkpoint-3927/pytorch_model.bin
Feature extractor saved in ./portu_clean/checkpoint-3927/preprocessor_config.json
Deleting older checkpoint [portu_clean/checkpoint-1122] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.27, 'learning_rate': 0.0002043470149253731, 'epoch': 3.5}                                                                                                          
{'loss': 0.2588, 'learning_rate': 0.00020406716417910444, 'epoch': 3.51}                                                                                                      
{'loss': 0.3305, 'learning_rate': 0.00020378731343283582, 'epoch': 3.52}                                                                                                      
{'loss': 0.3078, 'learning_rate': 0.00020350746268656716, 'epoch': 3.53}                                                                                                      
{'loss': 0.4111, 'learning_rate': 0.0002032276119402985, 'epoch': 3.54}                                                                                                       
{'loss': 0.2756, 'learning_rate': 0.00020294776119402983, 'epoch': 3.55}                                                                                                      
{'loss': 0.3007, 'learning_rate': 0.00020266791044776117, 'epoch': 3.56}                                                                                                      
{'loss': 0.2752, 'learning_rate': 0.00020238805970149252, 'epoch': 3.56}                                                                                                      
 36%|█████████████████████████████████████████████▋                                                                                  | 4000/11220 [4:07:58<1:25:04,  1.41it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.30825352668762207, 'eval_wer': 0.40375434213453343, 'eval_cer': 0.13231790925958997, 'eval_runtime': 298.1936, 'eval_samples_per_second': 29.135, 'eval_steps_per_second': 3.642, 'epoch': 3.56}                                                                                                                                            
{'loss': 0.3084, 'learning_rate': 0.00020210820895522386, 'epoch': 3.57}                                                                                                      
{'loss': 0.3856, 'learning_rate': 0.00020182835820895523, 'epoch': 3.58}                                                                                                      
{'loss': 0.28, 'learning_rate': 0.00020154850746268655, 'epoch': 3.59}                                                                                                        
{'loss': 0.3186, 'learning_rate': 0.0002012686567164179, 'epoch': 3.6}                                                                                                        
{'loss': 0.3565, 'learning_rate': 0.00020098880597014924, 'epoch': 3.61}                                                                                                      
{'loss': 0.3535, 'learning_rate': 0.00020070895522388056, 'epoch': 3.62}                                                                                                      
{'loss': 0.3901, 'learning_rate': 0.0002004291044776119, 'epoch': 3.63}                                                                                                       
{'loss': 0.3089, 'learning_rate': 0.00020014925373134325, 'epoch': 3.64}                                                                                                      
{'loss': 0.3236, 'learning_rate': 0.00019986940298507462, 'epoch': 3.64}                                                                                                      
{'loss': 0.2957, 'learning_rate': 0.00019958955223880597, 'epoch': 3.65}                                                                                                      
 37%|██████████████████████████████████████████████▊                                                                                 | 4100/11220 [4:14:19<1:21:17,  1.46it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.2984485328197479, 'eval_wer': 0.40168380704666407, 'eval_cer': 0.13160961464535326, 'eval_runtime': 299.4935, 'eval_samples_per_second': 29.009, 'eval_steps_per_second': 3.626, 'epoch': 3.65}                                                                                                                                             
{'loss': 0.3389, 'learning_rate': 0.0001993097014925373, 'epoch': 3.66}                                                                                                       
{'loss': 0.3308, 'learning_rate': 0.00019902985074626863, 'epoch': 3.67}                                                                                                      
{'loss': 0.2891, 'learning_rate': 0.00019874999999999998, 'epoch': 3.68}                                                                                                      
{'loss': 0.286, 'learning_rate': 0.00019847014925373132, 'epoch': 3.69}                                                                                                       
{'loss': 0.3015, 'learning_rate': 0.00019819029850746264, 'epoch': 3.7}                                                                                                       
{'loss': 0.3785, 'learning_rate': 0.00019791044776119402, 'epoch': 3.71}                                                                                                      
{'loss': 0.3155, 'learning_rate': 0.00019763059701492536, 'epoch': 3.72}                                                                                                      
{'loss': 0.4588, 'learning_rate': 0.0001973507462686567, 'epoch': 3.73}                                                                                                       
{'loss': 0.3173, 'learning_rate': 0.00019707089552238805, 'epoch': 3.73}                                                                                                      
{'loss': 0.3259, 'learning_rate': 0.00019679104477611937, 'epoch': 3.74}                                                                                                      
 37%|███████████████████████████████████████████████▉                                                                                | 4200/11220 [4:20:41<1:19:59,  1.46it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.29547691345214844, 'eval_wer': 0.4004346412498503, 'eval_cer': 0.13145221584218955, 'eval_runtime': 299.6332, 'eval_samples_per_second': 28.995, 'eval_steps_per_second': 3.624, 'epoch': 3.74}                                                                                                                                             
{'loss': 0.339, 'learning_rate': 0.00019651119402985072, 'epoch': 3.75}                                                                                                       
{'loss': 0.3157, 'learning_rate': 0.0001962313432835821, 'epoch': 3.76}                                                                                                       
{'loss': 0.3181, 'learning_rate': 0.00019595149253731343, 'epoch': 3.77}                                                                                                      
{'loss': 0.3143, 'learning_rate': 0.00019567164179104475, 'epoch': 3.78}                                                                                                      
{'loss': 0.3051, 'learning_rate': 0.0001953917910447761, 'epoch': 3.79}                                                                                                       
{'loss': 0.3355, 'learning_rate': 0.00019511194029850744, 'epoch': 3.8}                                                                                                       
{'loss': 0.3261, 'learning_rate': 0.0001948320895522388, 'epoch': 3.81}                                                                                                       
{'loss': 0.2991, 'learning_rate': 0.0001945522388059701, 'epoch': 3.81}                                                                                                       
{'loss': 0.2865, 'learning_rate': 0.00019427238805970148, 'epoch': 3.82}                                                                                                      
{'loss': 0.2899, 'learning_rate': 0.00019399253731343282, 'epoch': 3.83}                                                                                                      
 38%|█████████████████████████████████████████████████                                                                               | 4300/11220 [4:27:05<1:21:19,  1.42it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.2897927463054657, 'eval_wer': 0.39459949691130924, 'eval_cer': 0.12849190758268733, 'eval_runtime': 297.7707, 'eval_samples_per_second': 29.177, 'eval_steps_per_second': 3.647, 'epoch': 3.83}                                                                                                                                             
{'loss': 0.3108, 'learning_rate': 0.00019371268656716417, 'epoch': 3.84}                                                                                                      
{'loss': 0.3868, 'learning_rate': 0.00019343283582089551, 'epoch': 3.85}                                                                                                      
{'loss': 0.2609, 'learning_rate': 0.00019315298507462683, 'epoch': 3.86}                                                                                                      
{'loss': 0.3039, 'learning_rate': 0.00019287313432835818, 'epoch': 3.87}                                                                                                      
{'loss': 0.2869, 'learning_rate': 0.00019259328358208952, 'epoch': 3.88}                                                                                                      
{'loss': 0.3197, 'learning_rate': 0.0001923134328358209, 'epoch': 3.89}                                                                                                       
{'loss': 0.3759, 'learning_rate': 0.00019203358208955224, 'epoch': 3.89}                                                                                                      
{'loss': 0.2841, 'learning_rate': 0.00019175373134328356, 'epoch': 3.9}                                                                                                       
{'loss': 0.3234, 'learning_rate': 0.0001914738805970149, 'epoch': 3.91}                                                                                                       
{'loss': 0.3013, 'learning_rate': 0.00019119402985074625, 'epoch': 3.92}                                                                                                      
 39%|██████████████████████████████████████████████████▏                                                                             | 4400/11220 [4:33:26<1:18:47,  1.44it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3074724078178406, 'eval_wer': 0.40671469395437976, 'eval_cer': 0.13166712574650924, 'eval_runtime': 297.6916, 'eval_samples_per_second': 29.185, 'eval_steps_per_second': 3.648, 'epoch': 3.92}                                                                                                                                             
{'loss': 0.3377, 'learning_rate': 0.0001909141791044776, 'epoch': 3.93}                                                                                                       
{'loss': 0.3031, 'learning_rate': 0.00019063432835820894, 'epoch': 3.94}                                                                                                      
{'loss': 0.5216, 'learning_rate': 0.00019035447761194029, 'epoch': 3.95}                                                                                                      
{'loss': 0.3251, 'learning_rate': 0.00019010261194029847, 'epoch': 3.96}                                                                                                      
{'loss': 0.3656, 'learning_rate': 0.00018982276119402985, 'epoch': 3.97}                                                                                                      
{'loss': 0.3016, 'learning_rate': 0.0001895429104477612, 'epoch': 3.97}                                                                                                       
{'loss': 0.3017, 'learning_rate': 0.00018926305970149254, 'epoch': 3.98}                                                                                                      
{'loss': 0.289, 'learning_rate': 0.00018898320895522385, 'epoch': 3.99}                                                                                                       
 40%|███████████████████████████████████████████████████▏                                                                            | 4488/11220 [4:39:33<1:04:24,  1.74it/s]Saving model checkpoint to ./portu_clean/checkpoint-4488
Configuration saved in ./portu_clean/checkpoint-4488/config.json
Model weights saved in ./portu_clean/checkpoint-4488/pytorch_model.bin
Feature extractor saved in ./portu_clean/checkpoint-4488/preprocessor_config.json
Deleting older checkpoint [portu_clean/checkpoint-1683] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3112, 'learning_rate': 0.0001887033582089552, 'epoch': 4.0}                                                                                                        
{'loss': 0.2344, 'learning_rate': 0.00018842350746268655, 'epoch': 4.01}                                                                                                      
 40%|███████████████████████████████████████████████████▎                                                                            | 4500/11220 [4:39:51<1:59:29,  1.07s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.29776135087013245, 'eval_wer': 0.3941374766850904, 'eval_cer': 0.12891567359120504, 'eval_runtime': 297.5908, 'eval_samples_per_second': 29.194, 'eval_steps_per_second': 3.649, 'epoch': 4.01}                                                                                                                                             
{'loss': 0.2442, 'learning_rate': 0.0001881436567164179, 'epoch': 4.02}                                                                                                       
{'loss': 0.2699, 'learning_rate': 0.00018786380597014926, 'epoch': 4.03}                                                                                                      
{'loss': 0.3015, 'learning_rate': 0.00018758395522388058, 'epoch': 4.04}                                                                                                      
{'loss': 0.3222, 'learning_rate': 0.00018730410447761193, 'epoch': 4.05}                                                                                                      
{'loss': 0.2306, 'learning_rate': 0.00018702425373134327, 'epoch': 4.06}                                                                                                      
{'loss': 0.236, 'learning_rate': 0.0001867444029850746, 'epoch': 4.06}                                                                                                        
{'loss': 0.2885, 'learning_rate': 0.00018646455223880594, 'epoch': 4.07}                                                                                                      
{'loss': 0.2765, 'learning_rate': 0.0001861847014925373, 'epoch': 4.08}                                                                                                       
{'loss': 0.4149, 'learning_rate': 0.00018590485074626865, 'epoch': 4.09}                                                                                                      
{'loss': 0.2454, 'learning_rate': 0.000185625, 'epoch': 4.1}                                                                                                                  
 41%|████████████████████████████████████████████████████▍                                                                           | 4600/11220 [4:46:10<1:54:42,  1.04s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.30612435936927795, 'eval_wer': 0.39287119902804635, 'eval_cer': 0.1293818162005745, 'eval_runtime': 299.8617, 'eval_samples_per_second': 28.973, 'eval_steps_per_second': 3.622, 'epoch': 4.1}                                                                                                                                              
{'loss': 0.3047, 'learning_rate': 0.00018534514925373132, 'epoch': 4.11}                                                                                                      
{'loss': 0.2852, 'learning_rate': 0.00018506529850746266, 'epoch': 4.12}                                                                                                      
{'loss': 0.3007, 'learning_rate': 0.000184785447761194, 'epoch': 4.13}                                                                                                        
{'loss': 0.3175, 'learning_rate': 0.00018450559701492535, 'epoch': 4.14}                                                                                                      
{'loss': 0.2444, 'learning_rate': 0.00018422574626865673, 'epoch': 4.14}                                                                                                      
{'loss': 0.2904, 'learning_rate': 0.00018394589552238804, 'epoch': 4.15}                                                                                                      
{'loss': 0.2765, 'learning_rate': 0.0001836660447761194, 'epoch': 4.16}                                                                                                       
{'loss': 0.327, 'learning_rate': 0.00018338619402985073, 'epoch': 4.17}                                                                                                       
{'loss': 0.3469, 'learning_rate': 0.00018310634328358208, 'epoch': 4.18}                                                                                                      
{'loss': 0.2482, 'learning_rate': 0.0001828264925373134, 'epoch': 4.19}                                                                                                       
 42%|█████████████████████████████████████████████████████▌                                                                          | 4700/11220 [4:52:32<1:57:02,  1.08s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.30011337995529175, 'eval_wer': 0.3978507503550711, 'eval_cer': 0.1328778857708455, 'eval_runtime': 298.3099, 'eval_samples_per_second': 29.124, 'eval_steps_per_second': 3.641, 'epoch': 4.19}                                                                                                                                              
{'loss': 0.2741, 'learning_rate': 0.00018254664179104474, 'epoch': 4.2}                                                                                                       
{'loss': 0.308, 'learning_rate': 0.00018229477611940296, 'epoch': 4.21}                                                                                                       
{'loss': 0.292, 'learning_rate': 0.0001820149253731343, 'epoch': 4.22}                                                                                                        
{'loss': 0.3231, 'learning_rate': 0.00018173507462686565, 'epoch': 4.22}                                                                                                      
{'loss': 0.2937, 'learning_rate': 0.00018145522388059702, 'epoch': 4.23}                                                                                                      
{'loss': 0.3036, 'learning_rate': 0.00018117537313432834, 'epoch': 4.24}                                                                                                      
{'loss': 0.2904, 'learning_rate': 0.00018089552238805968, 'epoch': 4.25}                                                                                                      
{'loss': 0.3243, 'learning_rate': 0.00018061567164179103, 'epoch': 4.26}                                                                                                      
{'loss': 0.3638, 'learning_rate': 0.00018033582089552238, 'epoch': 4.27}                                                                                                      
{'loss': 0.3013, 'learning_rate': 0.0001800559701492537, 'epoch': 4.28}                                                                                                       
 43%|██████████████████████████████████████████████████████▊                                                                         | 4800/11220 [4:58:54<1:49:10,  1.02s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.29368582367897034, 'eval_wer': 0.39278563972689473, 'eval_cer': 0.13121309073738313, 'eval_runtime': 299.5568, 'eval_samples_per_second': 29.003, 'eval_steps_per_second': 3.625, 'epoch': 4.28}                                                                                                                                            
{'loss': 0.2002, 'learning_rate': 0.00017977611940298507, 'epoch': 4.29}                                                                                                      
{'loss': 0.3183, 'learning_rate': 0.0001794962686567164, 'epoch': 4.3}                                                                                                        
{'loss': 0.279, 'learning_rate': 0.00017921641791044776, 'epoch': 4.3}                                                                                                        
{'loss': 0.3118, 'learning_rate': 0.0001789365671641791, 'epoch': 4.31}                                                                                                       
{'loss': 0.3101, 'learning_rate': 0.00017865671641791042, 'epoch': 4.32}                                                                                                      
{'loss': 0.2605, 'learning_rate': 0.00017837686567164177, 'epoch': 4.33}                                                                                                      
{'loss': 0.3248, 'learning_rate': 0.0001780970149253731, 'epoch': 4.34}                                                                                                       
{'loss': 0.3576, 'learning_rate': 0.00017781716417910448, 'epoch': 4.35}                                                                                                      
{'loss': 0.3169, 'learning_rate': 0.0001775373134328358, 'epoch': 4.36}                                                                                                       
{'loss': 0.2294, 'learning_rate': 0.00017725746268656715, 'epoch': 4.37}                                                                                                      
 44%|███████████████████████████████████████████████████████▉                                                                        | 4900/11220 [5:05:15<1:53:08,  1.07s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.28993114829063416, 'eval_wer': 0.3892605965194476, 'eval_cer': 0.1281014374748389, 'eval_runtime': 300.6293, 'eval_samples_per_second': 28.899, 'eval_steps_per_second': 3.612, 'epoch': 4.37}                                                                                                                                              
{'loss': 0.2601, 'learning_rate': 0.0001769776119402985, 'epoch': 4.38}                                                                                                       
{'loss': 0.2811, 'learning_rate': 0.00017669776119402984, 'epoch': 4.38}                                                                                                      
{'loss': 0.3536, 'learning_rate': 0.00017641791044776116, 'epoch': 4.39}                                                                                                      
{'loss': 0.3076, 'learning_rate': 0.0001761380597014925, 'epoch': 4.4}                                                                                                        
{'loss': 0.3013, 'learning_rate': 0.00017585820895522387, 'epoch': 4.41}                                                                                                      
{'loss': 0.3132, 'learning_rate': 0.00017557835820895522, 'epoch': 4.42}                                                                                                      
{'loss': 0.2843, 'learning_rate': 0.00017529850746268656, 'epoch': 4.43}                                                                                                      
{'loss': 0.3139, 'learning_rate': 0.00017501865671641788, 'epoch': 4.44}                                                                                                      
{'loss': 0.3825, 'learning_rate': 0.00017473880597014923, 'epoch': 4.45}                                                                                                      
{'loss': 0.2459, 'learning_rate': 0.00017445895522388057, 'epoch': 4.46}                                                                                                      
 45%|█████████████████████████████████████████████████████████                                                                       | 5000/11220 [5:11:38<1:48:50,  1.05s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.2803632318973541, 'eval_wer': 0.3845548349561081, 'eval_cer': 0.12672117104709554, 'eval_runtime': 300.6783, 'eval_samples_per_second': 28.895, 'eval_steps_per_second': 3.612, 'epoch': 4.46}                                                                                                                                              
{'loss': 0.2582, 'learning_rate': 0.00017417910447761195, 'epoch': 4.47}                                                                                                      
{'loss': 0.2971, 'learning_rate': 0.0001738992537313433, 'epoch': 4.47}                                                                                                       
{'loss': 0.3003, 'learning_rate': 0.0001736194029850746, 'epoch': 4.48}                                                                                                       
{'loss': 0.3603, 'learning_rate': 0.00017333955223880596, 'epoch': 4.49}                                                                                                      
 45%|█████████████████████████████████████████████████████████▌                                                                      | 5049/11220 [5:17:19<1:52:14,  1.09s/it]Saving model checkpoint to ./portu_clean/checkpoint-5049
Configuration saved in ./portu_clean/checkpoint-5049/config.json
Model weights saved in ./portu_clean/checkpoint-5049/pytorch_model.bin
Feature extractor saved in ./portu_clean/checkpoint-5049/preprocessor_config.json
Deleting older checkpoint [portu_clean/checkpoint-2244] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3095, 'learning_rate': 0.0001730597014925373, 'epoch': 4.5}                                                                                                        
{'loss': 0.2894, 'learning_rate': 0.00017277985074626865, 'epoch': 4.51}                                                                                                      
{'loss': 0.2659, 'learning_rate': 0.00017249999999999996, 'epoch': 4.52}                                                                                                      
{'loss': 0.2891, 'learning_rate': 0.00017222014925373134, 'epoch': 4.53}                                                                                                      
{'loss': 0.2692, 'learning_rate': 0.00017194029850746268, 'epoch': 4.54}                                                                                                      
{'loss': 0.2505, 'learning_rate': 0.00017166044776119403, 'epoch': 4.55}                                                                                                      
 45%|██████████████████████████████████████████████████████████▏                                                                     | 5100/11220 [5:18:05<1:49:41,  1.08s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.28538280725479126, 'eval_wer': 0.38532486866647275, 'eval_cer': 0.12853125728347828, 'eval_runtime': 299.7261, 'eval_samples_per_second': 28.986, 'eval_steps_per_second': 3.623, 'epoch': 4.55}                                                                                                                                            
{'loss': 0.2577, 'learning_rate': 0.00017138059701492535, 'epoch': 4.55}                                                                                                      
{'loss': 0.3446, 'learning_rate': 0.0001711007462686567, 'epoch': 4.56}                                                                                                       
{'loss': 0.3317, 'learning_rate': 0.00017082089552238804, 'epoch': 4.57}                                                                                                      
{'loss': 0.3329, 'learning_rate': 0.00017054104477611938, 'epoch': 4.58}                                                                                                      
{'loss': 0.2472, 'learning_rate': 0.00017026119402985075, 'epoch': 4.59}                                                                                                      
{'loss': 0.3211, 'learning_rate': 0.00017000932835820894, 'epoch': 4.6}                                                                                                       
{'loss': 0.3203, 'learning_rate': 0.00016972947761194026, 'epoch': 4.61}                                                                                                      
{'loss': 0.3636, 'learning_rate': 0.00016944962686567163, 'epoch': 4.62}                                                                                                      
{'loss': 0.3809, 'learning_rate': 0.00016916977611940298, 'epoch': 4.63}                                                                                                      
{'loss': 0.3532, 'learning_rate': 0.00016888992537313432, 'epoch': 4.63}                                                                                                      
 46%|███████████████████████████████████████████████████████████▎                                                                    | 5200/11220 [5:24:26<1:40:31,  1.00s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3038024306297302, 'eval_wer': 0.38907236605691403, 'eval_cer': 0.12893383499157007, 'eval_runtime': 298.3719, 'eval_samples_per_second': 29.118, 'eval_steps_per_second': 3.64, 'epoch': 4.63}                                                                                                                                              
{'loss': 0.3555, 'learning_rate': 0.00016861007462686564, 'epoch': 4.64}                                                                                                      
{'loss': 0.3067, 'learning_rate': 0.00016833022388059699, 'epoch': 4.65}                                                                                                      
{'loss': 0.3428, 'learning_rate': 0.00016805037313432833, 'epoch': 4.66}                                                                                                      
{'loss': 0.4099, 'learning_rate': 0.0001677705223880597, 'epoch': 4.67}                                                                                                       
{'loss': 0.3206, 'learning_rate': 0.00016749067164179105, 'epoch': 4.68}                                                                                                      
{'loss': 0.3881, 'learning_rate': 0.00016721082089552237, 'epoch': 4.69}                                                                                                      
{'loss': 0.3219, 'learning_rate': 0.0001669309701492537, 'epoch': 4.7}                                                                                                        
{'loss': 0.3763, 'learning_rate': 0.00016665111940298506, 'epoch': 4.71}                                                                                                      
{'loss': 0.4302, 'learning_rate': 0.0001663712686567164, 'epoch': 4.71}                                                                                                       
{'loss': 0.3428, 'learning_rate': 0.00016609141791044772, 'epoch': 4.72}                                                                                                      
 47%|████████████████████████████████████████████████████████████▍                                                                   | 5300/11220 [5:30:47<1:43:08,  1.05s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3551158308982849, 'eval_wer': 0.40183781378873695, 'eval_cer': 0.13660097284567954, 'eval_runtime': 301.9121, 'eval_samples_per_second': 28.777, 'eval_steps_per_second': 3.597, 'epoch': 4.72}                                                                                                                                             
{'loss': 0.3893, 'learning_rate': 0.0001658115671641791, 'epoch': 4.73}                                                                                                       
{'loss': 0.3961, 'learning_rate': 0.00016553171641791044, 'epoch': 4.74}                                                                                                      
{'loss': 0.4768, 'learning_rate': 0.00016525186567164179, 'epoch': 4.75}                                                                                                      
{'loss': 0.474, 'learning_rate': 0.00016497201492537313, 'epoch': 4.76}                                                                                                       
{'loss': 0.4665, 'learning_rate': 0.00016469216417910445, 'epoch': 4.77}                                                                                                      
{'loss': 0.4393, 'learning_rate': 0.0001644123134328358, 'epoch': 4.78}                                                                                                       
{'loss': 0.5284, 'learning_rate': 0.00016413246268656714, 'epoch': 4.79}                                                                                                      
{'loss': 0.4506, 'learning_rate': 0.0001638526119402985, 'epoch': 4.79}                                                                                                       
{'loss': 0.5703, 'learning_rate': 0.00016357276119402986, 'epoch': 4.8}                                                                                                       
{'loss': 0.3897, 'learning_rate': 0.00016329291044776118, 'epoch': 4.81}                                                                                                      
 48%|█████████████████████████████████████████████████████████████▌                                                                  | 5400/11220 [5:37:12<1:40:37,  1.04s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3621087968349457, 'eval_wer': 0.424699259056452, 'eval_cer': 0.1388802285914926, 'eval_runtime': 299.104, 'eval_samples_per_second': 29.047, 'eval_steps_per_second': 3.631, 'epoch': 4.81}                                                                                                                                                 
{'loss': 0.4014, 'learning_rate': 0.00016301305970149252, 'epoch': 4.82}                                                                                                      
{'loss': 0.4319, 'learning_rate': 0.00016273320895522387, 'epoch': 4.83}                                                                                                      
{'loss': 0.3967, 'learning_rate': 0.00016245335820895519, 'epoch': 4.84}                                                                                                      
{'loss': 0.5096, 'learning_rate': 0.00016217350746268656, 'epoch': 4.85}                                                                                                      
{'loss': 0.4168, 'learning_rate': 0.0001618936567164179, 'epoch': 4.86}                                                                                                       
{'loss': 0.4729, 'learning_rate': 0.00016161380597014925, 'epoch': 4.87}                                                                                                      
{'loss': 0.5027, 'learning_rate': 0.0001613339552238806, 'epoch': 4.87}                                                                                                       
{'loss': 0.4767, 'learning_rate': 0.0001610541044776119, 'epoch': 4.88}                                                                                                       
{'loss': 0.4188, 'learning_rate': 0.00016077425373134326, 'epoch': 4.89}                                                                                                      
{'loss': 0.3691, 'learning_rate': 0.0001604944029850746, 'epoch': 4.9}                                                                                                        
 49%|██████████████████████████████████████████████████████████████▋                                                                 | 5500/11220 [5:43:34<1:40:58,  1.06s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3477896749973297, 'eval_wer': 0.4373449237666627, 'eval_cer': 0.1479124983730412, 'eval_runtime': 312.0854, 'eval_samples_per_second': 27.839, 'eval_steps_per_second': 3.48, 'epoch': 4.9}                                                                                                                                                 
{'loss': 0.3651, 'learning_rate': 0.00016021455223880598, 'epoch': 4.91}                                                                                                      
{'loss': 0.4379, 'learning_rate': 0.00015993470149253732, 'epoch': 4.92}                                                                                                      
{'loss': 0.4953, 'learning_rate': 0.00015965485074626864, 'epoch': 4.93}                                                                                                      
{'loss': 0.5268, 'learning_rate': 0.00015937499999999998, 'epoch': 4.94}                                                                                                      
{'loss': 0.4065, 'learning_rate': 0.00015909514925373133, 'epoch': 4.95}                                                                                                      
{'loss': 0.4187, 'learning_rate': 0.00015881529850746268, 'epoch': 4.96}                                                                                                      
{'loss': 0.4533, 'learning_rate': 0.000158535447761194, 'epoch': 4.96}                                                                                                        
{'loss': 0.4628, 'learning_rate': 0.00015825559701492537, 'epoch': 4.97}                                                                                                      
{'loss': 0.4452, 'learning_rate': 0.0001579757462686567, 'epoch': 4.98}                                                                                                       
{'loss': 0.4485, 'learning_rate': 0.00015769589552238806, 'epoch': 4.99}                                                                                                      
 50%|███████████████████████████████████████████████████████████████▉                                                                | 5600/11220 [5:50:08<1:22:45,  1.13it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.39998993277549744, 'eval_wer': 0.4547134619004432, 'eval_cer': 0.14597830923416402, 'eval_runtime': 311.4487, 'eval_samples_per_second': 27.895, 'eval_steps_per_second': 3.487, 'epoch': 4.99}                                                                                                                                             
{'loss': 0.4813, 'learning_rate': 0.00015741604477611937, 'epoch': 5.0}                                                                                                       
 50%|████████████████████████████████████████████████████████████████                                                                | 5610/11220 [5:55:26<6:49:52,  4.38s/it]Saving model checkpoint to ./portu_clean/checkpoint-5610
Configuration saved in ./portu_clean/checkpoint-5610/config.json
Model weights saved in ./portu_clean/checkpoint-5610/pytorch_model.bin
Feature extractor saved in ./portu_clean/checkpoint-5610/preprocessor_config.json
Deleting older checkpoint [portu_clean/checkpoint-2805] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4112, 'learning_rate': 0.00015713619402985072, 'epoch': 5.01}                                                                                                      
{'loss': 0.3793, 'learning_rate': 0.00015685634328358207, 'epoch': 5.02}                                                                                                      
{'loss': 0.4256, 'learning_rate': 0.0001565764925373134, 'epoch': 5.03}                                                                                                       
{'loss': 0.458, 'learning_rate': 0.00015629664179104478, 'epoch': 5.04}                                                                                                       
{'loss': 0.4943, 'learning_rate': 0.0001560167910447761, 'epoch': 5.04}                                                                                                       
{'loss': 0.3343, 'learning_rate': 0.00015573694029850745, 'epoch': 5.05}                                                                                                      
{'loss': 0.3665, 'learning_rate': 0.0001554570895522388, 'epoch': 5.06}                                                                                                       
{'loss': 0.4097, 'learning_rate': 0.00015517723880597014, 'epoch': 5.07}                                                                                                      
{'loss': 0.4107, 'learning_rate': 0.00015489738805970146, 'epoch': 5.08}                                                                                                      
 51%|██████████████████████████████████████████████████████████████████                                                                | 5700/11220 [5:56:49<59:25,  1.55it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8

^CTraceback (most recent call last):██████████▏                                                                                            | 334/1086 [01:42<04:10,  3.00it/s]
  File "/home/or/Desktop/wav2vec2/main_portu.py", line 316, in <module>
    trainer.train()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1501, in train
    return inner_training_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1826, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2089, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2796, in evaluate
    output = eval_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2974, in evaluation_loop
    loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 3217, in prediction_step
    loss, outputs = self.compute_loss(model, inputs, return_outputs=True)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2540, in compute_loss
    outputs = model(**inputs)
  File "/home/or/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1693, in forward
    if labels.max() >= self.config.vocab_size:
KeyboardInterrupt
 51%|█████████████████████████████████████████████████████████████████                                                               | 5700/11220 [5:58:33<5:47:13,  3.77s/it]

(base) or@anidjar:~/Desktop/wav2vec2$ cd augmentations/
(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ ls
augmentation_script.py  band_stop  gaussian  pitch
(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
^CTraceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/augmentations/augmentation_script.py", line 28, in <module>
    x, sr = a2n.audio_from_file(fullpath)
  File "/home/or/anaconda3/lib/python3.9/site-packages/audio2numpy/loader.py", line 76, in audio_from_file
    with _audio_read(path) as input_file:
  File "/home/or/anaconda3/lib/python3.9/site-packages/audio2numpy/loader.py", line 48, in _audio_read
    return FFmpegAudioFile(path)
  File "/home/or/anaconda3/lib/python3.9/site-packages/audio2numpy/mp3dec.py", line 101, in __init__
    self.proc = popen_multiple(
  File "/home/or/anaconda3/lib/python3.9/site-packages/audio2numpy/mp3dec.py", line 30, in popen_multiple
    return subprocess.Popen(cmd, *args, **kwargs)
  File "/home/or/anaconda3/lib/python3.9/subprocess.py", line 951, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/home/or/anaconda3/lib/python3.9/subprocess.py", line 1754, in _execute_child
    self.pid = _posixsubprocess.fork_exec(
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ cd ..
(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_portu.py
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-ccbadcfb5f01c6c8
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-ccbadcfb5f01c6c8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13486.51it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2551.28it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-ccbadcfb5f01c6c8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1111.07it/s]
Using custom data configuration default-2717b34285018d3a
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-2717b34285018d3a/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17623.13it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3474.98it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-2717b34285018d3a/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1168.98it/s]
Casting the dataset:  67%|██████████████████████████████████████████████████████████████████████████████▋                                       | 2/3 [00:00<00:00, 17.09ba/s]
Casting the dataset:   0%|                                                                                                                              | 0/1 [00:00<?, ?ba/s]
/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py:310: UserWarning: Decoding mp3 with `librosa` instead of `torchaudio`, decoding is slow.
  warnings.warn("Decoding mp3 with `librosa` instead of `torchaudio`, decoding is slow.")
/home/or/anaconda3/lib/python3.9/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.
  return f(*args, **kwargs)
Traceback (most recent call last):
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 296, in _decode_mp3
    array, sampling_rate = self._decode_mp3_torchaudio(path_or_file)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 325, in _decode_mp3_torchaudio
    array, sampling_rate = torchaudio.load(path_or_file, format="mp3")
  File "/home/or/anaconda3/lib/python3.9/site-packages/torchaudio/backend/sox_io_backend.py", line 227, in load
    return _fallback_load(filepath, frame_offset, num_frames, normalize, channels_first, format)
  File "/home/or/anaconda3/lib/python3.9/site-packages/torchaudio/io/_compat.py", line 102, in load_audio
    s = torch.classes.torchaudio.ffmpeg_StreamReader(src, format, None)
RuntimeError: Failed to open the input "/home/or/Desktop/portu_dataset/clips/common_voice_pt_30412531.mp3" (No such file or directory).

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/or/anaconda3/lib/python3.9/site-packages/librosa/core/audio.py", line 164, in load
    y, sr_native = __soundfile_load(path, offset, duration, dtype)
  File "/home/or/anaconda3/lib/python3.9/site-packages/librosa/core/audio.py", line 195, in __soundfile_load
    context = sf.SoundFile(path)
  File "/home/or/anaconda3/lib/python3.9/site-packages/soundfile.py", line 655, in __init__
    self._file = self._open(file, mode_int, closefd)
  File "/home/or/anaconda3/lib/python3.9/site-packages/soundfile.py", line 1213, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening '/home/or/Desktop/portu_dataset/clips/common_voice_pt_30412531.mp3': System error.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_portu.py", line 66, in <module>
    validation['audio']
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2343, in __getitem__
    return self._getitem(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2328, in _getitem
    formatted_output = format_table(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 512, in format_table
    return formatter(pa_table, query_type)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 284, in __call__
    return self.format_column(pa_table)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 319, in format_column
    column = self.python_features_decoder.decode_column(column, pa_table.column_names[0])
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 225, in decode_column
    return self.features.decode_column(column, column_name) if self.features else column
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1811, in decode_column
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1811, in <listcomp>
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1262, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 145, in decode_example
    array, sampling_rate = self._decode_mp3(file if file else path)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 312, in _decode_mp3
    array, sampling_rate = self._decode_mp3_librosa(path_or_file)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 339, in _decode_mp3_librosa
    array, sampling_rate = librosa.load(path_or_file, mono=self.mono, sr=self.sampling_rate)
  File "/home/or/anaconda3/lib/python3.9/site-packages/librosa/util/decorators.py", line 88, in inner_f
    return f(*args, **kwargs)
  File "/home/or/anaconda3/lib/python3.9/site-packages/librosa/core/audio.py", line 170, in load
    y, sr_native = __audioread_load(path, offset, duration, dtype)
  File "/home/or/anaconda3/lib/python3.9/site-packages/librosa/core/audio.py", line 226, in __audioread_load
    reader = audioread.audio_open(path)
  File "/home/or/anaconda3/lib/python3.9/site-packages/audioread/__init__.py", line 127, in audio_open
    return BackendClass(path)
  File "/home/or/anaconda3/lib/python3.9/site-packages/audioread/rawread.py", line 59, in __init__
    self._fh = open(filename, 'rb')
FileNotFoundError: [Errno 2] No such file or directory: '/home/or/Desktop/portu_dataset/clips/common_voice_pt_30412531.mp3'
(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_portu.py
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-ccbadcfb5f01c6c8
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-ccbadcfb5f01c6c8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 567.64it/s]
Using custom data configuration default-1003b384d98054c8
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-1003b384d98054c8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17189.77it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2951.66it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-1003b384d98054c8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1251.66it/s]
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-ccbadcfb5f01c6c8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-10b63906291d4fff.arrow
Casting the dataset:   0%|                                                                                                                              | 0/1 [00:00<?, ?ba/s]
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7f01a1be2550> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28739/28739 [00:00<00:00, 39341.27ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8688/8688 [00:00<00:00, 39970.77ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'ô': 0, 'ã': 1, 'ç': 2, '9': 3, '0': 4, '3': 5, 'ú': 6, 'k': 7, 'b': 8, '4': 9, 'p': 10, 'õ': 11, 'c': 12, 'j': 13, 'é': 14, 's': 15, 'a': 16, '1': 17, 'ñ': 18, '6': 19, 'í': 20, 'u': 21, '&': 22, '\t': 23, '7': 24, '«': 25, '_': 26, 'o': 27, '8': 28, 'x': 29, 'ž': 30, 'ü': 31, 't': 32, '»': 33, '\n': 34, 'g': 35, 'â': 36, 'z': 37, '5': 38, 'd': 39, 'n': 40, 'á': 41, "'": 42, 'w': 43, '2': 44, 'ó': 45, '´': 46, 'à': 47, 'l': 48, 'q': 49, 'm': 50, 'h': 51, 'y': 52, 'e': 53, 'f': 54, 'i': 55, 'š': 56, 'ê': 57, 'r': 58, ' ': 59, 'v': 60}
Vocab_len: 63
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_pt_20647694.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/portu_dataset/augmentations/train/common_voice_pt_20647694.mp3', 'array': array([ 0.0000000e+00, -3.4555868e-14, -1.7621338e-14, ...,
       -8.3237470e-09, -1.1833374e-08, -1.2140474e-08], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/portu_dataset/augmentations/train/common_voice_pt_20647694.mp3', 'array': array([-1.4328785e-14,  1.3285492e-14,  2.1856491e-14, ...,
        9.5008987e-09,  1.4524277e-08, -9.6353014e-09], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                            | 0/7185 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                            | 0/7184 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7185/7185 [11:15<00:00, 10.64ex/s]
#2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7185/7185 [11:17<00:00, 10.60ex/s]
#0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7185/7185 [11:18<00:00, 10.60ex/s]
#3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7184/7184 [11:18<00:00, 10.59ex/s]
#0:   0%|                                                                                                                                            | 0/2172 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                            | 0/2172 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                    | 1/2172 [00:00<03:55,  9.20ex/s]
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2172/2172 [04:12<00:00,  8.61ex/s]
#2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2172/2172 [04:14<00:00,  8.53ex/s]
#3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2172/2172 [04:15<00:00,  8.52ex/s]
#0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2172/2172 [04:15<00:00,  8.50ex/s]
#3:  99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 2161/2172 [04:14<00:00, 11.99ex/s]
#3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 2165/2172 [04:14<00:00, 11.20ex/s]
----------------- Preparing datasets complete. -----------------


----------------- saving datasets... -----------------
----------------- saving datasets complete. -----------


----------------- Loading Metrics... -----------------
/home/or/Desktop/wav2vec2/main_portu.py:246: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['project_hid.bias', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_hid.weight', 'quantizer.weight_proj.bias', 'project_q.weight', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 28739
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 16
  Gradient Accumulation steps = 2
  Total optimization steps = 17960
  Number of trainable parameters = 311293119
  0%|                                                                                                                                               | 0/17960 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 19.708, 'learning_rate': 4.8e-06, 'epoch': 0.01}                                                                                                                     
{'loss': 18.0914, 'learning_rate': 1.0799999999999998e-05, 'epoch': 0.01}                                                                                                     
{'loss': 20.8975, 'learning_rate': 1.6199999999999997e-05, 'epoch': 0.02}                                                                                                     
{'loss': 24.9466, 'learning_rate': 2.1599999999999996e-05, 'epoch': 0.02}                                                                                                     
{'loss': 27.4718, 'learning_rate': 2.7599999999999997e-05, 'epoch': 0.03}                                                                                                     
{'loss': 16.7455, 'learning_rate': 3.36e-05, 'epoch': 0.03}                                                                                                                   
{'loss': 13.19, 'learning_rate': 3.96e-05, 'epoch': 0.04}                                                                                                                     
{'loss': 10.5175, 'learning_rate': 4.56e-05, 'epoch': 0.04}                                                                                                                   
{'loss': 9.2042, 'learning_rate': 5.1599999999999994e-05, 'epoch': 0.05}                                                                                                      
{'loss': 7.6113, 'learning_rate': 5.76e-05, 'epoch': 0.06}                                                                                                                    
  1%|▋                                                                                                                                  | 100/17960 [01:23<2:08:42,  2.31it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 5.099483489990234, 'eval_wer': 1.0, 'eval_cer': 0.9991100913821128, 'eval_runtime': 296.9869, 'eval_samples_per_second': 29.254, 'eval_steps_per_second': 3.657, 'epoch': 0.06}                                                                                                                                                               
{'loss': 4.7893, 'learning_rate': 6.359999999999999e-05, 'epoch': 0.06}                                                                                                       
{'loss': 4.3459, 'learning_rate': 6.96e-05, 'epoch': 0.07}                                                                                                                    
{'loss': 3.8779, 'learning_rate': 7.56e-05, 'epoch': 0.07}                                                                                                                    
{'loss': 3.8886, 'learning_rate': 8.16e-05, 'epoch': 0.08}                                                                                                                    
{'loss': 3.7174, 'learning_rate': 8.759999999999999e-05, 'epoch': 0.08}                                                                                                       
{'loss': 3.2445, 'learning_rate': 9.36e-05, 'epoch': 0.09}                                                                                                                    
{'loss': 3.2365, 'learning_rate': 9.96e-05, 'epoch': 0.09}                                                                                                                    
{'loss': 3.1756, 'learning_rate': 0.00010559999999999998, 'epoch': 0.1}                                                                                                       
{'loss': 3.2089, 'learning_rate': 0.00011159999999999999, 'epoch': 0.11}                                                                                                      
{'loss': 3.3758, 'learning_rate': 0.0001176, 'epoch': 0.11}                                                                                                                   
  1%|█▍                                                                                                                                 | 200/17960 [07:38<2:04:42,  2.37it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 3.1580820083618164, 'eval_wer': 1.0, 'eval_cer': 0.9991100913821128, 'eval_runtime': 293.255, 'eval_samples_per_second': 29.626, 'eval_steps_per_second': 3.703, 'epoch': 0.11}                                                                                                                                                               
{'loss': 3.0733, 'learning_rate': 0.0001236, 'epoch': 0.12}                                                                                                                   
{'loss': 3.0232, 'learning_rate': 0.00012959999999999998, 'epoch': 0.12}                                                                                                      
{'loss': 3.138, 'learning_rate': 0.0001356, 'epoch': 0.13}                                                                                                                    
{'loss': 3.1581, 'learning_rate': 0.00014159999999999997, 'epoch': 0.13}                                                                                                      
{'loss': 3.2657, 'learning_rate': 0.00014759999999999998, 'epoch': 0.14}                                                                                                      
{'loss': 3.0555, 'learning_rate': 0.0001536, 'epoch': 0.14}                                                                                                                   
{'loss': 3.0684, 'learning_rate': 0.0001596, 'epoch': 0.15}                                                                                                                   
{'loss': 3.0418, 'learning_rate': 0.0001656, 'epoch': 0.16}                                                                                                                   
{'loss': 3.0968, 'learning_rate': 0.00017159999999999997, 'epoch': 0.16}                                                                                                      
{'loss': 3.2777, 'learning_rate': 0.00017759999999999998, 'epoch': 0.17}                                                                                                      
  2%|██▏                                                                                                                                | 300/17960 [13:50<2:17:55,  2.13it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 3.0927021503448486, 'eval_wer': 1.0, 'eval_cer': 0.9991100913821128, 'eval_runtime': 292.5193, 'eval_samples_per_second': 29.701, 'eval_steps_per_second': 3.713, 'epoch': 0.17}                                                                                                                                                              
{'loss': 3.7417, 'learning_rate': 0.00018299999999999998, 'epoch': 0.17}                                                                                                      
{'loss': 3.0398, 'learning_rate': 0.00018899999999999999, 'epoch': 0.18}                                                                                                      
{'loss': 3.0809, 'learning_rate': 0.000195, 'epoch': 0.18}                                                                                                                    
{'loss': 3.1821, 'learning_rate': 0.000201, 'epoch': 0.19}                                                                                                                    
{'loss': 3.3295, 'learning_rate': 0.00020639999999999998, 'epoch': 0.19}                                                                                                      
{'loss': 3.0124, 'learning_rate': 0.00021239999999999996, 'epoch': 0.2}                                                                                                       
{'loss': 2.9794, 'learning_rate': 0.00021839999999999997, 'epoch': 0.21}                                                                                                      
{'loss': 3.0328, 'learning_rate': 0.00022439999999999998, 'epoch': 0.21}                                                                                                      
{'loss': 3.0802, 'learning_rate': 0.0002304, 'epoch': 0.22}                                                                                                                   
{'loss': 3.1791, 'learning_rate': 0.0002364, 'epoch': 0.22}                                                                                                                   
  2%|██▉                                                                                                                                | 400/17960 [20:01<2:09:59,  2.25it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 3.0507266521453857, 'eval_wer': 1.0, 'eval_cer': 0.9991100913821128, 'eval_runtime': 293.9415, 'eval_samples_per_second': 29.557, 'eval_steps_per_second': 3.695, 'epoch': 0.22}                                                                                                                                                              
{'loss': 2.9606, 'learning_rate': 0.00024239999999999998, 'epoch': 0.23}                                                                                                      
{'loss': 2.984, 'learning_rate': 0.00024839999999999997, 'epoch': 0.23}                                                                                                       
{'loss': 3.0378, 'learning_rate': 0.00025439999999999995, 'epoch': 0.24}                                                                                                      
{'loss': 3.0338, 'learning_rate': 0.0002604, 'epoch': 0.24}                                                                                                                   
{'loss': 3.1484, 'learning_rate': 0.00026639999999999997, 'epoch': 0.25}                                                                                                      
{'loss': 2.9671, 'learning_rate': 0.0002724, 'epoch': 0.26}                                                                                                                   
{'loss': 2.9769, 'learning_rate': 0.0002784, 'epoch': 0.26}                                                                                                                   
{'loss': 2.9944, 'learning_rate': 0.0002844, 'epoch': 0.27}                                                                                                                   
{'loss': 3.0676, 'learning_rate': 0.00029039999999999996, 'epoch': 0.27}                                                                                                      
{'loss': 3.1576, 'learning_rate': 0.0002964, 'epoch': 0.28}                                                                                                                   
  3%|███▋                                                                                                                               | 500/17960 [26:14<2:08:58,  2.26it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 3.096207857131958, 'eval_wer': 1.0, 'eval_cer': 0.9991100913821128, 'eval_runtime': 294.6857, 'eval_samples_per_second': 29.482, 'eval_steps_per_second': 3.685, 'epoch': 0.28}                                                                                                                                                               
{'loss': 2.9981, 'learning_rate': 0.0002999312714776632, 'epoch': 0.28}                                                                                                       
{'loss': 2.98, 'learning_rate': 0.0002997594501718213, 'epoch': 0.29}                                                                                                         
{'loss': 2.9848, 'learning_rate': 0.00029958762886597934, 'epoch': 0.3}                                                                                                       
{'loss': 3.0575, 'learning_rate': 0.00029941580756013745, 'epoch': 0.3}                                                                                                       
{'loss': 3.0665, 'learning_rate': 0.0002992439862542955, 'epoch': 0.31}                                                                                                       
{'loss': 2.9695, 'learning_rate': 0.0002990721649484536, 'epoch': 0.31}                                                                                                       
{'loss': 2.9655, 'learning_rate': 0.00029890034364261166, 'epoch': 0.32}                                                                                                      
{'loss': 2.9317, 'learning_rate': 0.00029872852233676976, 'epoch': 0.32}                                                                                                      
{'loss': 2.9407, 'learning_rate': 0.0002985567010309278, 'epoch': 0.33}                                                                                                       
{'loss': 2.9727, 'learning_rate': 0.00029838487972508586, 'epoch': 0.33}                                                                                                      
  3%|████▍                                                                                                                              | 600/17960 [32:27<2:13:47,  2.16it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 2.974810838699341, 'eval_wer': 1.0, 'eval_cer': 0.9991100913821128, 'eval_runtime': 294.1792, 'eval_samples_per_second': 29.533, 'eval_steps_per_second': 3.692, 'epoch': 0.33}                                                                                                                                                               
{'loss': 2.9354, 'learning_rate': 0.00029821305841924397, 'epoch': 0.34}                                                                                                      
{'loss': 2.9203, 'learning_rate': 0.000298041237113402, 'epoch': 0.35}                                                                                                        
{'loss': 2.9285, 'learning_rate': 0.0002978694158075601, 'epoch': 0.35}                                                                                                       
{'loss': 2.9128, 'learning_rate': 0.0002976975945017182, 'epoch': 0.36}                                                                                                       
{'loss': 2.9518, 'learning_rate': 0.0002975257731958763, 'epoch': 0.36}                                                                                                       
{'loss': 2.9898, 'learning_rate': 0.00029735395189003434, 'epoch': 0.37}                                                                                                      
{'loss': 2.9276, 'learning_rate': 0.00029718213058419244, 'epoch': 0.37}                                                                                                      
{'loss': 2.9102, 'learning_rate': 0.0002970103092783505, 'epoch': 0.38}                                                                                                       
{'loss': 2.9195, 'learning_rate': 0.0002968384879725086, 'epoch': 0.38}                                                                                                       
{'loss': 2.9265, 'learning_rate': 0.00029666666666666665, 'epoch': 0.39}                                                                                                      
  4%|█████                                                                                                                              | 700/17960 [38:40<2:09:29,  2.22it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 2.9285290241241455, 'eval_wer': 1.0, 'eval_cer': 0.9991100913821128, 'eval_runtime': 293.136, 'eval_samples_per_second': 29.638, 'eval_steps_per_second': 3.705, 'epoch': 0.39}                                                                                                                                                               
{'loss': 2.9188, 'learning_rate': 0.00029649484536082476, 'epoch': 0.4}                                                                                                       
{'loss': 2.8897, 'learning_rate': 0.0002963230240549828, 'epoch': 0.4}                                                                                                        
{'loss': 2.8973, 'learning_rate': 0.00029615120274914086, 'epoch': 0.41}                                                                                                      
{'loss': 2.9246, 'learning_rate': 0.00029597938144329896, 'epoch': 0.41}                                                                                                      
{'loss': 2.9278, 'learning_rate': 0.000295807560137457, 'epoch': 0.42}                                                                                                        
{'loss': 2.9397, 'learning_rate': 0.0002956357388316151, 'epoch': 0.42}                                                                                                       
{'loss': 2.9185, 'learning_rate': 0.00029546391752577317, 'epoch': 0.43}                                                                                                      
{'loss': 2.9805, 'learning_rate': 0.00029530927835051544, 'epoch': 0.43}                                                                                                      
{'loss': 2.8949, 'learning_rate': 0.0002951374570446735, 'epoch': 0.44}                                                                                                       
{'loss': 2.9076, 'learning_rate': 0.0002949656357388316, 'epoch': 0.45}                                                                                                       
  4%|█████▊                                                                                                                             | 800/17960 [44:51<2:06:57,  2.25it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 2.9642679691314697, 'eval_wer': 1.0, 'eval_cer': 0.9991100913821128, 'eval_runtime': 293.9205, 'eval_samples_per_second': 29.559, 'eval_steps_per_second': 3.695, 'epoch': 0.45}                                                                                                                                                              
{'loss': 2.9245, 'learning_rate': 0.00029479381443298964, 'epoch': 0.45}                                                                                                      
{'loss': 2.8763, 'learning_rate': 0.00029462199312714775, 'epoch': 0.46}                                                                                                      
{'loss': 2.8464, 'learning_rate': 0.0002944501718213058, 'epoch': 0.46}                                                                                                       
{'loss': 2.8034, 'learning_rate': 0.00029427835051546385, 'epoch': 0.47}                                                                                                      
{'loss': 2.8541, 'learning_rate': 0.00029410652920962196, 'epoch': 0.47}                                                                                                      
{'loss': 2.8179, 'learning_rate': 0.00029393470790378, 'epoch': 0.48}                                                                                                         
{'loss': 2.6983, 'learning_rate': 0.0002937628865979381, 'epoch': 0.48}                                                                                                       
{'loss': 2.5998, 'learning_rate': 0.00029359106529209617, 'epoch': 0.49}                                                                                                      
{'loss': 2.4692, 'learning_rate': 0.00029341924398625427, 'epoch': 0.5}                                                                                                       
{'loss': 2.5201, 'learning_rate': 0.0002932474226804123, 'epoch': 0.5}                                                                                                        
  5%|██████▌                                                                                                                            | 900/17960 [51:04<2:06:49,  2.24it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 2.246835708618164, 'eval_wer': 0.9912729512825339, 'eval_cer': 0.8531953470492265, 'eval_runtime': 297.1392, 'eval_samples_per_second': 29.239, 'eval_steps_per_second': 3.655, 'epoch': 0.5}                                                                                                                                                 
{'loss': 2.413, 'learning_rate': 0.00029307560137457043, 'epoch': 0.51}                                                                                                       
{'loss': 2.2295, 'learning_rate': 0.0002929037800687285, 'epoch': 0.51}                                                                                                       
{'loss': 2.0461, 'learning_rate': 0.0002927319587628866, 'epoch': 0.52}                                                                                                       
{'loss': 2.115, 'learning_rate': 0.00029256013745704464, 'epoch': 0.52}                                                                                                       
{'loss': 2.1183, 'learning_rate': 0.0002923883161512027, 'epoch': 0.53}                                                                                                       
{'loss': 1.89, 'learning_rate': 0.0002922164948453608, 'epoch': 0.53}                                                                                                         
{'loss': 1.7787, 'learning_rate': 0.00029204467353951885, 'epoch': 0.54}                                                                                                      
{'loss': 1.7387, 'learning_rate': 0.00029187285223367695, 'epoch': 0.55}                                                                                                      
{'loss': 1.6443, 'learning_rate': 0.000291701030927835, 'epoch': 0.55}                                                                                                        
{'loss': 1.9553, 'learning_rate': 0.0002915292096219931, 'epoch': 0.56}                                                                                                       
  6%|███████▏                                                                                                                          | 1000/17960 [57:19<2:01:51,  2.32it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 1.5086588859558105, 'eval_wer': 0.9991615188487141, 'eval_cer': 0.4737219671218115, 'eval_runtime': 294.9719, 'eval_samples_per_second': 29.454, 'eval_steps_per_second': 3.682, 'epoch': 0.56}                                                                                                                                               
{'loss': 1.6422, 'learning_rate': 0.00029135738831615116, 'epoch': 0.56}                                                                                                      
{'loss': 1.6437, 'learning_rate': 0.00029118556701030927, 'epoch': 0.57}                                                                                                      
{'loss': 1.6076, 'learning_rate': 0.0002910137457044673, 'epoch': 0.57}                                                                                                       
{'loss': 1.6547, 'learning_rate': 0.0002908419243986254, 'epoch': 0.58}                                                                                                       
{'loss': 1.6075, 'learning_rate': 0.0002906701030927835, 'epoch': 0.58}                                                                                                       
{'loss': 1.5106, 'learning_rate': 0.0002904982817869416, 'epoch': 0.59}                                                                                                       
{'loss': 1.5005, 'learning_rate': 0.00029032646048109963, 'epoch': 0.6}                                                                                                       
{'loss': 1.4959, 'learning_rate': 0.0002901546391752577, 'epoch': 0.6}                                                                                                        
{'loss': 1.4628, 'learning_rate': 0.0002899828178694158, 'epoch': 0.61}                                                                                                       
{'loss': 1.655, 'learning_rate': 0.00028981099656357384, 'epoch': 0.61}                                                                                                       
  6%|███████▊                                                                                                                        | 1100/17960 [1:03:33<2:00:58,  2.32it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 1.1795200109481812, 'eval_wer': 0.9780797070449528, 'eval_cer': 0.4088312836175088, 'eval_runtime': 295.0098, 'eval_samples_per_second': 29.45, 'eval_steps_per_second': 3.681, 'epoch': 0.61}                                                                                                                                                
{'loss': 1.412, 'learning_rate': 0.00028963917525773195, 'epoch': 0.62}                                                                                                       
{'loss': 1.3082, 'learning_rate': 0.00028946735395189, 'epoch': 0.62}                                                                                                         
{'loss': 1.314, 'learning_rate': 0.0002892955326460481, 'epoch': 0.63}                                                                                                        
{'loss': 1.2859, 'learning_rate': 0.00028912371134020616, 'epoch': 0.63}                                                                                                      
{'loss': 1.4965, 'learning_rate': 0.00028895189003436426, 'epoch': 0.64}                                                                                                      
{'loss': 1.2674, 'learning_rate': 0.0002887800687285223, 'epoch': 0.65}                                                                                                       
{'loss': 1.3475, 'learning_rate': 0.0002886254295532646, 'epoch': 0.65}                                                                                                       
{'loss': 1.2804, 'learning_rate': 0.0002884536082474227, 'epoch': 0.66}                                                                                                       
{'loss': 1.1987, 'learning_rate': 0.00028828178694158073, 'epoch': 0.66}                                                                                                      
{'loss': 1.398, 'learning_rate': 0.00028810996563573884, 'epoch': 0.67}                                                                                                       
  7%|████████▌                                                                                                                       | 1200/17960 [1:09:48<2:06:46,  2.20it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 1.0799620151519775, 'eval_wer': 0.9356594055339756, 'eval_cer': 0.37178202687281875, 'eval_runtime': 296.5238, 'eval_samples_per_second': 29.3, 'eval_steps_per_second': 3.662, 'epoch': 0.67}                                                                                                                                                
{'loss': 1.2136, 'learning_rate': 0.0002879381443298969, 'epoch': 0.67}                                                                                                       
{'loss': 1.1847, 'learning_rate': 0.00028776632302405494, 'epoch': 0.68}                                                                                                      
{'loss': 1.2437, 'learning_rate': 0.00028759450171821305, 'epoch': 0.68}                                                                                                      
{'loss': 1.1976, 'learning_rate': 0.0002874226804123711, 'epoch': 0.69}                                                                                                       
{'loss': 1.2893, 'learning_rate': 0.0002872508591065292, 'epoch': 0.7}                                                                                                        
{'loss': 1.1556, 'learning_rate': 0.00028707903780068726, 'epoch': 0.7}                                                                                                       
{'loss': 1.1909, 'learning_rate': 0.00028690721649484536, 'epoch': 0.71}                                                                                                      
{'loss': 1.2094, 'learning_rate': 0.0002867353951890034, 'epoch': 0.71}                                                                                                       
{'loss': 1.211, 'learning_rate': 0.0002865635738831615, 'epoch': 0.72}                                                                                                        
{'loss': 1.3406, 'learning_rate': 0.00028639175257731957, 'epoch': 0.72}                                                                                                      
  7%|█████████▎                                                                                                                      | 1300/17960 [1:16:03<2:05:59,  2.20it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.8716369867324829, 'eval_wer': 0.8455996851417718, 'eval_cer': 0.30976084462619297, 'eval_runtime': 296.9953, 'eval_samples_per_second': 29.253, 'eval_steps_per_second': 3.657, 'epoch': 0.72}                                                                                                                                              
{'loss': 1.1296, 'learning_rate': 0.0002862199312714777, 'epoch': 0.73}                                                                                                       
{'loss': 1.1261, 'learning_rate': 0.00028604810996563573, 'epoch': 0.73}                                                                                                      
{'loss': 1.126, 'learning_rate': 0.0002858762886597938, 'epoch': 0.74}                                                                                                        
{'loss': 1.1219, 'learning_rate': 0.00028570446735395183, 'epoch': 0.75}                                                                                                      
{'loss': 1.3087, 'learning_rate': 0.00028553264604810994, 'epoch': 0.75}                                                                                                      
{'loss': 1.2476, 'learning_rate': 0.000285360824742268, 'epoch': 0.76}                                                                                                        
{'loss': 1.2007, 'learning_rate': 0.0002851890034364261, 'epoch': 0.76}                                                                                                       
{'loss': 1.0883, 'learning_rate': 0.00028501718213058415, 'epoch': 0.77}                                                                                                      
{'loss': 1.2209, 'learning_rate': 0.00028484536082474225, 'epoch': 0.77}                                                                                                      
{'loss': 1.4638, 'learning_rate': 0.0002846735395189003, 'epoch': 0.78}                                                                                                       
  8%|█████████▉                                                                                                                      | 1400/17960 [1:22:19<1:59:36,  2.31it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.7934753894805908, 'eval_wer': 0.8068926573007752, 'eval_cer': 0.28282748788483253, 'eval_runtime': 298.196, 'eval_samples_per_second': 29.135, 'eval_steps_per_second': 3.642, 'epoch': 0.78}                                                                                                                                               
{'loss': 1.193, 'learning_rate': 0.0002845017182130584, 'epoch': 0.78}                                                                                                        
{'loss': 1.1961, 'learning_rate': 0.00028432989690721646, 'epoch': 0.79}                                                                                                      
{'loss': 1.0319, 'learning_rate': 0.0002841580756013745, 'epoch': 0.8}                                                                                                        
{'loss': 1.1089, 'learning_rate': 0.0002839862542955326, 'epoch': 0.8}                                                                                                        
{'loss': 1.2836, 'learning_rate': 0.00028381443298969067, 'epoch': 0.81}                                                                                                      
{'loss': 0.959, 'learning_rate': 0.0002836426116838488, 'epoch': 0.81}                                                                                                        
{'loss': 0.9345, 'learning_rate': 0.0002834707903780068, 'epoch': 0.82}                                                                                                       
{'loss': 0.9969, 'learning_rate': 0.00028329896907216493, 'epoch': 0.82}                                                                                                      
{'loss': 0.9209, 'learning_rate': 0.000283127147766323, 'epoch': 0.83}                                                                                                        
{'loss': 1.2734, 'learning_rate': 0.0002829553264604811, 'epoch': 0.83}                                                                                                       
  8%|██████████▋                                                                                                                     | 1500/17960 [1:28:37<2:02:14,  2.24it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.7051019072532654, 'eval_wer': 0.7584660928489536, 'eval_cer': 0.26082192444252067, 'eval_runtime': 297.3243, 'eval_samples_per_second': 29.221, 'eval_steps_per_second': 3.653, 'epoch': 0.83}                                                                                                                                              
{'loss': 0.9607, 'learning_rate': 0.00028278350515463914, 'epoch': 0.84}                                                                                                      
{'loss': 1.0024, 'learning_rate': 0.00028261168384879725, 'epoch': 0.85}                                                                                                      
{'loss': 1.0576, 'learning_rate': 0.0002824398625429553, 'epoch': 0.85}                                                                                                       
{'loss': 0.9149, 'learning_rate': 0.00028226804123711335, 'epoch': 0.86}                                                                                                      
{'loss': 1.1648, 'learning_rate': 0.00028209621993127145, 'epoch': 0.86}                                                                                                      
{'loss': 1.0591, 'learning_rate': 0.0002819243986254295, 'epoch': 0.87}                                                                                                       
{'loss': 0.856, 'learning_rate': 0.0002817525773195876, 'epoch': 0.87}                                                                                                        
{'loss': 0.9755, 'learning_rate': 0.00028158075601374566, 'epoch': 0.88}                                                                                                      
{'loss': 0.9978, 'learning_rate': 0.00028140893470790377, 'epoch': 0.89}                                                                                                      
{'loss': 1.2406, 'learning_rate': 0.0002812371134020618, 'epoch': 0.89}                                                                                                       
  9%|███████████▍                                                                                                                    | 1600/17960 [1:34:53<2:01:36,  2.24it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.6649057865142822, 'eval_wer': 0.7169013843494927, 'eval_cer': 0.24231243057047985, 'eval_runtime': 297.4967, 'eval_samples_per_second': 29.204, 'eval_steps_per_second': 3.65, 'epoch': 0.89}                                                                                                                                               
{'loss': 0.8601, 'learning_rate': 0.0002810652920962199, 'epoch': 0.9}                                                                                                        
{'loss': 0.8265, 'learning_rate': 0.000280893470790378, 'epoch': 0.9}                                                                                                         
{'loss': 0.9973, 'learning_rate': 0.0002807216494845361, 'epoch': 0.91}                                                                                                       
{'loss': 1.006, 'learning_rate': 0.00028054982817869413, 'epoch': 0.91}                                                                                                       
{'loss': 1.0226, 'learning_rate': 0.0002803780068728522, 'epoch': 0.92}                                                                                                       
{'loss': 0.7732, 'learning_rate': 0.0002802061855670103, 'epoch': 0.92}                                                                                                       
{'loss': 0.8871, 'learning_rate': 0.00028003436426116834, 'epoch': 0.93}                                                                                                      
{'loss': 0.9166, 'learning_rate': 0.00027986254295532645, 'epoch': 0.94}                                                                                                      
{'loss': 0.9717, 'learning_rate': 0.0002796907216494845, 'epoch': 0.94}                                                                                                       
{'loss': 1.2079, 'learning_rate': 0.0002795189003436426, 'epoch': 0.95}                                                                                                       
  9%|████████████                                                                                                                    | 1700/17960 [1:41:10<2:02:01,  2.22it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.6086789965629578, 'eval_wer': 0.6950666506955971, 'eval_cer': 0.22450517751255405, 'eval_runtime': 297.3114, 'eval_samples_per_second': 29.222, 'eval_steps_per_second': 3.653, 'epoch': 0.95}                                                                                                                                              
{'loss': 1.1949, 'learning_rate': 0.00027934707903780066, 'epoch': 0.95}                                                                                                      
{'loss': 0.7949, 'learning_rate': 0.00027917525773195876, 'epoch': 0.96}                                                                                                      
{'loss': 0.8202, 'learning_rate': 0.0002790034364261168, 'epoch': 0.96}                                                                                                       
{'loss': 0.9316, 'learning_rate': 0.0002788316151202749, 'epoch': 0.97}                                                                                                       
{'loss': 1.1548, 'learning_rate': 0.00027865979381443297, 'epoch': 0.97}                                                                                                      
{'loss': 0.8723, 'learning_rate': 0.000278487972508591, 'epoch': 0.98}                                                                                                        
{'loss': 0.7966, 'learning_rate': 0.00027831615120274913, 'epoch': 0.99}                                                                                                      
{'loss': 0.8663, 'learning_rate': 0.0002781443298969072, 'epoch': 0.99}                                                                                                       
{'loss': 0.8947, 'learning_rate': 0.0002779725085910653, 'epoch': 1.0}                                                                                                        
 10%|████████████▊                                                                                                                   | 1796/17960 [1:47:24<2:03:49,  2.18it/s]Saving model checkpoint to ./portu_augmented/checkpoint-1796
Configuration saved in ./portu_augmented/checkpoint-1796/config.json
Model weights saved in ./portu_augmented/checkpoint-1796/pytorch_model.bin
Feature extractor saved in ./portu_augmented/checkpoint-1796/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 1.1086, 'learning_rate': 0.00027780068728522334, 'epoch': 1.0}                                                                                                       
 10%|████████████▊                                                                                                                   | 1800/17960 [1:47:32<6:34:46,  1.47s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.5857778787612915, 'eval_wer': 0.6598162186211263, 'eval_cer': 0.22047334663151427, 'eval_runtime': 296.1742, 'eval_samples_per_second': 29.334, 'eval_steps_per_second': 3.667, 'epoch': 1.0}                                                                                                                                               
{'loss': 0.7461, 'learning_rate': 0.00027762886597938144, 'epoch': 1.01}                                                                                                      
{'loss': 0.8217, 'learning_rate': 0.0002774570446735395, 'epoch': 1.01}                                                                                                       
{'loss': 0.8106, 'learning_rate': 0.0002772852233676976, 'epoch': 1.02}                                                                                                       
{'loss': 0.9647, 'learning_rate': 0.00027711340206185565, 'epoch': 1.02}                                                                                                      
{'loss': 1.0785, 'learning_rate': 0.00027694158075601376, 'epoch': 1.03}                                                                                                      
{'loss': 0.7217, 'learning_rate': 0.0002767697594501718, 'epoch': 1.04}                                                                                                       
{'loss': 0.7279, 'learning_rate': 0.0002765979381443299, 'epoch': 1.04}                                                                                                       
{'loss': 0.7745, 'learning_rate': 0.0002764261168384879, 'epoch': 1.05}                                                                                                       
{'loss': 1.015, 'learning_rate': 0.000276254295532646, 'epoch': 1.05}                                                                                                         
{'loss': 0.9749, 'learning_rate': 0.00027608247422680407, 'epoch': 1.06}                                                                                                      
 11%|█████████████▌                                                                                                                  | 1900/17960 [1:53:48<5:10:59,  1.16s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.5236507654190063, 'eval_wer': 0.6077619398004757, 'eval_cer': 0.19961195141220023, 'eval_runtime': 299.1428, 'eval_samples_per_second': 29.043, 'eval_steps_per_second': 3.63, 'epoch': 1.06}                                                                                                                                               
{'loss': 0.7031, 'learning_rate': 0.0002759106529209622, 'epoch': 1.06}                                                                                                       
{'loss': 0.8085, 'learning_rate': 0.0002757388316151202, 'epoch': 1.07}                                                                                                       
{'loss': 0.8426, 'learning_rate': 0.00027556701030927833, 'epoch': 1.07}                                                                                                      
{'loss': 0.8276, 'learning_rate': 0.0002753951890034364, 'epoch': 1.08}                                                                                                       
{'loss': 0.8493, 'learning_rate': 0.0002752233676975945, 'epoch': 1.09}                                                                                                       
{'loss': 0.7512, 'learning_rate': 0.00027505154639175254, 'epoch': 1.09}                                                                                                      
{'loss': 0.7761, 'learning_rate': 0.0002748797250859106, 'epoch': 1.1}                                                                                                        
{'loss': 0.7669, 'learning_rate': 0.0002747079037800687, 'epoch': 1.1}                                                                                                        
{'loss': 0.8996, 'learning_rate': 0.00027453608247422675, 'epoch': 1.11}                                                                                                      
{'loss': 0.9772, 'learning_rate': 0.00027436426116838486, 'epoch': 1.11}                                                                                                      
 11%|██████████████▎                                                                                                                 | 2000/17960 [2:00:06<4:57:49,  1.12s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.504855751991272, 'eval_wer': 0.5966563425109944, 'eval_cer': 0.19552866323012613, 'eval_runtime': 297.3221, 'eval_samples_per_second': 29.221, 'eval_steps_per_second': 3.653, 'epoch': 1.11}                                                                                                                                               
{'loss': 0.7117, 'learning_rate': 0.0002741924398625429, 'epoch': 1.12}                                                                                                       
{'loss': 0.84, 'learning_rate': 0.000274020618556701, 'epoch': 1.12}                                                                                                          
{'loss': 0.7766, 'learning_rate': 0.00027384879725085906, 'epoch': 1.13}                                                                                                      
{'loss': 0.8991, 'learning_rate': 0.00027367697594501717, 'epoch': 1.14}                                                                                                      
{'loss': 0.9914, 'learning_rate': 0.0002735051546391752, 'epoch': 1.14}                                                                                                       
{'loss': 0.751, 'learning_rate': 0.00027333333333333333, 'epoch': 1.15}                                                                                                       
{'loss': 0.6736, 'learning_rate': 0.0002731615120274914, 'epoch': 1.15}                                                                                                       
{'loss': 0.7203, 'learning_rate': 0.00027298969072164943, 'epoch': 1.16}                                                                                                      
{'loss': 0.7994, 'learning_rate': 0.00027281786941580754, 'epoch': 1.16}                                                                                                      
{'loss': 0.9446, 'learning_rate': 0.0002726460481099656, 'epoch': 1.17}                                                                                                       
 12%|██████████████▉                                                                                                                 | 2100/17960 [2:06:23<5:05:44,  1.16s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.49169254302978516, 'eval_wer': 0.5867999110183268, 'eval_cer': 0.19541969482793586, 'eval_runtime': 297.0757, 'eval_samples_per_second': 29.245, 'eval_steps_per_second': 3.656, 'epoch': 1.17}                                                                                                                                             
{'loss': 0.6288, 'learning_rate': 0.0002724742268041237, 'epoch': 1.17}                                                                                                       
{'loss': 0.7047, 'learning_rate': 0.00027230240549828174, 'epoch': 1.18}                                                                                                      
{'loss': 0.7946, 'learning_rate': 0.00027213058419243985, 'epoch': 1.19}                                                                                                      
{'loss': 0.8418, 'learning_rate': 0.0002719587628865979, 'epoch': 1.19}                                                                                                       
{'loss': 0.9464, 'learning_rate': 0.000271786941580756, 'epoch': 1.2}                                                                                                         
{'loss': 0.6846, 'learning_rate': 0.00027161512027491406, 'epoch': 1.2}                                                                                                       
{'loss': 0.6163, 'learning_rate': 0.00027144329896907216, 'epoch': 1.21}                                                                                                      
{'loss': 0.7424, 'learning_rate': 0.0002712714776632302, 'epoch': 1.21}                                                                                                       
{'loss': 0.7782, 'learning_rate': 0.0002710996563573883, 'epoch': 1.22}                                                                                                       
{'loss': 1.0112, 'learning_rate': 0.0002709278350515464, 'epoch': 1.22}                                                                                                       
 12%|███████████████▋                                                                                                                | 2200/17960 [2:12:40<4:58:10,  1.14s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.4696911871433258, 'eval_wer': 0.5786033299680008, 'eval_cer': 0.18997127471842262, 'eval_runtime': 298.2006, 'eval_samples_per_second': 29.135, 'eval_steps_per_second': 3.642, 'epoch': 1.22}                                                                                                                                              
{'loss': 0.717, 'learning_rate': 0.0002707560137457044, 'epoch': 1.23}                                                                                                        
{'loss': 0.6106, 'learning_rate': 0.00027058419243986253, 'epoch': 1.24}                                                                                                      
{'loss': 0.7323, 'learning_rate': 0.0002704123711340206, 'epoch': 1.24}                                                                                                       
{'loss': 0.8689, 'learning_rate': 0.0002702405498281787, 'epoch': 1.25}                                                                                                       
{'loss': 0.8788, 'learning_rate': 0.00027006872852233674, 'epoch': 1.25}                                                                                                      
{'loss': 0.6545, 'learning_rate': 0.00026989690721649485, 'epoch': 1.26}                                                                                                      
{'loss': 0.6855, 'learning_rate': 0.0002697250859106529, 'epoch': 1.26}                                                                                                       
{'loss': 0.7605, 'learning_rate': 0.000269553264604811, 'epoch': 1.27}                                                                                                        
{'loss': 0.8389, 'learning_rate': 0.00026938144329896905, 'epoch': 1.27}                                                                                                      
{'loss': 0.7724, 'learning_rate': 0.00026920962199312716, 'epoch': 1.28}                                                                                                      
 13%|████████████████▍                                                                                                               | 2300/17960 [2:18:59<5:08:16,  1.18s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.4847060739994049, 'eval_wer': 0.5691746949810914, 'eval_cer': 0.18669919575265384, 'eval_runtime': 297.4064, 'eval_samples_per_second': 29.213, 'eval_steps_per_second': 3.652, 'epoch': 1.28}                                                                                                                                              
{'loss': 0.6405, 'learning_rate': 0.0002690378006872852, 'epoch': 1.29}                                                                                                       
{'loss': 0.6653, 'learning_rate': 0.00026886597938144326, 'epoch': 1.29}                                                                                                      
{'loss': 0.6309, 'learning_rate': 0.00026869415807560137, 'epoch': 1.3}                                                                                                       
{'loss': 0.8421, 'learning_rate': 0.00026853951890034363, 'epoch': 1.3}                                                                                                       
{'loss': 0.8977, 'learning_rate': 0.0002683676975945017, 'epoch': 1.31}                                                                                                       
{'loss': 0.6628, 'learning_rate': 0.0002681958762886598, 'epoch': 1.31}                                                                                                       
{'loss': 0.576, 'learning_rate': 0.00026802405498281784, 'epoch': 1.32}                                                                                                       
{'loss': 0.5992, 'learning_rate': 0.00026785223367697595, 'epoch': 1.33}                                                                                                      
{'loss': 0.8547, 'learning_rate': 0.000267680412371134, 'epoch': 1.33}                                                                                                        
{'loss': 0.8349, 'learning_rate': 0.0002675085910652921, 'epoch': 1.34}                                                                                                       
 13%|█████████████████                                                                                                               | 2400/17960 [2:25:17<4:58:05,  1.15s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.4474007785320282, 'eval_wer': 0.5371584044901522, 'eval_cer': 0.18235559416534744, 'eval_runtime': 299.6525, 'eval_samples_per_second': 28.994, 'eval_steps_per_second': 3.624, 'epoch': 1.34}                                                                                                                                              
{'loss': 0.6266, 'learning_rate': 0.00026733676975945015, 'epoch': 1.34}                                                                                                      
{'loss': 0.614, 'learning_rate': 0.0002671649484536082, 'epoch': 1.35}                                                                                                        
{'loss': 0.7675, 'learning_rate': 0.00026699312714776626, 'epoch': 1.35}                                                                                                      
{'loss': 0.6906, 'learning_rate': 0.00026682130584192436, 'epoch': 1.36}                                                                                                      
{'loss': 0.8875, 'learning_rate': 0.0002666494845360824, 'epoch': 1.36}                                                                                                       
{'loss': 0.6901, 'learning_rate': 0.0002664776632302405, 'epoch': 1.37}                                                                                                       
{'loss': 0.7202, 'learning_rate': 0.00026630584192439857, 'epoch': 1.38}                                                                                                      
{'loss': 0.6605, 'learning_rate': 0.0002661340206185567, 'epoch': 1.38}                                                                                                       
{'loss': 0.7451, 'learning_rate': 0.00026596219931271473, 'epoch': 1.39}                                                                                                      
{'loss': 0.9725, 'learning_rate': 0.00026579037800687283, 'epoch': 1.39}                                                                                                      
 14%|█████████████████▊                                                                                                              | 2500/17960 [2:31:36<4:55:57,  1.15s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.4416368901729584, 'eval_wer': 0.5489484761888465, 'eval_cer': 0.18547935502813503, 'eval_runtime': 299.1156, 'eval_samples_per_second': 29.046, 'eval_steps_per_second': 3.631, 'epoch': 1.39}                                                                                                                                              
{'loss': 0.6353, 'learning_rate': 0.0002656185567010309, 'epoch': 1.4}                                                                                                        
{'loss': 0.6458, 'learning_rate': 0.000265446735395189, 'epoch': 1.4}                                                                                                         
{'loss': 0.6168, 'learning_rate': 0.00026527491408934704, 'epoch': 1.41}                                                                                                      
{'loss': 0.8004, 'learning_rate': 0.00026510309278350515, 'epoch': 1.41}                                                                                                      
{'loss': 0.9208, 'learning_rate': 0.0002649312714776632, 'epoch': 1.42}                                                                                                       
{'loss': 0.6542, 'learning_rate': 0.00026475945017182125, 'epoch': 1.43}                                                                                                      
{'loss': 0.5868, 'learning_rate': 0.00026458762886597936, 'epoch': 1.43}                                                                                                      
{'loss': 0.6913, 'learning_rate': 0.0002644158075601374, 'epoch': 1.44}                                                                                                       
{'loss': 0.7859, 'learning_rate': 0.0002642439862542955, 'epoch': 1.44}                                                                                                       
{'loss': 1.1363, 'learning_rate': 0.00026407216494845357, 'epoch': 1.45}                                                                                                      
 14%|██████████████████▌                                                                                                             | 2600/17960 [2:37:55<5:00:36,  1.17s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.42625197768211365, 'eval_wer': 0.5399305258474649, 'eval_cer': 0.17797264287725012, 'eval_runtime': 298.2647, 'eval_samples_per_second': 29.128, 'eval_steps_per_second': 3.641, 'epoch': 1.45}                                                                                                                                             
{'loss': 0.6128, 'learning_rate': 0.00026390034364261167, 'epoch': 1.45}                                                                                                      
{'loss': 0.6087, 'learning_rate': 0.0002637285223367697, 'epoch': 1.46}                                                                                                       
{'loss': 0.6784, 'learning_rate': 0.00026355670103092783, 'epoch': 1.46}                                                                                                      
{'loss': 0.6779, 'learning_rate': 0.0002633848797250859, 'epoch': 1.47}                                                                                                       
{'loss': 0.8252, 'learning_rate': 0.000263213058419244, 'epoch': 1.48}                                                                                                        
{'loss': 0.6289, 'learning_rate': 0.00026304123711340204, 'epoch': 1.48}                                                                                                      
{'loss': 0.6221, 'learning_rate': 0.0002628694158075601, 'epoch': 1.49}                                                                                                       
{'loss': 0.6531, 'learning_rate': 0.0002626975945017182, 'epoch': 1.49}                                                                                                       
{'loss': 0.7321, 'learning_rate': 0.00026252577319587625, 'epoch': 1.5}                                                                                                       
{'loss': 0.9026, 'learning_rate': 0.00026235395189003435, 'epoch': 1.5}                                                                                                       
 15%|███████████████████▏                                                                                                            | 2700/17960 [2:44:12<4:50:52,  1.14s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.40248027443885803, 'eval_wer': 0.5222026386488475, 'eval_cer': 0.17093812713585635, 'eval_runtime': 297.2233, 'eval_samples_per_second': 29.231, 'eval_steps_per_second': 3.654, 'epoch': 1.5}                                                                                                                                              
{'loss': 0.5113, 'learning_rate': 0.0002621821305841924, 'epoch': 1.51}                                                                                                       
{'loss': 0.6181, 'learning_rate': 0.0002620103092783505, 'epoch': 1.51}                                                                                                       
{'loss': 0.6989, 'learning_rate': 0.00026183848797250856, 'epoch': 1.52}                                                                                                      
{'loss': 0.6409, 'learning_rate': 0.00026166666666666667, 'epoch': 1.53}                                                                                                      
{'loss': 0.7085, 'learning_rate': 0.0002614948453608247, 'epoch': 1.53}                                                                                                       
{'loss': 0.5739, 'learning_rate': 0.0002613230240549828, 'epoch': 1.54}                                                                                                       
{'loss': 0.5812, 'learning_rate': 0.0002611512027491409, 'epoch': 1.54}                                                                                                       
{'loss': 0.6588, 'learning_rate': 0.0002609793814432989, 'epoch': 1.55}                                                                                                       
{'loss': 0.6957, 'learning_rate': 0.00026080756013745703, 'epoch': 1.55}                                                                                                      
{'loss': 0.9248, 'learning_rate': 0.0002606357388316151, 'epoch': 1.56}                                                                                                       
 16%|███████████████████▉                                                                                                            | 2800/17960 [2:50:29<4:45:33,  1.13s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.4043298065662384, 'eval_wer': 0.5098649874227827, 'eval_cer': 0.1671696365601097, 'eval_runtime': 298.8353, 'eval_samples_per_second': 29.073, 'eval_steps_per_second': 3.634, 'epoch': 1.56}                                                                                                                                               
{'loss': 0.557, 'learning_rate': 0.0002604639175257732, 'epoch': 1.56}                                                                                                        
{'loss': 0.5829, 'learning_rate': 0.00026029209621993124, 'epoch': 1.57}                                                                                                      
{'loss': 0.5718, 'learning_rate': 0.00026012027491408935, 'epoch': 1.58}                                                                                                      
{'loss': 0.7086, 'learning_rate': 0.0002599484536082474, 'epoch': 1.58}                                                                                                       
{'loss': 0.8273, 'learning_rate': 0.0002597766323024055, 'epoch': 1.59}                                                                                                       
{'loss': 0.5672, 'learning_rate': 0.00025960481099656356, 'epoch': 1.59}                                                                                                      
{'loss': 0.519, 'learning_rate': 0.00025943298969072166, 'epoch': 1.6}                                                                                                        
{'loss': 0.6511, 'learning_rate': 0.0002592611683848797, 'epoch': 1.6}                                                                                                        
{'loss': 0.7246, 'learning_rate': 0.00025908934707903776, 'epoch': 1.61}                                                                                                      
{'loss': 0.8604, 'learning_rate': 0.00025891752577319587, 'epoch': 1.61}                                                                                                      
 16%|████████████████████▋                                                                                                           | 2900/17960 [2:56:48<4:42:27,  1.13s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.4000125527381897, 'eval_wer': 0.5221855267886172, 'eval_cer': 0.1697001250109725, 'eval_runtime': 298.7576, 'eval_samples_per_second': 29.08, 'eval_steps_per_second': 3.635, 'epoch': 1.61}                                                                                                                                                
{'loss': 0.5939, 'learning_rate': 0.0002587457044673539, 'epoch': 1.62}                                                                                                       
{'loss': 0.6041, 'learning_rate': 0.000258573883161512, 'epoch': 1.63}                                                                                                        
{'loss': 0.6531, 'learning_rate': 0.0002584020618556701, 'epoch': 1.63}                                                                                                       
{'loss': 0.703, 'learning_rate': 0.0002582302405498282, 'epoch': 1.64}                                                                                                        
{'loss': 0.7975, 'learning_rate': 0.00025805841924398624, 'epoch': 1.64}                                                                                                      
{'loss': 0.5248, 'learning_rate': 0.00025788659793814434, 'epoch': 1.65}                                                                                                      
{'loss': 0.5472, 'learning_rate': 0.0002577147766323024, 'epoch': 1.65}                                                                                                       
{'loss': 0.557, 'learning_rate': 0.00025754295532646044, 'epoch': 1.66}                                                                                                       
{'loss': 0.6387, 'learning_rate': 0.0002573711340206185, 'epoch': 1.66}                                                                                                       
{'loss': 0.7605, 'learning_rate': 0.0002571993127147766, 'epoch': 1.67}                                                                                                       
 17%|█████████████████████▍                                                                                                          | 3000/17960 [3:03:07<4:55:37,  1.19s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.38280773162841797, 'eval_wer': 0.4947723266996355, 'eval_cer': 0.16078590433179668, 'eval_runtime': 301.0718, 'eval_samples_per_second': 28.857, 'eval_steps_per_second': 3.607, 'epoch': 1.67}                                                                                                                                             
{'loss': 0.586, 'learning_rate': 0.00025702749140893465, 'epoch': 1.68}                                                                                                       
{'loss': 0.646, 'learning_rate': 0.00025685567010309276, 'epoch': 1.68}                                                                                                       
{'loss': 0.5939, 'learning_rate': 0.0002566838487972508, 'epoch': 1.69}                                                                                                       
{'loss': 0.6686, 'learning_rate': 0.0002565120274914089, 'epoch': 1.69}                                                                                                       
{'loss': 0.7808, 'learning_rate': 0.00025634020618556697, 'epoch': 1.7}                                                                                                       
{'loss': 0.5537, 'learning_rate': 0.0002561683848797251, 'epoch': 1.7}                                                                                                        
{'loss': 0.5934, 'learning_rate': 0.0002559965635738831, 'epoch': 1.71}                                                                                                       
{'loss': 0.5376, 'learning_rate': 0.00025582474226804123, 'epoch': 1.71}                                                                                                      
{'loss': 0.7335, 'learning_rate': 0.0002556529209621993, 'epoch': 1.72}                                                                                                       
{'loss': 0.7583, 'learning_rate': 0.00025548109965635733, 'epoch': 1.73}                                                                                                      
 17%|██████████████████████                                                                                                          | 3100/17960 [3:09:28<4:47:44,  1.16s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.399339497089386, 'eval_wer': 0.5049538835366792, 'eval_cer': 0.16672165535110528, 'eval_runtime': 299.6623, 'eval_samples_per_second': 28.993, 'eval_steps_per_second': 3.624, 'epoch': 1.73}                                                                                                                                               
{'loss': 0.5231, 'learning_rate': 0.00025530927835051544, 'epoch': 1.73}                                                                                                      
{'loss': 0.5427, 'learning_rate': 0.0002551374570446735, 'epoch': 1.74}                                                                                                       
{'loss': 0.6177, 'learning_rate': 0.0002549656357388316, 'epoch': 1.74}                                                                                                       
{'loss': 0.6533, 'learning_rate': 0.00025479381443298965, 'epoch': 1.75}                                                                                                      
{'loss': 0.8172, 'learning_rate': 0.00025462199312714775, 'epoch': 1.75}                                                                                                      
{'loss': 0.6927, 'learning_rate': 0.0002544501718213058, 'epoch': 1.76}                                                                                                       
{'loss': 0.562, 'learning_rate': 0.00025429553264604807, 'epoch': 1.76}                                                                                                       
{'loss': 0.5855, 'learning_rate': 0.0002541237113402062, 'epoch': 1.77}                                                                                                       
{'loss': 0.6667, 'learning_rate': 0.0002539518900343642, 'epoch': 1.78}                                                                                                       
{'loss': 0.7946, 'learning_rate': 0.00025378006872852233, 'epoch': 1.78}                                                                                                      
 18%|██████████████████████▊                                                                                                         | 3200/17960 [3:15:46<4:45:05,  1.16s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3770580589771271, 'eval_wer': 0.5055356867845103, 'eval_cer': 0.16483589661320153, 'eval_runtime': 298.7769, 'eval_samples_per_second': 29.079, 'eval_steps_per_second': 3.635, 'epoch': 1.78}                                                                                                                                              
{'loss': 0.5045, 'learning_rate': 0.0002536082474226804, 'epoch': 1.79}                                                                                                       
{'loss': 0.5793, 'learning_rate': 0.0002534364261168385, 'epoch': 1.79}                                                                                                       
{'loss': 0.5618, 'learning_rate': 0.00025326460481099654, 'epoch': 1.8}                                                                                                       
{'loss': 0.5976, 'learning_rate': 0.0002530927835051546, 'epoch': 1.8}                                                                                                        
{'loss': 0.794, 'learning_rate': 0.0002529209621993127, 'epoch': 1.81}                                                                                                        
{'loss': 0.4822, 'learning_rate': 0.00025274914089347075, 'epoch': 1.81}                                                                                                      
{'loss': 0.5528, 'learning_rate': 0.00025257731958762885, 'epoch': 1.82}                                                                                                      
{'loss': 0.6051, 'learning_rate': 0.0002524054982817869, 'epoch': 1.83}                                                                                                       
{'loss': 0.6228, 'learning_rate': 0.000252233676975945, 'epoch': 1.83}                                                                                                        
{'loss': 0.721, 'learning_rate': 0.00025206185567010306, 'epoch': 1.84}                                                                                                       
 18%|███████████████████████▌                                                                                                        | 3300/17960 [3:22:06<4:47:16,  1.18s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3854995369911194, 'eval_wer': 0.4835469463885419, 'eval_cer': 0.15777111187119935, 'eval_runtime': 298.2551, 'eval_samples_per_second': 29.129, 'eval_steps_per_second': 3.641, 'epoch': 1.84}                                                                                                                                              
{'loss': 0.5006, 'learning_rate': 0.00025189003436426117, 'epoch': 1.84}                                                                                                      
{'loss': 0.5531, 'learning_rate': 0.0002517182130584192, 'epoch': 1.85}                                                                                                       
{'loss': 0.5267, 'learning_rate': 0.0002515463917525773, 'epoch': 1.85}                                                                                                       
{'loss': 0.617, 'learning_rate': 0.0002513745704467354, 'epoch': 1.86}                                                                                                        
{'loss': 0.7164, 'learning_rate': 0.0002512027491408935, 'epoch': 1.87}                                                                                                       
{'loss': 0.4917, 'learning_rate': 0.00025103092783505153, 'epoch': 1.87}                                                                                                      
{'loss': 0.5553, 'learning_rate': 0.0002508762886597938, 'epoch': 1.88}                                                                                                       
{'loss': 0.5813, 'learning_rate': 0.0002507044673539519, 'epoch': 1.88}                                                                                                       
{'loss': 0.6424, 'learning_rate': 0.00025053264604810995, 'epoch': 1.89}                                                                                                      
{'loss': 0.7608, 'learning_rate': 0.000250360824742268, 'epoch': 1.89}                                                                                                        
 19%|████████████████████████▏                                                                                                       | 3400/17960 [3:28:24<4:32:08,  1.12s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.37337976694107056, 'eval_wer': 0.4836838412703845, 'eval_cer': 0.16025014302102789, 'eval_runtime': 300.6238, 'eval_samples_per_second': 28.9, 'eval_steps_per_second': 3.612, 'epoch': 1.89}                                                                                                                                               
{'loss': 0.6783, 'learning_rate': 0.0002501890034364261, 'epoch': 1.9}                                                                                                        
{'loss': 0.542, 'learning_rate': 0.00025001718213058416, 'epoch': 1.9}                                                                                                        
{'loss': 0.6667, 'learning_rate': 0.00024984536082474227, 'epoch': 1.91}                                                                                                      
{'loss': 0.6771, 'learning_rate': 0.0002496735395189003, 'epoch': 1.92}                                                                                                       
{'loss': 0.761, 'learning_rate': 0.0002495017182130584, 'epoch': 1.92}                                                                                                        
{'loss': 0.5381, 'learning_rate': 0.0002493298969072165, 'epoch': 1.93}                                                                                                       
{'loss': 0.5045, 'learning_rate': 0.0002491580756013746, 'epoch': 1.93}                                                                                                       
{'loss': 0.4707, 'learning_rate': 0.00024898625429553263, 'epoch': 1.94}                                                                                                      
{'loss': 0.6132, 'learning_rate': 0.00024881443298969074, 'epoch': 1.94}                                                                                                      
{'loss': 0.6735, 'learning_rate': 0.0002486426116838488, 'epoch': 1.95}                                                                                                       
 19%|████████████████████████▉                                                                                                       | 3500/17960 [3:34:45<4:41:31,  1.17s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3660033345222473, 'eval_wer': 0.47177398655007785, 'eval_cer': 0.15699925235568496, 'eval_runtime': 300.103, 'eval_samples_per_second': 28.95, 'eval_steps_per_second': 3.619, 'epoch': 1.95}                                                                                                                                               
{'loss': 0.4451, 'learning_rate': 0.00024847079037800684, 'epoch': 1.95}                                                                                                      
{'loss': 0.6228, 'learning_rate': 0.0002482989690721649, 'epoch': 1.96}                                                                                                       
{'loss': 0.6209, 'learning_rate': 0.000248127147766323, 'epoch': 1.97}                                                                                                        
{'loss': 0.5952, 'learning_rate': 0.00024795532646048105, 'epoch': 1.97}                                                                                                      
{'loss': 0.9958, 'learning_rate': 0.00024778350515463916, 'epoch': 1.98}                                                                                                      
{'loss': 0.4702, 'learning_rate': 0.0002476116838487972, 'epoch': 1.98}                                                                                                       
{'loss': 0.4886, 'learning_rate': 0.0002474398625429553, 'epoch': 1.99}                                                                                                       
{'loss': 0.6284, 'learning_rate': 0.00024726804123711337, 'epoch': 1.99}                                                                                                      
{'loss': 0.7105, 'learning_rate': 0.00024709621993127147, 'epoch': 2.0}                                                                                                       
 20%|█████████████████████████▌                                                                                                      | 3592/17960 [3:40:55<1:50:52,  2.16it/s]Saving model checkpoint to ./portu_augmented/checkpoint-3592
Configuration saved in ./portu_augmented/checkpoint-3592/config.json
Model weights saved in ./portu_augmented/checkpoint-3592/pytorch_model.bin
Feature extractor saved in ./portu_augmented/checkpoint-3592/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.6794, 'learning_rate': 0.0002469243986254295, 'epoch': 2.0}                                                                                                        
 20%|█████████████████████████▋                                                                                                      | 3600/17960 [3:41:08<4:43:30,  1.18s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.35653698444366455, 'eval_wer': 0.47203066445353276, 'eval_cer': 0.156808557651852, 'eval_runtime': 299.858, 'eval_samples_per_second': 28.974, 'eval_steps_per_second': 3.622, 'epoch': 2.0}                                                                                                                                                
{'loss': 0.4294, 'learning_rate': 0.0002467525773195876, 'epoch': 2.01}                                                                                                       
{'loss': 0.4307, 'learning_rate': 0.0002465807560137457, 'epoch': 2.02}                                                                                                       
{'loss': 0.5002, 'learning_rate': 0.00024640893470790373, 'epoch': 2.02}                                                                                                      
{'loss': 0.7454, 'learning_rate': 0.00024623711340206184, 'epoch': 2.03}                                                                                                      
{'loss': 0.5151, 'learning_rate': 0.0002460652920962199, 'epoch': 2.03}                                                                                                       
{'loss': 0.4686, 'learning_rate': 0.000245893470790378, 'epoch': 2.04}                                                                                                        
{'loss': 0.4839, 'learning_rate': 0.00024572164948453605, 'epoch': 2.04}                                                                                                      
{'loss': 0.5319, 'learning_rate': 0.00024554982817869415, 'epoch': 2.05}                                                                                                      
{'loss': 0.6414, 'learning_rate': 0.0002453780068728522, 'epoch': 2.05}                                                                                                       
{'loss': 0.5282, 'learning_rate': 0.0002452061855670103, 'epoch': 2.06}                                                                                                       
 21%|██████████████████████████▎                                                                                                     | 3700/17960 [3:47:27<4:30:33,  1.14s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3593939542770386, 'eval_wer': 0.46770136381526034, 'eval_cer': 0.15274948467026464, 'eval_runtime': 298.8324, 'eval_samples_per_second': 29.073, 'eval_steps_per_second': 3.634, 'epoch': 2.06}                                                                                                                                             
{'loss': 0.4998, 'learning_rate': 0.00024503436426116836, 'epoch': 2.07}                                                                                                      
{'loss': 0.4659, 'learning_rate': 0.0002448625429553264, 'epoch': 2.07}                                                                                                       
{'loss': 0.5215, 'learning_rate': 0.0002446907216494845, 'epoch': 2.08}                                                                                                       
{'loss': 0.6904, 'learning_rate': 0.00024451890034364257, 'epoch': 2.08}                                                                                                      
{'loss': 0.5716, 'learning_rate': 0.0002443470790378007, 'epoch': 2.09}                                                                                                       
{'loss': 0.4002, 'learning_rate': 0.0002441752577319587, 'epoch': 2.09}                                                                                                       
{'loss': 0.4853, 'learning_rate': 0.0002440034364261168, 'epoch': 2.1}                                                                                                        
{'loss': 0.5559, 'learning_rate': 0.00024383161512027488, 'epoch': 2.1}                                                                                                       
{'loss': 0.6634, 'learning_rate': 0.00024365979381443296, 'epoch': 2.11}                                                                                                      
{'loss': 0.5985, 'learning_rate': 0.00024348797250859104, 'epoch': 2.12}                                                                                                      
 21%|███████████████████████████                                                                                                     | 3800/17960 [3:53:47<4:27:28,  1.13s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.34242576360702515, 'eval_wer': 0.4539605400503089, 'eval_cer': 0.1495772934065036, 'eval_runtime': 300.7729, 'eval_samples_per_second': 28.886, 'eval_steps_per_second': 3.611, 'epoch': 2.12}                                                                                                                                              
{'loss': 0.4004, 'learning_rate': 0.00024331615120274912, 'epoch': 2.12}                                                                                                      
{'loss': 0.4842, 'learning_rate': 0.0002431443298969072, 'epoch': 2.13}                                                                                                       
{'loss': 0.5473, 'learning_rate': 0.00024297250859106528, 'epoch': 2.13}                                                                                                      
{'loss': 0.5602, 'learning_rate': 0.00024280068728522335, 'epoch': 2.14}                                                                                                      
{'loss': 0.5049, 'learning_rate': 0.00024262886597938143, 'epoch': 2.14}                                                                                                      
{'loss': 0.604, 'learning_rate': 0.0002424570446735395, 'epoch': 2.15}                                                                                                        
{'loss': 0.4376, 'learning_rate': 0.0002422852233676976, 'epoch': 2.15}                                                                                                       
{'loss': 0.4964, 'learning_rate': 0.00024211340206185564, 'epoch': 2.16}                                                                                                      
{'loss': 0.5993, 'learning_rate': 0.00024194158075601372, 'epoch': 2.17}                                                                                                      
{'loss': 0.5205, 'learning_rate': 0.0002417697594501718, 'epoch': 2.17}                                                                                                       
 22%|███████████████████████████▊                                                                                                    | 3900/17960 [4:00:08<4:13:17,  1.08s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.34631213545799255, 'eval_wer': 0.4515819914782936, 'eval_cer': 0.149607562407112, 'eval_runtime': 298.8967, 'eval_samples_per_second': 29.067, 'eval_steps_per_second': 3.633, 'epoch': 2.17}                                                                                                                                               
{'loss': 0.4831, 'learning_rate': 0.0002416151202749141, 'epoch': 2.18}                                                                                                       
{'loss': 0.5657, 'learning_rate': 0.00024144329896907214, 'epoch': 2.18}                                                                                                      
{'loss': 0.6421, 'learning_rate': 0.00024127147766323022, 'epoch': 2.19}                                                                                                      
{'loss': 0.6579, 'learning_rate': 0.0002410996563573883, 'epoch': 2.19}                                                                                                       
{'loss': 0.4746, 'learning_rate': 0.00024092783505154638, 'epoch': 2.2}                                                                                                       
{'loss': 0.3864, 'learning_rate': 0.00024075601374570445, 'epoch': 2.2}                                                                                                       
{'loss': 0.3731, 'learning_rate': 0.00024058419243986253, 'epoch': 2.21}                                                                                                      
{'loss': 0.4906, 'learning_rate': 0.0002404123711340206, 'epoch': 2.22}                                                                                                       
{'loss': 0.5682, 'learning_rate': 0.0002402405498281787, 'epoch': 2.22}                                                                                                       
{'loss': 0.4899, 'learning_rate': 0.00024006872852233677, 'epoch': 2.23}                                                                                                      
 22%|████████████████████████████▌                                                                                                   | 4000/17960 [4:06:26<4:33:07,  1.17s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.34269487857818604, 'eval_wer': 0.45483324492205546, 'eval_cer': 0.15070330022913633, 'eval_runtime': 299.4182, 'eval_samples_per_second': 29.016, 'eval_steps_per_second': 3.627, 'epoch': 2.23}                                                                                                                                            
{'loss': 0.4417, 'learning_rate': 0.00023989690721649485, 'epoch': 2.23}                                                                                                      
{'loss': 0.4446, 'learning_rate': 0.00023972508591065293, 'epoch': 2.24}                                                                                                      
{'loss': 0.4584, 'learning_rate': 0.00023955326460481098, 'epoch': 2.24}                                                                                                      
{'loss': 0.6376, 'learning_rate': 0.00023938144329896906, 'epoch': 2.25}                                                                                                      
{'loss': 0.4996, 'learning_rate': 0.00023920962199312714, 'epoch': 2.25}                                                                                                      
{'loss': 0.4167, 'learning_rate': 0.0002390378006872852, 'epoch': 2.26}                                                                                                       
{'loss': 0.5154, 'learning_rate': 0.00023886597938144327, 'epoch': 2.27}                                                                                                      
{'loss': 0.4955, 'learning_rate': 0.00023869415807560134, 'epoch': 2.27}                                                                                                      
{'loss': 0.7413, 'learning_rate': 0.00023852233676975942, 'epoch': 2.28}                                                                                                      
{'loss': 0.5736, 'learning_rate': 0.0002383505154639175, 'epoch': 2.28}                                                                                                       
 23%|█████████████████████████████▏                                                                                                  | 4100/17960 [4:12:46<4:28:13,  1.16s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3313271403312683, 'eval_wer': 0.45021304265986756, 'eval_cer': 0.1469529710537547, 'eval_runtime': 299.7467, 'eval_samples_per_second': 28.984, 'eval_steps_per_second': 3.623, 'epoch': 2.28}                                                                                                                                              
{'loss': 0.4235, 'learning_rate': 0.00023817869415807558, 'epoch': 2.29}                                                                                                      
{'loss': 0.449, 'learning_rate': 0.00023800687285223363, 'epoch': 2.29}                                                                                                       
{'loss': 0.4996, 'learning_rate': 0.0002378350515463917, 'epoch': 2.3}                                                                                                        
{'loss': 0.6175, 'learning_rate': 0.0002376632302405498, 'epoch': 2.31}                                                                                                       
{'loss': 0.5228, 'learning_rate': 0.00023749140893470787, 'epoch': 2.31}                                                                                                      
{'loss': 0.4153, 'learning_rate': 0.00023731958762886595, 'epoch': 2.32}                                                                                                      
{'loss': 0.4611, 'learning_rate': 0.00023714776632302402, 'epoch': 2.32}                                                                                                      
{'loss': 0.564, 'learning_rate': 0.0002369759450171821, 'epoch': 2.33}                                                                                                        
{'loss': 0.6158, 'learning_rate': 0.00023680412371134018, 'epoch': 2.33}                                                                                                      
{'loss': 0.5776, 'learning_rate': 0.00023663230240549826, 'epoch': 2.34}                                                                                                      
 23%|█████████████████████████████▉                                                                                                  | 4200/17960 [4:19:07<4:18:18,  1.13s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.33735862374305725, 'eval_wer': 0.4454388336556067, 'eval_cer': 0.14925341509999365, 'eval_runtime': 300.4045, 'eval_samples_per_second': 28.921, 'eval_steps_per_second': 3.615, 'epoch': 2.34}                                                                                                                                             
{'loss': 0.4252, 'learning_rate': 0.00023646048109965634, 'epoch': 2.34}                                                                                                      
{'loss': 0.5478, 'learning_rate': 0.00023628865979381442, 'epoch': 2.35}                                                                                                      
{'loss': 0.4939, 'learning_rate': 0.00023611683848797247, 'epoch': 2.36}                                                                                                      
{'loss': 0.6068, 'learning_rate': 0.00023594501718213055, 'epoch': 2.36}                                                                                                      
{'loss': 0.5138, 'learning_rate': 0.00023577319587628863, 'epoch': 2.37}                                                                                                      
{'loss': 0.4054, 'learning_rate': 0.0002356013745704467, 'epoch': 2.37}                                                                                                       
{'loss': 0.4573, 'learning_rate': 0.00023542955326460478, 'epoch': 2.38}                                                                                                      
{'loss': 0.5039, 'learning_rate': 0.00023525773195876286, 'epoch': 2.38}                                                                                                      
{'loss': 0.5824, 'learning_rate': 0.00023508591065292094, 'epoch': 2.39}                                                                                                      
{'loss': 0.6966, 'learning_rate': 0.00023491408934707902, 'epoch': 2.39}                                                                                                      
 24%|██████████████████████████████▋                                                                                                 | 4300/17960 [4:25:28<4:14:41,  1.12s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.331378310918808, 'eval_wer': 0.44747514502301544, 'eval_cer': 0.1500010594150213, 'eval_runtime': 299.0982, 'eval_samples_per_second': 29.047, 'eval_steps_per_second': 3.631, 'epoch': 2.39}                                                                                                                                               
{'loss': 0.4677, 'learning_rate': 0.0002347422680412371, 'epoch': 2.4}                                                                                                        
{'loss': 0.4866, 'learning_rate': 0.00023457044673539518, 'epoch': 2.41}                                                                                                      
{'loss': 0.4253, 'learning_rate': 0.00023439862542955325, 'epoch': 2.41}                                                                                                      
{'loss': 0.59, 'learning_rate': 0.00023422680412371133, 'epoch': 2.42}                                                                                                        
{'loss': 0.594, 'learning_rate': 0.00023405498281786938, 'epoch': 2.42}                                                                                                       
{'loss': 0.4496, 'learning_rate': 0.00023388316151202746, 'epoch': 2.43}                                                                                                      
{'loss': 0.4257, 'learning_rate': 0.00023371134020618554, 'epoch': 2.43}                                                                                                      
{'loss': 0.4856, 'learning_rate': 0.00023353951890034362, 'epoch': 2.44}                                                                                                      
{'loss': 0.6172, 'learning_rate': 0.0002333676975945017, 'epoch': 2.44}                                                                                                       
{'loss': 0.4612, 'learning_rate': 0.00023319587628865978, 'epoch': 2.45}                                                                                                      
 24%|███████████████████████████████▎                                                                                                | 4400/17960 [4:31:46<4:10:36,  1.11s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.34089788794517517, 'eval_wer': 0.4496654631324971, 'eval_cer': 0.15130565334124363, 'eval_runtime': 298.7098, 'eval_samples_per_second': 29.085, 'eval_steps_per_second': 3.636, 'epoch': 2.45}                                                                                                                                             
{'loss': 0.5291, 'learning_rate': 0.00023302405498281786, 'epoch': 2.46}                                                                                                      
{'loss': 0.4212, 'learning_rate': 0.00023285223367697593, 'epoch': 2.46}                                                                                                      
{'loss': 0.5454, 'learning_rate': 0.000232680412371134, 'epoch': 2.47}                                                                                                        
{'loss': 0.6851, 'learning_rate': 0.0002325085910652921, 'epoch': 2.47}                                                                                                       
{'loss': 0.5485, 'learning_rate': 0.00023233676975945017, 'epoch': 2.48}                                                                                                      
{'loss': 0.4669, 'learning_rate': 0.00023216494845360822, 'epoch': 2.48}                                                                                                      
{'loss': 0.4582, 'learning_rate': 0.0002319931271477663, 'epoch': 2.49}                                                                                                       
{'loss': 0.5019, 'learning_rate': 0.00023182130584192438, 'epoch': 2.49}                                                                                                      
{'loss': 0.6499, 'learning_rate': 0.00023164948453608246, 'epoch': 2.5}                                                                                                       
{'loss': 0.5327, 'learning_rate': 0.00023147766323024054, 'epoch': 2.51}                                                                                                      
 25%|████████████████████████████████                                                                                                | 4500/17960 [4:38:05<4:06:06,  1.10s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.32604891061782837, 'eval_wer': 0.4386112014237068, 'eval_cer': 0.14447091300386536, 'eval_runtime': 299.8152, 'eval_samples_per_second': 28.978, 'eval_steps_per_second': 3.622, 'epoch': 2.51}                                                                                                                                             
{'loss': 0.3492, 'learning_rate': 0.00023130584192439862, 'epoch': 2.51}                                                                                                      
{'loss': 0.4368, 'learning_rate': 0.0002311340206185567, 'epoch': 2.52}                                                                                                       
{'loss': 0.4913, 'learning_rate': 0.00023096219931271477, 'epoch': 2.52}                                                                                                      
{'loss': 0.726, 'learning_rate': 0.00023079037800687285, 'epoch': 2.53}                                                                                                       
{'loss': 0.5133, 'learning_rate': 0.00023061855670103093, 'epoch': 2.53}                                                                                                      
{'loss': 0.4254, 'learning_rate': 0.000230446735395189, 'epoch': 2.54}                                                                                                        
{'loss': 0.5127, 'learning_rate': 0.0002302749140893471, 'epoch': 2.54}                                                                                                       
{'loss': 0.5141, 'learning_rate': 0.00023010309278350514, 'epoch': 2.55}                                                                                                      
{'loss': 0.6872, 'learning_rate': 0.00022993127147766322, 'epoch': 2.56}                                                                                                      
{'loss': 0.5197, 'learning_rate': 0.0002297594501718213, 'epoch': 2.56}                                                                                                       
 26%|████████████████████████████████▊                                                                                               | 4600/17960 [4:44:24<4:06:23,  1.11s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3349997103214264, 'eval_wer': 0.43727647632574135, 'eval_cer': 0.14477662991001025, 'eval_runtime': 299.5099, 'eval_samples_per_second': 29.007, 'eval_steps_per_second': 3.626, 'epoch': 2.56}                                                                                                                                             
{'loss': 0.3549, 'learning_rate': 0.00022958762886597935, 'epoch': 2.57}                                                                                                      
{'loss': 0.4698, 'learning_rate': 0.00022941580756013743, 'epoch': 2.57}                                                                                                      
{'loss': 0.453, 'learning_rate': 0.0002292439862542955, 'epoch': 2.58}                                                                                                        
{'loss': 0.6301, 'learning_rate': 0.00022907216494845358, 'epoch': 2.58}                                                                                                      
{'loss': 0.3942, 'learning_rate': 0.00022890034364261166, 'epoch': 2.59}                                                                                                      
{'loss': 0.3674, 'learning_rate': 0.0002287285223367697, 'epoch': 2.59}                                                                                                       
{'loss': 0.3967, 'learning_rate': 0.0002285567010309278, 'epoch': 2.6}                                                                                                        
{'loss': 0.457, 'learning_rate': 0.00022838487972508587, 'epoch': 2.61}                                                                                                       
{'loss': 0.5827, 'learning_rate': 0.00022821305841924395, 'epoch': 2.61}                                                                                                      
{'loss': 0.584, 'learning_rate': 0.00022804123711340203, 'epoch': 2.62}                                                                                                       
 26%|█████████████████████████████████▍                                                                                              | 4700/17960 [4:50:43<4:03:13,  1.10s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3173823356628418, 'eval_wer': 0.43012371874946526, 'eval_cer': 0.14204636605513196, 'eval_runtime': 299.0196, 'eval_samples_per_second': 29.055, 'eval_steps_per_second': 3.632, 'epoch': 2.62}                                                                                                                                             
{'loss': 0.402, 'learning_rate': 0.0002278694158075601, 'epoch': 2.62}                                                                                                        
{'loss': 0.4157, 'learning_rate': 0.00022769759450171818, 'epoch': 2.63}                                                                                                      
{'loss': 0.4795, 'learning_rate': 0.00022752577319587626, 'epoch': 2.63}                                                                                                      
{'loss': 0.5874, 'learning_rate': 0.00022735395189003434, 'epoch': 2.64}                                                                                                      
{'loss': 0.6018, 'learning_rate': 0.00022718213058419242, 'epoch': 2.64}                                                                                                      
{'loss': 0.3899, 'learning_rate': 0.0002270103092783505, 'epoch': 2.65}                                                                                                       
{'loss': 0.3408, 'learning_rate': 0.00022683848797250858, 'epoch': 2.66}                                                                                                      
{'loss': 0.5134, 'learning_rate': 0.00022666666666666663, 'epoch': 2.66}                                                                                                      
{'loss': 0.6185, 'learning_rate': 0.0002264948453608247, 'epoch': 2.67}                                                                                                       
{'loss': 0.6036, 'learning_rate': 0.00022632302405498279, 'epoch': 2.67}                                                                                                      
 27%|██████████████████████████████████▏                                                                                             | 4800/17960 [4:57:02<4:04:42,  1.12s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.31908565759658813, 'eval_wer': 0.44112664487756464, 'eval_cer': 0.14208571575592288, 'eval_runtime': 300.9025, 'eval_samples_per_second': 28.873, 'eval_steps_per_second': 3.609, 'epoch': 2.67}                                                                                                                                            
{'loss': 0.4729, 'learning_rate': 0.00022615120274914086, 'epoch': 2.68}                                                                                                      
{'loss': 0.4119, 'learning_rate': 0.00022597938144329894, 'epoch': 2.68}                                                                                                      
{'loss': 0.4467, 'learning_rate': 0.00022580756013745702, 'epoch': 2.69}                                                                                                      
{'loss': 0.553, 'learning_rate': 0.0002256357388316151, 'epoch': 2.69}                                                                                                        
{'loss': 0.4453, 'learning_rate': 0.00022546391752577318, 'epoch': 2.7}                                                                                                       
{'loss': 0.369, 'learning_rate': 0.00022529209621993126, 'epoch': 2.71}                                                                                                       
{'loss': 0.4403, 'learning_rate': 0.00022513745704467352, 'epoch': 2.71}                                                                                                      
{'loss': 0.5246, 'learning_rate': 0.0002249656357388316, 'epoch': 2.72}                                                                                                       
{'loss': 0.6799, 'learning_rate': 0.00022479381443298968, 'epoch': 2.72}                                                                                                      
{'loss': 0.4514, 'learning_rate': 0.00022462199312714776, 'epoch': 2.73}                                                                                                      
 27%|██████████████████████████████████▉                                                                                             | 4900/17960 [5:03:23<3:59:47,  1.10s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3208460807800293, 'eval_wer': 0.4267526822840911, 'eval_cer': 0.13903460049459546, 'eval_runtime': 299.5231, 'eval_samples_per_second': 29.006, 'eval_steps_per_second': 3.626, 'epoch': 2.73}                                                                                                                                              
{'loss': 0.3757, 'learning_rate': 0.00022445017182130583, 'epoch': 2.73}                                                                                                      
{'loss': 0.4678, 'learning_rate': 0.0002242783505154639, 'epoch': 2.74}                                                                                                       
{'loss': 0.5584, 'learning_rate': 0.00022410652920962196, 'epoch': 2.74}                                                                                                      
{'loss': 0.6591, 'learning_rate': 0.00022393470790378004, 'epoch': 2.75}                                                                                                      
{'loss': 0.5406, 'learning_rate': 0.00022376288659793812, 'epoch': 2.76}                                                                                                      
{'loss': 0.4413, 'learning_rate': 0.0002235910652920962, 'epoch': 2.76}                                                                                                       
{'loss': 0.4184, 'learning_rate': 0.00022341924398625428, 'epoch': 2.77}                                                                                                      
{'loss': 0.5091, 'learning_rate': 0.00022324742268041236, 'epoch': 2.77}                                                                                                      
{'loss': 0.5818, 'learning_rate': 0.00022307560137457044, 'epoch': 2.78}                                                                                                      
{'loss': 0.503, 'learning_rate': 0.00022290378006872851, 'epoch': 2.78}                                                                                                       
 28%|███████████████████████████████████▋                                                                                            | 5000/17960 [5:09:42<4:02:46,  1.12s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.32393112778663635, 'eval_wer': 0.42878899365149986, 'eval_cer': 0.141589304145945, 'eval_runtime': 299.0229, 'eval_samples_per_second': 29.055, 'eval_steps_per_second': 3.632, 'epoch': 2.78}                                                                                                                                              
{'loss': 0.4308, 'learning_rate': 0.0002227319587628866, 'epoch': 2.79}                                                                                                       
{'loss': 0.4332, 'learning_rate': 0.00022256013745704467, 'epoch': 2.79}                                                                                                      
{'loss': 0.444, 'learning_rate': 0.00022238831615120275, 'epoch': 2.8}                                                                                                        
{'loss': 0.5943, 'learning_rate': 0.0002222164948453608, 'epoch': 2.81}                                                                                                       
{'loss': 0.4235, 'learning_rate': 0.00022204467353951888, 'epoch': 2.81}                                                                                                      
{'loss': 0.4344, 'learning_rate': 0.00022187285223367696, 'epoch': 2.82}                                                                                                      
{'loss': 0.4661, 'learning_rate': 0.00022170103092783504, 'epoch': 2.82}                                                                                                      
{'loss': 0.477, 'learning_rate': 0.00022152920962199312, 'epoch': 2.83}                                                                                                       
{'loss': 0.7092, 'learning_rate': 0.0002213573883161512, 'epoch': 2.83}                                                                                                       
{'loss': 0.4339, 'learning_rate': 0.00022118556701030927, 'epoch': 2.84}                                                                                                      
 28%|████████████████████████████████████▎                                                                                           | 5100/17960 [5:16:01<4:04:47,  1.14s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3086434006690979, 'eval_wer': 0.42137955817176886, 'eval_cer': 0.13689760905164194, 'eval_runtime': 301.4891, 'eval_samples_per_second': 28.817, 'eval_steps_per_second': 3.602, 'epoch': 2.84}                                                                                                                                             
{'loss': 0.4034, 'learning_rate': 0.00022101374570446735, 'epoch': 2.84}                                                                                                      
{'loss': 0.4147, 'learning_rate': 0.00022084192439862543, 'epoch': 2.85}                                                                                                      
{'loss': 0.4847, 'learning_rate': 0.0002206701030927835, 'epoch': 2.86}                                                                                                       
{'loss': 0.6403, 'learning_rate': 0.0002204982817869416, 'epoch': 2.86}                                                                                                       
{'loss': 0.5439, 'learning_rate': 0.00022032646048109967, 'epoch': 2.87}                                                                                                      
{'loss': 0.4078, 'learning_rate': 0.0002201546391752577, 'epoch': 2.87}                                                                                                       
{'loss': 0.448, 'learning_rate': 0.00021998281786941577, 'epoch': 2.88}                                                                                                       
{'loss': 0.4811, 'learning_rate': 0.00021981099656357385, 'epoch': 2.88}                                                                                                      
{'loss': 0.642, 'learning_rate': 0.0002196563573883161, 'epoch': 2.89}                                                                                                        
{'loss': 0.5572, 'learning_rate': 0.0002194845360824742, 'epoch': 2.9}                                                                                                        
 29%|█████████████████████████████████████                                                                                           | 5200/17960 [5:22:22<3:49:43,  1.08s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.31702113151550293, 'eval_wer': 0.4288745529526515, 'eval_cer': 0.1394311244025656, 'eval_runtime': 301.7002, 'eval_samples_per_second': 28.797, 'eval_steps_per_second': 3.6, 'epoch': 2.9}                                                                                                                                                 
{'loss': 0.4107, 'learning_rate': 0.00021931271477663227, 'epoch': 2.9}                                                                                                       
{'loss': 0.4339, 'learning_rate': 0.00021914089347079035, 'epoch': 2.91}                                                                                                      
{'loss': 0.5204, 'learning_rate': 0.00021896907216494843, 'epoch': 2.91}                                                                                                      
{'loss': 0.6521, 'learning_rate': 0.0002187972508591065, 'epoch': 2.92}                                                                                                       
{'loss': 0.4774, 'learning_rate': 0.00021862542955326458, 'epoch': 2.92}                                                                                                      
{'loss': 0.411, 'learning_rate': 0.00021845360824742266, 'epoch': 2.93}                                                                                                       
{'loss': 0.3635, 'learning_rate': 0.00021828178694158074, 'epoch': 2.93}                                                                                                      
{'loss': 0.5815, 'learning_rate': 0.0002181099656357388, 'epoch': 2.94}                                                                                                       
{'loss': 0.5828, 'learning_rate': 0.00021793814432989687, 'epoch': 2.95}                                                                                                      
{'loss': 0.4616, 'learning_rate': 0.00021776632302405495, 'epoch': 2.95}                                                                                                      
 30%|█████████████████████████████████████▊                                                                                          | 5300/17960 [5:28:44<4:00:55,  1.14s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3181746304035187, 'eval_wer': 0.42731737367169187, 'eval_cer': 0.1389770893934395, 'eval_runtime': 300.4442, 'eval_samples_per_second': 28.917, 'eval_steps_per_second': 3.615, 'epoch': 2.95}                                                                                                                                              
{'loss': 0.4143, 'learning_rate': 0.00021759450171821303, 'epoch': 2.96}                                                                                                      
{'loss': 0.4295, 'learning_rate': 0.0002174226804123711, 'epoch': 2.96}                                                                                                       
{'loss': 0.4975, 'learning_rate': 0.00021725085910652918, 'epoch': 2.97}                                                                                                      
{'loss': 0.6492, 'learning_rate': 0.00021707903780068726, 'epoch': 2.97}                                                                                                      
{'loss': 0.4945, 'learning_rate': 0.00021690721649484534, 'epoch': 2.98}                                                                                                      
{'loss': 0.351, 'learning_rate': 0.00021673539518900342, 'epoch': 2.98}                                                                                                       
{'loss': 0.397, 'learning_rate': 0.0002165635738831615, 'epoch': 2.99}                                                                                                        
{'loss': 0.4997, 'learning_rate': 0.00021639175257731958, 'epoch': 3.0}                                                                                                       
 30%|██████████████████████████████████████▍                                                                                         | 5388/17960 [5:34:51<1:32:33,  2.26it/s]Saving model checkpoint to ./portu_augmented/checkpoint-5388
Configuration saved in ./portu_augmented/checkpoint-5388/config.json
Model weights saved in ./portu_augmented/checkpoint-5388/pytorch_model.bin
Feature extractor saved in ./portu_augmented/checkpoint-5388/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.7326, 'learning_rate': 0.00021621993127147766, 'epoch': 3.0}                                                                                                       
{'loss': 0.3318, 'learning_rate': 0.0002160481099656357, 'epoch': 3.01}                                                                                                       
 30%|██████████████████████████████████████▍                                                                                         | 5400/17960 [5:35:08<3:32:59,  1.02s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.31472793221473694, 'eval_wer': 0.41301185851913963, 'eval_cer': 0.13692787805225035, 'eval_runtime': 301.4285, 'eval_samples_per_second': 28.823, 'eval_steps_per_second': 3.603, 'epoch': 3.01}                                                                                                                                            
{'loss': 0.3959, 'learning_rate': 0.00021587628865979379, 'epoch': 3.01}                                                                                                      
{'loss': 0.4434, 'learning_rate': 0.00021570446735395186, 'epoch': 3.02}                                                                                                      
{'loss': 0.4131, 'learning_rate': 0.00021553264604810994, 'epoch': 3.02}                                                                                                      
{'loss': 0.5346, 'learning_rate': 0.00021536082474226802, 'epoch': 3.03}                                                                                                      
{'loss': 0.3296, 'learning_rate': 0.0002151890034364261, 'epoch': 3.03}                                                                                                       
{'loss': 0.368, 'learning_rate': 0.00021501718213058418, 'epoch': 3.04}                                                                                                       
{'loss': 0.3837, 'learning_rate': 0.00021484536082474226, 'epoch': 3.05}                                                                                                      
{'loss': 0.5008, 'learning_rate': 0.00021467353951890034, 'epoch': 3.05}                                                                                                      
{'loss': 0.6179, 'learning_rate': 0.00021450171821305841, 'epoch': 3.06}                                                                                                      
{'loss': 0.3638, 'learning_rate': 0.0002143298969072165, 'epoch': 3.06}                                                                                                       
 31%|███████████████████████████████████████▏                                                                                        | 5500/17960 [5:41:27<3:27:22,  1.00it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.31482642889022827, 'eval_wer': 0.4204897414397919, 'eval_cer': 0.13905578879502137, 'eval_runtime': 302.274, 'eval_samples_per_second': 28.742, 'eval_steps_per_second': 3.593, 'epoch': 3.06}                                                                                                                                              
{'loss': 0.3557, 'learning_rate': 0.00021417525773195876, 'epoch': 3.07}                                                                                                      
{'loss': 0.3784, 'learning_rate': 0.00021400343642611683, 'epoch': 3.07}                                                                                                      
{'loss': 0.4419, 'learning_rate': 0.0002138316151202749, 'epoch': 3.08}                                                                                                       
{'loss': 0.6306, 'learning_rate': 0.00021365979381443296, 'epoch': 3.08}                                                                                                      
{'loss': 0.3551, 'learning_rate': 0.00021348797250859104, 'epoch': 3.09}                                                                                                      
{'loss': 0.3388, 'learning_rate': 0.00021331615120274912, 'epoch': 3.1}                                                                                                       
{'loss': 0.3798, 'learning_rate': 0.0002131443298969072, 'epoch': 3.1}                                                                                                        
{'loss': 0.5055, 'learning_rate': 0.00021297250859106528, 'epoch': 3.11}                                                                                                      
{'loss': 0.6844, 'learning_rate': 0.00021280068728522336, 'epoch': 3.11}                                                                                                      
{'loss': 0.3131, 'learning_rate': 0.00021262886597938144, 'epoch': 3.12}                                                                                                      
 31%|███████████████████████████████████████▉                                                                                        | 5600/17960 [5:47:49<3:34:30,  1.04s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.30867260694503784, 'eval_wer': 0.4165882373072777, 'eval_cer': 0.13527519061903134, 'eval_runtime': 301.9245, 'eval_samples_per_second': 28.775, 'eval_steps_per_second': 3.597, 'epoch': 3.12}                                                                                                                                             
{'loss': 0.3419, 'learning_rate': 0.00021245704467353951, 'epoch': 3.12}                                                                                                      
{'loss': 0.4102, 'learning_rate': 0.0002122852233676976, 'epoch': 3.13}                                                                                                       
{'loss': 0.4872, 'learning_rate': 0.00021211340206185567, 'epoch': 3.13}                                                                                                      
{'loss': 0.6156, 'learning_rate': 0.00021194158075601375, 'epoch': 3.14}                                                                                                      
{'loss': 0.3782, 'learning_rate': 0.00021176975945017183, 'epoch': 3.15}                                                                                                      
{'loss': 0.3634, 'learning_rate': 0.00021159793814432988, 'epoch': 3.15}                                                                                                      
{'loss': 0.3804, 'learning_rate': 0.00021142611683848796, 'epoch': 3.16}                                                                                                      
{'loss': 0.4428, 'learning_rate': 0.00021125429553264604, 'epoch': 3.16}                                                                                                      
{'loss': 0.5863, 'learning_rate': 0.00021108247422680412, 'epoch': 3.17}                                                                                                      
{'loss': 0.3372, 'learning_rate': 0.00021091065292096217, 'epoch': 3.17}                                                                                                      
 32%|████████████████████████████████████████▌                                                                                       | 5700/17960 [5:54:11<3:27:52,  1.02s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3118319809436798, 'eval_wer': 0.41011995414021457, 'eval_cer': 0.1357413332284008, 'eval_runtime': 302.2544, 'eval_samples_per_second': 28.744, 'eval_steps_per_second': 3.593, 'epoch': 3.17}                                                                                                                                              
{'loss': 0.3495, 'learning_rate': 0.00021073883161512025, 'epoch': 3.18}                                                                                                      
{'loss': 0.4009, 'learning_rate': 0.00021056701030927832, 'epoch': 3.18}                                                                                                      
{'loss': 0.3655, 'learning_rate': 0.0002103951890034364, 'epoch': 3.19}                                                                                                       
{'loss': 0.6037, 'learning_rate': 0.00021022336769759448, 'epoch': 3.2}                                                                                                       
{'loss': 0.2958, 'learning_rate': 0.00021005154639175253, 'epoch': 3.2}                                                                                                       
{'loss': 0.4123, 'learning_rate': 0.0002098797250859106, 'epoch': 3.21}                                                                                                       
{'loss': 0.3913, 'learning_rate': 0.0002097079037800687, 'epoch': 3.21}                                                                                                       
{'loss': 0.5177, 'learning_rate': 0.00020953608247422677, 'epoch': 3.22}                                                                                                      
{'loss': 0.7844, 'learning_rate': 0.00020936426116838485, 'epoch': 3.22}                                                                                                      
{'loss': 0.3233, 'learning_rate': 0.00020919243986254293, 'epoch': 3.23}                                                                                                      
 32%|█████████████████████████████████████████▎                                                                                      | 5800/17960 [6:00:32<3:27:21,  1.02s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3174239993095398, 'eval_wer': 0.41717004055510876, 'eval_cer': 0.13742126276216737, 'eval_runtime': 302.0829, 'eval_samples_per_second': 28.76, 'eval_steps_per_second': 3.595, 'epoch': 3.23}                                                                                                                                              
{'loss': 0.3829, 'learning_rate': 0.000209020618556701, 'epoch': 3.23}                                                                                                        
{'loss': 0.4787, 'learning_rate': 0.00020884879725085908, 'epoch': 3.24}                                                                                                      
{'loss': 0.5087, 'learning_rate': 0.00020867697594501716, 'epoch': 3.25}                                                                                                      
{'loss': 0.5496, 'learning_rate': 0.00020850515463917524, 'epoch': 3.25}                                                                                                      
{'loss': 0.3133, 'learning_rate': 0.00020833333333333332, 'epoch': 3.26}                                                                                                      
{'loss': 0.4642, 'learning_rate': 0.00020816151202749137, 'epoch': 3.26}                                                                                                      
{'loss': 0.3873, 'learning_rate': 0.00020798969072164945, 'epoch': 3.27}                                                                                                      
{'loss': 0.4942, 'learning_rate': 0.00020781786941580753, 'epoch': 3.27}                                                                                                      
{'loss': 0.6892, 'learning_rate': 0.0002076460481099656, 'epoch': 3.28}                                                                                                       
{'loss': 0.3496, 'learning_rate': 0.00020747422680412369, 'epoch': 3.28}                                                                                                      
 33%|██████████████████████████████████████████                                                                                      | 5900/17960 [6:06:54<3:36:04,  1.08s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3153451085090637, 'eval_wer': 0.41503105802631807, 'eval_cer': 0.13562025722596718, 'eval_runtime': 301.6622, 'eval_samples_per_second': 28.8, 'eval_steps_per_second': 3.6, 'epoch': 3.28}                                                                                                                                                 
{'loss': 0.4786, 'learning_rate': 0.00020730240549828176, 'epoch': 3.29}                                                                                                      
{'loss': 0.3887, 'learning_rate': 0.00020713058419243984, 'epoch': 3.3}                                                                                                       
{'loss': 0.4405, 'learning_rate': 0.00020695876288659792, 'epoch': 3.3}                                                                                                       
{'loss': 0.6478, 'learning_rate': 0.000206786941580756, 'epoch': 3.31}                                                                                                        
{'loss': 0.4067, 'learning_rate': 0.00020661512027491408, 'epoch': 3.31}                                                                                                      
{'loss': 0.3707, 'learning_rate': 0.00020644329896907216, 'epoch': 3.32}                                                                                                      
{'loss': 0.4396, 'learning_rate': 0.00020627147766323024, 'epoch': 3.32}                                                                                                      
{'loss': 0.4782, 'learning_rate': 0.0002060996563573883, 'epoch': 3.33}                                                                                                       
{'loss': 0.6986, 'learning_rate': 0.00020592783505154637, 'epoch': 3.34}                                                                                                      
{'loss': 0.37, 'learning_rate': 0.00020575601374570444, 'epoch': 3.34}                                                                                                        
 33%|██████████████████████████████████████████▊                                                                                     | 6000/17960 [6:13:16<3:31:18,  1.06s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.334363728761673, 'eval_wer': 0.4205239651602526, 'eval_cer': 0.13762709196630454, 'eval_runtime': 300.6488, 'eval_samples_per_second': 28.898, 'eval_steps_per_second': 3.612, 'epoch': 3.34}                                                                                                                                               
{'loss': 0.4277, 'learning_rate': 0.00020558419243986252, 'epoch': 3.35}                                                                                                      
{'loss': 0.5044, 'learning_rate': 0.00020542955326460479, 'epoch': 3.35}                                                                                                      
{'loss': 0.5139, 'learning_rate': 0.00020525773195876286, 'epoch': 3.36}                                                                                                      
{'loss': 0.7514, 'learning_rate': 0.00020508591065292094, 'epoch': 3.36}                                                                                                      
{'loss': 0.3957, 'learning_rate': 0.00020491408934707902, 'epoch': 3.37}                                                                                                      
{'loss': 0.3765, 'learning_rate': 0.0002047422680412371, 'epoch': 3.37}                                                                                                       
{'loss': 0.507, 'learning_rate': 0.00020457044673539518, 'epoch': 3.38}                                                                                                       
{'loss': 0.5677, 'learning_rate': 0.00020439862542955326, 'epoch': 3.39}                                                                                                      
{'loss': 0.7446, 'learning_rate': 0.00020422680412371134, 'epoch': 3.39}                                                                                                      
{'loss': 0.4246, 'learning_rate': 0.00020405498281786941, 'epoch': 3.4}                                                                                                       
 34%|███████████████████████████████████████████▍                                                                                    | 6100/17960 [6:19:36<3:22:19,  1.02s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3831189274787903, 'eval_wer': 0.457331576515683, 'eval_cer': 0.1471739347581961, 'eval_runtime': 301.2569, 'eval_samples_per_second': 28.839, 'eval_steps_per_second': 3.605, 'epoch': 3.4}                                                                                                                                                 
{'loss': 0.5249, 'learning_rate': 0.0002038831615120275, 'epoch': 3.4}                                                                                                        
{'loss': 0.5789, 'learning_rate': 0.00020371134020618557, 'epoch': 3.41}                                                                                                      
{'loss': 0.6008, 'learning_rate': 0.00020353951890034362, 'epoch': 3.41}                                                                                                      
{'loss': 0.7521, 'learning_rate': 0.0002033676975945017, 'epoch': 3.42}                                                                                                       
{'loss': 0.4306, 'learning_rate': 0.00020319587628865978, 'epoch': 3.42}                                                                                                      
{'loss': 0.4446, 'learning_rate': 0.00020302405498281786, 'epoch': 3.43}                                                                                                      
{'loss': 0.5276, 'learning_rate': 0.00020285223367697594, 'epoch': 3.44}                                                                                                      
{'loss': 0.6138, 'learning_rate': 0.00020268041237113402, 'epoch': 3.44}                                                                                                      
{'loss': 0.8004, 'learning_rate': 0.0002025085910652921, 'epoch': 3.45}                                                                                                       
{'loss': 0.555, 'learning_rate': 0.00020233676975945017, 'epoch': 3.45}                                                                                                       
 35%|████████████████████████████████████████████▏                                                                                   | 6200/17960 [6:25:57<3:11:36,  1.02it/s]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.43574991822242737, 'eval_wer': 0.46183199575625866, 'eval_cer': 0.14830599538095052, 'eval_runtime': 301.5457, 'eval_samples_per_second': 28.812, 'eval_steps_per_second': 3.601, 'epoch': 3.45}                                                                                                                                            
{'loss': 0.5724, 'learning_rate': 0.00020216494845360825, 'epoch': 3.46}                                                                                                      
{'loss': 0.5666, 'learning_rate': 0.00020199312714776633, 'epoch': 3.46}                                                                                                      
{'loss': 0.6716, 'learning_rate': 0.0002018213058419244, 'epoch': 3.47}                                                                                                       
{'loss': 0.7278, 'learning_rate': 0.00020164948453608246, 'epoch': 3.47}                                                                                                      
{'loss': 0.5429, 'learning_rate': 0.0002014776632302405, 'epoch': 3.48}                                                                                                       
{'loss': 0.4815, 'learning_rate': 0.0002013058419243986, 'epoch': 3.49}                                                                                                       
{'loss': 0.6467, 'learning_rate': 0.00020113402061855667, 'epoch': 3.49}                                                                                                      
{'loss': 0.6156, 'learning_rate': 0.00020096219931271475, 'epoch': 3.5}                                                                                                       
{'loss': 0.8595, 'learning_rate': 0.00020079037800687283, 'epoch': 3.5}                                                                                                       
{'loss': 0.5184, 'learning_rate': 0.0002006185567010309, 'epoch': 3.51}                                                                                                       
 35%|████████████████████████████████████████████▉                                                                                   | 6300/17960 [6:32:17<3:17:47,  1.02s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.44588643312454224, 'eval_wer': 0.5053132326015161, 'eval_cer': 0.159620547808373, 'eval_runtime': 301.0358, 'eval_samples_per_second': 28.86, 'eval_steps_per_second': 3.608, 'epoch': 3.51}                                                                                                                                                
{'loss': 0.6398, 'learning_rate': 0.00020044673539518898, 'epoch': 3.51}                                                                                                      
{'loss': 0.5526, 'learning_rate': 0.00020027491408934706, 'epoch': 3.52}                                                                                                      
{'loss': 0.6142, 'learning_rate': 0.00020010309278350511, 'epoch': 3.52}                                                                                                      
{'loss': 0.8863, 'learning_rate': 0.0001999312714776632, 'epoch': 3.53}                                                                                                       
{'loss': 0.4653, 'learning_rate': 0.00019975945017182127, 'epoch': 3.54}                                                                                                      
{'loss': 0.5712, 'learning_rate': 0.00019958762886597935, 'epoch': 3.54}                                                                                                      
{'loss': 0.5149, 'learning_rate': 0.00019941580756013743, 'epoch': 3.55}                                                                                                      
{'loss': 0.5961, 'learning_rate': 0.0001992439862542955, 'epoch': 3.55}                                                                                                       
{'loss': 0.8223, 'learning_rate': 0.00019907216494845359, 'epoch': 3.56}                                                                                                      
{'loss': 0.5598, 'learning_rate': 0.00019890034364261166, 'epoch': 3.56}                                                                                                      
 36%|█████████████████████████████████████████████▌                                                                                  | 6400/17960 [6:38:38<3:14:58,  1.01s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.4385155141353607, 'eval_wer': 0.46968633960197814, 'eval_cer': 0.15041574472335648, 'eval_runtime': 301.4755, 'eval_samples_per_second': 28.818, 'eval_steps_per_second': 3.602, 'epoch': 3.56}                                                                                                                                             
{'loss': 0.6138, 'learning_rate': 0.00019872852233676974, 'epoch': 3.57}                                                                                                      
{'loss': 0.6444, 'learning_rate': 0.00019855670103092782, 'epoch': 3.57}                                                                                                      
{'loss': 0.6465, 'learning_rate': 0.0001983848797250859, 'epoch': 3.58}                                                                                                       
{'loss': 0.7323, 'learning_rate': 0.00019821305841924395, 'epoch': 3.59}                                                                                                      
{'loss': 0.5071, 'learning_rate': 0.00019804123711340203, 'epoch': 3.59}                                                                                                      
{'loss': 0.4755, 'learning_rate': 0.0001978694158075601, 'epoch': 3.6}                                                                                                        
{'loss': 0.5275, 'learning_rate': 0.0001976975945017182, 'epoch': 3.6}                                                                                                        
{'loss': 0.5712, 'learning_rate': 0.00019752577319587627, 'epoch': 3.61}                                                                                                      
{'loss': 0.8045, 'learning_rate': 0.00019735395189003434, 'epoch': 3.61}                                                                                                      
{'loss': 0.4337, 'learning_rate': 0.00019718213058419242, 'epoch': 3.62}                                                                                                      
 36%|██████████████████████████████████████████████▎                                                                                 | 6500/17960 [6:44:59<3:25:12,  1.07s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3964410424232483, 'eval_wer': 0.4602063690343777, 'eval_cer': 0.14917168879835094, 'eval_runtime': 312.1367, 'eval_samples_per_second': 27.834, 'eval_steps_per_second': 3.479, 'epoch': 3.62}                                                                                                                                              
{'loss': 0.4984, 'learning_rate': 0.0001970103092783505, 'epoch': 3.62}                                                                                                       
{'loss': 0.5269, 'learning_rate': 0.00019683848797250858, 'epoch': 3.63}                                                                                                      
{'loss': 0.5728, 'learning_rate': 0.00019666666666666666, 'epoch': 3.64}                                                                                                      
{'loss': 0.7802, 'learning_rate': 0.00019649484536082474, 'epoch': 3.64}                                                                                                      
{'loss': 0.4328, 'learning_rate': 0.00019632302405498282, 'epoch': 3.65}                                                                                                      
{'loss': 0.5399, 'learning_rate': 0.00019615120274914087, 'epoch': 3.65}                                                                                                      
{'loss': 0.5501, 'learning_rate': 0.00019597938144329895, 'epoch': 3.66}                                                                                                      
{'loss': 0.6264, 'learning_rate': 0.00019580756013745702, 'epoch': 3.66}                                                                                                      
{'loss': 0.6364, 'learning_rate': 0.0001956357388316151, 'epoch': 3.67}                                                                                                       
{'loss': 0.4033, 'learning_rate': 0.00019546391752577318, 'epoch': 3.67}                                                                                                      
 37%|███████████████████████████████████████████████                                                                                 | 6600/17960 [6:51:34<3:25:01,  1.08s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.3830365538597107, 'eval_wer': 0.449237666626739, 'eval_cer': 0.145902636732643, 'eval_runtime': 310.6994, 'eval_samples_per_second': 27.963, 'eval_steps_per_second': 3.495, 'epoch': 3.67}                                                                                                                                                 
{'loss': 0.5141, 'learning_rate': 0.00019529209621993126, 'epoch': 3.68}                                                                                                      
{'loss': 0.5091, 'learning_rate': 0.00019512027491408934, 'epoch': 3.69}                                                                                                      
{'loss': 0.5723, 'learning_rate': 0.00019494845360824742, 'epoch': 3.69}                                                                                                      
{'loss': 0.7668, 'learning_rate': 0.0001947766323024055, 'epoch': 3.7}                                                                                                        
{'loss': 0.4512, 'learning_rate': 0.00019460481099656357, 'epoch': 3.7}                                                                                                       
{'loss': 0.4775, 'learning_rate': 0.00019443298969072165, 'epoch': 3.71}                                                                                                      
{'loss': 0.442, 'learning_rate': 0.0001942611683848797, 'epoch': 3.71}                                                                                                        
{'loss': 0.6444, 'learning_rate': 0.00019408934707903778, 'epoch': 3.72}                                                                                                      
{'loss': 0.6699, 'learning_rate': 0.00019391752577319586, 'epoch': 3.72}                                                                                                      
{'loss': 0.4418, 'learning_rate': 0.00019374570446735394, 'epoch': 3.73}                                                                                                      
 37%|███████████████████████████████████████████████▊                                                                                | 6700/17960 [6:58:07<3:19:14,  1.06s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8
{'eval_loss': 0.39026957750320435, 'eval_wer': 0.44631153852735334, 'eval_cer': 0.1478428796716419, 'eval_runtime': 310.1582, 'eval_samples_per_second': 28.012, 'eval_steps_per_second': 3.501, 'epoch': 3.73}                                                                                                                                             
{'loss': 0.4188, 'learning_rate': 0.00019357388316151202, 'epoch': 3.74}                                                                                                      
{'loss': 0.5809, 'learning_rate': 0.0001934020618556701, 'epoch': 3.74}                                                                                                       
{'loss': 0.5315, 'learning_rate': 0.00019323024054982818, 'epoch': 3.75}                                                                                                      
{'loss': 0.7698, 'learning_rate': 0.00019305841924398625, 'epoch': 3.75}                                                                                                      
{'loss': 0.4259, 'learning_rate': 0.00019288659793814433, 'epoch': 3.76}                                                                                                      
{'loss': 0.4259, 'learning_rate': 0.0001927147766323024, 'epoch': 3.76}                                                                                                       
{'loss': 0.46, 'learning_rate': 0.0001925429553264605, 'epoch': 3.77}                                                                                                         
{'loss': 0.5491, 'learning_rate': 0.00019238831615120275, 'epoch': 3.77}                                                                                                      
{'loss': 0.6562, 'learning_rate': 0.00019221649484536083, 'epoch': 3.78}                                                                                                      
{'loss': 0.5255, 'learning_rate': 0.00019204467353951886, 'epoch': 3.79}                                                                                                      
 38%|████████████████████████████████████████████████▍                                                                               | 6800/17960 [7:04:39<3:17:45,  1.06s/it]***** Running Evaluation *****
  Num examples = 8688
  Batch size = 8

Killed█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 1029/1086 [05:05<00:18,  3.08it/s]
(base) or@anidjar:~/Desktop/wav2vec2$ 


