(base) or@anidjar:~/Desktop/wav2vec2$ python3 main.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-270037d7330ddc21
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-270037d7330ddc21/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13107.20it/s]
Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2551.28it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-270037d7330ddc21/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 642.31it/s]
Using custom data configuration default-ad58e38bec0ae8e5
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-ad58e38bec0ae8e5/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17697.49it/s]
Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3566.59it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-ad58e38bec0ae8e5/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1198.03it/s]
Casting the dataset:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                       | 2/3 [00:00<00:00, 19.36ba/s]
Casting the dataset:   0%|                                                                                                                              | 0/1 [00:00<?, ?ba/s]
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7f0c571e3700> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25867/25867 [00:00<00:00, 38859.39ex/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9578/9578 [00:00<00:00, 39936.58ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'Ì‡': 0, '8': 1, 'i': 2, '_': 3, 'm': 4, 'Ã¢': 5, 'h': 6, 's': 7, 'n': 8, 'Ã»': 9, 'z': 10, 'â€™': 11, '2': 12, 'â€¦': 13, 'x': 14, 'Ã§': 15, 'a': 16, '\t': 17, '9': 18, 'f': 19, 'v': 20, 'u': 21, 'k': 22, 'o': 23, 'ÅŸ': 24, ')': 25, 'r': 26, '6': 27, 'Ä±': 28, 'c': 29, 'b': 30, 'q': 31, '(': 32, 'l': 33, 't': 34, 'w': 35, 'Ã¶': 36, '3': 37, '4': 38, '0': 39, '7': 40, 'Ã¼': 41, 'ÄŸ': 42, 'g': 43, 'p': 44, 'y': 45, 'e': 46, '5': 47, '\n': 48, 'd': 49, 'j': 50, 'Ã®': 51, "'": 52, ' ': 53, '1': 54}
Vocab_len: 57
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_tr_28856093.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/turkish/train/common_voice_tr_28856093.mp3', 'array': array([-6.4102474e-16, -8.4578083e-14, -1.3026152e-13, ...,
       -1.0928638e-06,  6.6938028e-06,  5.9030531e-06], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/turkish/train/common_voice_tr_28856093.mp3', 'array': array([-3.5049451e-14, -1.1166960e-13, -2.4764685e-13, ...,
        1.1000534e-05, -1.0808196e-06, -1.7927586e-06], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
  0%|                                                                                                                                               | 0/25867 [00:00<?, ?ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25867/25867 [01:36<00:00, 268.71ex/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9578/9578 [00:37<00:00, 257.77ex/s]


----------------- Preparing datasets complete. -----------------


----------------- saving datasets... -----------------
----------------- saving datasets complete. -----------


----------------- Loading Metrics... -----------------
/home/or/Desktop/wav2vec2/main.py:247: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
Downloading builder script: 4.48kB [00:00, 2.28MB/s]                                                                                                                          
Downloading builder script: 5.59kB [00:00, 3.38MB/s]                                                                                                                          
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.weight', 'project_hid.bias', 'project_q.weight', 'project_q.bias', 'quantizer.codevectors', 'project_hid.weight', 'quantizer.weight_proj.bias']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
^CTraceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main.py", line 317, in <module>
    trainer.train()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1501, in train
    return inner_training_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1513, in _inner_training_loop
    train_dataloader = self.get_train_dataloader()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 868, in get_train_dataloader
    train_sampler = self._get_train_sampler()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 790, in _get_train_sampler
    return LengthGroupedSampler(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer_pt_utils.py", line 575, in __init__
    lengths = [len(feature[model_input_name]) for feature in dataset]
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer_pt_utils.py", line 575, in <listcomp>
    lengths = [len(feature[model_input_name]) for feature in dataset]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 1970, in _iter
    formatted_output = format_table(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 517, in format_table
    formatted_output = formatter(pa_table_to_format, query_type=query_type)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 282, in __call__
    return self.format_row(pa_table)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 311, in format_row
    row = self.python_arrow_extractor().extract_row(pa_table)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 141, in extract_row
    return _unnest(pa_table.to_pydict())
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ cd augmentations/
(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
^CTraceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/augmentations/augmentation_script.py", line 29, in <module>
    augmented_samples = augment(samples=x, sample_rate=48000)
  File "/home/or/anaconda3/lib/python3.9/site-packages/audiomentations/core/composition.py", line 88, in __call__
    samples = transform(samples, sample_rate)
  File "/home/or/anaconda3/lib/python3.9/site-packages/audiomentations/core/transforms_interface.py", line 84, in __call__
    return self.apply(samples, sample_rate)
  File "/home/or/anaconda3/lib/python3.9/site-packages/audiomentations/augmentations/pitch_shift.py", line 32, in apply
    pitch_shifted_samples = librosa.effects.pitch_shift(
  File "/home/or/anaconda3/lib/python3.9/site-packages/librosa/util/decorators.py", line 88, in inner_f
    return f(*args, **kwargs)
  File "/home/or/anaconda3/lib/python3.9/site-packages/librosa/effects.py", line 327, in pitch_shift
    y_shift = core.resample(
  File "/home/or/anaconda3/lib/python3.9/site-packages/librosa/util/decorators.py", line 88, in inner_f
    return f(*args, **kwargs)
  File "/home/or/anaconda3/lib/python3.9/site-packages/librosa/core/audio.py", line 647, in resample
    y_hat = resampy.resample(y, orig_sr, target_sr, filter=res_type, axis=-1)
  File "/home/or/anaconda3/lib/python3.9/site-packages/resampy/core.py", line 168, in resample
    resample_f_s(
  File "/home/or/anaconda3/lib/python3.9/site-packages/numba/np/ufunc/gufunc.py", line 192, in __call__
    return self.ufunc(*args, **kwargs)
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ cd ..
(base) or@anidjar:~/Desktop/wav2vec2$ python3 main.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
----------------- Loading Datasets complete. ----------


----------------- Loading Metrics... -----------------
/home/or/Desktop/wav2vec2/main.py:247: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['project_hid.weight', 'quantizer.weight_proj.bias', 'quantizer.codevectors', 'project_hid.bias', 'project_q.bias', 'quantizer.weight_proj.weight', 'project_q.weight']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
^CTraceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main.py", line 317, in <module>
    trainer.train()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1501, in train
    return inner_training_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1513, in _inner_training_loop
    train_dataloader = self.get_train_dataloader()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 868, in get_train_dataloader
    train_sampler = self._get_train_sampler()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 790, in _get_train_sampler
    return LengthGroupedSampler(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer_pt_utils.py", line 575, in __init__
    lengths = [len(feature[model_input_name]) for feature in dataset]
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer_pt_utils.py", line 575, in <listcomp>
    lengths = [len(feature[model_input_name]) for feature in dataset]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 1970, in _iter
    formatted_output = format_table(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 517, in format_table
    formatted_output = formatter(pa_table_to_format, query_type=query_type)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 282, in __call__
    return self.format_row(pa_table)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 311, in format_row
    row = self.python_arrow_extractor().extract_row(pa_table)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 141, in extract_row
    return _unnest(pa_table.to_pydict())
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ python3 main.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
----------------- Loading Datasets complete. ----------


----------------- Loading Metrics... -----------------
/home/or/Desktop/wav2vec2/main.py:247: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.bias', 'project_hid.bias', 'project_hid.weight', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_q.weight', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 25867
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 16
  Gradient Accumulation steps = 2
  Total optimization steps = 16170
  Number of trainable parameters = 311286969
  0%|                                                                                                                                               | 0/16170 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 18.4318, 'learning_rate': 4.8e-06, 'epoch': 0.01}                                                                                                                    
{'loss': 25.9903, 'learning_rate': 1.02e-05, 'epoch': 0.01}                                                                                                                   
{'loss': 30.9855, 'learning_rate': 1.6199999999999997e-05, 'epoch': 0.02}                                                                                                     
{'loss': 33.8756, 'learning_rate': 2.1599999999999996e-05, 'epoch': 0.02}                                                                                                     
{'loss': 30.5266, 'learning_rate': 2.6999999999999996e-05, 'epoch': 0.03}                                                                                                     
{'loss': 16.5756, 'learning_rate': 3.2999999999999996e-05, 'epoch': 0.04}                                                                                                     
{'loss': 19.0495, 'learning_rate': 3.9e-05, 'epoch': 0.04}                                                                                                                    
{'loss': 15.567, 'learning_rate': 4.4999999999999996e-05, 'epoch': 0.05}                                                                                                      
{'loss': 10.8375, 'learning_rate': 5.1e-05, 'epoch': 0.06}                                                                                                                    
{'loss': 8.3571, 'learning_rate': 5.6999999999999996e-05, 'epoch': 0.06}                                                                                                      
  1%|â–Š                                                                                                                                  | 100/16170 [01:13<1:58:20,  2.26it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8

Traceback (most recent call last):â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 1125/1198 [04:51<00:26,  2.73it/s]
  File "/home/or/Desktop/wav2vec2/main.py", line 317, in <module>
    trainer.train()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1501, in train
    return inner_training_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1826, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2089, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2796, in evaluate
    output = eval_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2987, in evaluation_loop
    labels_host = labels if labels_host is None else nested_concat(labels_host, labels, padding_index=-100)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer_pt_utils.py", line 115, in nested_concat
    return torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_index)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer_pt_utils.py", line 80, in torch_pad_and_concatenate
    result = tensor1.new_full(new_shape, padding_index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.70 GiB (GPU 0; 15.75 GiB total capacity; 8.91 GiB already allocated; 819.81 MiB free; 13.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  1%|â–Š                                                                                                                                 | 100/16170 [06:05<16:18:09,  3.65s/it]

(base) or@anidjar:~/Desktop/wav2vec2$ python3 main.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
----------------- Loading Datasets complete. ----------


----------------- Loading Metrics... -----------------
/home/or/Desktop/wav2vec2/main.py:247: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['project_hid.weight', 'project_q.weight', 'project_q.bias', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'project_hid.bias', 'quantizer.codevectors']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 25867
  Num Epochs = 10
  Instantaneous batch size per device = 4
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 2
  Total optimization steps = 32330
  Number of trainable parameters = 311286969
  0%|                                                                                                                                               | 0/32330 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 19.1851, 'learning_rate': 4.8e-06, 'epoch': 0.0}                                                                                                                     
{'loss': 27.9093, 'learning_rate': 9.6e-06, 'epoch': 0.01}                                                                                                                    
{'loss': 31.395, 'learning_rate': 1.4999999999999999e-05, 'epoch': 0.01}                                                                                                      
{'loss': 32.0217, 'learning_rate': 2.1e-05, 'epoch': 0.01}                                                                                                                    
{'loss': 30.119, 'learning_rate': 2.6999999999999996e-05, 'epoch': 0.02}                                                                                                      
{'loss': 14.9173, 'learning_rate': 3.2999999999999996e-05, 'epoch': 0.02}                                                                                                     
{'loss': 17.3895, 'learning_rate': 3.9e-05, 'epoch': 0.02}                                                                                                                    
{'loss': 16.6684, 'learning_rate': 4.4999999999999996e-05, 'epoch': 0.02}                                                                                                     
{'loss': 13.1867, 'learning_rate': 5.1e-05, 'epoch': 0.03}                                                                                                                    
{'loss': 8.783, 'learning_rate': 5.6999999999999996e-05, 'epoch': 0.03}                                                                                                       
  0%|â–                                                                                                                                  | 100/32330 [00:46<2:42:02,  3.31it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 1.0, 'eval_cer': 0.9990541516245487, 'eval_runtime': 564.4507, 'eval_samples_per_second': 16.969, 'eval_steps_per_second': 2.122, 'epoch': 0.03}                                                                                                                                                                             
{'loss': 4.9757, 'learning_rate': 6.299999999999999e-05, 'epoch': 0.03}                                                                                                       
{'loss': 5.0792, 'learning_rate': 6.9e-05, 'epoch': 0.04}                                                                                                                     
{'loss': 4.528, 'learning_rate': 7.5e-05, 'epoch': 0.04}                                                                                                                      
{'loss': 4.0973, 'learning_rate': 8.1e-05, 'epoch': 0.04}                                                                                                                     
{'loss': 3.9732, 'learning_rate': 8.699999999999999e-05, 'epoch': 0.05}                                                                                                       
{'loss': 3.5, 'learning_rate': 9.3e-05, 'epoch': 0.05}                                                                                                                        
{'loss': 3.628, 'learning_rate': 9.9e-05, 'epoch': 0.05}                                                                                                                      
{'loss': 3.469, 'learning_rate': 0.00010499999999999999, 'epoch': 0.06}                                                                                                       
{'loss': 3.3705, 'learning_rate': 0.00011099999999999999, 'epoch': 0.06}                                                                                                      
{'loss': 3.3618, 'learning_rate': 0.000117, 'epoch': 0.06}                                                                                                                    
  1%|â–Š                                                                                                                                  | 200/32330 [10:55<2:46:24,  3.22it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 1.0, 'eval_cer': 0.9990541516245487, 'eval_runtime': 532.1649, 'eval_samples_per_second': 17.998, 'eval_steps_per_second': 2.251, 'epoch': 0.06}                                                                                                                                                                             
{'loss': 3.2741, 'learning_rate': 0.00012299999999999998, 'epoch': 0.06}                                                                                                      
{'loss': 3.3519, 'learning_rate': 0.000129, 'epoch': 0.07}                                                                                                                    
{'loss': 3.276, 'learning_rate': 0.000135, 'epoch': 0.07}                                                                                                                     
{'loss': 3.2659, 'learning_rate': 0.00014099999999999998, 'epoch': 0.07}                                                                                                      
{'loss': 3.3323, 'learning_rate': 0.000147, 'epoch': 0.08}                                                                                                                    
{'loss': 3.264, 'learning_rate': 0.00015299999999999998, 'epoch': 0.08}                                                                                                       
{'loss': 3.3159, 'learning_rate': 0.000159, 'epoch': 0.08}                                                                                                                    
{'loss': 3.2568, 'learning_rate': 0.000165, 'epoch': 0.09}                                                                                                                    
{'loss': 3.2772, 'learning_rate': 0.00017099999999999998, 'epoch': 0.09}                                                                                                      
{'loss': 3.3191, 'learning_rate': 0.00017699999999999997, 'epoch': 0.09}                                                                                                      
  1%|â–ˆâ–                                                                                                                                 | 300/32330 [20:31<2:37:24,  3.39it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 1.0, 'eval_cer': 0.9990541516245487, 'eval_runtime': 526.8529, 'eval_samples_per_second': 18.18, 'eval_steps_per_second': 2.274, 'epoch': 0.09}
{'loss': 3.2567, 'learning_rate': 0.00018299999999999998, 'epoch': 0.1}                                                                                                       
{'loss': 3.5068, 'learning_rate': 0.00018899999999999999, 'epoch': 0.1}                                                                                                       
{'loss': 3.3157, 'learning_rate': 0.000195, 'epoch': 0.1}                                                                                                                     
{'loss': 3.3202, 'learning_rate': 0.000201, 'epoch': 0.11}                                                                                                                    
{'loss': 3.3264, 'learning_rate': 0.00020699999999999996, 'epoch': 0.11}                                                                                                      
{'loss': 3.2529, 'learning_rate': 0.00021299999999999997, 'epoch': 0.11}                                                                                                      
{'loss': 3.2354, 'learning_rate': 0.00021899999999999998, 'epoch': 0.11}                                                                                                      
{'loss': 3.2486, 'learning_rate': 0.000225, 'epoch': 0.12}                                                                                                                    
{'loss': 3.215, 'learning_rate': 0.00023099999999999998, 'epoch': 0.12}                                                                                                       
{'loss': 3.2358, 'learning_rate': 0.000237, 'epoch': 0.12}                                                                                                                    
  1%|â–ˆâ–Œ                                                                                                                                 | 400/32330 [30:03<2:31:55,  3.50it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 1.0, 'eval_cer': 0.9990541516245487, 'eval_runtime': 526.7075, 'eval_samples_per_second': 18.185, 'eval_steps_per_second': 2.275, 'epoch': 0.12}                                                                                                                                                                             
{'loss': 3.4053, 'learning_rate': 0.00024239999999999998, 'epoch': 0.13}                                                                                                      
{'loss': 3.168, 'learning_rate': 0.00024839999999999997, 'epoch': 0.13}                                                                                                       
{'loss': 3.1498, 'learning_rate': 0.00025439999999999995, 'epoch': 0.13}                                                                                                      
{'loss': 3.1453, 'learning_rate': 0.0002604, 'epoch': 0.14}                                                                                                                   
{'loss': 3.1335, 'learning_rate': 0.00026639999999999997, 'epoch': 0.14}                                                                                                      
{'loss': 3.1704, 'learning_rate': 0.0002724, 'epoch': 0.14}                                                                                                                   
{'loss': 3.0877, 'learning_rate': 0.0002784, 'epoch': 0.15}                                                                                                                   
{'loss': 3.0897, 'learning_rate': 0.0002844, 'epoch': 0.15}                                                                                                                   
{'loss': 3.0762, 'learning_rate': 0.00029039999999999996, 'epoch': 0.15}                                                                                                      
{'loss': 3.0371, 'learning_rate': 0.0002964, 'epoch': 0.15}                                                                                                                   
  2%|â–ˆâ–ˆ                                                                                                                                 | 500/32330 [39:34<2:38:02,  3.36it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 1.0, 'eval_cer': 0.9990541516245487, 'eval_runtime': 525.2614, 'eval_samples_per_second': 18.235, 'eval_steps_per_second': 2.281, 'epoch': 0.15}                                                                                                                                                                             
{'loss': 3.4078, 'learning_rate': 0.00029996229971724785, 'epoch': 0.16}                                                                                                      
{'loss': 3.0306, 'learning_rate': 0.00029986804901036755, 'epoch': 0.16}                                                                                                      
{'loss': 2.9799, 'learning_rate': 0.00029977379830348726, 'epoch': 0.16}                                                                                                      
{'loss': 2.9785, 'learning_rate': 0.00029967954759660696, 'epoch': 0.17}                                                                                                      
{'loss': 2.9169, 'learning_rate': 0.00029958529688972667, 'epoch': 0.17}                                                                                                      
{'loss': 3.0057, 'learning_rate': 0.0002994910461828464, 'epoch': 0.17}                                                                                                       
{'loss': 2.9544, 'learning_rate': 0.000299396795475966, 'epoch': 0.18}                                                                                                        
{'loss': 2.9466, 'learning_rate': 0.00029930254476908573, 'epoch': 0.18}                                                                                                      
{'loss': 2.8772, 'learning_rate': 0.00029920829406220544, 'epoch': 0.18}                                                                                                      
{'loss': 2.8614, 'learning_rate': 0.00029911404335532514, 'epoch': 0.19}                                                                                                      
  2%|â–ˆâ–ˆâ–                                                                                                                                | 600/32330 [49:05<2:38:50,  3.33it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 1.0, 'eval_cer': 0.9990541516245487, 'eval_runtime': 534.318, 'eval_samples_per_second': 17.926, 'eval_steps_per_second': 2.242, 'epoch': 0.19}
{'loss': 3.0064, 'learning_rate': 0.00029902921771913284, 'epoch': 0.19}                                                                                                      
{'loss': 2.6918, 'learning_rate': 0.00029893496701225255, 'epoch': 0.19}                                                                                                      
{'loss': 2.5301, 'learning_rate': 0.00029884071630537225, 'epoch': 0.19}                                                                                                      
{'loss': 2.6098, 'learning_rate': 0.00029874646559849196, 'epoch': 0.2}                                                                                                       
{'loss': 2.3796, 'learning_rate': 0.00029865221489161167, 'epoch': 0.2}                                                                                                       
{'loss': 2.2471, 'learning_rate': 0.00029855796418473137, 'epoch': 0.2}                                                                                                       
{'loss': 1.9801, 'learning_rate': 0.0002984637134778511, 'epoch': 0.21}                                                                                                       
{'loss': 1.9764, 'learning_rate': 0.0002983694627709708, 'epoch': 0.21}                                                                                                       
{'loss': 1.9577, 'learning_rate': 0.00029827521206409044, 'epoch': 0.21}                                                                                                      
{'loss': 1.7541, 'learning_rate': 0.00029818096135721014, 'epoch': 0.22}                                                                                                      
  2%|â–ˆâ–ˆâ–Š                                                                                                                                | 700/32330 [58:46<2:42:08,  3.25it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 1.0208938501120426, 'eval_cer': 0.6320770156438027, 'eval_runtime': 528.9617, 'eval_samples_per_second': 18.107, 'eval_steps_per_second': 2.265, 'epoch': 0.22}                                                                                                                                                              
{'loss': 1.6871, 'learning_rate': 0.00029808671065032985, 'epoch': 0.22}                                                                                                      
{'loss': 1.6052, 'learning_rate': 0.00029799245994344955, 'epoch': 0.22}                                                                                                      
{'loss': 1.4466, 'learning_rate': 0.00029789820923656926, 'epoch': 0.23}                                                                                                      
{'loss': 1.5191, 'learning_rate': 0.00029780395852968897, 'epoch': 0.23}                                                                                                      
{'loss': 1.6585, 'learning_rate': 0.00029770970782280867, 'epoch': 0.23}                                                                                                      
{'loss': 1.7849, 'learning_rate': 0.0002976154571159283, 'epoch': 0.24}                                                                                                       
{'loss': 1.3949, 'learning_rate': 0.00029752120640904803, 'epoch': 0.24}                                                                                                      
{'loss': 1.4155, 'learning_rate': 0.00029742695570216774, 'epoch': 0.24}                                                                                                      
{'loss': 1.3808, 'learning_rate': 0.00029733270499528744, 'epoch': 0.24}                                                                                                      
{'loss': 1.4031, 'learning_rate': 0.00029723845428840715, 'epoch': 0.25}                                                                                                      
  2%|â–ˆâ–ˆâ–ˆâ–                                                                                                                             | 800/32330 [1:08:21<2:34:02,  3.41it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 1.0192754585442776, 'eval_cer': 0.5758387484957882, 'eval_runtime': 529.3604, 'eval_samples_per_second': 18.094, 'eval_steps_per_second': 2.263, 'epoch': 0.25}                                                                                                                                                              
{'loss': 1.2075, 'learning_rate': 0.00029714420358152685, 'epoch': 0.25}                                                                                                      
{'loss': 1.2599, 'learning_rate': 0.00029704995287464656, 'epoch': 0.25}                                                                                                      
{'loss': 1.1464, 'learning_rate': 0.00029695570216776627, 'epoch': 0.26}                                                                                                      
{'loss': 1.1141, 'learning_rate': 0.0002968614514608859, 'epoch': 0.26}                                                                                                       
{'loss': 1.4204, 'learning_rate': 0.0002967672007540056, 'epoch': 0.26}                                                                                                       
{'loss': 1.2141, 'learning_rate': 0.00029667295004712533, 'epoch': 0.27}                                                                                                      
{'loss': 1.1196, 'learning_rate': 0.00029657869934024503, 'epoch': 0.27}                                                                                                      
{'loss': 1.1516, 'learning_rate': 0.0002964844486333647, 'epoch': 0.27}                                                                                                       
{'loss': 1.0233, 'learning_rate': 0.0002963901979264844, 'epoch': 0.28}                                                                                                       
{'loss': 1.2566, 'learning_rate': 0.00029629594721960415, 'epoch': 0.28}                                                                                                      
  3%|â–ˆâ–ˆâ–ˆâ–Œ                                                                                                                             | 900/32330 [1:17:54<2:38:29,  3.31it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 1.0524524856834592, 'eval_cer': 0.5257569193742478, 'eval_runtime': 528.292, 'eval_samples_per_second': 18.13, 'eval_steps_per_second': 2.268, 'epoch': 0.28}                                                                                                                                                                
{'loss': 1.0693, 'learning_rate': 0.0002962016965127238, 'epoch': 0.28}                                                                                                       
{'loss': 0.989, 'learning_rate': 0.0002961074458058435, 'epoch': 0.28}                                                                                                        
{'loss': 0.9697, 'learning_rate': 0.0002960131950989632, 'epoch': 0.29}                                                                                                       
{'loss': 1.044, 'learning_rate': 0.0002959189443920829, 'epoch': 0.29}                                                                                                        
{'loss': 1.1693, 'learning_rate': 0.00029582469368520263, 'epoch': 0.29}                                                                                                      
{'loss': 1.3125, 'learning_rate': 0.0002957304429783223, 'epoch': 0.3}                                                                                                        
{'loss': 0.9018, 'learning_rate': 0.000295636192271442, 'epoch': 0.3}                                                                                                         
{'loss': 0.8567, 'learning_rate': 0.00029554194156456175, 'epoch': 0.3}                                                                                                       
{'loss': 1.081, 'learning_rate': 0.0002954476908576814, 'epoch': 0.31}                                                                                                        
{'loss': 1.2661, 'learning_rate': 0.0002953534401508011, 'epoch': 0.31}                                                                                                       
  3%|â–ˆâ–ˆâ–ˆâ–‰                                                                                                                            | 1000/32330 [1:27:28<2:33:53,  3.39it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.9637521786040335, 'eval_cer': 0.5000890493381468, 'eval_runtime': 528.5293, 'eval_samples_per_second': 18.122, 'eval_steps_per_second': 2.267, 'epoch': 0.31}                                                                                                                                                              
{'loss': 0.856, 'learning_rate': 0.0002952591894439208, 'epoch': 0.31}                                                                                                        
{'loss': 0.9001, 'learning_rate': 0.0002951649387370405, 'epoch': 0.32}                                                                                                       
{'loss': 0.8705, 'learning_rate': 0.0002950706880301602, 'epoch': 0.32}                                                                                                       
{'loss': 0.8559, 'learning_rate': 0.0002949764373232799, 'epoch': 0.32}                                                                                                       
{'loss': 1.0512, 'learning_rate': 0.0002948821866163996, 'epoch': 0.32}                                                                                                       
{'loss': 1.232, 'learning_rate': 0.0002947879359095193, 'epoch': 0.33}                                                                                                        
{'loss': 0.9141, 'learning_rate': 0.000294693685202639, 'epoch': 0.33}                                                                                                        
{'loss': 0.866, 'learning_rate': 0.0002945994344957587, 'epoch': 0.33}                                                                                                        
{'loss': 0.9525, 'learning_rate': 0.0002945051837888784, 'epoch': 0.34}                                                                                                       
{'loss': 0.8396, 'learning_rate': 0.0002944109330819981, 'epoch': 0.34}                                                                                                       
  3%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                           | 1100/32330 [1:37:02<2:40:01,  3.25it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.9733172877417213, 'eval_cer': 0.49814440433213, 'eval_runtime': 528.5629, 'eval_samples_per_second': 18.121, 'eval_steps_per_second': 2.267, 'epoch': 0.34}                                                                                                                                                                
{'loss': 1.0373, 'learning_rate': 0.00029431668237511776, 'epoch': 0.34}                                                                                                      
{'loss': 0.873, 'learning_rate': 0.00029422243166823747, 'epoch': 0.35}                                                                                                       
{'loss': 0.7808, 'learning_rate': 0.0002941281809613572, 'epoch': 0.35}                                                                                                       
{'loss': 0.9235, 'learning_rate': 0.0002940339302544769, 'epoch': 0.35}                                                                                                       
{'loss': 1.0471, 'learning_rate': 0.0002939396795475966, 'epoch': 0.36}                                                                                                       
{'loss': 1.1916, 'learning_rate': 0.0002938454288407163, 'epoch': 0.36}                                                                                                       
{'loss': 1.0268, 'learning_rate': 0.000293751178133836, 'epoch': 0.36}                                                                                                        
{'loss': 0.8137, 'learning_rate': 0.0002936569274269557, 'epoch': 0.36}                                                                                                       
{'loss': 0.8648, 'learning_rate': 0.00029356267672007535, 'epoch': 0.37}                                                                                                      
{'loss': 1.0068, 'learning_rate': 0.00029346842601319506, 'epoch': 0.37}                                                                                                      
  4%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                           | 1200/32330 [1:46:36<2:32:36,  3.40it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.9210930367665366, 'eval_cer': 0.4823225030084236, 'eval_runtime': 528.0756, 'eval_samples_per_second': 18.138, 'eval_steps_per_second': 2.269, 'epoch': 0.37}                                                                                                                                                              
{'loss': 0.7341, 'learning_rate': 0.00029337417530631477, 'epoch': 0.37}                                                                                                      
{'loss': 0.6405, 'learning_rate': 0.00029327992459943447, 'epoch': 0.38}                                                                                                      
{'loss': 0.8024, 'learning_rate': 0.0002931856738925542, 'epoch': 0.38}                                                                                                       
{'loss': 0.8447, 'learning_rate': 0.0002930914231856739, 'epoch': 0.38}                                                                                                       
{'loss': 1.0018, 'learning_rate': 0.0002929971724787936, 'epoch': 0.39}                                                                                                       
{'loss': 0.9201, 'learning_rate': 0.00029290292177191324, 'epoch': 0.39}                                                                                                      
{'loss': 0.7467, 'learning_rate': 0.00029280867106503295, 'epoch': 0.39}                                                                                                      
{'loss': 0.7104, 'learning_rate': 0.00029271442035815265, 'epoch': 0.4}                                                                                                       
{'loss': 0.905, 'learning_rate': 0.00029262016965127236, 'epoch': 0.4}                                                                                                        
{'loss': 0.9608, 'learning_rate': 0.00029252591894439207, 'epoch': 0.4}                                                                                                       
  4%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                          | 1300/32330 [1:56:10<2:39:35,  3.24it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.902689019835671, 'eval_cer': 0.47410589651022866, 'eval_runtime': 534.8394, 'eval_samples_per_second': 17.908, 'eval_steps_per_second': 2.24, 'epoch': 0.4}                                                                                                                                                                
{'loss': 0.8417, 'learning_rate': 0.0002924316682375117, 'epoch': 0.41}                                                                                                       
{'loss': 0.742, 'learning_rate': 0.0002923374175306315, 'epoch': 0.41}                                                                                                        
{'loss': 0.7027, 'learning_rate': 0.0002922431668237512, 'epoch': 0.41}                                                                                                       
{'loss': 0.7301, 'learning_rate': 0.00029214891611687084, 'epoch': 0.41}                                                                                                      
{'loss': 0.8914, 'learning_rate': 0.00029205466540999054, 'epoch': 0.42}                                                                                                      
{'loss': 0.6372, 'learning_rate': 0.00029196041470311025, 'epoch': 0.42}                                                                                                      
{'loss': 0.6545, 'learning_rate': 0.00029186616399622995, 'epoch': 0.42}                                                                                                      
{'loss': 0.7721, 'learning_rate': 0.00029177191328934966, 'epoch': 0.43}                                                                                                      
{'loss': 0.7286, 'learning_rate': 0.0002916776625824693, 'epoch': 0.43}                                                                                                       
{'loss': 0.9047, 'learning_rate': 0.00029158341187558907, 'epoch': 0.43}                                                                                                      
  4%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                          | 1400/32330 [2:05:50<2:31:11,  3.41it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.9070669765125736, 'eval_cer': 0.4753116726835138, 'eval_runtime': 528.7364, 'eval_samples_per_second': 18.115, 'eval_steps_per_second': 2.266, 'epoch': 0.43}                                                                                                                                                              
{'loss': 1.6739, 'learning_rate': 0.0002914891611687088, 'epoch': 0.44}                                                                                                       
{'loss': 0.6577, 'learning_rate': 0.00029139491046182843, 'epoch': 0.44}                                                                                                      
{'loss': 0.6592, 'learning_rate': 0.00029130065975494814, 'epoch': 0.44}                                                                                                      
{'loss': 0.7618, 'learning_rate': 0.00029120640904806784, 'epoch': 0.45}                                                                                                      
{'loss': 0.9876, 'learning_rate': 0.00029111215834118755, 'epoch': 0.45}                                                                                                      
{'loss': 1.1164, 'learning_rate': 0.0002910179076343072, 'epoch': 0.45}                                                                                                       
{'loss': 0.7264, 'learning_rate': 0.0002909236569274269, 'epoch': 0.45}                                                                                                       
{'loss': 0.6344, 'learning_rate': 0.0002908294062205466, 'epoch': 0.46}                                                                                                       
{'loss': 0.7436, 'learning_rate': 0.0002907351555136663, 'epoch': 0.46}                                                                                                       
{'loss': 1.0148, 'learning_rate': 0.000290640904806786, 'epoch': 0.46}                                                                                                        
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                          | 1500/32330 [2:15:24<2:41:24,  3.18it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.9134990455639472, 'eval_cer': 0.4779903730445247, 'eval_runtime': 534.5496, 'eval_samples_per_second': 17.918, 'eval_steps_per_second': 2.241, 'epoch': 0.46}                                                                                                                                                              
{'loss': 0.6688, 'learning_rate': 0.00029054665409990573, 'epoch': 0.47}                                                                                                      
{'loss': 0.5748, 'learning_rate': 0.00029045240339302543, 'epoch': 0.47}                                                                                                      
{'loss': 0.8539, 'learning_rate': 0.00029035815268614514, 'epoch': 0.47}                                                                                                      
{'loss': 0.5965, 'learning_rate': 0.0002902639019792648, 'epoch': 0.48}                                                                                                       
{'loss': 0.8664, 'learning_rate': 0.0002901696512723845, 'epoch': 0.48}                                                                                                       
{'loss': 1.1605, 'learning_rate': 0.0002900754005655042, 'epoch': 0.48}                                                                                                       
{'loss': 0.6565, 'learning_rate': 0.0002899811498586239, 'epoch': 0.49}                                                                                                       
{'loss': 0.6329, 'learning_rate': 0.0002898868991517436, 'epoch': 0.49}                                                                                                       
{'loss': 0.656, 'learning_rate': 0.0002897926484448633, 'epoch': 0.49}                                                                                                        
{'loss': 1.1049, 'learning_rate': 0.00028969839773798303, 'epoch': 0.49}                                                                                                      
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                         | 1600/32330 [2:25:05<2:29:38,  3.42it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8953440119511993, 'eval_cer': 0.4735980746089049, 'eval_runtime': 528.0657, 'eval_samples_per_second': 18.138, 'eval_steps_per_second': 2.269, 'epoch': 0.49}                                                                                                                                                              
{'loss': 0.6601, 'learning_rate': 0.0002896041470311027, 'epoch': 0.5}                                                                                                        
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                        | 1616/32330 [2:34:03<10:27:09,  1.23s/it]Saving model checkpoint to turkish_clean/checkpoint-1616
Configuration saved in turkish_clean/checkpoint-1616/config.json
Model weights saved in turkish_clean/checkpoint-1616/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-1616/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.8165, 'learning_rate': 0.0002895098963242224, 'epoch': 0.5}                                                                                                        
{'loss': 0.6927, 'learning_rate': 0.0002894156456173421, 'epoch': 0.5}                                                                                                        
{'loss': 0.6964, 'learning_rate': 0.0002893213949104618, 'epoch': 0.51}                                                                                                       
{'loss': 0.8894, 'learning_rate': 0.0002892271442035815, 'epoch': 0.51}                                                                                                       
{'loss': 1.127, 'learning_rate': 0.0002891328934967012, 'epoch': 0.51}                                                                                                        
{'loss': 0.6207, 'learning_rate': 0.0002890386427898209, 'epoch': 0.52}                                                                                                       
{'loss': 0.6505, 'learning_rate': 0.0002889443920829406, 'epoch': 0.52}                                                                                                       
{'loss': 0.7505, 'learning_rate': 0.0002888501413760603, 'epoch': 0.52}                                                                                                       
{'loss': 0.7853, 'learning_rate': 0.00028875589066918, 'epoch': 0.53}                                                                                                         
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                         | 1700/32330 [2:34:40<2:30:53,  3.38it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8555274296622126, 'eval_cer': 0.4561612515042118, 'eval_runtime': 537.3593, 'eval_samples_per_second': 17.824, 'eval_steps_per_second': 2.229, 'epoch': 0.53}                                                                                                                                                              
{'loss': 0.6486, 'learning_rate': 0.0002886616399622997, 'epoch': 0.53}                                                                                                       
{'loss': 0.5726, 'learning_rate': 0.0002885673892554194, 'epoch': 0.53}                                                                                                       
{'loss': 0.6053, 'learning_rate': 0.0002884731385485391, 'epoch': 0.54}                                                                                                       
{'loss': 0.6825, 'learning_rate': 0.0002883788878416588, 'epoch': 0.54}                                                                                                       
{'loss': 0.8731, 'learning_rate': 0.0002882846371347785, 'epoch': 0.54}                                                                                                       
{'loss': 0.7676, 'learning_rate': 0.0002881903864278982, 'epoch': 0.54}                                                                                                       
{'loss': 0.7052, 'learning_rate': 0.00028809613572101787, 'epoch': 0.55}                                                                                                      
{'loss': 0.6342, 'learning_rate': 0.0002880018850141376, 'epoch': 0.55}                                                                                                       
{'loss': 0.6095, 'learning_rate': 0.0002879076343072573, 'epoch': 0.55}                                                                                                       
{'loss': 0.9007, 'learning_rate': 0.000287813383600377, 'epoch': 0.56}                                                                                                        
  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                        | 1800/32330 [2:44:23<2:31:53,  3.35it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.9092870777657897, 'eval_cer': 0.46430565583634176, 'eval_runtime': 529.5853, 'eval_samples_per_second': 18.086, 'eval_steps_per_second': 2.262, 'epoch': 0.56}                                                                                                                                                             
{'loss': 1.0804, 'learning_rate': 0.00028771913289349664, 'epoch': 0.56}                                                                                                      
{'loss': 0.6338, 'learning_rate': 0.0002876248821866164, 'epoch': 0.56}                                                                                                       
{'loss': 0.5489, 'learning_rate': 0.0002875306314797361, 'epoch': 0.57}                                                                                                       
{'loss': 0.6004, 'learning_rate': 0.00028743638077285575, 'epoch': 0.57}                                                                                                      
{'loss': 0.9326, 'learning_rate': 0.00028734213006597546, 'epoch': 0.57}                                                                                                      
{'loss': 0.5628, 'learning_rate': 0.00028724787935909517, 'epoch': 0.58}                                                                                                      
{'loss': 0.588, 'learning_rate': 0.00028715362865221487, 'epoch': 0.58}                                                                                                       
{'loss': 0.6417, 'learning_rate': 0.0002870593779453346, 'epoch': 0.58}                                                                                                       
{'loss': 0.6034, 'learning_rate': 0.00028696512723845423, 'epoch': 0.58}                                                                                                      
{'loss': 0.8674, 'learning_rate': 0.00028687087653157394, 'epoch': 0.59}                                                                                                      
  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                        | 1900/32330 [2:53:58<2:32:51,  3.32it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8701551996016267, 'eval_cer': 0.45903249097472926, 'eval_runtime': 534.3169, 'eval_samples_per_second': 17.926, 'eval_steps_per_second': 2.242, 'epoch': 0.59}                                                                                                                                                             
{'loss': 0.7713, 'learning_rate': 0.0002867766258246937, 'epoch': 0.59}                                                                                                       
{'loss': 0.5775, 'learning_rate': 0.00028668237511781335, 'epoch': 0.59}                                                                                                      
{'loss': 0.6053, 'learning_rate': 0.00028658812441093305, 'epoch': 0.6}                                                                                                       
{'loss': 0.6267, 'learning_rate': 0.00028649387370405276, 'epoch': 0.6}                                                                                                       
{'loss': 0.7727, 'learning_rate': 0.00028639962299717247, 'epoch': 0.6}                                                                                                       
{'loss': 0.6999, 'learning_rate': 0.00028630537229029217, 'epoch': 0.61}                                                                                                      
{'loss': 0.6342, 'learning_rate': 0.0002862111215834118, 'epoch': 0.61}                                                                                                       
{'loss': 0.6662, 'learning_rate': 0.00028611687087653153, 'epoch': 0.61}                                                                                                      
{'loss': 0.6282, 'learning_rate': 0.00028602262016965124, 'epoch': 0.62}                                                                                                      
{'loss': 0.7724, 'learning_rate': 0.00028592836946277094, 'epoch': 0.62}                                                                                                      
  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                        | 2000/32330 [3:03:37<2:29:51,  3.37it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8509627354967217, 'eval_cer': 0.4498628158844765, 'eval_runtime': 530.0396, 'eval_samples_per_second': 18.07, 'eval_steps_per_second': 2.26, 'epoch': 0.62}                                                                                                                                                                
{'loss': 0.6688, 'learning_rate': 0.00028583411875589065, 'epoch': 0.62}                                                                                                      
{'loss': 0.6194, 'learning_rate': 0.00028573986804901035, 'epoch': 0.62}                                                                                                      
{'loss': 0.6434, 'learning_rate': 0.00028564561734213006, 'epoch': 0.63}                                                                                                      
{'loss': 0.6201, 'learning_rate': 0.0002855513666352497, 'epoch': 0.63}                                                                                                       
{'loss': 0.8042, 'learning_rate': 0.0002854571159283694, 'epoch': 0.63}                                                                                                       
{'loss': 0.9727, 'learning_rate': 0.0002853628652214891, 'epoch': 0.64}                                                                                                       
{'loss': 0.5762, 'learning_rate': 0.00028526861451460883, 'epoch': 0.64}                                                                                                      
{'loss': 0.5649, 'learning_rate': 0.00028517436380772854, 'epoch': 0.64}                                                                                                      
{'loss': 0.5616, 'learning_rate': 0.00028508011310084824, 'epoch': 0.65}                                                                                                      
{'loss': 0.8577, 'learning_rate': 0.00028498586239396795, 'epoch': 0.65}                                                                                                      
  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                       | 2100/32330 [3:13:12<2:27:22,  3.42it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8710473898248817, 'eval_cer': 0.4547412755716005, 'eval_runtime': 528.6565, 'eval_samples_per_second': 18.118, 'eval_steps_per_second': 2.266, 'epoch': 0.65}                                                                                                                                                              
{'loss': 0.653, 'learning_rate': 0.00028489161168708765, 'epoch': 0.65}                                                                                                       
{'loss': 0.5968, 'learning_rate': 0.0002847973609802073, 'epoch': 0.66}                                                                                                       
{'loss': 0.5819, 'learning_rate': 0.000284703110273327, 'epoch': 0.66}                                                                                                        
{'loss': 0.6442, 'learning_rate': 0.0002846088595664467, 'epoch': 0.66}                                                                                                       
{'loss': 0.8092, 'learning_rate': 0.0002845146088595664, 'epoch': 0.66}                                                                                                       
{'loss': 0.7303, 'learning_rate': 0.00028442035815268613, 'epoch': 0.67}                                                                                                      
{'loss': 0.5176, 'learning_rate': 0.00028432610744580583, 'epoch': 0.67}                                                                                                      
{'loss': 0.5326, 'learning_rate': 0.00028423185673892554, 'epoch': 0.67}                                                                                                      
{'loss': 0.548, 'learning_rate': 0.0002841376060320452, 'epoch': 0.68}                                                                                                        
{'loss': 0.8784, 'learning_rate': 0.0002840433553251649, 'epoch': 0.68}                                                                                                       
  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                       | 2200/32330 [3:22:45<2:26:27,  3.43it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8439912025894265, 'eval_cer': 0.450820697954272, 'eval_runtime': 527.4735, 'eval_samples_per_second': 18.158, 'eval_steps_per_second': 2.271, 'epoch': 0.68}                                                                                                                                                               
{'loss': 1.2712, 'learning_rate': 0.0002839491046182846, 'epoch': 0.68}                                                                                                       
{'loss': 0.5587, 'learning_rate': 0.0002838548539114043, 'epoch': 0.69}                                                                                                       
{'loss': 0.5704, 'learning_rate': 0.000283760603204524, 'epoch': 0.69}                                                                                                        
{'loss': 0.6446, 'learning_rate': 0.0002836663524976437, 'epoch': 0.69}                                                                                                       
{'loss': 0.8491, 'learning_rate': 0.00028357210179076343, 'epoch': 0.7}                                                                                                       
{'loss': 0.5564, 'learning_rate': 0.00028347785108388313, 'epoch': 0.7}                                                                                                       
{'loss': 0.8987, 'learning_rate': 0.0002833836003770028, 'epoch': 0.7}                                                                                                        
{'loss': 0.4653, 'learning_rate': 0.0002832893496701225, 'epoch': 0.71}                                                                                                       
{'loss': 0.5385, 'learning_rate': 0.0002831950989632422, 'epoch': 0.71}                                                                                                       
{'loss': 0.695, 'learning_rate': 0.0002831008482563619, 'epoch': 0.71}                                                                                                        
  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                       | 2300/32330 [3:32:17<2:30:16,  3.33it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8552162005145655, 'eval_cer': 0.4487701564380265, 'eval_runtime': 534.5509, 'eval_samples_per_second': 17.918, 'eval_steps_per_second': 2.241, 'epoch': 0.71}                                                                                                                                                              
{'loss': 0.9814, 'learning_rate': 0.0002830065975494816, 'epoch': 0.71}                                                                                                       
{'loss': 0.8002, 'learning_rate': 0.00028291234684260126, 'epoch': 0.72}                                                                                                      
{'loss': 0.5325, 'learning_rate': 0.000282818096135721, 'epoch': 0.72}                                                                                                        
{'loss': 0.6225, 'learning_rate': 0.0002827238454288407, 'epoch': 0.72}                                                                                                       
{'loss': 0.8307, 'learning_rate': 0.0002826295947219604, 'epoch': 0.73}                                                                                                       
{'loss': 0.8135, 'learning_rate': 0.0002825353440150801, 'epoch': 0.73}                                                                                                       
{'loss': 0.5191, 'learning_rate': 0.0002824410933081998, 'epoch': 0.73}                                                                                                       
{'loss': 0.5964, 'learning_rate': 0.0002823468426013195, 'epoch': 0.74}                                                                                                       
{'loss': 0.5791, 'learning_rate': 0.00028225259189443915, 'epoch': 0.74}                                                                                                      
{'loss': 0.7611, 'learning_rate': 0.00028215834118755886, 'epoch': 0.74}                                                                                                      
  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                      | 2400/32330 [3:41:56<2:24:22,  3.46it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8441571914681716, 'eval_cer': 0.44804091456077016, 'eval_runtime': 527.6076, 'eval_samples_per_second': 18.154, 'eval_steps_per_second': 2.271, 'epoch': 0.74}                                                                                                                                                             
{'loss': 0.6713, 'learning_rate': 0.0002820640904806786, 'epoch': 0.75}                                                                                                       
{'loss': 0.606, 'learning_rate': 0.00028196983977379827, 'epoch': 0.75}                                                                                                       
{'loss': 0.5623, 'learning_rate': 0.000281875589066918, 'epoch': 0.75}                                                                                                        
{'loss': 0.6931, 'learning_rate': 0.0002817813383600377, 'epoch': 0.75}                                                                                                       
{'loss': 0.7973, 'learning_rate': 0.0002816870876531574, 'epoch': 0.76}                                                                                                       
{'loss': 0.5227, 'learning_rate': 0.0002815928369462771, 'epoch': 0.76}                                                                                                       
{'loss': 0.5236, 'learning_rate': 0.00028149858623939674, 'epoch': 0.76}                                                                                                      
{'loss': 0.5693, 'learning_rate': 0.00028140433553251645, 'epoch': 0.77}                                                                                                      
{'loss': 0.6442, 'learning_rate': 0.0002813100848256362, 'epoch': 0.77}                                                                                                       
{'loss': 0.6773, 'learning_rate': 0.00028121583411875586, 'epoch': 0.77}                                                                                                      
  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                      | 2500/32330 [3:51:29<2:25:44,  3.41it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8322059921985226, 'eval_cer': 0.4458339350180505, 'eval_runtime': 525.811, 'eval_samples_per_second': 18.216, 'eval_steps_per_second': 2.278, 'epoch': 0.77}                                                                                                                                                               
{'loss': 0.5954, 'learning_rate': 0.00028112158341187557, 'epoch': 0.78}                                                                                                      
{'loss': 0.419, 'learning_rate': 0.00028102733270499527, 'epoch': 0.78}                                                                                                       
{'loss': 0.5197, 'learning_rate': 0.000280933081998115, 'epoch': 0.78}                                                                                                        
{'loss': 0.5356, 'learning_rate': 0.00028083883129123463, 'epoch': 0.79}                                                                                                      
{'loss': 0.8667, 'learning_rate': 0.00028074458058435434, 'epoch': 0.79}                                                                                                      
{'loss': 0.9067, 'learning_rate': 0.00028065032987747404, 'epoch': 0.79}                                                                                                      
{'loss': 0.4353, 'learning_rate': 0.00028055607917059375, 'epoch': 0.79}                                                                                                      
{'loss': 0.5351, 'learning_rate': 0.00028046182846371345, 'epoch': 0.8}                                                                                                       
{'loss': 0.5154, 'learning_rate': 0.00028036757775683316, 'epoch': 0.8}                                                                                                       
{'loss': 0.7527, 'learning_rate': 0.00028027332704995287, 'epoch': 0.8}                                                                                                       
  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                     | 2600/32330 [4:01:00<2:27:16,  3.36it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8361274794588762, 'eval_cer': 0.446173285198556, 'eval_runtime': 526.5646, 'eval_samples_per_second': 18.19, 'eval_steps_per_second': 2.275, 'epoch': 0.8}                                                                                                                                                                 
{'loss': 0.4904, 'learning_rate': 0.00028017907634307257, 'epoch': 0.81}                                                                                                      
{'loss': 0.5051, 'learning_rate': 0.0002800848256361922, 'epoch': 0.81}                                                                                                       
{'loss': 0.5126, 'learning_rate': 0.00027999057492931193, 'epoch': 0.81}                                                                                                      
{'loss': 0.571, 'learning_rate': 0.00027989632422243164, 'epoch': 0.82}                                                                                                       
{'loss': 0.8265, 'learning_rate': 0.00027980207351555134, 'epoch': 0.82}                                                                                                      
{'loss': 0.5803, 'learning_rate': 0.00027970782280867105, 'epoch': 0.82}                                                                                                      
{'loss': 0.5125, 'learning_rate': 0.00027961357210179075, 'epoch': 0.83}                                                                                                      
{'loss': 0.5289, 'learning_rate': 0.00027951932139491046, 'epoch': 0.83}                                                                                                      
{'loss': 0.5983, 'learning_rate': 0.00027942507068803017, 'epoch': 0.83}                                                                                                      
{'loss': 0.8196, 'learning_rate': 0.0002793308199811498, 'epoch': 0.84}                                                                                                       
  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                     | 2700/32330 [4:10:32<2:26:22,  3.37it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8330151879824051, 'eval_cer': 0.4522117930204573, 'eval_runtime': 528.0455, 'eval_samples_per_second': 18.139, 'eval_steps_per_second': 2.269, 'epoch': 0.84}                                                                                                                                                              
{'loss': 0.586, 'learning_rate': 0.0002792365692742695, 'epoch': 0.84}                                                                                                        
{'loss': 0.4519, 'learning_rate': 0.00027914231856738923, 'epoch': 0.84}                                                                                                      
{'loss': 0.531, 'learning_rate': 0.00027904806786050894, 'epoch': 0.84}                                                                                                       
{'loss': 0.5873, 'learning_rate': 0.0002789538171536286, 'epoch': 0.85}                                                                                                       
{'loss': 0.6447, 'learning_rate': 0.00027885956644674835, 'epoch': 0.85}                                                                                                      
{'loss': 0.5879, 'learning_rate': 0.00027876531573986805, 'epoch': 0.85}                                                                                                      
{'loss': 0.423, 'learning_rate': 0.0002786710650329877, 'epoch': 0.86}                                                                                                        
{'loss': 0.4569, 'learning_rate': 0.0002785768143261074, 'epoch': 0.86}                                                                                                       
{'loss': 0.586, 'learning_rate': 0.0002784825636192271, 'epoch': 0.86}                                                                                                        
{'loss': 0.844, 'learning_rate': 0.0002783883129123468, 'epoch': 0.87}                                                                                                        
  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                     | 2800/32330 [4:20:05<2:18:57,  3.54it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8275998008133455, 'eval_cer': 0.44336221419975935, 'eval_runtime': 528.0576, 'eval_samples_per_second': 18.138, 'eval_steps_per_second': 2.269, 'epoch': 0.87}                                                                                                                                                             
{'loss': 0.5079, 'learning_rate': 0.00027829406220546653, 'epoch': 0.87}                                                                                                      
{'loss': 0.5236, 'learning_rate': 0.0002781998114985862, 'epoch': 0.87}                                                                                                       
{'loss': 0.4462, 'learning_rate': 0.00027810556079170594, 'epoch': 0.88}                                                                                                      
{'loss': 0.5774, 'learning_rate': 0.00027801131008482565, 'epoch': 0.88}                                                                                                      
{'loss': 0.6503, 'learning_rate': 0.0002779170593779453, 'epoch': 0.88}                                                                                                       
{'loss': 0.5729, 'learning_rate': 0.000277822808671065, 'epoch': 0.88}                                                                                                        
{'loss': 0.5018, 'learning_rate': 0.0002777285579641847, 'epoch': 0.89}                                                                                                       
{'loss': 0.4499, 'learning_rate': 0.0002776343072573044, 'epoch': 0.89}                                                                                                       
{'loss': 0.5605, 'learning_rate': 0.00027754005655042407, 'epoch': 0.89}                                                                                                      
{'loss': 0.8454, 'learning_rate': 0.0002774458058435438, 'epoch': 0.9}                                                                                                        
  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                    | 2900/32330 [4:29:38<2:29:47,  3.27it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8354635239438958, 'eval_cer': 0.4516341756919374, 'eval_runtime': 534.1147, 'eval_samples_per_second': 17.932, 'eval_steps_per_second': 2.243, 'epoch': 0.9}                                                                                                                                                               
{'loss': 0.7027, 'learning_rate': 0.00027735155513666353, 'epoch': 0.9}                                                                                                       
{'loss': 0.5578, 'learning_rate': 0.0002772573044297832, 'epoch': 0.9}                                                                                                        
{'loss': 0.7388, 'learning_rate': 0.0002771630537229029, 'epoch': 0.91}                                                                                                       
{'loss': 0.5364, 'learning_rate': 0.0002770688030160226, 'epoch': 0.91}                                                                                                       
{'loss': 0.7647, 'learning_rate': 0.0002769745523091423, 'epoch': 0.91}                                                                                                       
{'loss': 0.8109, 'learning_rate': 0.000276880301602262, 'epoch': 0.92}                                                                                                        
{'loss': 0.596, 'learning_rate': 0.00027678605089538166, 'epoch': 0.92}                                                                                                       
{'loss': 0.4499, 'learning_rate': 0.00027669180018850137, 'epoch': 0.92}                                                                                                      
{'loss': 0.5153, 'learning_rate': 0.0002765975494816211, 'epoch': 0.92}                                                                                                       
{'loss': 0.6837, 'learning_rate': 0.0002765032987747408, 'epoch': 0.93}                                                                                                       
  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                    | 3000/32330 [4:39:18<2:27:28,  3.31it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.806705950701303, 'eval_cer': 0.44544404332129967, 'eval_runtime': 535.18, 'eval_samples_per_second': 17.897, 'eval_steps_per_second': 2.238, 'epoch': 0.93}                                                                                                                                                                
{'loss': 0.6794, 'learning_rate': 0.0002764090480678605, 'epoch': 0.93}                                                                                                       
{'loss': 0.5891, 'learning_rate': 0.0002763147973609802, 'epoch': 0.93}                                                                                                       
{'loss': 0.5492, 'learning_rate': 0.0002762205466540999, 'epoch': 0.94}                                                                                                       
{'loss': 0.505, 'learning_rate': 0.0002761262959472196, 'epoch': 0.94}                                                                                                        
{'loss': 0.5723, 'learning_rate': 0.00027603204524033926, 'epoch': 0.94}                                                                                                      
{'loss': 0.4908, 'learning_rate': 0.00027593779453345896, 'epoch': 0.95}                                                                                                      
{'loss': 0.4401, 'learning_rate': 0.00027584354382657867, 'epoch': 0.95}                                                                                                      
{'loss': 0.5183, 'learning_rate': 0.0002757492931196984, 'epoch': 0.95}                                                                                                       
{'loss': 0.5448, 'learning_rate': 0.0002756550424128181, 'epoch': 0.96}                                                                                                       
{'loss': 0.7563, 'learning_rate': 0.0002755607917059378, 'epoch': 0.96}                                                                                                       
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                   | 3100/32330 [4:49:00<2:24:15,  3.38it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8581210058926052, 'eval_cer': 0.4491383874849579, 'eval_runtime': 536.1419, 'eval_samples_per_second': 17.865, 'eval_steps_per_second': 2.234, 'epoch': 0.96}                                                                                                                                                              
{'loss': 0.529, 'learning_rate': 0.0002754665409990575, 'epoch': 0.96}                                                                                                        
{'loss': 0.544, 'learning_rate': 0.00027537229029217714, 'epoch': 0.96}                                                                                                       
{'loss': 0.393, 'learning_rate': 0.00027527803958529685, 'epoch': 0.97}                                                                                                       
{'loss': 0.5605, 'learning_rate': 0.00027518378887841655, 'epoch': 0.97}                                                                                                      
{'loss': 0.7035, 'learning_rate': 0.00027508953817153626, 'epoch': 0.97}                                                                                                      
{'loss': 0.496, 'learning_rate': 0.00027499528746465597, 'epoch': 0.98}                                                                                                       
{'loss': 0.5228, 'learning_rate': 0.00027490103675777567, 'epoch': 0.98}                                                                                                      
{'loss': 0.4027, 'learning_rate': 0.0002748067860508954, 'epoch': 0.98}                                                                                                       
{'loss': 0.5086, 'learning_rate': 0.0002747125353440151, 'epoch': 0.99}                                                                                                       
{'loss': 0.7678, 'learning_rate': 0.00027461828463713474, 'epoch': 0.99}                                                                                                      
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                   | 3200/32330 [4:58:41<2:18:15,  3.51it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.873599468835588, 'eval_cer': 0.44665703971119136, 'eval_runtime': 536.2359, 'eval_samples_per_second': 17.862, 'eval_steps_per_second': 2.234, 'epoch': 0.99}                                                                                                                                                              
{'loss': 0.5149, 'learning_rate': 0.00027452403393025444, 'epoch': 0.99}                                                                                                      
{'loss': 0.3976, 'learning_rate': 0.00027442978322337415, 'epoch': 1.0}                                                                                                       
{'loss': 0.4425, 'learning_rate': 0.00027433553251649385, 'epoch': 1.0}                                                                                                       
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                   | 3232/32330 [5:07:53<2:47:40,  2.89it/s]Saving model checkpoint to turkish_clean/checkpoint-3232
Configuration saved in turkish_clean/checkpoint-3232/config.json
Model weights saved in turkish_clean/checkpoint-3232/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-3232/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.5697, 'learning_rate': 0.00027424128180961356, 'epoch': 1.0}                                                                                                       
{'loss': 0.4078, 'learning_rate': 0.00027414703110273327, 'epoch': 1.01}                                                                                                      
{'loss': 0.4402, 'learning_rate': 0.00027405278039585297, 'epoch': 1.01}                                                                                                      
{'loss': 0.4713, 'learning_rate': 0.0002739585296889726, 'epoch': 1.01}                                                                                                       
{'loss': 0.5063, 'learning_rate': 0.00027386427898209233, 'epoch': 1.01}                                                                                                      
{'loss': 0.6956, 'learning_rate': 0.00027377002827521204, 'epoch': 1.02}                                                                                                      
{'loss': 0.4345, 'learning_rate': 0.00027367577756833174, 'epoch': 1.02}                                                                                                      
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                   | 3300/32330 [5:08:29<4:02:03,  2.00it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7895468503610258, 'eval_cer': 0.4317737665463297, 'eval_runtime': 533.773, 'eval_samples_per_second': 17.944, 'eval_steps_per_second': 2.244, 'epoch': 1.02}                                                                                                                                                               
{'loss': 0.3984, 'learning_rate': 0.00027358152686145145, 'epoch': 1.02}                                                                                                      
{'loss': 0.6399, 'learning_rate': 0.0002734872761545711, 'epoch': 1.03}                                                                                                       
{'loss': 0.4924, 'learning_rate': 0.00027339302544769086, 'epoch': 1.03}                                                                                                      
{'loss': 0.5442, 'learning_rate': 0.00027329877474081057, 'epoch': 1.03}                                                                                                      
{'loss': 0.4518, 'learning_rate': 0.0002732045240339302, 'epoch': 1.04}                                                                                                       
{'loss': 0.4127, 'learning_rate': 0.0002731102733270499, 'epoch': 1.04}                                                                                                       
{'loss': 0.4498, 'learning_rate': 0.00027301602262016963, 'epoch': 1.04}                                                                                                      
{'loss': 0.537, 'learning_rate': 0.00027292177191328934, 'epoch': 1.05}                                                                                                       
{'loss': 0.629, 'learning_rate': 0.00027282752120640904, 'epoch': 1.05}                                                                                                       
{'loss': 0.5987, 'learning_rate': 0.0002727332704995287, 'epoch': 1.05}                                                                                                       
 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                  | 3400/32330 [5:18:08<3:45:39,  2.14it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.813055025313304, 'eval_cer': 0.4404476534296029, 'eval_runtime': 533.181, 'eval_samples_per_second': 17.964, 'eval_steps_per_second': 2.247, 'epoch': 1.05}                                                                                                                                                                
{'loss': 0.3669, 'learning_rate': 0.0002726390197926484, 'epoch': 1.05}                                                                                                       
{'loss': 0.4266, 'learning_rate': 0.00027254476908576816, 'epoch': 1.06}                                                                                                      
{'loss': 0.5894, 'learning_rate': 0.0002724505183788878, 'epoch': 1.06}                                                                                                       
{'loss': 0.5652, 'learning_rate': 0.0002723562676720075, 'epoch': 1.06}                                                                                                       
{'loss': 0.4205, 'learning_rate': 0.0002722620169651272, 'epoch': 1.07}                                                                                                       
{'loss': 0.5353, 'learning_rate': 0.00027216776625824693, 'epoch': 1.07}                                                                                                      
{'loss': 0.4735, 'learning_rate': 0.0002720735155513666, 'epoch': 1.07}                                                                                                       
{'loss': 0.4732, 'learning_rate': 0.0002719792648444863, 'epoch': 1.08}                                                                                                       
{'loss': 0.6301, 'learning_rate': 0.000271885014137606, 'epoch': 1.08}                                                                                                        
{'loss': 0.4156, 'learning_rate': 0.0002717907634307257, 'epoch': 1.08}                                                                                                       
 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                  | 3500/32330 [5:27:47<3:43:06,  2.15it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.79340609179185, 'eval_cer': 0.4366401925391095, 'eval_runtime': 534.89, 'eval_samples_per_second': 17.906, 'eval_steps_per_second': 2.24, 'epoch': 1.08}                                                                                                                                                                   
{'loss': 0.4236, 'learning_rate': 0.0002716965127238454, 'epoch': 1.09}                                                                                                       
{'loss': 0.379, 'learning_rate': 0.0002716022620169651, 'epoch': 1.09}                                                                                                        
{'loss': 0.5369, 'learning_rate': 0.0002715080113100848, 'epoch': 1.09}                                                                                                       
{'loss': 0.6208, 'learning_rate': 0.0002714137606032045, 'epoch': 1.09}                                                                                                       
{'loss': 0.4196, 'learning_rate': 0.0002713195098963242, 'epoch': 1.1}                                                                                                        
{'loss': 0.3862, 'learning_rate': 0.0002712252591894439, 'epoch': 1.1}                                                                                                        
{'loss': 0.4952, 'learning_rate': 0.0002711310084825636, 'epoch': 1.1}                                                                                                        
{'loss': 0.5975, 'learning_rate': 0.0002710367577756833, 'epoch': 1.11}                                                                                                       
{'loss': 0.7483, 'learning_rate': 0.000270942507068803, 'epoch': 1.11}                                                                                                        
{'loss': 0.4594, 'learning_rate': 0.0002708482563619227, 'epoch': 1.11}                                                                                                       
 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                 | 3600/32330 [5:37:26<3:41:19,  2.16it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7940700473068304, 'eval_cer': 0.4358580024067389, 'eval_runtime': 535.1335, 'eval_samples_per_second': 17.898, 'eval_steps_per_second': 2.239, 'epoch': 1.11}                                                                                                                                                              
{'loss': 0.373, 'learning_rate': 0.0002707540056550424, 'epoch': 1.12}                                                                                                        
{'loss': 0.4266, 'learning_rate': 0.00027065975494816206, 'epoch': 1.12}                                                                                                      
{'loss': 0.6547, 'learning_rate': 0.00027056550424128177, 'epoch': 1.12}                                                                                                      
{'loss': 0.675, 'learning_rate': 0.0002704712535344015, 'epoch': 1.13}                                                                                                        
{'loss': 0.4364, 'learning_rate': 0.0002703770028275212, 'epoch': 1.13}                                                                                                       
{'loss': 0.4622, 'learning_rate': 0.0002702827521206409, 'epoch': 1.13}                                                                                                       
{'loss': 0.4551, 'learning_rate': 0.0002701885014137606, 'epoch': 1.14}                                                                                                       
{'loss': 0.4334, 'learning_rate': 0.0002700942507068803, 'epoch': 1.14}                                                                                                       
{'loss': 0.7094, 'learning_rate': 0.00027, 'epoch': 1.14}                                                                                                                     
{'loss': 0.502, 'learning_rate': 0.00026990574929311966, 'epoch': 1.14}                                                                                                       
 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                 | 3700/32330 [5:47:07<3:47:06,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7993401942069881, 'eval_cer': 0.4342503008423586, 'eval_runtime': 532.0982, 'eval_samples_per_second': 18.0, 'eval_steps_per_second': 2.251, 'epoch': 1.14}                                                                                                                                                                
{'loss': 0.4567, 'learning_rate': 0.00026981149858623936, 'epoch': 1.15}                                                                                                      
{'loss': 0.4779, 'learning_rate': 0.00026971724787935907, 'epoch': 1.15}                                                                                                      
{'loss': 0.4935, 'learning_rate': 0.0002696229971724788, 'epoch': 1.15}                                                                                                       
{'loss': 0.5815, 'learning_rate': 0.0002695287464655985, 'epoch': 1.16}                                                                                                       
{'loss': 0.3622, 'learning_rate': 0.0002694344957587182, 'epoch': 1.16}                                                                                                       
{'loss': 0.3947, 'learning_rate': 0.0002693402450518379, 'epoch': 1.16}                                                                                                       
{'loss': 0.3873, 'learning_rate': 0.0002692459943449576, 'epoch': 1.17}                                                                                                       
{'loss': 0.5289, 'learning_rate': 0.00026915174363807725, 'epoch': 1.17}                                                                                                      
{'loss': 0.5188, 'learning_rate': 0.00026905749293119695, 'epoch': 1.17}                                                                                                      
{'loss': 0.5401, 'learning_rate': 0.00026896324222431666, 'epoch': 1.18}                                                                                                      
 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                 | 3800/32330 [5:56:44<3:41:33,  2.15it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7924101585193792, 'eval_cer': 0.43748255114320095, 'eval_runtime': 527.6644, 'eval_samples_per_second': 18.152, 'eval_steps_per_second': 2.27, 'epoch': 1.18}                                                                                                                                                              
{'loss': 0.3458, 'learning_rate': 0.00026886899151743637, 'epoch': 1.18}                                                                                                      
{'loss': 0.464, 'learning_rate': 0.000268774740810556, 'epoch': 1.18}                                                                                                         
{'loss': 0.4923, 'learning_rate': 0.0002686804901036757, 'epoch': 1.18}                                                                                                       
{'loss': 0.5732, 'learning_rate': 0.0002685862393967955, 'epoch': 1.19}                                                                                                       
{'loss': 0.6111, 'learning_rate': 0.00026849198868991514, 'epoch': 1.19}                                                                                                      
{'loss': 0.4388, 'learning_rate': 0.00026839773798303484, 'epoch': 1.19}                                                                                                      
{'loss': 0.4191, 'learning_rate': 0.00026830348727615455, 'epoch': 1.2}                                                                                                       
{'loss': 0.4543, 'learning_rate': 0.00026820923656927425, 'epoch': 1.2}                                                                                                       
{'loss': 0.5047, 'learning_rate': 0.00026811498586239396, 'epoch': 1.2}                                                                                                       
{'loss': 0.3814, 'learning_rate': 0.0002680207351555136, 'epoch': 1.21}                                                                                                       
 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                | 3900/32330 [6:06:18<3:43:09,  2.12it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7820980994273383, 'eval_cer': 0.43620697954271964, 'eval_runtime': 527.5237, 'eval_samples_per_second': 18.157, 'eval_steps_per_second': 2.271, 'epoch': 1.21}                                                                                                                                                             
{'loss': 0.4268, 'learning_rate': 0.0002679264844486333, 'epoch': 1.21}                                                                                                       
{'loss': 0.4404, 'learning_rate': 0.0002678322337417531, 'epoch': 1.21}                                                                                                       
{'loss': 0.5559, 'learning_rate': 0.00026773798303487273, 'epoch': 1.22}                                                                                                      
{'loss': 0.774, 'learning_rate': 0.00026764373232799244, 'epoch': 1.22}                                                                                                       
{'loss': 0.4923, 'learning_rate': 0.00026754948162111214, 'epoch': 1.22}                                                                                                      
{'loss': 0.4236, 'learning_rate': 0.00026745523091423185, 'epoch': 1.22}                                                                                                      
{'loss': 0.3916, 'learning_rate': 0.00026736098020735155, 'epoch': 1.23}                                                                                                      
{'loss': 0.3822, 'learning_rate': 0.0002672667295004712, 'epoch': 1.23}                                                                                                       
{'loss': 0.6858, 'learning_rate': 0.0002671724787935909, 'epoch': 1.23}                                                                                                       
{'loss': 0.4897, 'learning_rate': 0.0002670782280867106, 'epoch': 1.24}                                                                                                       
 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                | 4000/32330 [6:15:52<3:48:02,  2.07it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7807909370072205, 'eval_cer': 0.43325150421179304, 'eval_runtime': 528.6327, 'eval_samples_per_second': 18.118, 'eval_steps_per_second': 2.266, 'epoch': 1.24}                                                                                                                                                             
{'loss': 0.4365, 'learning_rate': 0.0002669839773798303, 'epoch': 1.24}                                                                                                       
{'loss': 0.4626, 'learning_rate': 0.00026688972667295003, 'epoch': 1.24}                                                                                                      
{'loss': 0.5275, 'learning_rate': 0.00026679547596606974, 'epoch': 1.25}                                                                                                      
{'loss': 0.5135, 'learning_rate': 0.00026670122525918944, 'epoch': 1.25}                                                                                                      
{'loss': 0.3875, 'learning_rate': 0.0002666069745523091, 'epoch': 1.25}                                                                                                       
{'loss': 0.3726, 'learning_rate': 0.0002665127238454288, 'epoch': 1.26}                                                                                                       
{'loss': 0.5077, 'learning_rate': 0.0002664184731385485, 'epoch': 1.26}                                                                                                       
{'loss': 0.4308, 'learning_rate': 0.0002663242224316682, 'epoch': 1.26}                                                                                                       
{'loss': 0.6322, 'learning_rate': 0.0002662299717247879, 'epoch': 1.27}                                                                                                       
{'loss': 0.4346, 'learning_rate': 0.0002661357210179076, 'epoch': 1.27}                                                                                                       
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                               | 4100/32330 [6:25:26<3:43:19,  2.11it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7809154286662794, 'eval_cer': 0.4308399518652226, 'eval_runtime': 533.2437, 'eval_samples_per_second': 17.962, 'eval_steps_per_second': 2.247, 'epoch': 1.27}                                                                                                                                                              
{'loss': 0.3355, 'learning_rate': 0.00026604147031102733, 'epoch': 1.27}                                                                                                      
{'loss': 0.4371, 'learning_rate': 0.00026594721960414703, 'epoch': 1.27}                                                                                                      
{'loss': 0.44, 'learning_rate': 0.0002658529688972667, 'epoch': 1.28}                                                                                                         
{'loss': 0.4883, 'learning_rate': 0.0002657587181903864, 'epoch': 1.28}                                                                                                       
{'loss': 0.4463, 'learning_rate': 0.0002656644674835061, 'epoch': 1.28}                                                                                                       
{'loss': 0.3746, 'learning_rate': 0.0002655702167766258, 'epoch': 1.29}                                                                                                       
{'loss': 0.4761, 'learning_rate': 0.0002654759660697455, 'epoch': 1.29}                                                                                                       
{'loss': 0.5864, 'learning_rate': 0.0002653817153628652, 'epoch': 1.29}                                                                                                       
{'loss': 0.5976, 'learning_rate': 0.0002652874646559849, 'epoch': 1.3}                                                                                                        
{'loss': 0.4045, 'learning_rate': 0.0002651932139491046, 'epoch': 1.3}                                                                                                        
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                               | 4200/32330 [6:35:04<3:49:33,  2.04it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7762262428417296, 'eval_cer': 0.4328231046931408, 'eval_runtime': 527.8381, 'eval_samples_per_second': 18.146, 'eval_steps_per_second': 2.27, 'epoch': 1.3}                                                                                                                                                                
{'loss': 0.4881, 'learning_rate': 0.0002650989632422243, 'epoch': 1.3}                                                                                                        
{'loss': 0.3612, 'learning_rate': 0.000265004712535344, 'epoch': 1.31}                                                                                                        
{'loss': 0.473, 'learning_rate': 0.0002649104618284637, 'epoch': 1.31}                                                                                                        
{'loss': 0.6485, 'learning_rate': 0.0002648162111215834, 'epoch': 1.31}                                                                                                       
{'loss': 0.5217, 'learning_rate': 0.00026472196041470305, 'epoch': 1.31}                                                                                                      
{'loss': 0.3154, 'learning_rate': 0.0002646277097078228, 'epoch': 1.32}                                                                                                       
{'loss': 0.415, 'learning_rate': 0.0002645334590009425, 'epoch': 1.32}                                                                                                        
{'loss': 0.4539, 'learning_rate': 0.00026443920829406217, 'epoch': 1.32}                                                                                                      
{'loss': 0.588, 'learning_rate': 0.0002643449575871819, 'epoch': 1.33}                                                                                                        
{'loss': 0.4172, 'learning_rate': 0.0002642507068803016, 'epoch': 1.33}                                                                                                       
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                               | 4300/32330 [6:44:37<3:46:59,  2.06it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7747945887625529, 'eval_cer': 0.4332707581227437, 'eval_runtime': 533.6552, 'eval_samples_per_second': 17.948, 'eval_steps_per_second': 2.245, 'epoch': 1.33}                                                                                                                                                              
{'loss': 0.4053, 'learning_rate': 0.0002641564561734213, 'epoch': 1.33}                                                                                                       
{'loss': 0.4394, 'learning_rate': 0.000264062205466541, 'epoch': 1.34}                                                                                                        
{'loss': 0.467, 'learning_rate': 0.00026396795475966064, 'epoch': 1.34}                                                                                                       
{'loss': 1.1709, 'learning_rate': 0.0002638737040527804, 'epoch': 1.34}                                                                                                       
{'loss': 0.41, 'learning_rate': 0.0002637888784165881, 'epoch': 1.35}                                                                                                         
{'loss': 0.4598, 'learning_rate': 0.0002636946277097078, 'epoch': 1.35}                                                                                                       
{'loss': 0.3945, 'learning_rate': 0.0002636003770028275, 'epoch': 1.35}                                                                                                       
{'loss': 0.5493, 'learning_rate': 0.0002635061262959472, 'epoch': 1.35}                                                                                                       
{'loss': 0.8688, 'learning_rate': 0.0002634118755890669, 'epoch': 1.36}                                                                                                       
{'loss': 0.5964, 'learning_rate': 0.0002633176248821866, 'epoch': 1.36}                                                                                                       
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                              | 4400/32330 [6:54:16<3:38:16,  2.13it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8013113121420865, 'eval_cer': 0.43482551143200965, 'eval_runtime': 533.9028, 'eval_samples_per_second': 17.94, 'eval_steps_per_second': 2.244, 'epoch': 1.36}                                                                                                                                                              
{'loss': 0.4126, 'learning_rate': 0.0002632233741753063, 'epoch': 1.36}                                                                                                       
{'loss': 0.4249, 'learning_rate': 0.000263129123468426, 'epoch': 1.37}                                                                                                        
{'loss': 0.508, 'learning_rate': 0.0002630348727615457, 'epoch': 1.37}                                                                                                        
{'loss': 0.6798, 'learning_rate': 0.00026294062205466535, 'epoch': 1.37}                                                                                                      
{'loss': 1.0757, 'learning_rate': 0.0002628463713477851, 'epoch': 1.38}                                                                                                       
{'loss': 0.3865, 'learning_rate': 0.0002627521206409048, 'epoch': 1.38}                                                                                                       
{'loss': 0.4609, 'learning_rate': 0.00026265786993402446, 'epoch': 1.38}                                                                                                      
{'loss': 0.4978, 'learning_rate': 0.00026256361922714417, 'epoch': 1.39}                                                                                                      
{'loss': 0.6573, 'learning_rate': 0.0002624693685202639, 'epoch': 1.39}                                                                                                       
{'loss': 0.4793, 'learning_rate': 0.0002623751178133836, 'epoch': 1.39}                                                                                                       
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                              | 4500/32330 [7:03:56<4:04:43,  1.90it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7617852103909039, 'eval_cer': 0.4280264741275572, 'eval_runtime': 533.8612, 'eval_samples_per_second': 17.941, 'eval_steps_per_second': 2.244, 'epoch': 1.39}                                                                                                                                                              
{'loss': 0.474, 'learning_rate': 0.0002622808671065033, 'epoch': 1.39}                                                                                                        
{'loss': 0.424, 'learning_rate': 0.00026218661639962294, 'epoch': 1.4}                                                                                                        
{'loss': 0.5159, 'learning_rate': 0.00026209236569274265, 'epoch': 1.4}                                                                                                       
{'loss': 0.4897, 'learning_rate': 0.0002619981149858624, 'epoch': 1.4}                                                                                                        
{'loss': 0.3971, 'learning_rate': 0.00026190386427898206, 'epoch': 1.41}                                                                                                      
{'loss': 0.3929, 'learning_rate': 0.00026180961357210176, 'epoch': 1.41}                                                                                                      
{'loss': 0.4305, 'learning_rate': 0.00026171536286522147, 'epoch': 1.41}                                                                                                      
{'loss': 0.4979, 'learning_rate': 0.0002616211121583412, 'epoch': 1.42}                                                                                                       
{'loss': 0.4769, 'learning_rate': 0.0002615268614514609, 'epoch': 1.42}                                                                                                       
{'loss': 0.3794, 'learning_rate': 0.00026143261074458053, 'epoch': 1.42}                                                                                                      
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                             | 4600/32330 [7:13:35<3:35:04,  2.15it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7714333139679641, 'eval_cer': 0.4292298435619735, 'eval_runtime': 534.7519, 'eval_samples_per_second': 17.911, 'eval_steps_per_second': 2.24, 'epoch': 1.42}                                                                                                                                                               
{'loss': 0.3437, 'learning_rate': 0.00026133836003770024, 'epoch': 1.43}                                                                                                      
{'loss': 0.4114, 'learning_rate': 0.00026124410933082, 'epoch': 1.43}                                                                                                         
{'loss': 0.4608, 'learning_rate': 0.00026114985862393965, 'epoch': 1.43}                                                                                                      
{'loss': 0.6277, 'learning_rate': 0.00026105560791705936, 'epoch': 1.44}                                                                                                      
{'loss': 0.4193, 'learning_rate': 0.00026096135721017906, 'epoch': 1.44}                                                                                                      
{'loss': 0.4125, 'learning_rate': 0.00026086710650329877, 'epoch': 1.44}                                                                                                      
{'loss': 0.3612, 'learning_rate': 0.0002607728557964184, 'epoch': 1.44}                                                                                                       
{'loss': 0.5816, 'learning_rate': 0.0002606786050895381, 'epoch': 1.45}                                                                                                       
{'loss': 0.6416, 'learning_rate': 0.00026058435438265783, 'epoch': 1.45}                                                                                                      
{'loss': 0.6868, 'learning_rate': 0.00026049010367577754, 'epoch': 1.45}                                                                                                      
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                             | 4700/32330 [7:23:16<3:38:47,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7821603452568678, 'eval_cer': 0.43750661853188927, 'eval_runtime': 528.0654, 'eval_samples_per_second': 18.138, 'eval_steps_per_second': 2.269, 'epoch': 1.45}                                                                                                                                                             
{'loss': 0.4054, 'learning_rate': 0.00026039585296889724, 'epoch': 1.46}                                                                                                      
{'loss': 0.468, 'learning_rate': 0.00026030160226201695, 'epoch': 1.46}                                                                                                       
{'loss': 0.49, 'learning_rate': 0.00026020735155513666, 'epoch': 1.46}                                                                                                        
{'loss': 0.7643, 'learning_rate': 0.00026011310084825636, 'epoch': 1.47}                                                                                                      
{'loss': 0.4602, 'learning_rate': 0.000260018850141376, 'epoch': 1.47}                                                                                                        
{'loss': 0.3841, 'learning_rate': 0.0002599245994344957, 'epoch': 1.47}                                                                                                       
{'loss': 0.5291, 'learning_rate': 0.0002598303487276154, 'epoch': 1.48}                                                                                                       
{'loss': 0.5074, 'learning_rate': 0.00025973609802073513, 'epoch': 1.48}                                                                                                      
{'loss': 0.6706, 'learning_rate': 0.00025964184731385484, 'epoch': 1.48}                                                                                                      
{'loss': 0.4372, 'learning_rate': 0.00025954759660697454, 'epoch': 1.48}                                                                                                      
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                             | 4800/32330 [7:32:50<3:39:49,  2.09it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.755477632998589, 'eval_cer': 0.42424067388688325, 'eval_runtime': 527.193, 'eval_samples_per_second': 18.168, 'eval_steps_per_second': 2.272, 'epoch': 1.48}                                                                                                                                                               
{'loss': 0.4199, 'learning_rate': 0.00025945334590009425, 'epoch': 1.49}                                                                                                      
{'loss': 0.4221, 'learning_rate': 0.0002593590951932139, 'epoch': 1.49}                                                                                                       
{'loss': 0.437, 'learning_rate': 0.0002592648444863336, 'epoch': 1.49}                                                                                                        
{'loss': 0.6016, 'learning_rate': 0.0002591705937794533, 'epoch': 1.5}                                                                                                        
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                            | 4848/32330 [7:41:59<3:57:04,  1.93it/s]Saving model checkpoint to turkish_clean/checkpoint-4848
Configuration saved in turkish_clean/checkpoint-4848/config.json
Model weights saved in turkish_clean/checkpoint-4848/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-4848/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4144, 'learning_rate': 0.000259076343072573, 'epoch': 1.5}                                                                                                         
{'loss': 0.2935, 'learning_rate': 0.0002589820923656927, 'epoch': 1.5}                                                                                                        
{'loss': 0.3735, 'learning_rate': 0.00025888784165881243, 'epoch': 1.51}                                                                                                      
{'loss': 0.473, 'learning_rate': 0.00025879359095193214, 'epoch': 1.51}                                                                                                       
{'loss': 0.8557, 'learning_rate': 0.00025869934024505184, 'epoch': 1.51}                                                                                                      
{'loss': 0.4221, 'learning_rate': 0.0002586050895381715, 'epoch': 1.52}                                                                                                       
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                            | 4900/32330 [7:42:25<3:46:09,  2.02it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7732176944144742, 'eval_cer': 0.4289314079422383, 'eval_runtime': 529.5023, 'eval_samples_per_second': 18.089, 'eval_steps_per_second': 2.263, 'epoch': 1.52}                                                                                                                                                              
{'loss': 0.3277, 'learning_rate': 0.0002585108388312912, 'epoch': 1.52}                                                                                                       
{'loss': 0.433, 'learning_rate': 0.0002584165881244109, 'epoch': 1.52}                                                                                                        
{'loss': 0.5082, 'learning_rate': 0.0002583223374175306, 'epoch': 1.52}                                                                                                       
{'loss': 0.6078, 'learning_rate': 0.0002582280867106503, 'epoch': 1.53}                                                                                                       
{'loss': 0.4142, 'learning_rate': 0.00025813383600376997, 'epoch': 1.53}                                                                                                      
{'loss': 0.5774, 'learning_rate': 0.00025803958529688973, 'epoch': 1.53}                                                                                                      
{'loss': 0.5176, 'learning_rate': 0.00025794533459000944, 'epoch': 1.54}                                                                                                      
{'loss': 0.4743, 'learning_rate': 0.0002578510838831291, 'epoch': 1.54}                                                                                                       
{'loss': 0.6767, 'learning_rate': 0.0002577568331762488, 'epoch': 1.54}                                                                                                       
{'loss': 0.5273, 'learning_rate': 0.0002576625824693685, 'epoch': 1.55}                                                                                                       
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                            | 5000/32330 [7:52:00<3:44:24,  2.03it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7657481948709437, 'eval_cer': 0.4316774969915764, 'eval_runtime': 534.6903, 'eval_samples_per_second': 17.913, 'eval_steps_per_second': 2.241, 'epoch': 1.55}                                                                                                                                                              
{'loss': 0.393, 'learning_rate': 0.0002575683317624882, 'epoch': 1.55}                                                                                                        
{'loss': 0.4597, 'learning_rate': 0.00025747408105560786, 'epoch': 1.55}                                                                                                      
{'loss': 0.3905, 'learning_rate': 0.00025737983034872756, 'epoch': 1.56}                                                                                                      
{'loss': 1.2253, 'learning_rate': 0.0002572855796418473, 'epoch': 1.56}                                                                                                       
{'loss': 0.389, 'learning_rate': 0.000257191328934967, 'epoch': 1.56}                                                                                                         
{'loss': 0.3772, 'learning_rate': 0.0002570970782280867, 'epoch': 1.57}                                                                                                       
{'loss': 0.4068, 'learning_rate': 0.0002570028275212064, 'epoch': 1.57}                                                                                                       
{'loss': 0.4411, 'learning_rate': 0.0002569085768143261, 'epoch': 1.57}                                                                                                       
{'loss': 0.6332, 'learning_rate': 0.0002568143261074458, 'epoch': 1.57}                                                                                                       
{'loss': 0.3934, 'learning_rate': 0.00025672007540056545, 'epoch': 1.58}                                                                                                      
 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                           | 5100/32330 [8:01:40<3:31:55,  2.14it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7543572080670595, 'eval_cer': 0.4241468110709988, 'eval_runtime': 534.6712, 'eval_samples_per_second': 17.914, 'eval_steps_per_second': 2.241, 'epoch': 1.58}                                                                                                                                                              
{'loss': 0.4917, 'learning_rate': 0.00025662582469368516, 'epoch': 1.58}                                                                                                      
{'loss': 0.4548, 'learning_rate': 0.0002565315739868049, 'epoch': 1.58}                                                                                                       
{'loss': 0.5246, 'learning_rate': 0.00025643732327992457, 'epoch': 1.59}                                                                                                      
{'loss': 0.9197, 'learning_rate': 0.0002563430725730443, 'epoch': 1.59}                                                                                                       
{'loss': 0.6222, 'learning_rate': 0.000256248821866164, 'epoch': 1.59}                                                                                                        
{'loss': 0.4658, 'learning_rate': 0.0002561545711592837, 'epoch': 1.6}                                                                                                        
{'loss': 0.3984, 'learning_rate': 0.0002560603204524034, 'epoch': 1.6}                                                                                                        
{'loss': 0.4461, 'learning_rate': 0.00025596606974552305, 'epoch': 1.6}                                                                                                       
{'loss': 0.5773, 'learning_rate': 0.00025587181903864275, 'epoch': 1.61}                                                                                                      
{'loss': 0.4423, 'learning_rate': 0.00025577756833176246, 'epoch': 1.61}                                                                                                      
 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                           | 5200/32330 [8:11:20<3:25:00,  2.21it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7483401112125487, 'eval_cer': 0.4243826714801444, 'eval_runtime': 535.041, 'eval_samples_per_second': 17.901, 'eval_steps_per_second': 2.239, 'epoch': 1.61}                                                                                                                                                               
{'loss': 0.3613, 'learning_rate': 0.00025568331762488216, 'epoch': 1.61}                                                                                                      
{'loss': 0.3677, 'learning_rate': 0.00025558906691800187, 'epoch': 1.61}                                                                                                      
{'loss': 0.4918, 'learning_rate': 0.0002554948162111216, 'epoch': 1.62}                                                                                                       
{'loss': 0.4981, 'learning_rate': 0.0002554005655042413, 'epoch': 1.62}                                                                                                       
{'loss': 0.3498, 'learning_rate': 0.00025530631479736093, 'epoch': 1.62}                                                                                                      
{'loss': 0.3022, 'learning_rate': 0.00025521206409048064, 'epoch': 1.63}                                                                                                      
{'loss': 0.4718, 'learning_rate': 0.00025511781338360035, 'epoch': 1.63}                                                                                                      
{'loss': 0.5531, 'learning_rate': 0.00025502356267672005, 'epoch': 1.63}                                                                                                      
{'loss': 0.5371, 'learning_rate': 0.00025492931196983976, 'epoch': 1.64}                                                                                                      
{'loss': 0.3102, 'learning_rate': 0.00025484448633364745, 'epoch': 1.64}                                                                                                      
 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                           | 5300/32330 [8:21:01<3:27:51,  2.17it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7600215785542369, 'eval_cer': 0.42488567990373044, 'eval_runtime': 535.9235, 'eval_samples_per_second': 17.872, 'eval_steps_per_second': 2.235, 'epoch': 1.64}                                                                                                                                                             
{'loss': 0.5101, 'learning_rate': 0.00025475023562676716, 'epoch': 1.64}                                                                                                      
{'loss': 0.4273, 'learning_rate': 0.00025465598491988687, 'epoch': 1.65}                                                                                                      
{'loss': 0.4928, 'learning_rate': 0.00025456173421300657, 'epoch': 1.65}                                                                                                      
{'loss': 0.8062, 'learning_rate': 0.0002544674835061263, 'epoch': 1.65}                                                                                                       
{'loss': 0.37, 'learning_rate': 0.000254373232799246, 'epoch': 1.65}                                                                                                          
{'loss': 0.2972, 'learning_rate': 0.0002542789820923657, 'epoch': 1.66}                                                                                                       
{'loss': 0.3186, 'learning_rate': 0.00025418473138548534, 'epoch': 1.66}                                                                                                      
{'loss': 0.3728, 'learning_rate': 0.00025409048067860505, 'epoch': 1.66}                                                                                                      
{'loss': 0.647, 'learning_rate': 0.00025399622997172475, 'epoch': 1.67}                                                                                                       
{'loss': 0.402, 'learning_rate': 0.00025390197926484446, 'epoch': 1.67}                                                                                                       
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                          | 5400/32330 [8:30:42<3:36:09,  2.08it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7617022159515312, 'eval_cer': 0.42897232250300843, 'eval_runtime': 531.2513, 'eval_samples_per_second': 18.029, 'eval_steps_per_second': 2.255, 'epoch': 1.67}                                                                                                                                                             
{'loss': 0.3521, 'learning_rate': 0.00025380772855796417, 'epoch': 1.67}                                                                                                      
{'loss': 0.4705, 'learning_rate': 0.00025371347785108387, 'epoch': 1.68}                                                                                                      
{'loss': 0.647, 'learning_rate': 0.0002536192271442036, 'epoch': 1.68}                                                                                                        
{'loss': 0.9886, 'learning_rate': 0.0002535249764373233, 'epoch': 1.68}                                                                                                       
{'loss': 1.0775, 'learning_rate': 0.00025343072573044294, 'epoch': 1.69}                                                                                                      
{'loss': 0.3428, 'learning_rate': 0.00025333647502356264, 'epoch': 1.69}                                                                                                      
{'loss': 0.4234, 'learning_rate': 0.00025324222431668235, 'epoch': 1.69}                                                                                                      
{'loss': 0.566, 'learning_rate': 0.00025314797360980205, 'epoch': 1.69}                                                                                                       
{'loss': 0.5055, 'learning_rate': 0.00025305372290292176, 'epoch': 1.7}                                                                                                       
{'loss': 0.3452, 'learning_rate': 0.00025295947219604147, 'epoch': 1.7}                                                                                                       
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                          | 5500/32330 [8:40:19<3:44:33,  1.99it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7558511079757656, 'eval_cer': 0.42482551143200964, 'eval_runtime': 537.3235, 'eval_samples_per_second': 17.825, 'eval_steps_per_second': 2.23, 'epoch': 1.7}                                                                                                                                                               
{'loss': 0.3326, 'learning_rate': 0.00025286522148916117, 'epoch': 1.7}                                                                                                       
{'loss': 0.476, 'learning_rate': 0.0002527709707822808, 'epoch': 1.71}                                                                                                        
{'loss': 0.4868, 'learning_rate': 0.00025267672007540053, 'epoch': 1.71}                                                                                                      
{'loss': 0.5223, 'learning_rate': 0.00025258246936852024, 'epoch': 1.71}                                                                                                      
{'loss': 0.6571, 'learning_rate': 0.00025248821866163994, 'epoch': 1.72}                                                                                                      
{'loss': 0.3813, 'learning_rate': 0.00025239396795475965, 'epoch': 1.72}                                                                                                      
{'loss': 0.4313, 'learning_rate': 0.00025229971724787935, 'epoch': 1.72}                                                                                                      
{'loss': 0.5348, 'learning_rate': 0.00025220546654099906, 'epoch': 1.73}                                                                                                      
{'loss': 0.733, 'learning_rate': 0.00025211121583411876, 'epoch': 1.73}                                                                                                       
{'loss': 0.4197, 'learning_rate': 0.0002520169651272384, 'epoch': 1.73}                                                                                                       
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                         | 5600/32330 [8:50:03<3:30:45,  2.11it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7567225495891775, 'eval_cer': 0.42454632972322504, 'eval_runtime': 537.2605, 'eval_samples_per_second': 17.827, 'eval_steps_per_second': 2.23, 'epoch': 1.73}                                                                                                                                                              
{'loss': 0.324, 'learning_rate': 0.0002519227144203581, 'epoch': 1.74}                                                                                                        
{'loss': 0.3699, 'learning_rate': 0.00025182846371347783, 'epoch': 1.74}                                                                                                      
{'loss': 0.4021, 'learning_rate': 0.00025173421300659753, 'epoch': 1.74}                                                                                                      
{'loss': 0.5653, 'learning_rate': 0.0002516399622997172, 'epoch': 1.74}                                                                                                       
{'loss': 0.3268, 'learning_rate': 0.00025154571159283695, 'epoch': 1.75}                                                                                                      
{'loss': 0.4028, 'learning_rate': 0.00025145146088595665, 'epoch': 1.75}                                                                                                      
{'loss': 0.3784, 'learning_rate': 0.0002513572101790763, 'epoch': 1.75}                                                                                                       
{'loss': 0.5462, 'learning_rate': 0.000251262959472196, 'epoch': 1.76}                                                                                                        
{'loss': 0.5815, 'learning_rate': 0.0002511687087653157, 'epoch': 1.76}                                                                                                       
{'loss': 0.4327, 'learning_rate': 0.0002510744580584354, 'epoch': 1.76}                                                                                                       
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                         | 5700/32330 [8:59:46<3:27:14,  2.14it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7493775417047058, 'eval_cer': 0.42368712394705177, 'eval_runtime': 528.5657, 'eval_samples_per_second': 18.121, 'eval_steps_per_second': 2.267, 'epoch': 1.76}                                                                                                                                                             
{'loss': 0.3344, 'learning_rate': 0.00025098020735155513, 'epoch': 1.77}                                                                                                      
{'loss': 0.4518, 'learning_rate': 0.0002508859566446748, 'epoch': 1.77}                                                                                                       
{'loss': 0.4931, 'learning_rate': 0.0002507917059377945, 'epoch': 1.77}                                                                                                       
{'loss': 0.5459, 'learning_rate': 0.00025069745523091425, 'epoch': 1.78}                                                                                                      
{'loss': 0.4916, 'learning_rate': 0.0002506032045240339, 'epoch': 1.78}                                                                                                       
{'loss': 0.3804, 'learning_rate': 0.0002505089538171536, 'epoch': 1.78}                                                                                                       
{'loss': 0.3907, 'learning_rate': 0.0002504147031102733, 'epoch': 1.78}                                                                                                       
{'loss': 0.4051, 'learning_rate': 0.000250320452403393, 'epoch': 1.79}                                                                                                        
{'loss': 0.8282, 'learning_rate': 0.0002502262016965127, 'epoch': 1.79}                                                                                                       
{'loss': 0.3842, 'learning_rate': 0.0002501319509896324, 'epoch': 1.79}                                                                                                       
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                         | 5800/32330 [9:09:19<3:20:26,  2.21it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7481741223338036, 'eval_cer': 0.4251022864019254, 'eval_runtime': 534.8742, 'eval_samples_per_second': 17.907, 'eval_steps_per_second': 2.24, 'epoch': 1.79}                                                                                                                                                               
{'loss': 0.3214, 'learning_rate': 0.0002500377002827521, 'epoch': 1.8}                                                                                                        
{'loss': 0.4136, 'learning_rate': 0.00024994344957587184, 'epoch': 1.8}                                                                                                       
{'loss': 0.4365, 'learning_rate': 0.0002498491988689915, 'epoch': 1.8}                                                                                                        
{'loss': 0.5208, 'learning_rate': 0.0002497549481621112, 'epoch': 1.81}                                                                                                       
{'loss': 0.3794, 'learning_rate': 0.0002496606974552309, 'epoch': 1.81}                                                                                                       
{'loss': 0.4024, 'learning_rate': 0.0002495664467483506, 'epoch': 1.81}                                                                                                       
{'loss': 0.3739, 'learning_rate': 0.00024947219604147026, 'epoch': 1.82}                                                                                                      
{'loss': 0.4425, 'learning_rate': 0.00024937794533458997, 'epoch': 1.82}                                                                                                      
{'loss': 0.5328, 'learning_rate': 0.0002492836946277097, 'epoch': 1.82}                                                                                                       
{'loss': 0.3644, 'learning_rate': 0.0002491894439208294, 'epoch': 1.82}                                                                                                       
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                        | 5900/32330 [9:19:00<3:45:03,  1.96it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7531952859158436, 'eval_cer': 0.4229987966305656, 'eval_runtime': 534.4731, 'eval_samples_per_second': 17.92, 'eval_steps_per_second': 2.241, 'epoch': 1.82}                                                                                                                                                               
{'loss': 0.3449, 'learning_rate': 0.0002490951932139491, 'epoch': 1.83}                                                                                                       
{'loss': 0.3401, 'learning_rate': 0.0002490009425070688, 'epoch': 1.83}                                                                                                       
{'loss': 0.4431, 'learning_rate': 0.0002489066918001885, 'epoch': 1.83}                                                                                                       
{'loss': 0.7094, 'learning_rate': 0.0002488124410933082, 'epoch': 1.84}                                                                                                       
{'loss': 0.386, 'learning_rate': 0.00024871819038642785, 'epoch': 1.84}                                                                                                       
{'loss': 0.3702, 'learning_rate': 0.00024862393967954756, 'epoch': 1.84}                                                                                                      
{'loss': 0.4034, 'learning_rate': 0.00024852968897266727, 'epoch': 1.85}                                                                                                      
{'loss': 0.5051, 'learning_rate': 0.00024843543826578697, 'epoch': 1.85}                                                                                                      
{'loss': 0.5087, 'learning_rate': 0.0002483411875589067, 'epoch': 1.85}                                                                                                       
{'loss': 0.3922, 'learning_rate': 0.0002482469368520264, 'epoch': 1.86}                                                                                                       
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                        | 6000/32330 [9:28:40<3:30:06,  2.09it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7423645115777243, 'eval_cer': 0.42152346570397115, 'eval_runtime': 528.8035, 'eval_samples_per_second': 18.113, 'eval_steps_per_second': 2.265, 'epoch': 1.86}                                                                                                                                                             
{'loss': 0.3199, 'learning_rate': 0.0002481526861451461, 'epoch': 1.86}                                                                                                       
{'loss': 0.3945, 'learning_rate': 0.00024805843543826574, 'epoch': 1.86}                                                                                                      
{'loss': 0.5063, 'learning_rate': 0.00024796418473138545, 'epoch': 1.87}                                                                                                      
{'loss': 0.6904, 'learning_rate': 0.00024786993402450515, 'epoch': 1.87}                                                                                                      
{'loss': 0.3809, 'learning_rate': 0.00024777568331762486, 'epoch': 1.87}                                                                                                      
{'loss': 0.3341, 'learning_rate': 0.00024768143261074457, 'epoch': 1.87}                                                                                                      
{'loss': 0.3087, 'learning_rate': 0.00024758718190386427, 'epoch': 1.88}                                                                                                      
{'loss': 0.4503, 'learning_rate': 0.000247492931196984, 'epoch': 1.88}                                                                                                        
{'loss': 0.5868, 'learning_rate': 0.0002473986804901037, 'epoch': 1.88}                                                                                                       
{'loss': 0.3523, 'learning_rate': 0.00024730442978322334, 'epoch': 1.89}                                                                                                      
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                       | 6100/32330 [9:38:14<3:16:34,  2.22it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7662876587268653, 'eval_cer': 0.4340890493381468, 'eval_runtime': 534.4845, 'eval_samples_per_second': 17.92, 'eval_steps_per_second': 2.241, 'epoch': 1.89}                                                                                                                                                               
{'loss': 0.4094, 'learning_rate': 0.00024721017907634304, 'epoch': 1.89}                                                                                                      
{'loss': 0.3981, 'learning_rate': 0.00024711592836946275, 'epoch': 1.89}                                                                                                      
{'loss': 0.4709, 'learning_rate': 0.00024702167766258245, 'epoch': 1.9}                                                                                                       
{'loss': 1.1297, 'learning_rate': 0.00024692742695570216, 'epoch': 1.9}                                                                                                       
{'loss': 0.4247, 'learning_rate': 0.0002468331762488218, 'epoch': 1.9}                                                                                                        
{'loss': 0.3625, 'learning_rate': 0.00024673892554194157, 'epoch': 1.91}                                                                                                      
{'loss': 0.3933, 'learning_rate': 0.0002466446748350613, 'epoch': 1.91}                                                                                                       
{'loss': 0.4291, 'learning_rate': 0.00024655042412818093, 'epoch': 1.91}                                                                                                      
{'loss': 0.9477, 'learning_rate': 0.00024645617342130064, 'epoch': 1.91}                                                                                                      
{'loss': 0.3825, 'learning_rate': 0.00024636192271442034, 'epoch': 1.92}                                                                                                      
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                       | 6200/32330 [9:47:54<3:27:55,  2.09it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7637148311063159, 'eval_cer': 0.42792779783393503, 'eval_runtime': 530.6376, 'eval_samples_per_second': 18.05, 'eval_steps_per_second': 2.258, 'epoch': 1.92}                                                                                                                                                              
{'loss': 0.3444, 'learning_rate': 0.00024626767200754005, 'epoch': 1.92}                                                                                                      
{'loss': 0.4003, 'learning_rate': 0.0002461734213006597, 'epoch': 1.92}                                                                                                       
{'loss': 0.4639, 'learning_rate': 0.0002460791705937794, 'epoch': 1.93}                                                                                                       
{'loss': 1.0033, 'learning_rate': 0.00024598491988689917, 'epoch': 1.93}                                                                                                      
{'loss': 0.3698, 'learning_rate': 0.0002458906691800188, 'epoch': 1.93}                                                                                                       
{'loss': 0.3468, 'learning_rate': 0.0002457964184731385, 'epoch': 1.94}                                                                                                       
{'loss': 0.4696, 'learning_rate': 0.00024570216776625823, 'epoch': 1.94}                                                                                                      
{'loss': 0.5222, 'learning_rate': 0.00024560791705937793, 'epoch': 1.94}                                                                                                      
{'loss': 0.7314, 'learning_rate': 0.00024551366635249764, 'epoch': 1.95}                                                                                                      
{'loss': 0.4031, 'learning_rate': 0.0002454194156456173, 'epoch': 1.95}                                                                                                       
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                       | 6300/32330 [9:57:30<3:29:32,  2.07it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7587559133538053, 'eval_cer': 0.4293453670276775, 'eval_runtime': 535.0054, 'eval_samples_per_second': 17.903, 'eval_steps_per_second': 2.239, 'epoch': 1.95}                                                                                                                                                              
{'loss': 0.4185, 'learning_rate': 0.000245325164938737, 'epoch': 1.95}                                                                                                        
{'loss': 0.4131, 'learning_rate': 0.0002452309142318567, 'epoch': 1.95}                                                                                                       
{'loss': 0.3858, 'learning_rate': 0.0002451366635249764, 'epoch': 1.96}                                                                                                       
{'loss': 0.8189, 'learning_rate': 0.0002450424128180961, 'epoch': 1.96}                                                                                                       
{'loss': 0.4047, 'learning_rate': 0.0002449481621112158, 'epoch': 1.96}                                                                                                       
{'loss': 0.2998, 'learning_rate': 0.00024485391140433553, 'epoch': 1.97}                                                                                                      
{'loss': 0.3866, 'learning_rate': 0.0002447596606974552, 'epoch': 1.97}                                                                                                       
{'loss': 0.4179, 'learning_rate': 0.0002446654099905749, 'epoch': 1.97}                                                                                                       
{'loss': 0.4851, 'learning_rate': 0.0002445711592836946, 'epoch': 1.98}                                                                                                       
{'loss': 0.476, 'learning_rate': 0.0002444769085768143, 'epoch': 1.98}                                                                                                        
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                     | 6400/32330 [10:07:12<3:38:56,  1.97it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7412648352560378, 'eval_cer': 0.42173285198555954, 'eval_runtime': 536.6524, 'eval_samples_per_second': 17.848, 'eval_steps_per_second': 2.232, 'epoch': 1.98}                                                                                                                                                             
{'loss': 0.3518, 'learning_rate': 0.000244382657869934, 'epoch': 1.98}                                                                                                        
{'loss': 0.4034, 'learning_rate': 0.0002442884071630537, 'epoch': 1.99}                                                                                                       
{'loss': 0.3969, 'learning_rate': 0.0002441941564561734, 'epoch': 1.99}                                                                                                       
{'loss': 0.5368, 'learning_rate': 0.0002440999057492931, 'epoch': 1.99}                                                                                                       
{'loss': 0.3699, 'learning_rate': 0.0002440056550424128, 'epoch': 1.99}                                                                                                       
{'loss': 0.434, 'learning_rate': 0.00024391140433553248, 'epoch': 2.0}                                                                                                        
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                     | 6464/32330 [10:16:35<2:28:02,  2.91it/s]Saving model checkpoint to turkish_clean/checkpoint-6464
Configuration saved in turkish_clean/checkpoint-6464/config.json
Model weights saved in turkish_clean/checkpoint-6464/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-6464/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.5384, 'learning_rate': 0.00024381715362865219, 'epoch': 2.0}                                                                                                       
{'loss': 0.4638, 'learning_rate': 0.0002437229029217719, 'epoch': 2.0}                                                                                                        
{'loss': 0.3518, 'learning_rate': 0.0002436286522148916, 'epoch': 2.01}                                                                                                       
{'loss': 0.361, 'learning_rate': 0.0002435344015080113, 'epoch': 2.01}                                                                                                        
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                     | 6500/32330 [10:16:55<2:40:27,  2.68it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7513071624201179, 'eval_cer': 0.4269915764139591, 'eval_runtime': 534.5591, 'eval_samples_per_second': 17.918, 'eval_steps_per_second': 2.241, 'epoch': 2.01}                                                                                                                                                              
{'loss': 0.3301, 'learning_rate': 0.00024344015080113098, 'epoch': 2.01}                                                                                                      
{'loss': 0.4204, 'learning_rate': 0.0002433459000942507, 'epoch': 2.02}                                                                                                       
{'loss': 0.3557, 'learning_rate': 0.0002432516493873704, 'epoch': 2.02}                                                                                                       
{'loss': 0.2639, 'learning_rate': 0.00024315739868049007, 'epoch': 2.02}                                                                                                      
{'loss': 0.3344, 'learning_rate': 0.00024306314797360978, 'epoch': 2.03}                                                                                                      
{'loss': 0.4297, 'learning_rate': 0.00024296889726672946, 'epoch': 2.03}                                                                                                      
{'loss': 0.4845, 'learning_rate': 0.00024287464655984916, 'epoch': 2.03}                                                                                                      
{'loss': 0.3462, 'learning_rate': 0.0002427803958529689, 'epoch': 2.04}                                                                                                       
{'loss': 0.3016, 'learning_rate': 0.00024268614514608858, 'epoch': 2.04}                                                                                                      
{'loss': 0.3485, 'learning_rate': 0.00024259189443920828, 'epoch': 2.04}                                                                                                      
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                     | 6600/32330 [10:26:35<2:44:42,  2.60it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7568262926383932, 'eval_cer': 0.4279783393501805, 'eval_runtime': 529.5088, 'eval_samples_per_second': 18.088, 'eval_steps_per_second': 2.262, 'epoch': 2.04}                                                                                                                                                              
{'loss': 0.306, 'learning_rate': 0.00024249764373232796, 'epoch': 2.04}                                                                                                       
{'loss': 0.4462, 'learning_rate': 0.00024240339302544767, 'epoch': 2.05}                                                                                                      
{'loss': 0.4128, 'learning_rate': 0.00024230914231856737, 'epoch': 2.05}                                                                                                      
{'loss': 0.2952, 'learning_rate': 0.00024221489161168705, 'epoch': 2.05}                                                                                                      
{'loss': 0.2848, 'learning_rate': 0.00024212064090480676, 'epoch': 2.06}                                                                                                      
{'loss': 0.377, 'learning_rate': 0.0002420263901979265, 'epoch': 2.06}                                                                                                        
{'loss': 0.4861, 'learning_rate': 0.00024193213949104617, 'epoch': 2.06}                                                                                                      
{'loss': 0.3578, 'learning_rate': 0.00024183788878416588, 'epoch': 2.07}                                                                                                      
{'loss': 0.3225, 'learning_rate': 0.00024174363807728555, 'epoch': 2.07}                                                                                                      
{'loss': 0.4024, 'learning_rate': 0.00024164938737040526, 'epoch': 2.07}                                                                                                      
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                    | 6700/32330 [10:36:11<2:46:47,  2.56it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.749564279193294, 'eval_cer': 0.424777376654633, 'eval_runtime': 533.9751, 'eval_samples_per_second': 17.937, 'eval_steps_per_second': 2.244, 'epoch': 2.07}                                                                                                                                                                
{'loss': 0.3463, 'learning_rate': 0.00024155513666352494, 'epoch': 2.08}                                                                                                      
{'loss': 0.4467, 'learning_rate': 0.00024146088595664464, 'epoch': 2.08}                                                                                                      
{'loss': 0.348, 'learning_rate': 0.00024136663524976435, 'epoch': 2.08}                                                                                                       
{'loss': 0.3076, 'learning_rate': 0.00024127238454288403, 'epoch': 2.08}                                                                                                      
{'loss': 0.356, 'learning_rate': 0.00024117813383600376, 'epoch': 2.09}                                                                                                       
{'loss': 0.4077, 'learning_rate': 0.00024108388312912347, 'epoch': 2.09}                                                                                                      
{'loss': 0.8973, 'learning_rate': 0.00024098963242224315, 'epoch': 2.09}                                                                                                      
{'loss': 0.6068, 'learning_rate': 0.00024089538171536285, 'epoch': 2.1}                                                                                                       
{'loss': 0.3519, 'learning_rate': 0.00024080113100848253, 'epoch': 2.1}                                                                                                       
{'loss': 0.3306, 'learning_rate': 0.00024070688030160224, 'epoch': 2.1}                                                                                                       
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                    | 6800/32330 [10:45:51<2:42:16,  2.62it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7454975516640385, 'eval_cer': 0.4243826714801444, 'eval_runtime': 534.0972, 'eval_samples_per_second': 17.933, 'eval_steps_per_second': 2.243, 'epoch': 2.1}                                                                                                                                                               
{'loss': 0.3527, 'learning_rate': 0.00024061262959472192, 'epoch': 2.11}                                                                                                      
{'loss': 0.4224, 'learning_rate': 0.00024051837888784162, 'epoch': 2.11}                                                                                                      
{'loss': 0.3886, 'learning_rate': 0.00024042412818096136, 'epoch': 2.11}                                                                                                      
{'loss': 0.3092, 'learning_rate': 0.00024032987747408104, 'epoch': 2.12}                                                                                                      
{'loss': 0.28, 'learning_rate': 0.00024023562676720074, 'epoch': 2.12}                                                                                                        
{'loss': 0.3928, 'learning_rate': 0.00024014137606032045, 'epoch': 2.12}                                                                                                      
{'loss': 0.577, 'learning_rate': 0.00024004712535344013, 'epoch': 2.12}                                                                                                       
{'loss': 0.718, 'learning_rate': 0.00023995287464655983, 'epoch': 2.13}                                                                                                       
{'loss': 0.2945, 'learning_rate': 0.0002398586239396795, 'epoch': 2.13}                                                                                                       
{'loss': 0.4352, 'learning_rate': 0.00023976437323279922, 'epoch': 2.13}                                                                                                      
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                    | 6900/32330 [10:55:30<2:43:29,  2.59it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7337745871026641, 'eval_cer': 0.4215691937424789, 'eval_runtime': 528.7247, 'eval_samples_per_second': 18.115, 'eval_steps_per_second': 2.266, 'epoch': 2.13}                                                                                                                                                              
{'loss': 0.3072, 'learning_rate': 0.00023967012252591895, 'epoch': 2.14}                                                                                                      
{'loss': 0.4742, 'learning_rate': 0.00023957587181903863, 'epoch': 2.14}                                                                                                      
{'loss': 0.3674, 'learning_rate': 0.00023948162111215833, 'epoch': 2.14}                                                                                                      
{'loss': 0.3312, 'learning_rate': 0.00023938737040527801, 'epoch': 2.15}                                                                                                      
{'loss': 0.3314, 'learning_rate': 0.00023929311969839772, 'epoch': 2.15}                                                                                                      
{'loss': 0.358, 'learning_rate': 0.0002391988689915174, 'epoch': 2.15}                                                                                                        
{'loss': 0.5658, 'learning_rate': 0.0002391046182846371, 'epoch': 2.16}                                                                                                       
{'loss': 0.3764, 'learning_rate': 0.0002390103675777568, 'epoch': 2.16}                                                                                                       
{'loss': 0.2901, 'learning_rate': 0.0002389161168708765, 'epoch': 2.16}                                                                                                       
{'loss': 0.317, 'learning_rate': 0.00023882186616399622, 'epoch': 2.17}                                                                                                       
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                   | 7000/32330 [11:05:05<2:41:56,  2.61it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7360984314050959, 'eval_cer': 0.4208447653429603, 'eval_runtime': 530.2667, 'eval_samples_per_second': 18.063, 'eval_steps_per_second': 2.259, 'epoch': 2.17}                                                                                                                                                              
{'loss': 0.3999, 'learning_rate': 0.00023872761545711593, 'epoch': 2.17}                                                                                                      
{'loss': 0.5653, 'learning_rate': 0.0002386333647502356, 'epoch': 2.17}                                                                                                       
{'loss': 0.3658, 'learning_rate': 0.0002385391140433553, 'epoch': 2.17}                                                                                                       
{'loss': 0.3082, 'learning_rate': 0.000238444863336475, 'epoch': 2.18}                                                                                                        
{'loss': 0.3025, 'learning_rate': 0.0002383506126295947, 'epoch': 2.18}                                                                                                       
{'loss': 0.3225, 'learning_rate': 0.00023825636192271438, 'epoch': 2.18}                                                                                                      
{'loss': 0.5455, 'learning_rate': 0.00023816211121583408, 'epoch': 2.19}                                                                                                      
{'loss': 0.3478, 'learning_rate': 0.00023806786050895382, 'epoch': 2.19}                                                                                                      
{'loss': 0.3523, 'learning_rate': 0.0002379736098020735, 'epoch': 2.19}                                                                                                       
{'loss': 0.3359, 'learning_rate': 0.0002378793590951932, 'epoch': 2.2}                                                                                                        
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                   | 7100/32330 [11:14:41<2:41:58,  2.60it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7398539297867043, 'eval_cer': 0.42349939831528277, 'eval_runtime': 532.0072, 'eval_samples_per_second': 18.004, 'eval_steps_per_second': 2.252, 'epoch': 2.2}                                                                                                                                                              
{'loss': 0.4504, 'learning_rate': 0.0002377851083883129, 'epoch': 2.2}                                                                                                        
{'loss': 0.4939, 'learning_rate': 0.00023769085768143259, 'epoch': 2.2}                                                                                                       
{'loss': 0.6214, 'learning_rate': 0.0002375966069745523, 'epoch': 2.21}                                                                                                       
{'loss': 0.253, 'learning_rate': 0.00023750235626767197, 'epoch': 2.21}                                                                                                       
{'loss': 0.2986, 'learning_rate': 0.00023740810556079168, 'epoch': 2.21}                                                                                                      
{'loss': 0.4157, 'learning_rate': 0.00023731385485391136, 'epoch': 2.21}                                                                                                      
{'loss': 0.5197, 'learning_rate': 0.0002372196041470311, 'epoch': 2.22}                                                                                                       
{'loss': 0.3974, 'learning_rate': 0.00023713477851083879, 'epoch': 2.22}                                                                                                      
{'loss': 0.3469, 'learning_rate': 0.00023704052780395852, 'epoch': 2.22}                                                                                                      
{'loss': 0.3654, 'learning_rate': 0.00023694627709707822, 'epoch': 2.23}                                                                                                      
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                  | 7200/32330 [11:24:18<2:40:40,  2.61it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7326126649514483, 'eval_cer': 0.4220673886883273, 'eval_runtime': 529.5846, 'eval_samples_per_second': 18.086, 'eval_steps_per_second': 2.262, 'epoch': 2.23}                                                                                                                                                              
{'loss': 0.2907, 'learning_rate': 0.0002368520263901979, 'epoch': 2.23}                                                                                                       
{'loss': 0.4048, 'learning_rate': 0.0002367577756833176, 'epoch': 2.23}                                                                                                       
{'loss': 0.3339, 'learning_rate': 0.00023666352497643732, 'epoch': 2.24}                                                                                                      
{'loss': 0.275, 'learning_rate': 0.000236569274269557, 'epoch': 2.24}                                                                                                         
{'loss': 0.3923, 'learning_rate': 0.0002364750235626767, 'epoch': 2.24}                                                                                                       
{'loss': 0.4101, 'learning_rate': 0.00023638077285579638, 'epoch': 2.25}                                                                                                      
{'loss': 0.5129, 'learning_rate': 0.00023628652214891609, 'epoch': 2.25}                                                                                                      
{'loss': 0.3749, 'learning_rate': 0.00023619227144203582, 'epoch': 2.25}                                                                                                      
{'loss': 0.2409, 'learning_rate': 0.0002360980207351555, 'epoch': 2.25}                                                                                                       
{'loss': 0.2367, 'learning_rate': 0.0002360037700282752, 'epoch': 2.26}                                                                                                       
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                  | 7300/32330 [11:33:53<2:41:43,  2.58it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7527595651091377, 'eval_cer': 0.42324428399518654, 'eval_runtime': 529.8115, 'eval_samples_per_second': 18.078, 'eval_steps_per_second': 2.261, 'epoch': 2.26}                                                                                                                                                             
{'loss': 0.3244, 'learning_rate': 0.00023590951932139488, 'epoch': 2.26}                                                                                                      
{'loss': 0.6126, 'learning_rate': 0.0002358152686145146, 'epoch': 2.26}                                                                                                       
{'loss': 0.4892, 'learning_rate': 0.00023572101790763427, 'epoch': 2.27}                                                                                                      
{'loss': 0.3197, 'learning_rate': 0.00023562676720075397, 'epoch': 2.27}                                                                                                      
{'loss': 0.2996, 'learning_rate': 0.00023553251649387368, 'epoch': 2.27}                                                                                                      
{'loss': 0.3509, 'learning_rate': 0.00023543826578699338, 'epoch': 2.28}                                                                                                      
{'loss': 0.6122, 'learning_rate': 0.0002353440150801131, 'epoch': 2.28}                                                                                                       
{'loss': 0.3543, 'learning_rate': 0.0002352497643732328, 'epoch': 2.28}                                                                                                       
{'loss': 0.2642, 'learning_rate': 0.00023515551366635248, 'epoch': 2.29}                                                                                                      
{'loss': 0.3155, 'learning_rate': 0.00023506126295947218, 'epoch': 2.29}                                                                                                      
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                  | 7400/32330 [11:43:29<2:43:30,  2.54it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7453315627852933, 'eval_cer': 0.4237978339350181, 'eval_runtime': 529.5407, 'eval_samples_per_second': 18.087, 'eval_steps_per_second': 2.262, 'epoch': 2.29}                                                                                                                                                              
{'loss': 0.3528, 'learning_rate': 0.00023496701225259186, 'epoch': 2.29}                                                                                                      
{'loss': 0.5503, 'learning_rate': 0.00023487276154571157, 'epoch': 2.3}                                                                                                       
{'loss': 0.3402, 'learning_rate': 0.00023477851083883125, 'epoch': 2.3}                                                                                                       
{'loss': 0.3085, 'learning_rate': 0.00023468426013195098, 'epoch': 2.3}                                                                                                       
{'loss': 0.3458, 'learning_rate': 0.00023459000942507068, 'epoch': 2.3}                                                                                                       
{'loss': 0.3298, 'learning_rate': 0.00023449575871819036, 'epoch': 2.31}                                                                                                      
{'loss': 0.4972, 'learning_rate': 0.00023440150801131007, 'epoch': 2.31}                                                                                                      
{'loss': 0.3662, 'learning_rate': 0.00023430725730442977, 'epoch': 2.31}                                                                                                      
{'loss': 0.3053, 'learning_rate': 0.00023421300659754945, 'epoch': 2.32}                                                                                                      
{'loss': 0.3621, 'learning_rate': 0.00023411875589066916, 'epoch': 2.32}                                                                                                      
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                 | 7500/32330 [11:53:04<2:37:29,  2.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.734791268984978, 'eval_cer': 0.41688567990373043, 'eval_runtime': 535.6737, 'eval_samples_per_second': 17.88, 'eval_steps_per_second': 2.236, 'epoch': 2.32}                                                                                                                                                               
{'loss': 0.3789, 'learning_rate': 0.00023402450518378884, 'epoch': 2.32}                                                                                                      
{'loss': 0.6116, 'learning_rate': 0.00023393025447690854, 'epoch': 2.33}                                                                                                      
{'loss': 0.3228, 'learning_rate': 0.00023383600377002828, 'epoch': 2.33}                                                                                                      
{'loss': 0.26, 'learning_rate': 0.00023374175306314796, 'epoch': 2.33}                                                                                                        
{'loss': 0.3106, 'learning_rate': 0.00023364750235626766, 'epoch': 2.34}                                                                                                      
{'loss': 0.4032, 'learning_rate': 0.00023355325164938734, 'epoch': 2.34}                                                                                                      
{'loss': 0.7407, 'learning_rate': 0.00023345900094250705, 'epoch': 2.34}                                                                                                      
{'loss': 0.2949, 'learning_rate': 0.00023336475023562675, 'epoch': 2.34}                                                                                                      
{'loss': 0.2862, 'learning_rate': 0.00023327049952874643, 'epoch': 2.35}                                                                                                      
{'loss': 0.2305, 'learning_rate': 0.00023317624882186614, 'epoch': 2.35}                                                                                                      
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                 | 7600/32330 [12:02:45<2:34:10,  2.67it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7194995435305834, 'eval_cer': 0.4174632972322503, 'eval_runtime': 534.6358, 'eval_samples_per_second': 17.915, 'eval_steps_per_second': 2.241, 'epoch': 2.35}                                                                                                                                                              
{'loss': 0.3938, 'learning_rate': 0.00023308199811498584, 'epoch': 2.35}                                                                                                      
{'loss': 0.482, 'learning_rate': 0.00023298774740810555, 'epoch': 2.36}                                                                                                       
{'loss': 0.3102, 'learning_rate': 0.00023289349670122526, 'epoch': 2.36}                                                                                                      
{'loss': 0.2821, 'learning_rate': 0.00023279924599434493, 'epoch': 2.36}                                                                                                      
{'loss': 0.3685, 'learning_rate': 0.00023270499528746464, 'epoch': 2.37}                                                                                                      
{'loss': 0.3421, 'learning_rate': 0.00023261074458058432, 'epoch': 2.37}                                                                                                      
{'loss': 0.9691, 'learning_rate': 0.00023251649387370403, 'epoch': 2.37}                                                                                                      
{'loss': 0.3632, 'learning_rate': 0.00023242224316682373, 'epoch': 2.38}                                                                                                      
{'loss': 0.4658, 'learning_rate': 0.0002323279924599434, 'epoch': 2.38}                                                                                                       
{'loss': 0.2692, 'learning_rate': 0.00023223374175306314, 'epoch': 2.38}                                                                                                      
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                | 7700/32330 [12:12:25<2:40:10,  2.56it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7314922400199186, 'eval_cer': 0.42001203369434414, 'eval_runtime': 536.413, 'eval_samples_per_second': 17.856, 'eval_steps_per_second': 2.233, 'epoch': 2.38}                                                                                                                                                              
{'loss': 0.3622, 'learning_rate': 0.00023213949104618282, 'epoch': 2.38}                                                                                                      
{'loss': 0.3733, 'learning_rate': 0.00023204524033930253, 'epoch': 2.39}                                                                                                      
{'loss': 0.3057, 'learning_rate': 0.00023195098963242223, 'epoch': 2.39}                                                                                                      
{'loss': 0.2657, 'learning_rate': 0.0002318567389255419, 'epoch': 2.39}                                                                                                       
{'loss': 0.3048, 'learning_rate': 0.00023176248821866162, 'epoch': 2.4}                                                                                                       
{'loss': 0.3072, 'learning_rate': 0.0002316682375117813, 'epoch': 2.4}                                                                                                        
{'loss': 0.5048, 'learning_rate': 0.000231573986804901, 'epoch': 2.4}                                                                                                         
{'loss': 0.429, 'learning_rate': 0.00023147973609802074, 'epoch': 2.41}                                                                                                       
{'loss': 0.3949, 'learning_rate': 0.00023138548539114042, 'epoch': 2.41}                                                                                                      
{'loss': 0.3053, 'learning_rate': 0.00023129123468426012, 'epoch': 2.41}                                                                                                      
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                | 7800/32330 [12:22:06<2:31:26,  2.70it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7488795750684704, 'eval_cer': 0.42228158844765346, 'eval_runtime': 536.947, 'eval_samples_per_second': 17.838, 'eval_steps_per_second': 2.231, 'epoch': 2.41}                                                                                                                                                              
{'loss': 0.4101, 'learning_rate': 0.0002311969839773798, 'epoch': 2.42}                                                                                                       
{'loss': 0.557, 'learning_rate': 0.0002311027332704995, 'epoch': 2.42}                                                                                                        
{'loss': 0.4063, 'learning_rate': 0.0002310084825636192, 'epoch': 2.42}                                                                                                       
{'loss': 0.3017, 'learning_rate': 0.0002309142318567389, 'epoch': 2.42}                                                                                                       
{'loss': 0.2958, 'learning_rate': 0.0002308199811498586, 'epoch': 2.43}                                                                                                       
{'loss': 0.4033, 'learning_rate': 0.00023072573044297833, 'epoch': 2.43}                                                                                                      
{'loss': 0.4921, 'learning_rate': 0.000230631479736098, 'epoch': 2.43}                                                                                                        
{'loss': 0.8094, 'learning_rate': 0.00023053722902921772, 'epoch': 2.44}                                                                                                      
{'loss': 0.2782, 'learning_rate': 0.0002304429783223374, 'epoch': 2.44}                                                                                                       
{'loss': 0.2887, 'learning_rate': 0.0002303487276154571, 'epoch': 2.44}                                                                                                       
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                | 7900/32330 [12:31:49<2:32:43,  2.67it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7229230641547016, 'eval_cer': 0.4188977135980746, 'eval_runtime': 529.01, 'eval_samples_per_second': 18.106, 'eval_steps_per_second': 2.265, 'epoch': 2.44}                                                                                                                                                                
{'loss': 0.4474, 'learning_rate': 0.00023025447690857678, 'epoch': 2.45}                                                                                                      
{'loss': 0.7072, 'learning_rate': 0.00023016022620169649, 'epoch': 2.45}                                                                                                      
{'loss': 0.3425, 'learning_rate': 0.0002300659754948162, 'epoch': 2.45}                                                                                                       
{'loss': 0.278, 'learning_rate': 0.00022997172478793587, 'epoch': 2.46}                                                                                                       
{'loss': 0.244, 'learning_rate': 0.0002298774740810556, 'epoch': 2.46}                                                                                                        
{'loss': 0.3507, 'learning_rate': 0.0002297832233741753, 'epoch': 2.46}                                                                                                       
{'loss': 0.4803, 'learning_rate': 0.000229688972667295, 'epoch': 2.47}                                                                                                        
{'loss': 0.3218, 'learning_rate': 0.0002295947219604147, 'epoch': 2.47}                                                                                                       
{'loss': 0.3461, 'learning_rate': 0.00022950047125353437, 'epoch': 2.47}                                                                                                      
{'loss': 0.2983, 'learning_rate': 0.00022940622054665408, 'epoch': 2.47}                                                                                                      
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                               | 8000/32330 [12:41:23<2:30:59,  2.69it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7343140509585858, 'eval_cer': 0.42351143200962693, 'eval_runtime': 532.0091, 'eval_samples_per_second': 18.003, 'eval_steps_per_second': 2.252, 'epoch': 2.47}                                                                                                                                                             
{'loss': 0.3238, 'learning_rate': 0.00022931196983977376, 'epoch': 2.48}                                                                                                      
{'loss': 0.5673, 'learning_rate': 0.00022921771913289346, 'epoch': 2.48}                                                                                                      
{'loss': 0.3605, 'learning_rate': 0.0002291234684260132, 'epoch': 2.48}                                                                                                       
{'loss': 0.3415, 'learning_rate': 0.00022902921771913288, 'epoch': 2.49}                                                                                                      
{'loss': 0.2512, 'learning_rate': 0.00022893496701225258, 'epoch': 2.49}                                                                                                      
{'loss': 0.352, 'learning_rate': 0.00022884071630537226, 'epoch': 2.49}                                                                                                       
{'loss': 1.0272, 'learning_rate': 0.00022874646559849197, 'epoch': 2.5}                                                                                                       
{'loss': 0.3259, 'learning_rate': 0.00022865221489161167, 'epoch': 2.5}                                                                                                       
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                               | 8080/32330 [12:50:52<3:36:02,  1.87it/s]Saving model checkpoint to turkish_clean/checkpoint-8080
Configuration saved in turkish_clean/checkpoint-8080/config.json
Model weights saved in turkish_clean/checkpoint-8080/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-8080/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3123, 'learning_rate': 0.00022855796418473135, 'epoch': 2.5}                                                                                                       
{'loss': 0.2821, 'learning_rate': 0.00022846371347785106, 'epoch': 2.51}                                                                                                      
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                               | 8100/32330 [12:51:02<2:38:05,  2.55it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7344592912274878, 'eval_cer': 0.422777376654633, 'eval_runtime': 530.8947, 'eval_samples_per_second': 18.041, 'eval_steps_per_second': 2.257, 'epoch': 2.51}                                                                                                                                                               
{'loss': 0.3724, 'learning_rate': 0.00022836946277097074, 'epoch': 2.51}                                                                                                      
{'loss': 0.6506, 'learning_rate': 0.00022827521206409047, 'epoch': 2.51}                                                                                                      
{'loss': 0.4076, 'learning_rate': 0.00022818096135721017, 'epoch': 2.51}                                                                                                      
{'loss': 0.2798, 'learning_rate': 0.00022808671065032985, 'epoch': 2.52}                                                                                                      
{'loss': 0.2612, 'learning_rate': 0.00022799245994344956, 'epoch': 2.52}                                                                                                      
{'loss': 0.3247, 'learning_rate': 0.00022789820923656924, 'epoch': 2.52}                                                                                                      
{'loss': 0.4707, 'learning_rate': 0.00022780395852968894, 'epoch': 2.53}                                                                                                      
{'loss': 0.5457, 'learning_rate': 0.00022770970782280865, 'epoch': 2.53}                                                                                                      
{'loss': 0.2933, 'learning_rate': 0.00022761545711592833, 'epoch': 2.53}                                                                                                      
{'loss': 0.3683, 'learning_rate': 0.00022752120640904806, 'epoch': 2.54}                                                                                                      
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                              | 8200/32330 [13:00:40<2:33:22,  2.62it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7359324425263507, 'eval_cer': 0.42614199759326116, 'eval_runtime': 536.1988, 'eval_samples_per_second': 17.863, 'eval_steps_per_second': 2.234, 'epoch': 2.54}                                                                                                                                                             
{'loss': 0.4776, 'learning_rate': 0.00022742695570216777, 'epoch': 2.54}                                                                                                      
{'loss': 0.5457, 'learning_rate': 0.00022733270499528745, 'epoch': 2.54}                                                                                                      
{'loss': 0.3238, 'learning_rate': 0.00022723845428840715, 'epoch': 2.55}                                                                                                      
{'loss': 0.3116, 'learning_rate': 0.00022714420358152683, 'epoch': 2.55}                                                                                                      
{'loss': 0.3455, 'learning_rate': 0.00022704995287464654, 'epoch': 2.55}                                                                                                      
{'loss': 0.3144, 'learning_rate': 0.00022695570216776622, 'epoch': 2.55}                                                                                                      
{'loss': 0.6143, 'learning_rate': 0.00022686145146088592, 'epoch': 2.56}                                                                                                      
{'loss': 0.3666, 'learning_rate': 0.00022676720075400566, 'epoch': 2.56}                                                                                                      
{'loss': 0.2943, 'learning_rate': 0.00022667295004712533, 'epoch': 2.56}                                                                                                      
{'loss': 0.343, 'learning_rate': 0.00022657869934024504, 'epoch': 2.57}                                                                                                       
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                              | 8300/32330 [13:10:22<2:33:06,  2.62it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7222798572495642, 'eval_cer': 0.4149723225030084, 'eval_runtime': 536.209, 'eval_samples_per_second': 17.862, 'eval_steps_per_second': 2.234, 'epoch': 2.57}                                                                                                                                                               
{'loss': 0.3116, 'learning_rate': 0.00022648444863336475, 'epoch': 2.57}                                                                                                      
{'loss': 0.6, 'learning_rate': 0.00022639019792648443, 'epoch': 2.57}                                                                                                         
{'loss': 0.3997, 'learning_rate': 0.00022629594721960413, 'epoch': 2.58}                                                                                                      
{'loss': 0.2486, 'learning_rate': 0.0002262016965127238, 'epoch': 2.58}                                                                                                       
{'loss': 0.3769, 'learning_rate': 0.00022610744580584352, 'epoch': 2.58}                                                                                                      
{'loss': 0.3478, 'learning_rate': 0.0002260131950989632, 'epoch': 2.59}                                                                                                       
{'loss': 0.5003, 'learning_rate': 0.00022591894439208293, 'epoch': 2.59}                                                                                                      
{'loss': 0.2595, 'learning_rate': 0.00022582469368520263, 'epoch': 2.59}                                                                                                      
{'loss': 0.3002, 'learning_rate': 0.0002257304429783223, 'epoch': 2.6}                                                                                                        
{'loss': 0.2738, 'learning_rate': 0.00022563619227144202, 'epoch': 2.6}                                                                                                       
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                              | 8400/32330 [13:20:04<2:30:04,  2.66it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7298323512324675, 'eval_cer': 0.4236606498194946, 'eval_runtime': 529.1534, 'eval_samples_per_second': 18.101, 'eval_steps_per_second': 2.264, 'epoch': 2.6}                                                                                                                                                               
{'loss': 0.5213, 'learning_rate': 0.00022554194156456173, 'epoch': 2.6}                                                                                                       
{'loss': 0.4865, 'learning_rate': 0.0002254476908576814, 'epoch': 2.6}                                                                                                        
{'loss': 0.3406, 'learning_rate': 0.0002253534401508011, 'epoch': 2.61}                                                                                                       
{'loss': 0.2584, 'learning_rate': 0.0002252591894439208, 'epoch': 2.61}                                                                                                       
{'loss': 0.3446, 'learning_rate': 0.00022516493873704052, 'epoch': 2.61}                                                                                                      
{'loss': 0.3509, 'learning_rate': 0.00022507068803016023, 'epoch': 2.62}                                                                                                      
{'loss': 0.4785, 'learning_rate': 0.0002249764373232799, 'epoch': 2.62}                                                                                                       
{'loss': 0.4894, 'learning_rate': 0.0002248821866163996, 'epoch': 2.62}                                                                                                       
{'loss': 0.3558, 'learning_rate': 0.0002247879359095193, 'epoch': 2.63}                                                                                                       
{'loss': 0.3218, 'learning_rate': 0.000224693685202639, 'epoch': 2.63}                                                                                                        
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                             | 8500/32330 [13:29:38<2:31:27,  2.62it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.734500788447174, 'eval_cer': 0.42143922984356197, 'eval_runtime': 531.2224, 'eval_samples_per_second': 18.03, 'eval_steps_per_second': 2.255, 'epoch': 2.63}                                                                                                                                                               
{'loss': 0.4379, 'learning_rate': 0.00022459943449575868, 'epoch': 2.63}                                                                                                      
{'loss': 0.4792, 'learning_rate': 0.00022450518378887838, 'epoch': 2.64}                                                                                                      
{'loss': 0.2674, 'learning_rate': 0.0002244109330819981, 'epoch': 2.64}                                                                                                       
{'loss': 0.2902, 'learning_rate': 0.0002243166823751178, 'epoch': 2.64}                                                                                                       
{'loss': 0.315, 'learning_rate': 0.0002242224316682375, 'epoch': 2.64}                                                                                                        
{'loss': 0.3, 'learning_rate': 0.0002241281809613572, 'epoch': 2.65}                                                                                                          
{'loss': 0.5598, 'learning_rate': 0.00022403393025447689, 'epoch': 2.65}                                                                                                      
{'loss': 0.3129, 'learning_rate': 0.0002239396795475966, 'epoch': 2.65}                                                                                                       
{'loss': 0.3106, 'learning_rate': 0.00022384542884071627, 'epoch': 2.66}                                                                                                      
{'loss': 0.2851, 'learning_rate': 0.00022375117813383598, 'epoch': 2.66}                                                                                                      
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                             | 8600/32330 [13:39:15<2:29:00,  2.65it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7289816582288987, 'eval_cer': 0.4185583634175692, 'eval_runtime': 531.5086, 'eval_samples_per_second': 18.02, 'eval_steps_per_second': 2.254, 'epoch': 2.66}                                                                                                                                                               
{'loss': 0.3684, 'learning_rate': 0.00022365692742695565, 'epoch': 2.66}                                                                                                      
{'loss': 0.4844, 'learning_rate': 0.0002235626767200754, 'epoch': 2.67}                                                                                                       
{'loss': 0.4329, 'learning_rate': 0.0002234684260131951, 'epoch': 2.67}                                                                                                       
{'loss': 0.3263, 'learning_rate': 0.00022337417530631477, 'epoch': 2.67}                                                                                                      
{'loss': 0.3519, 'learning_rate': 0.00022327992459943448, 'epoch': 2.68}                                                                                                      
{'loss': 0.3658, 'learning_rate': 0.00022318567389255418, 'epoch': 2.68}                                                                                                      
{'loss': 0.4817, 'learning_rate': 0.00022309142318567386, 'epoch': 2.68}                                                                                                      
{'loss': 0.2835, 'learning_rate': 0.00022299717247879357, 'epoch': 2.68}                                                                                                      
{'loss': 0.2768, 'learning_rate': 0.00022290292177191325, 'epoch': 2.69}                                                                                                      
{'loss': 0.2906, 'learning_rate': 0.00022280867106503298, 'epoch': 2.69}                                                                                                      
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                            | 8700/32330 [13:48:51<2:28:50,  2.65it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7295626193045066, 'eval_cer': 0.4172563176895307, 'eval_runtime': 531.5551, 'eval_samples_per_second': 18.019, 'eval_steps_per_second': 2.254, 'epoch': 2.69}                                                                                                                                                              
{'loss': 0.2988, 'learning_rate': 0.0002227144203581527, 'epoch': 2.69}                                                                                                       
{'loss': 0.5352, 'learning_rate': 0.00022262016965127237, 'epoch': 2.7}                                                                                                       
{'loss': 0.4137, 'learning_rate': 0.00022252591894439207, 'epoch': 2.7}                                                                                                       
{'loss': 0.3048, 'learning_rate': 0.00022243166823751175, 'epoch': 2.7}                                                                                                       
{'loss': 0.3149, 'learning_rate': 0.00022233741753063146, 'epoch': 2.71}                                                                                                      
{'loss': 0.3417, 'learning_rate': 0.00022224316682375116, 'epoch': 2.71}                                                                                                      
{'loss': 0.5106, 'learning_rate': 0.00022214891611687084, 'epoch': 2.71}                                                                                                      
{'loss': 0.4469, 'learning_rate': 0.00022205466540999055, 'epoch': 2.72}                                                                                                      
{'loss': 0.2482, 'learning_rate': 0.00022196041470311028, 'epoch': 2.72}                                                                                                      
{'loss': 0.2979, 'learning_rate': 0.00022186616399622996, 'epoch': 2.72}                                                                                                      
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                            | 8800/32330 [13:58:28<2:29:14,  2.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7193543032616815, 'eval_cer': 0.4204693140794224, 'eval_runtime': 537.8185, 'eval_samples_per_second': 17.809, 'eval_steps_per_second': 2.228, 'epoch': 2.72}                                                                                                                                                              
{'loss': 0.3919, 'learning_rate': 0.00022177191328934967, 'epoch': 2.72}                                                                                                      
{'loss': 0.5112, 'learning_rate': 0.00022167766258246934, 'epoch': 2.73}                                                                                                      
{'loss': 0.3043, 'learning_rate': 0.00022158341187558905, 'epoch': 2.73}                                                                                                      
{'loss': 0.3007, 'learning_rate': 0.00022148916116870873, 'epoch': 2.73}                                                                                                      
{'loss': 0.2968, 'learning_rate': 0.00022139491046182844, 'epoch': 2.74}                                                                                                      
{'loss': 0.3643, 'learning_rate': 0.00022130065975494814, 'epoch': 2.74}                                                                                                      
{'loss': 0.5723, 'learning_rate': 0.00022120640904806785, 'epoch': 2.74}                                                                                                      
{'loss': 0.2762, 'learning_rate': 0.00022112158341187554, 'epoch': 2.75}                                                                                                      
{'loss': 0.3435, 'learning_rate': 0.00022102733270499525, 'epoch': 2.75}                                                                                                      
{'loss': 0.3567, 'learning_rate': 0.00022093308199811498, 'epoch': 2.75}                                                                                                      
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                            | 8900/32330 [14:08:11<2:27:30,  2.65it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.728006473566271, 'eval_cer': 0.4207509025270758, 'eval_runtime': 536.77, 'eval_samples_per_second': 17.844, 'eval_steps_per_second': 2.232, 'epoch': 2.75}                                                                                                                                                                 
{'loss': 0.3035, 'learning_rate': 0.00022083883129123466, 'epoch': 2.76}                                                                                                      
{'loss': 0.4659, 'learning_rate': 0.00022074458058435437, 'epoch': 2.76}                                                                                                      
{'loss': 0.3074, 'learning_rate': 0.00022065032987747407, 'epoch': 2.76}                                                                                                      
{'loss': 0.2875, 'learning_rate': 0.00022055607917059375, 'epoch': 2.77}                                                                                                      
{'loss': 0.2333, 'learning_rate': 0.00022046182846371346, 'epoch': 2.77}                                                                                                      
{'loss': 0.4667, 'learning_rate': 0.00022036757775683314, 'epoch': 2.77}                                                                                                      
{'loss': 0.3665, 'learning_rate': 0.00022027332704995284, 'epoch': 2.77}                                                                                                      
{'loss': 0.2875, 'learning_rate': 0.00022017907634307258, 'epoch': 2.78}                                                                                                      
{'loss': 0.2807, 'learning_rate': 0.00022008482563619226, 'epoch': 2.78}                                                                                                      
{'loss': 0.3774, 'learning_rate': 0.00021999057492931196, 'epoch': 2.78}                                                                                                      
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                           | 9000/32330 [14:17:54<2:30:35,  2.58it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7175699228151714, 'eval_cer': 0.418604091456077, 'eval_runtime': 533.2238, 'eval_samples_per_second': 17.962, 'eval_steps_per_second': 2.247, 'epoch': 2.78}                                                                                                                                                               
{'loss': 0.3264, 'learning_rate': 0.00021989632422243164, 'epoch': 2.79}                                                                                                      
{'loss': 0.4605, 'learning_rate': 0.00021980207351555135, 'epoch': 2.79}                                                                                                      
{'loss': 0.298, 'learning_rate': 0.00021970782280867105, 'epoch': 2.79}                                                                                                       
{'loss': 0.2737, 'learning_rate': 0.00021961357210179073, 'epoch': 2.8}                                                                                                       
{'loss': 0.2735, 'learning_rate': 0.00021951932139491044, 'epoch': 2.8}                                                                                                       
{'loss': 0.3485, 'learning_rate': 0.00021942507068803012, 'epoch': 2.8}                                                                                                       
{'loss': 0.4961, 'learning_rate': 0.00021933081998114985, 'epoch': 2.81}                                                                                                      
{'loss': 1.2454, 'learning_rate': 0.00021923656927426956, 'epoch': 2.81}                                                                                                      
{'loss': 0.2522, 'learning_rate': 0.00021914231856738923, 'epoch': 2.81}                                                                                                      
{'loss': 0.2718, 'learning_rate': 0.00021904806786050894, 'epoch': 2.81}                                                                                                      
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                           | 9100/32330 [14:27:33<2:29:35,  2.59it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7229438127645448, 'eval_cer': 0.42039470517448857, 'eval_runtime': 536.6264, 'eval_samples_per_second': 17.849, 'eval_steps_per_second': 2.232, 'epoch': 2.81}                                                                                                                                                             
{'loss': 0.3994, 'learning_rate': 0.00021895381715362862, 'epoch': 2.82}                                                                                                      
{'loss': 0.4561, 'learning_rate': 0.00021885956644674833, 'epoch': 2.82}                                                                                                      
{'loss': 0.2899, 'learning_rate': 0.00021876531573986803, 'epoch': 2.82}                                                                                                      
{'loss': 0.2805, 'learning_rate': 0.0002186710650329877, 'epoch': 2.83}                                                                                                       
{'loss': 0.3383, 'learning_rate': 0.00021857681432610744, 'epoch': 2.83}                                                                                                      
{'loss': 0.3453, 'learning_rate': 0.00021848256361922712, 'epoch': 2.83}                                                                                                      
{'loss': 0.3949, 'learning_rate': 0.00021838831291234683, 'epoch': 2.84}                                                                                                      
{'loss': 0.3016, 'learning_rate': 0.00021829406220546653, 'epoch': 2.84}                                                                                                      
{'loss': 0.3568, 'learning_rate': 0.0002181998114985862, 'epoch': 2.84}                                                                                                       
{'loss': 0.3165, 'learning_rate': 0.00021810556079170592, 'epoch': 2.85}                                                                                                      
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                          | 9200/32330 [14:37:15<2:30:08,  2.57it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7163457548344261, 'eval_cer': 0.4190228640192539, 'eval_runtime': 538.5351, 'eval_samples_per_second': 17.785, 'eval_steps_per_second': 2.225, 'epoch': 2.85}                                                                                                                                                              
{'loss': 0.3627, 'learning_rate': 0.0002180113100848256, 'epoch': 2.85}                                                                                                       
{'loss': 0.5196, 'learning_rate': 0.0002179170593779453, 'epoch': 2.85}                                                                                                       
{'loss': 0.3115, 'learning_rate': 0.00021782280867106504, 'epoch': 2.85}                                                                                                      
{'loss': 0.3267, 'learning_rate': 0.00021772855796418472, 'epoch': 2.86}                                                                                                      
{'loss': 0.2986, 'learning_rate': 0.00021763430725730442, 'epoch': 2.86}                                                                                                      
{'loss': 0.3991, 'learning_rate': 0.0002175400565504241, 'epoch': 2.86}                                                                                                       
{'loss': 0.5203, 'learning_rate': 0.0002174458058435438, 'epoch': 2.87}                                                                                                       
{'loss': 0.498, 'learning_rate': 0.0002173515551366635, 'epoch': 2.87}                                                                                                        
{'loss': 0.24, 'learning_rate': 0.0002172573044297832, 'epoch': 2.87}                                                                                                         
{'loss': 0.3413, 'learning_rate': 0.0002171630537229029, 'epoch': 2.88}                                                                                                       
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                          | 9300/32330 [14:46:59<2:27:04,  2.61it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7134824466760727, 'eval_cer': 0.41806498194945846, 'eval_runtime': 538.2069, 'eval_samples_per_second': 17.796, 'eval_steps_per_second': 2.226, 'epoch': 2.88}                                                                                                                                                             
{'loss': 0.3016, 'learning_rate': 0.00021706880301602258, 'epoch': 2.88}                                                                                                      
{'loss': 0.445, 'learning_rate': 0.0002169745523091423, 'epoch': 2.88}                                                                                                        
{'loss': 0.3442, 'learning_rate': 0.00021688030160226202, 'epoch': 2.89}                                                                                                      
{'loss': 0.282, 'learning_rate': 0.0002167860508953817, 'epoch': 2.89}                                                                                                        
{'loss': 0.5267, 'learning_rate': 0.0002166918001885014, 'epoch': 2.89}                                                                                                       
{'loss': 0.3074, 'learning_rate': 0.00021659754948162108, 'epoch': 2.9}                                                                                                       
{'loss': 0.4464, 'learning_rate': 0.00021650329877474078, 'epoch': 2.9}                                                                                                       
{'loss': 0.2939, 'learning_rate': 0.0002164090480678605, 'epoch': 2.9}                                                                                                        
{'loss': 0.258, 'learning_rate': 0.00021631479736098017, 'epoch': 2.9}                                                                                                        
{'loss': 0.3305, 'learning_rate': 0.0002162205466540999, 'epoch': 2.91}                                                                                                       
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                          | 9400/32330 [14:56:43<2:27:24,  2.59it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7273632666611337, 'eval_cer': 0.4263537906137184, 'eval_runtime': 537.8615, 'eval_samples_per_second': 17.808, 'eval_steps_per_second': 2.227, 'epoch': 2.91}                                                                                                                                                              
{'loss': 0.3573, 'learning_rate': 0.0002161262959472196, 'epoch': 2.91}                                                                                                       
{'loss': 0.5015, 'learning_rate': 0.0002160320452403393, 'epoch': 2.91}                                                                                                       
{'loss': 0.4065, 'learning_rate': 0.000215937794533459, 'epoch': 2.92}                                                                                                        
{'loss': 0.2907, 'learning_rate': 0.00021584354382657867, 'epoch': 2.92}                                                                                                      
{'loss': 0.2876, 'learning_rate': 0.00021574929311969838, 'epoch': 2.92}                                                                                                      
{'loss': 0.3713, 'learning_rate': 0.00021565504241281806, 'epoch': 2.93}                                                                                                      
{'loss': 0.4317, 'learning_rate': 0.00021556079170593776, 'epoch': 2.93}                                                                                                      
{'loss': 0.3025, 'learning_rate': 0.00021546654099905747, 'epoch': 2.93}                                                                                                      
{'loss': 0.2989, 'learning_rate': 0.00021537229029217718, 'epoch': 2.94}                                                                                                      
{'loss': 0.3012, 'learning_rate': 0.00021527803958529688, 'epoch': 2.94}                                                                                                      
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                         | 9500/32330 [15:06:26<2:26:15,  2.60it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7234832766204664, 'eval_cer': 0.4219326113116727, 'eval_runtime': 540.2935, 'eval_samples_per_second': 17.727, 'eval_steps_per_second': 2.217, 'epoch': 2.94}                                                                                                                                                              
{'loss': 0.4037, 'learning_rate': 0.0002151837888784166, 'epoch': 2.94}                                                                                                       
{'loss': 0.4131, 'learning_rate': 0.00021508953817153627, 'epoch': 2.94}                                                                                                      
{'loss': 0.3186, 'learning_rate': 0.00021499528746465597, 'epoch': 2.95}                                                                                                      
{'loss': 0.3125, 'learning_rate': 0.00021490103675777565, 'epoch': 2.95}                                                                                                      
{'loss': 0.3721, 'learning_rate': 0.00021480678605089536, 'epoch': 2.95}                                                                                                      
{'loss': 0.3, 'learning_rate': 0.00021471253534401504, 'epoch': 2.96}                                                                                                         
{'loss': 1.0041, 'learning_rate': 0.00021461828463713477, 'epoch': 2.96}                                                                                                      
{'loss': 0.5973, 'learning_rate': 0.00021452403393025447, 'epoch': 2.96}                                                                                                      
{'loss': 0.2982, 'learning_rate': 0.00021442978322337415, 'epoch': 2.97}                                                                                                      
{'loss': 0.2853, 'learning_rate': 0.00021433553251649386, 'epoch': 2.97}                                                                                                      
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                         | 9600/32330 [15:16:12<2:25:44,  2.60it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7174246825462695, 'eval_cer': 0.41812033694344164, 'eval_runtime': 538.1682, 'eval_samples_per_second': 17.797, 'eval_steps_per_second': 2.226, 'epoch': 2.97}                                                                                                                                                             
{'loss': 0.2152, 'learning_rate': 0.00021424128180961357, 'epoch': 2.97}                                                                                                      
{'loss': 0.504, 'learning_rate': 0.00021414703110273324, 'epoch': 2.98}                                                                                                       
{'loss': 0.3365, 'learning_rate': 0.00021405278039585295, 'epoch': 2.98}                                                                                                      
{'loss': 0.2577, 'learning_rate': 0.00021395852968897263, 'epoch': 2.98}                                                                                                      
{'loss': 0.3234, 'learning_rate': 0.00021386427898209236, 'epoch': 2.98}                                                                                                      
{'loss': 0.2376, 'learning_rate': 0.00021377002827521207, 'epoch': 2.99}                                                                                                      
{'loss': 0.4787, 'learning_rate': 0.00021367577756833175, 'epoch': 2.99}                                                                                                      
{'loss': 0.275, 'learning_rate': 0.00021358152686145145, 'epoch': 2.99}                                                                                                       
{'loss': 0.2894, 'learning_rate': 0.00021348727615457113, 'epoch': 3.0}                                                                                                       
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                         | 9696/32330 [15:25:53<2:12:44,  2.84it/s]Saving model checkpoint to turkish_clean/checkpoint-9696
Configuration saved in turkish_clean/checkpoint-9696/config.json
Model weights saved in turkish_clean/checkpoint-9696/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-9696/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4172, 'learning_rate': 0.00021339302544769084, 'epoch': 3.0}                                                                                                       
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                         | 9700/32330 [15:25:57<5:10:10,  1.22it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7213254211967798, 'eval_cer': 0.41823826714801443, 'eval_runtime': 539.8854, 'eval_samples_per_second': 17.741, 'eval_steps_per_second': 2.219, 'epoch': 3.0}                                                                                                                                                              
{'loss': 0.6508, 'learning_rate': 0.00021329877474081052, 'epoch': 3.0}                                                                                                       
{'loss': 0.2394, 'learning_rate': 0.00021320452403393022, 'epoch': 3.01}                                                                                                      
{'loss': 0.2812, 'learning_rate': 0.00021311027332704993, 'epoch': 3.01}                                                                                                      
{'loss': 0.2733, 'learning_rate': 0.00021301602262016963, 'epoch': 3.01}                                                                                                      
{'loss': 0.5256, 'learning_rate': 0.00021292177191328934, 'epoch': 3.02}                                                                                                      
{'loss': 0.3172, 'learning_rate': 0.00021282752120640905, 'epoch': 3.02}                                                                                                      
{'loss': 0.2122, 'learning_rate': 0.00021273327049952873, 'epoch': 3.02}                                                                                                      
{'loss': 0.2204, 'learning_rate': 0.00021263901979264843, 'epoch': 3.03}                                                                                                      
{'loss': 0.2361, 'learning_rate': 0.0002125447690857681, 'epoch': 3.03}                                                                                                       
{'loss': 0.3744, 'learning_rate': 0.00021245051837888782, 'epoch': 3.03}                                                                                                      
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                        | 9800/32330 [15:35:42<3:15:31,  1.92it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7162420117852104, 'eval_cer': 0.41591817087845967, 'eval_runtime': 537.0737, 'eval_samples_per_second': 17.834, 'eval_steps_per_second': 2.231, 'epoch': 3.03}                                                                                                                                                             
{'loss': 0.2877, 'learning_rate': 0.0002123562676720075, 'epoch': 3.03}                                                                                                       
{'loss': 0.2361, 'learning_rate': 0.00021226201696512723, 'epoch': 3.04}                                                                                                      
{'loss': 0.2312, 'learning_rate': 0.00021216776625824693, 'epoch': 3.04}                                                                                                      
{'loss': 0.2497, 'learning_rate': 0.0002120735155513666, 'epoch': 3.04}                                                                                                       
{'loss': 0.4936, 'learning_rate': 0.00021197926484448632, 'epoch': 3.05}                                                                                                      
{'loss': 1.0587, 'learning_rate': 0.00021188501413760602, 'epoch': 3.05}                                                                                                      
{'loss': 0.2759, 'learning_rate': 0.0002117907634307257, 'epoch': 3.05}                                                                                                       
{'loss': 0.298, 'learning_rate': 0.0002116965127238454, 'epoch': 3.06}                                                                                                        
{'loss': 0.2728, 'learning_rate': 0.0002116022620169651, 'epoch': 3.06}                                                                                                       
{'loss': 0.5126, 'learning_rate': 0.0002115080113100848, 'epoch': 3.06}                                                                                                       
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                        | 9900/32330 [15:45:27<3:14:21,  1.92it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7095609594157192, 'eval_cer': 0.4158194945848375, 'eval_runtime': 534.2303, 'eval_samples_per_second': 17.929, 'eval_steps_per_second': 2.242, 'epoch': 3.06}                                                                                                                                                              
{'loss': 0.2671, 'learning_rate': 0.00021141376060320453, 'epoch': 3.07}                                                                                                      
{'loss': 0.2528, 'learning_rate': 0.0002113195098963242, 'epoch': 3.07}                                                                                                       
{'loss': 0.2065, 'learning_rate': 0.0002112252591894439, 'epoch': 3.07}                                                                                                       
{'loss': 0.235, 'learning_rate': 0.0002111310084825636, 'epoch': 3.07}                                                                                                        
{'loss': 0.8664, 'learning_rate': 0.0002110367577756833, 'epoch': 3.08}                                                                                                       
{'loss': 0.3204, 'learning_rate': 0.000210942507068803, 'epoch': 3.08}                                                                                                        
{'loss': 0.2851, 'learning_rate': 0.00021084825636192268, 'epoch': 3.08}                                                                                                      
{'loss': 0.2205, 'learning_rate': 0.0002107540056550424, 'epoch': 3.09}                                                                                                       
{'loss': 0.2776, 'learning_rate': 0.0002106597549481621, 'epoch': 3.09}                                                                                                       
{'loss': 0.4169, 'learning_rate': 0.0002105655042412818, 'epoch': 3.09}                                                                                                       
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                       | 10000/32330 [15:55:06<3:13:34,  1.92it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.715163084073367, 'eval_cer': 0.4179350180505415, 'eval_runtime': 538.4052, 'eval_samples_per_second': 17.79, 'eval_steps_per_second': 2.225, 'epoch': 3.09}                                                                                                                                                                
{'loss': 0.3185, 'learning_rate': 0.0002104806786050895, 'epoch': 3.1}                                                                                                        
{'loss': 0.2285, 'learning_rate': 0.00021038642789820923, 'epoch': 3.1}                                                                                                       
{'loss': 0.2449, 'learning_rate': 0.00021029217719132894, 'epoch': 3.1}                                                                                                       
{'loss': 0.2847, 'learning_rate': 0.00021019792648444862, 'epoch': 3.11}                                                                                                      
{'loss': 0.5095, 'learning_rate': 0.00021010367577756832, 'epoch': 3.11}                                                                                                      
{'loss': 0.3465, 'learning_rate': 0.000210009425070688, 'epoch': 3.11}                                                                                                        
{'loss': 0.2695, 'learning_rate': 0.0002099151743638077, 'epoch': 3.11}                                                                                                       
{'loss': 0.2621, 'learning_rate': 0.00020982092365692738, 'epoch': 3.12}                                                                                                      
{'loss': 0.2476, 'learning_rate': 0.0002097266729500471, 'epoch': 3.12}                                                                                                       
{'loss': 0.3778, 'learning_rate': 0.00020963242224316682, 'epoch': 3.12}                                                                                                      
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                      | 10100/32330 [16:04:50<3:10:31,  1.94it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7163872520541124, 'eval_cer': 0.41561010830324907, 'eval_runtime': 537.6669, 'eval_samples_per_second': 17.814, 'eval_steps_per_second': 2.228, 'epoch': 3.12}                                                                                                                                                             
{'loss': 0.3038, 'learning_rate': 0.0002095381715362865, 'epoch': 3.13}                                                                                                       
{'loss': 0.2371, 'learning_rate': 0.0002094439208294062, 'epoch': 3.13}                                                                                                       
{'loss': 0.259, 'learning_rate': 0.00020934967012252591, 'epoch': 3.13}                                                                                                       
{'loss': 0.3058, 'learning_rate': 0.0002092554194156456, 'epoch': 3.14}                                                                                                       
{'loss': 0.4961, 'learning_rate': 0.0002091611687087653, 'epoch': 3.14}                                                                                                       
{'loss': 0.2897, 'learning_rate': 0.00020906691800188498, 'epoch': 3.14}                                                                                                      
{'loss': 0.2366, 'learning_rate': 0.00020897266729500468, 'epoch': 3.15}                                                                                                      
{'loss': 0.2406, 'learning_rate': 0.00020887841658812442, 'epoch': 3.15}                                                                                                      
{'loss': 0.3573, 'learning_rate': 0.0002087841658812441, 'epoch': 3.15}                                                                                                       
{'loss': 0.4532, 'learning_rate': 0.0002086899151743638, 'epoch': 3.15}                                                                                                       
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                      | 10200/32330 [16:14:33<3:11:59,  1.92it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7054734832766205, 'eval_cer': 0.4169434416365824, 'eval_runtime': 533.7334, 'eval_samples_per_second': 17.945, 'eval_steps_per_second': 2.245, 'epoch': 3.15}                                                                                                                                                              
{'loss': 0.3231, 'learning_rate': 0.00020859566446748348, 'epoch': 3.16}                                                                                                      
{'loss': 0.2445, 'learning_rate': 0.0002085014137606032, 'epoch': 3.16}                                                                                                       
{'loss': 0.2014, 'learning_rate': 0.0002084071630537229, 'epoch': 3.16}                                                                                                       
{'loss': 0.3084, 'learning_rate': 0.00020831291234684257, 'epoch': 3.17}                                                                                                      
{'loss': 0.4441, 'learning_rate': 0.00020821866163996228, 'epoch': 3.17}                                                                                                      
{'loss': 0.3919, 'learning_rate': 0.00020812441093308196, 'epoch': 3.17}                                                                                                      
{'loss': 0.2454, 'learning_rate': 0.0002080301602262017, 'epoch': 3.18}                                                                                                       
{'loss': 0.2539, 'learning_rate': 0.0002079359095193214, 'epoch': 3.18}                                                                                                       
{'loss': 0.2704, 'learning_rate': 0.00020784165881244107, 'epoch': 3.18}                                                                                                      
{'loss': 0.5104, 'learning_rate': 0.00020774740810556078, 'epoch': 3.19}                                                                                                      
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                     | 10300/32330 [16:24:14<2:59:28,  2.05it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7032948792430908, 'eval_cer': 0.41622864019253913, 'eval_runtime': 538.5966, 'eval_samples_per_second': 17.783, 'eval_steps_per_second': 2.224, 'epoch': 3.19}                                                                                                                                                             
{'loss': 0.278, 'learning_rate': 0.00020765315739868046, 'epoch': 3.19}                                                                                                       
{'loss': 0.2445, 'learning_rate': 0.00020755890669180017, 'epoch': 3.19}                                                                                                      
{'loss': 0.2826, 'learning_rate': 0.00020746465598491987, 'epoch': 3.2}                                                                                                       
{'loss': 0.2281, 'learning_rate': 0.00020737040527803955, 'epoch': 3.2}                                                                                                       
{'loss': 0.4504, 'learning_rate': 0.00020727615457115928, 'epoch': 3.2}                                                                                                       
{'loss': 0.2821, 'learning_rate': 0.00020718190386427896, 'epoch': 3.2}                                                                                                       
{'loss': 0.2212, 'learning_rate': 0.00020708765315739867, 'epoch': 3.21}                                                                                                      
{'loss': 0.3062, 'learning_rate': 0.00020699340245051837, 'epoch': 3.21}                                                                                                      
{'loss': 0.3072, 'learning_rate': 0.00020689915174363805, 'epoch': 3.21}                                                                                                      
{'loss': 0.4431, 'learning_rate': 0.00020680490103675776, 'epoch': 3.22}                                                                                                      
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                     | 10400/32330 [16:33:58<3:14:08,  1.88it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7057847124242675, 'eval_cer': 0.41493622141997594, 'eval_runtime': 531.8122, 'eval_samples_per_second': 18.01, 'eval_steps_per_second': 2.253, 'epoch': 3.22}                                                                                                                                                              
{'loss': 0.6424, 'learning_rate': 0.00020671065032987744, 'epoch': 3.22}                                                                                                      
{'loss': 0.2118, 'learning_rate': 0.00020661639962299714, 'epoch': 3.22}                                                                                                      
{'loss': 0.267, 'learning_rate': 0.00020652214891611682, 'epoch': 3.23}                                                                                                       
{'loss': 0.3178, 'learning_rate': 0.00020642789820923656, 'epoch': 3.23}                                                                                                      
{'loss': 0.4109, 'learning_rate': 0.00020633364750235626, 'epoch': 3.23}                                                                                                      
{'loss': 0.3166, 'learning_rate': 0.00020623939679547594, 'epoch': 3.24}                                                                                                      
{'loss': 0.2839, 'learning_rate': 0.00020614514608859565, 'epoch': 3.24}                                                                                                      
{'loss': 0.2826, 'learning_rate': 0.00020605089538171535, 'epoch': 3.24}                                                                                                      
{'loss': 0.2784, 'learning_rate': 0.00020595664467483503, 'epoch': 3.24}                                                                                                      
{'loss': 0.5109, 'learning_rate': 0.00020586239396795474, 'epoch': 3.25}                                                                                                      
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                     | 10500/32330 [16:43:35<3:11:11,  1.90it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7068428915262678, 'eval_cer': 0.41604091456077014, 'eval_runtime': 537.0361, 'eval_samples_per_second': 17.835, 'eval_steps_per_second': 2.231, 'epoch': 3.25}                                                                                                                                                             
{'loss': 0.3171, 'learning_rate': 0.00020576814326107442, 'epoch': 3.25}                                                                                                      
{'loss': 0.2294, 'learning_rate': 0.00020567389255419415, 'epoch': 3.25}                                                                                                      
{'loss': 0.2938, 'learning_rate': 0.00020557964184731386, 'epoch': 3.26}                                                                                                      
{'loss': 0.3266, 'learning_rate': 0.00020548539114043353, 'epoch': 3.26}                                                                                                      
{'loss': 0.3991, 'learning_rate': 0.00020539114043355324, 'epoch': 3.26}                                                                                                      
{'loss': 0.5604, 'learning_rate': 0.00020529688972667292, 'epoch': 3.27}                                                                                                      
{'loss': 0.2643, 'learning_rate': 0.00020520263901979263, 'epoch': 3.27}                                                                                                      
{'loss': 0.2986, 'learning_rate': 0.00020510838831291233, 'epoch': 3.27}                                                                                                      
{'loss': 0.3328, 'learning_rate': 0.000205014137606032, 'epoch': 3.28}                                                                                                        
{'loss': 0.5299, 'learning_rate': 0.00020491988689915174, 'epoch': 3.28}                                                                                                      
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                    | 10600/32330 [16:53:17<2:58:26,  2.03it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7172794422773674, 'eval_cer': 0.4215090252707581, 'eval_runtime': 537.633, 'eval_samples_per_second': 17.815, 'eval_steps_per_second': 2.228, 'epoch': 3.28}                                                                                                                                                               
{'loss': 0.2865, 'learning_rate': 0.00020482563619227145, 'epoch': 3.28}                                                                                                      
{'loss': 0.2462, 'learning_rate': 0.00020473138548539113, 'epoch': 3.28}                                                                                                      
{'loss': 0.2512, 'learning_rate': 0.00020463713477851083, 'epoch': 3.29}                                                                                                      
{'loss': 0.2692, 'learning_rate': 0.0002045428840716305, 'epoch': 3.29}                                                                                                       
{'loss': 0.5326, 'learning_rate': 0.00020444863336475022, 'epoch': 3.29}                                                                                                      
{'loss': 0.2737, 'learning_rate': 0.0002043543826578699, 'epoch': 3.3}                                                                                                        
{'loss': 0.2323, 'learning_rate': 0.0002042601319509896, 'epoch': 3.3}                                                                                                        
{'loss': 0.2674, 'learning_rate': 0.0002041658812441093, 'epoch': 3.3}                                                                                                        
{'loss': 0.2655, 'learning_rate': 0.00020407163053722902, 'epoch': 3.31}                                                                                                      
{'loss': 0.5434, 'learning_rate': 0.00020397737983034872, 'epoch': 3.31}                                                                                                      
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                    | 10700/32330 [17:03:00<3:07:42,  1.92it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7242509751846626, 'eval_cer': 0.41653188929001206, 'eval_runtime': 535.5331, 'eval_samples_per_second': 17.885, 'eval_steps_per_second': 2.237, 'epoch': 3.31}                                                                                                                                                             
{'loss': 0.3232, 'learning_rate': 0.00020388312912346843, 'epoch': 3.31}                                                                                                      
{'loss': 0.2462, 'learning_rate': 0.0002037888784165881, 'epoch': 3.32}                                                                                                       
{'loss': 0.2891, 'learning_rate': 0.0002036946277097078, 'epoch': 3.32}                                                                                                       
{'loss': 0.267, 'learning_rate': 0.0002036003770028275, 'epoch': 3.32}                                                                                                        
{'loss': 0.4078, 'learning_rate': 0.0002035061262959472, 'epoch': 3.33}                                                                                                       
{'loss': 0.2701, 'learning_rate': 0.00020342130065975492, 'epoch': 3.33}                                                                                                      
{'loss': 0.3159, 'learning_rate': 0.00020332704995287463, 'epoch': 3.33}                                                                                                      
{'loss': 0.2881, 'learning_rate': 0.0002032327992459943, 'epoch': 3.33}                                                                                                       
{'loss': 0.3338, 'learning_rate': 0.000203138548539114, 'epoch': 3.34}                                                                                                        
{'loss': 0.4067, 'learning_rate': 0.00020304429783223375, 'epoch': 3.34}                                                                                                      
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                    | 10800/32330 [17:12:42<3:02:28,  1.97it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7348535148145074, 'eval_cer': 0.4192611311672684, 'eval_runtime': 532.9138, 'eval_samples_per_second': 17.973, 'eval_steps_per_second': 2.248, 'epoch': 3.34}                                                                                                                                                              
{'loss': 0.2892, 'learning_rate': 0.00020295004712535342, 'epoch': 3.34}                                                                                                      
{'loss': 0.2625, 'learning_rate': 0.00020285579641847313, 'epoch': 3.35}                                                                                                      
{'loss': 0.3113, 'learning_rate': 0.0002027615457115928, 'epoch': 3.35}                                                                                                       
{'loss': 0.234, 'learning_rate': 0.00020266729500471252, 'epoch': 3.35}                                                                                                       
{'loss': 0.4876, 'learning_rate': 0.00020257304429783222, 'epoch': 3.36}                                                                                                      
{'loss': 0.3194, 'learning_rate': 0.0002024787935909519, 'epoch': 3.36}                                                                                                       
{'loss': 0.2958, 'learning_rate': 0.0002023845428840716, 'epoch': 3.36}                                                                                                       
{'loss': 0.2546, 'learning_rate': 0.00020229029217719134, 'epoch': 3.37}                                                                                                      
{'loss': 0.4841, 'learning_rate': 0.00020219604147031102, 'epoch': 3.37}                                                                                                      
{'loss': 0.5078, 'learning_rate': 0.00020210179076343072, 'epoch': 3.37}                                                                                                      
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                   | 10900/32330 [17:22:20<3:02:51,  1.95it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7006390571831688, 'eval_cer': 0.4138531889290012, 'eval_runtime': 538.4281, 'eval_samples_per_second': 17.789, 'eval_steps_per_second': 2.225, 'epoch': 3.37}                                                                                                                                                              
{'loss': 0.5082, 'learning_rate': 0.0002020075400565504, 'epoch': 3.37}                                                                                                       
{'loss': 0.2463, 'learning_rate': 0.0002019132893496701, 'epoch': 3.38}                                                                                                       
{'loss': 0.2629, 'learning_rate': 0.0002018190386427898, 'epoch': 3.38}                                                                                                       
{'loss': 0.2806, 'learning_rate': 0.0002017247879359095, 'epoch': 3.38}                                                                                                       
{'loss': 0.3796, 'learning_rate': 0.0002016305372290292, 'epoch': 3.39}                                                                                                       
{'loss': 0.2531, 'learning_rate': 0.00020153628652214888, 'epoch': 3.39}                                                                                                      
{'loss': 0.2259, 'learning_rate': 0.0002014420358152686, 'epoch': 3.39}                                                                                                       
{'loss': 0.2478, 'learning_rate': 0.00020134778510838832, 'epoch': 3.4}                                                                                                       
{'loss': 0.258, 'learning_rate': 0.000201253534401508, 'epoch': 3.4}                                                                                                          
{'loss': 0.4333, 'learning_rate': 0.0002011592836946277, 'epoch': 3.4}                                                                                                        
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                   | 11000/32330 [17:32:04<3:00:53,  1.97it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7150385924143082, 'eval_cer': 0.4165246690734055, 'eval_runtime': 538.0467, 'eval_samples_per_second': 17.801, 'eval_steps_per_second': 2.227, 'epoch': 3.4}                                                                                                                                                               
{'loss': 0.287, 'learning_rate': 0.00020106503298774738, 'epoch': 3.41}                                                                                                       
{'loss': 0.2695, 'learning_rate': 0.0002009707822808671, 'epoch': 3.41}                                                                                                       
{'loss': 0.2598, 'learning_rate': 0.00020087653157398677, 'epoch': 3.41}                                                                                                      
{'loss': 0.2332, 'learning_rate': 0.00020078228086710647, 'epoch': 3.41}                                                                                                      
{'loss': 0.418, 'learning_rate': 0.0002006880301602262, 'epoch': 3.42}                                                                                                        
{'loss': 0.2598, 'learning_rate': 0.00020059377945334588, 'epoch': 3.42}                                                                                                      
{'loss': 0.2496, 'learning_rate': 0.0002004995287464656, 'epoch': 3.42}                                                                                                       
{'loss': 0.3071, 'learning_rate': 0.00020040527803958527, 'epoch': 3.43}                                                                                                      
{'loss': 0.3318, 'learning_rate': 0.00020031102733270497, 'epoch': 3.43}                                                                                                      
{'loss': 0.4906, 'learning_rate': 0.00020021677662582468, 'epoch': 3.43}                                                                                                      
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                  | 11100/32330 [17:41:47<2:59:31,  1.97it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7128807369906216, 'eval_cer': 0.4169987966305656, 'eval_runtime': 538.5792, 'eval_samples_per_second': 17.784, 'eval_steps_per_second': 2.224, 'epoch': 3.43}                                                                                                                                                              
{'loss': 0.6042, 'learning_rate': 0.00020012252591894436, 'epoch': 3.44}                                                                                                      
{'loss': 0.2268, 'learning_rate': 0.00020002827521206407, 'epoch': 3.44}                                                                                                      
{'loss': 0.4672, 'learning_rate': 0.0001999340245051838, 'epoch': 3.44}                                                                                                       
{'loss': 0.3115, 'learning_rate': 0.00019983977379830348, 'epoch': 3.45}                                                                                                      
{'loss': 0.4566, 'learning_rate': 0.00019974552309142318, 'epoch': 3.45}                                                                                                      
{'loss': 0.2872, 'learning_rate': 0.00019965127238454286, 'epoch': 3.45}                                                                                                      
{'loss': 0.2072, 'learning_rate': 0.00019955702167766257, 'epoch': 3.45}                                                                                                      
{'loss': 0.316, 'learning_rate': 0.00019946277097078225, 'epoch': 3.46}                                                                                                       
{'loss': 0.3342, 'learning_rate': 0.00019936852026390195, 'epoch': 3.46}                                                                                                      
{'loss': 0.4208, 'learning_rate': 0.00019927426955702166, 'epoch': 3.46}                                                                                                      
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                  | 11200/32330 [17:51:30<3:05:30,  1.90it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7043115611254046, 'eval_cer': 0.4137280385078219, 'eval_runtime': 539.3846, 'eval_samples_per_second': 17.757, 'eval_steps_per_second': 2.221, 'epoch': 3.46}                                                                                                                                                              
{'loss': 0.3502, 'learning_rate': 0.00019918001885014134, 'epoch': 3.47}                                                                                                      
{'loss': 0.2084, 'learning_rate': 0.00019908576814326107, 'epoch': 3.47}                                                                                                      
{'loss': 0.3279, 'learning_rate': 0.00019899151743638078, 'epoch': 3.47}                                                                                                      
{'loss': 0.2369, 'learning_rate': 0.00019889726672950046, 'epoch': 3.48}                                                                                                      
{'loss': 0.5619, 'learning_rate': 0.00019880301602262016, 'epoch': 3.48}                                                                                                      
{'loss': 0.2346, 'learning_rate': 0.00019870876531573984, 'epoch': 3.48}                                                                                                      
{'loss': 0.2266, 'learning_rate': 0.00019861451460885955, 'epoch': 3.49}                                                                                                      
{'loss': 0.244, 'learning_rate': 0.00019852026390197923, 'epoch': 3.49}                                                                                                       
{'loss': 0.3219, 'learning_rate': 0.00019842601319509893, 'epoch': 3.49}                                                                                                      
{'loss': 0.4014, 'learning_rate': 0.00019833176248821866, 'epoch': 3.5}                                                                                                       
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                  | 11300/32330 [18:01:16<2:56:09,  1.99it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.709249730268072, 'eval_cer': 0.41665944645006014, 'eval_runtime': 538.8445, 'eval_samples_per_second': 17.775, 'eval_steps_per_second': 2.223, 'epoch': 3.5}                                                                                                                                                               
{'loss': 0.3246, 'learning_rate': 0.00019823751178133834, 'epoch': 3.5}                                                                                                       
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                 | 11312/32330 [18:10:23<21:54:05,  3.75s/it]Saving model checkpoint to turkish_clean/checkpoint-11312
Configuration saved in turkish_clean/checkpoint-11312/config.json
Model weights saved in turkish_clean/checkpoint-11312/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-11312/preprocessor_config.json
Deleting older checkpoint [turkish_clean/checkpoint-1616] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2701, 'learning_rate': 0.00019814326107445805, 'epoch': 3.5}                                                                                                       
{'loss': 0.2122, 'learning_rate': 0.00019804901036757776, 'epoch': 3.5}                                                                                                       
{'loss': 0.2239, 'learning_rate': 0.00019795475966069743, 'epoch': 3.51}                                                                                                      
{'loss': 0.5023, 'learning_rate': 0.00019786050895381714, 'epoch': 3.51}                                                                                                      
{'loss': 0.2311, 'learning_rate': 0.00019776625824693682, 'epoch': 3.51}                                                                                                      
{'loss': 0.3594, 'learning_rate': 0.00019767200754005652, 'epoch': 3.52}                                                                                                      
{'loss': 0.2301, 'learning_rate': 0.0001975777568331762, 'epoch': 3.52}                                                                                                       
{'loss': 0.2407, 'learning_rate': 0.00019748350612629594, 'epoch': 3.52}                                                                                                      
{'loss': 0.4385, 'learning_rate': 0.00019738925541941564, 'epoch': 3.53}                                                                                                      
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                 | 11400/32330 [18:11:03<2:53:07,  2.01it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7078180761888954, 'eval_cer': 0.41668110709987966, 'eval_runtime': 533.9694, 'eval_samples_per_second': 17.937, 'eval_steps_per_second': 2.244, 'epoch': 3.53}                                                                                                                                                             
{'loss': 0.2722, 'learning_rate': 0.00019729500471253532, 'epoch': 3.53}                                                                                                      
{'loss': 0.2437, 'learning_rate': 0.00019720075400565503, 'epoch': 3.53}                                                                                                      
{'loss': 0.3314, 'learning_rate': 0.00019710650329877473, 'epoch': 3.54}                                                                                                      
{'loss': 0.3399, 'learning_rate': 0.0001970122525918944, 'epoch': 3.54}                                                                                                       
{'loss': 0.495, 'learning_rate': 0.00019691800188501412, 'epoch': 3.54}                                                                                                       
{'loss': 0.2791, 'learning_rate': 0.0001968237511781338, 'epoch': 3.54}                                                                                                       
{'loss': 0.1817, 'learning_rate': 0.00019672950047125353, 'epoch': 3.55}                                                                                                      
{'loss': 0.2507, 'learning_rate': 0.00019663524976437324, 'epoch': 3.55}                                                                                                      
{'loss': 0.2773, 'learning_rate': 0.00019654099905749292, 'epoch': 3.55}                                                                                                      
{'loss': 0.4336, 'learning_rate': 0.00019644674835061262, 'epoch': 3.56}                                                                                                      
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                 | 11500/32330 [18:20:42<2:54:02,  1.99it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7188978338451324, 'eval_cer': 0.4177208182912154, 'eval_runtime': 532.7501, 'eval_samples_per_second': 17.978, 'eval_steps_per_second': 2.249, 'epoch': 3.56}                                                                                                                                                              
{'loss': 0.3016, 'learning_rate': 0.0001963524976437323, 'epoch': 3.56}                                                                                                       
{'loss': 0.2505, 'learning_rate': 0.000196258246936852, 'epoch': 3.56}                                                                                                        
{'loss': 0.319, 'learning_rate': 0.0001961639962299717, 'epoch': 3.57}                                                                                                        
{'loss': 0.3035, 'learning_rate': 0.0001960697455230914, 'epoch': 3.57}                                                                                                       
{'loss': 0.5163, 'learning_rate': 0.00019597549481621112, 'epoch': 3.57}                                                                                                      
{'loss': 0.5104, 'learning_rate': 0.0001958812441093308, 'epoch': 3.58}                                                                                                       
{'loss': 0.2483, 'learning_rate': 0.0001957869934024505, 'epoch': 3.58}                                                                                                       
{'loss': 0.2129, 'learning_rate': 0.00019569274269557021, 'epoch': 3.58}                                                                                                      
{'loss': 0.2324, 'learning_rate': 0.0001955984919886899, 'epoch': 3.58}                                                                                                       
{'loss': 0.428, 'learning_rate': 0.0001955042412818096, 'epoch': 3.59}                                                                                                        
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                | 11600/32330 [18:30:20<2:57:11,  1.95it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.713233463357955, 'eval_cer': 0.4181973525872443, 'eval_runtime': 538.2823, 'eval_samples_per_second': 17.794, 'eval_steps_per_second': 2.226, 'epoch': 3.59}                                                                                                                                                               
{'loss': 0.2786, 'learning_rate': 0.00019540999057492928, 'epoch': 3.59}                                                                                                      
{'loss': 0.2484, 'learning_rate': 0.00019531573986804898, 'epoch': 3.59}                                                                                                      
{'loss': 0.2577, 'learning_rate': 0.00019522148916116866, 'epoch': 3.6}                                                                                                       
{'loss': 0.2718, 'learning_rate': 0.0001951272384542884, 'epoch': 3.6}                                                                                                        
{'loss': 0.3803, 'learning_rate': 0.0001950329877474081, 'epoch': 3.6}                                                                                                        
{'loss': 0.3611, 'learning_rate': 0.00019493873704052778, 'epoch': 3.61}                                                                                                      
{'loss': 0.3001, 'learning_rate': 0.0001948444863336475, 'epoch': 3.61}                                                                                                       
{'loss': 0.2943, 'learning_rate': 0.0001947502356267672, 'epoch': 3.61}                                                                                                       
{'loss': 0.2783, 'learning_rate': 0.00019465598491988687, 'epoch': 3.62}                                                                                                      
{'loss': 0.3702, 'learning_rate': 0.00019456173421300658, 'epoch': 3.62}                                                                                                      
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                | 11700/32330 [18:40:04<3:02:25,  1.88it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7264295792181924, 'eval_cer': 0.4187268351383875, 'eval_runtime': 538.7954, 'eval_samples_per_second': 17.777, 'eval_steps_per_second': 2.223, 'epoch': 3.62}                                                                                                                                                              
{'loss': 0.6451, 'learning_rate': 0.00019446748350612626, 'epoch': 3.62}                                                                                                      
{'loss': 0.2292, 'learning_rate': 0.000194373232799246, 'epoch': 3.63}                                                                                                        
{'loss': 0.3129, 'learning_rate': 0.0001942789820923657, 'epoch': 3.63}                                                                                                       
{'loss': 0.2838, 'learning_rate': 0.00019418473138548537, 'epoch': 3.63}                                                                                                      
{'loss': 0.4397, 'learning_rate': 0.00019409048067860508, 'epoch': 3.63}                                                                                                      
{'loss': 0.267, 'learning_rate': 0.00019399622997172476, 'epoch': 3.64}                                                                                                       
{'loss': 0.2366, 'learning_rate': 0.00019390197926484447, 'epoch': 3.64}                                                                                                      
{'loss': 0.2931, 'learning_rate': 0.00019380772855796417, 'epoch': 3.64}                                                                                                      
{'loss': 0.2239, 'learning_rate': 0.00019371347785108385, 'epoch': 3.65}                                                                                                      
{'loss': 0.3716, 'learning_rate': 0.00019361922714420356, 'epoch': 3.65}                                                                                                      
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                | 11800/32330 [18:49:48<2:55:35,  1.95it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.703336376462777, 'eval_cer': 0.41371600481347776, 'eval_runtime': 533.3803, 'eval_samples_per_second': 17.957, 'eval_steps_per_second': 2.246, 'epoch': 3.65}                                                                                                                                                              
{'loss': 0.2658, 'learning_rate': 0.0001935249764373233, 'epoch': 3.65}                                                                                                       
{'loss': 0.253, 'learning_rate': 0.00019343072573044297, 'epoch': 3.66}                                                                                                       
{'loss': 0.3059, 'learning_rate': 0.00019333647502356267, 'epoch': 3.66}                                                                                                      
{'loss': 0.3131, 'learning_rate': 0.00019324222431668235, 'epoch': 3.66}                                                                                                      
{'loss': 0.2907, 'learning_rate': 0.00019314797360980206, 'epoch': 3.67}                                                                                                      
{'loss': 0.2803, 'learning_rate': 0.00019305372290292174, 'epoch': 3.67}                                                                                                      
{'loss': 0.2526, 'learning_rate': 0.00019295947219604144, 'epoch': 3.67}                                                                                                      
{'loss': 0.2708, 'learning_rate': 0.00019286522148916115, 'epoch': 3.67}                                                                                                      
{'loss': 0.2633, 'learning_rate': 0.00019277097078228086, 'epoch': 3.68}                                                                                                      
{'loss': 0.3886, 'learning_rate': 0.00019267672007540056, 'epoch': 3.68}                                                                                                      
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                               | 11900/32330 [18:59:28<2:53:59,  1.96it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7035438625612084, 'eval_cer': 0.416043321299639, 'eval_runtime': 532.2169, 'eval_samples_per_second': 17.996, 'eval_steps_per_second': 2.251, 'epoch': 3.68}                                                                                                                                                               
{'loss': 0.3372, 'learning_rate': 0.00019258246936852024, 'epoch': 3.68}                                                                                                      
{'loss': 0.2117, 'learning_rate': 0.00019248821866163995, 'epoch': 3.69}                                                                                                      
{'loss': 0.2626, 'learning_rate': 0.00019239396795475965, 'epoch': 3.69}                                                                                                      
{'loss': 0.272, 'learning_rate': 0.00019229971724787933, 'epoch': 3.69}                                                                                                       
{'loss': 0.4342, 'learning_rate': 0.00019220546654099904, 'epoch': 3.7}                                                                                                       
{'loss': 0.321, 'learning_rate': 0.00019211121583411872, 'epoch': 3.7}                                                                                                        
{'loss': 0.234, 'learning_rate': 0.00019201696512723845, 'epoch': 3.7}                                                                                                        
{'loss': 0.2561, 'learning_rate': 0.00019192271442035816, 'epoch': 3.71}                                                                                                      
{'loss': 0.3229, 'learning_rate': 0.00019182846371347783, 'epoch': 3.71}                                                                                                      
{'loss': 0.4217, 'learning_rate': 0.00019173421300659754, 'epoch': 3.71}                                                                                                      
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                               | 12000/32330 [19:09:05<2:41:22,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7075275956510914, 'eval_cer': 0.4134560770156438, 'eval_runtime': 538.5967, 'eval_samples_per_second': 17.783, 'eval_steps_per_second': 2.224, 'epoch': 3.71}                                                                                                                                                              
{'loss': 0.308, 'learning_rate': 0.00019163996229971722, 'epoch': 3.71}                                                                                                       
{'loss': 0.1979, 'learning_rate': 0.00019154571159283692, 'epoch': 3.72}                                                                                                      
{'loss': 0.2418, 'learning_rate': 0.00019145146088595663, 'epoch': 3.72}                                                                                                      
{'loss': 0.2657, 'learning_rate': 0.0001913572101790763, 'epoch': 3.72}                                                                                                       
{'loss': 0.4063, 'learning_rate': 0.00019126295947219602, 'epoch': 3.73}                                                                                                      
{'loss': 0.6075, 'learning_rate': 0.00019116870876531575, 'epoch': 3.73}                                                                                                      
{'loss': 0.2606, 'learning_rate': 0.00019107445805843543, 'epoch': 3.73}                                                                                                      
{'loss': 0.238, 'learning_rate': 0.00019098020735155513, 'epoch': 3.74}                                                                                                       
{'loss': 0.362, 'learning_rate': 0.0001908859566446748, 'epoch': 3.74}                                                                                                        
{'loss': 0.4306, 'learning_rate': 0.00019079170593779452, 'epoch': 3.74}                                                                                                      
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                              | 12100/32330 [19:18:49<2:44:40,  2.05it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7185243588679558, 'eval_cer': 0.4177087845968712, 'eval_runtime': 531.4907, 'eval_samples_per_second': 18.021, 'eval_steps_per_second': 2.254, 'epoch': 3.74}                                                                                                                                                              
{'loss': 0.2266, 'learning_rate': 0.0001906974552309142, 'epoch': 3.75}                                                                                                       
{'loss': 0.1868, 'learning_rate': 0.0001906032045240339, 'epoch': 3.75}                                                                                                       
{'loss': 0.2491, 'learning_rate': 0.0001905089538171536, 'epoch': 3.75}                                                                                                       
{'loss': 0.2233, 'learning_rate': 0.00019041470311027332, 'epoch': 3.75}                                                                                                      
{'loss': 0.4579, 'learning_rate': 0.00019032045240339302, 'epoch': 3.76}                                                                                                      
{'loss': 0.2893, 'learning_rate': 0.00019022620169651273, 'epoch': 3.76}                                                                                                      
{'loss': 0.3213, 'learning_rate': 0.0001901319509896324, 'epoch': 3.76}                                                                                                       
{'loss': 0.2528, 'learning_rate': 0.0001900377002827521, 'epoch': 3.77}                                                                                                       
{'loss': 0.2767, 'learning_rate': 0.0001899434495758718, 'epoch': 3.77}                                                                                                       
{'loss': 0.3474, 'learning_rate': 0.0001898491988689915, 'epoch': 3.77}                                                                                                       
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                              | 12200/32330 [19:28:26<2:38:13,  2.12it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7122375300854843, 'eval_cer': 0.4158772563176895, 'eval_runtime': 531.8014, 'eval_samples_per_second': 18.01, 'eval_steps_per_second': 2.253, 'epoch': 3.77}                                                                                                                                                               
{'loss': 0.2909, 'learning_rate': 0.00018975494816211118, 'epoch': 3.78}                                                                                                      
{'loss': 0.2605, 'learning_rate': 0.00018966069745523088, 'epoch': 3.78}                                                                                                      
{'loss': 0.3284, 'learning_rate': 0.00018956644674835061, 'epoch': 3.78}                                                                                                      
{'loss': 0.2692, 'learning_rate': 0.0001894721960414703, 'epoch': 3.79}                                                                                                       
{'loss': 0.4694, 'learning_rate': 0.00018937794533459, 'epoch': 3.79}                                                                                                         
{'loss': 0.2668, 'learning_rate': 0.0001892836946277097, 'epoch': 3.79}                                                                                                       
{'loss': 0.2321, 'learning_rate': 0.00018918944392082938, 'epoch': 3.8}                                                                                                       
{'loss': 0.2693, 'learning_rate': 0.0001890951932139491, 'epoch': 3.8}                                                                                                        
{'loss': 0.2707, 'learning_rate': 0.00018900094250706877, 'epoch': 3.8}                                                                                                       
{'loss': 0.4545, 'learning_rate': 0.00018890669180018848, 'epoch': 3.8}                                                                                                       
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                              | 12300/32330 [19:38:03<2:41:51,  2.06it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7019877168229729, 'eval_cer': 0.4140529482551143, 'eval_runtime': 533.9082, 'eval_samples_per_second': 17.939, 'eval_steps_per_second': 2.244, 'epoch': 3.8}                                                                                                                                                               
{'loss': 0.2713, 'learning_rate': 0.0001888124410933082, 'epoch': 3.81}                                                                                                       
{'loss': 0.3083, 'learning_rate': 0.0001887181903864279, 'epoch': 3.81}                                                                                                       
{'loss': 0.2008, 'learning_rate': 0.0001886239396795476, 'epoch': 3.81}                                                                                                       
{'loss': 0.3024, 'learning_rate': 0.00018852968897266727, 'epoch': 3.82}                                                                                                      
{'loss': 0.3081, 'learning_rate': 0.00018843543826578698, 'epoch': 3.82}                                                                                                      
{'loss': 0.3425, 'learning_rate': 0.00018834118755890666, 'epoch': 3.82}                                                                                                      
{'loss': 0.2706, 'learning_rate': 0.00018824693685202636, 'epoch': 3.83}                                                                                                      
{'loss': 0.2711, 'learning_rate': 0.00018815268614514607, 'epoch': 3.83}                                                                                                      
{'loss': 0.3449, 'learning_rate': 0.00018805843543826577, 'epoch': 3.83}                                                                                                      
{'loss': 0.3658, 'learning_rate': 0.00018796418473138548, 'epoch': 3.84}                                                                                                      
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                             | 12400/32330 [19:47:42<2:51:55,  1.93it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6908872105568927, 'eval_cer': 0.41774488567990375, 'eval_runtime': 532.9015, 'eval_samples_per_second': 17.973, 'eval_steps_per_second': 2.248, 'epoch': 3.84}                                                                                                                                                             
{'loss': 0.2559, 'learning_rate': 0.00018786993402450519, 'epoch': 3.84}                                                                                                      
{'loss': 0.2399, 'learning_rate': 0.00018777568331762487, 'epoch': 3.84}                                                                                                      
{'loss': 0.2458, 'learning_rate': 0.00018768143261074457, 'epoch': 3.84}                                                                                                      
{'loss': 0.3365, 'learning_rate': 0.00018758718190386425, 'epoch': 3.85}                                                                                                      
{'loss': 0.3874, 'learning_rate': 0.00018749293119698396, 'epoch': 3.85}                                                                                                      
{'loss': 0.2466, 'learning_rate': 0.00018739868049010363, 'epoch': 3.85}                                                                                                      
{'loss': 0.2369, 'learning_rate': 0.00018730442978322334, 'epoch': 3.86}                                                                                                      
{'loss': 0.2383, 'learning_rate': 0.00018721017907634307, 'epoch': 3.86}                                                                                                      
{'loss': 0.2441, 'learning_rate': 0.00018711592836946275, 'epoch': 3.86}                                                                                                      
{'loss': 0.443, 'learning_rate': 0.00018702167766258246, 'epoch': 3.87}                                                                                                       
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                             | 12500/32330 [19:57:21<2:43:55,  2.02it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6865507510996763, 'eval_cer': 0.41102045728038505, 'eval_runtime': 533.8792, 'eval_samples_per_second': 17.94, 'eval_steps_per_second': 2.244, 'epoch': 3.87}                                                                                                                                                              
{'loss': 0.289, 'learning_rate': 0.00018692742695570216, 'epoch': 3.87}                                                                                                       
{'loss': 0.1984, 'learning_rate': 0.00018683317624882184, 'epoch': 3.87}                                                                                                      
{'loss': 0.2121, 'learning_rate': 0.00018673892554194155, 'epoch': 3.88}                                                                                                      
{'loss': 0.2739, 'learning_rate': 0.00018664467483506123, 'epoch': 3.88}                                                                                                      
{'loss': 0.5428, 'learning_rate': 0.00018655042412818093, 'epoch': 3.88}                                                                                                      
{'loss': 0.2184, 'learning_rate': 0.00018645617342130067, 'epoch': 3.88}                                                                                                      
{'loss': 0.2434, 'learning_rate': 0.00018636192271442035, 'epoch': 3.89}                                                                                                      
{'loss': 0.279, 'learning_rate': 0.00018626767200754005, 'epoch': 3.89}                                                                                                       
{'loss': 0.278, 'learning_rate': 0.00018617342130065973, 'epoch': 3.89}                                                                                                       
{'loss': 0.5604, 'learning_rate': 0.00018607917059377944, 'epoch': 3.9}                                                                                                       
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                             | 12600/32330 [20:06:59<2:41:24,  2.04it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6906797244584613, 'eval_cer': 0.4122069795427196, 'eval_runtime': 540.0943, 'eval_samples_per_second': 17.734, 'eval_steps_per_second': 2.218, 'epoch': 3.9}                                                                                                                                                               
{'loss': 0.3148, 'learning_rate': 0.00018598491988689914, 'epoch': 3.9}                                                                                                       
{'loss': 0.2247, 'learning_rate': 0.00018589066918001882, 'epoch': 3.9}                                                                                                       
{'loss': 0.2369, 'learning_rate': 0.00018579641847313853, 'epoch': 3.91}                                                                                                      
{'loss': 0.2928, 'learning_rate': 0.0001857021677662582, 'epoch': 3.91}                                                                                                       
{'loss': 0.4541, 'learning_rate': 0.00018560791705937794, 'epoch': 3.91}                                                                                                      
{'loss': 0.2548, 'learning_rate': 0.00018551366635249765, 'epoch': 3.92}                                                                                                      
{'loss': 0.287, 'learning_rate': 0.00018541941564561732, 'epoch': 3.92}                                                                                                       
{'loss': 0.1825, 'learning_rate': 0.00018532516493873703, 'epoch': 3.92}                                                                                                      
{'loss': 0.2458, 'learning_rate': 0.0001852309142318567, 'epoch': 3.93}                                                                                                       
{'loss': 0.387, 'learning_rate': 0.00018513666352497642, 'epoch': 3.93}                                                                                                       
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                            | 12700/32330 [20:16:45<2:52:45,  1.89it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7037513486596398, 'eval_cer': 0.41731889290012036, 'eval_runtime': 537.8916, 'eval_samples_per_second': 17.807, 'eval_steps_per_second': 2.227, 'epoch': 3.93}                                                                                                                                                             
{'loss': 0.2995, 'learning_rate': 0.00018504241281809612, 'epoch': 3.93}                                                                                                      
{'loss': 0.1878, 'learning_rate': 0.0001849481621112158, 'epoch': 3.93}                                                                                                       
{'loss': 0.252, 'learning_rate': 0.00018485391140433553, 'epoch': 3.94}                                                                                                       
{'loss': 0.2407, 'learning_rate': 0.0001847596606974552, 'epoch': 3.94}                                                                                                       
{'loss': 0.4517, 'learning_rate': 0.00018466540999057492, 'epoch': 3.94}                                                                                                      
{'loss': 0.4908, 'learning_rate': 0.00018457115928369462, 'epoch': 3.95}                                                                                                      
{'loss': 0.2166, 'learning_rate': 0.0001844769085768143, 'epoch': 3.95}                                                                                                       
{'loss': 0.2053, 'learning_rate': 0.000184382657869934, 'epoch': 3.95}                                                                                                        
{'loss': 0.2295, 'learning_rate': 0.0001842884071630537, 'epoch': 3.96}                                                                                                       
{'loss': 0.3683, 'learning_rate': 0.0001841941564561734, 'epoch': 3.96}                                                                                                       
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                            | 12800/32330 [20:26:28<2:52:36,  1.89it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6995393808614823, 'eval_cer': 0.416101083032491, 'eval_runtime': 535.2125, 'eval_samples_per_second': 17.896, 'eval_steps_per_second': 2.238, 'epoch': 3.96}                                                                                                                                                               
{'loss': 0.2612, 'learning_rate': 0.00018409990574929313, 'epoch': 3.96}                                                                                                      
{'loss': 0.2829, 'learning_rate': 0.0001840056550424128, 'epoch': 3.97}                                                                                                       
{'loss': 0.2772, 'learning_rate': 0.0001839114043355325, 'epoch': 3.97}                                                                                                       
{'loss': 0.3699, 'learning_rate': 0.0001838171536286522, 'epoch': 3.97}                                                                                                       
{'loss': 0.388, 'learning_rate': 0.0001837229029217719, 'epoch': 3.97}                                                                                                        
{'loss': 0.2841, 'learning_rate': 0.0001836286522148916, 'epoch': 3.98}                                                                                                       
{'loss': 0.267, 'learning_rate': 0.00018353440150801128, 'epoch': 3.98}                                                                                                       
{'loss': 0.2908, 'learning_rate': 0.000183440150801131, 'epoch': 3.98}                                                                                                        
{'loss': 0.2859, 'learning_rate': 0.00018334590009425067, 'epoch': 3.99}                                                                                                      
{'loss': 0.4725, 'learning_rate': 0.0001832516493873704, 'epoch': 3.99}                                                                                                       
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                           | 12900/32330 [20:36:08<2:37:18,  2.06it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7139181674827787, 'eval_cer': 0.4184909747292419, 'eval_runtime': 530.5906, 'eval_samples_per_second': 18.052, 'eval_steps_per_second': 2.258, 'epoch': 3.99}                                                                                                                                                              
{'loss': 0.2848, 'learning_rate': 0.0001831573986804901, 'epoch': 3.99}                                                                                                       
{'loss': 0.2479, 'learning_rate': 0.00018306314797360978, 'epoch': 4.0}                                                                                                       
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                           | 12928/32330 [20:45:12<2:00:32,  2.68it/s]Saving model checkpoint to turkish_clean/checkpoint-12928
Configuration saved in turkish_clean/checkpoint-12928/config.json
Model weights saved in turkish_clean/checkpoint-12928/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-12928/preprocessor_config.json
Deleting older checkpoint [turkish_clean/checkpoint-3232] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3181, 'learning_rate': 0.0001829688972667295, 'epoch': 4.0}                                                                                                        
{'loss': 0.3107, 'learning_rate': 0.00018287464655984917, 'epoch': 4.0}                                                                                                       
{'loss': 0.2425, 'learning_rate': 0.00018278039585296888, 'epoch': 4.01}                                                                                                      
{'loss': 0.2534, 'learning_rate': 0.00018268614514608858, 'epoch': 4.01}                                                                                                      
{'loss': 0.2005, 'learning_rate': 0.00018259189443920826, 'epoch': 4.01}                                                                                                      
{'loss': 0.3188, 'learning_rate': 0.000182497643732328, 'epoch': 4.01}                                                                                                        
{'loss': 0.3398, 'learning_rate': 0.0001824033930254477, 'epoch': 4.02}                                                                                                       
{'loss': 0.4606, 'learning_rate': 0.00018230914231856738, 'epoch': 4.02}                                                                                                      
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                           | 13000/32330 [20:45:49<2:33:11,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.695949871358619, 'eval_cer': 0.414719614921781, 'eval_runtime': 538.8199, 'eval_samples_per_second': 17.776, 'eval_steps_per_second': 2.223, 'epoch': 4.02}                                                                                                                                                                
{'loss': 0.2417, 'learning_rate': 0.00018221489161168708, 'epoch': 4.02}                                                                                                      
{'loss': 0.2183, 'learning_rate': 0.00018212064090480676, 'epoch': 4.03}                                                                                                      
{'loss': 0.2834, 'learning_rate': 0.00018202639019792647, 'epoch': 4.03}                                                                                                      
{'loss': 0.357, 'learning_rate': 0.00018193213949104615, 'epoch': 4.03}                                                                                                       
{'loss': 0.3329, 'learning_rate': 0.00018183788878416585, 'epoch': 4.04}                                                                                                      
{'loss': 0.2052, 'learning_rate': 0.00018174363807728556, 'epoch': 4.04}                                                                                                      
{'loss': 0.239, 'learning_rate': 0.00018164938737040527, 'epoch': 4.04}                                                                                                       
{'loss': 0.2848, 'learning_rate': 0.00018155513666352497, 'epoch': 4.05}                                                                                                      
{'loss': 0.4027, 'learning_rate': 0.00018146088595664468, 'epoch': 4.05}                                                                                                      
{'loss': 0.2311, 'learning_rate': 0.00018136663524976436, 'epoch': 4.05}                                                                                                      
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                           | 13100/32330 [20:55:33<2:29:51,  2.14it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6865300024898332, 'eval_cer': 0.40902045728038505, 'eval_runtime': 533.136, 'eval_samples_per_second': 17.965, 'eval_steps_per_second': 2.247, 'epoch': 4.05}                                                                                                                                                              
{'loss': 0.208, 'learning_rate': 0.00018127238454288406, 'epoch': 4.06}                                                                                                       
{'loss': 0.2265, 'learning_rate': 0.00018117813383600374, 'epoch': 4.06}                                                                                                      
{'loss': 0.3672, 'learning_rate': 0.00018108388312912345, 'epoch': 4.06}                                                                                                      
{'loss': 0.3515, 'learning_rate': 0.00018098963242224313, 'epoch': 4.06}                                                                                                      
{'loss': 0.1722, 'learning_rate': 0.00018089538171536286, 'epoch': 4.07}                                                                                                      
{'loss': 0.2054, 'learning_rate': 0.00018080113100848256, 'epoch': 4.07}                                                                                                      
{'loss': 0.241, 'learning_rate': 0.00018070688030160224, 'epoch': 4.07}                                                                                                       
{'loss': 0.2937, 'learning_rate': 0.00018061262959472195, 'epoch': 4.08}                                                                                                      
{'loss': 0.3461, 'learning_rate': 0.00018051837888784163, 'epoch': 4.08}                                                                                                      
{'loss': 0.2614, 'learning_rate': 0.00018042412818096133, 'epoch': 4.08}                                                                                                      
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                          | 13200/32330 [21:05:10<2:21:38,  2.25it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6819653083243423, 'eval_cer': 0.4085824308062575, 'eval_runtime': 532.3758, 'eval_samples_per_second': 17.991, 'eval_steps_per_second': 2.25, 'epoch': 4.08}                                                                                                                                                               
{'loss': 0.1965, 'learning_rate': 0.00018032987747408104, 'epoch': 4.09}                                                                                                      
{'loss': 0.2501, 'learning_rate': 0.00018023562676720072, 'epoch': 4.09}                                                                                                      
{'loss': 0.2595, 'learning_rate': 0.00018014137606032045, 'epoch': 4.09}                                                                                                      
{'loss': 0.3025, 'learning_rate': 0.00018004712535344016, 'epoch': 4.1}                                                                                                       
{'loss': 0.202, 'learning_rate': 0.00017995287464655984, 'epoch': 4.1}                                                                                                        
{'loss': 0.2171, 'learning_rate': 0.00017985862393967954, 'epoch': 4.1}                                                                                                       
{'loss': 0.2434, 'learning_rate': 0.00017976437323279922, 'epoch': 4.1}                                                                                                       
{'loss': 0.3626, 'learning_rate': 0.00017967012252591893, 'epoch': 4.11}                                                                                                      
{'loss': 0.3526, 'learning_rate': 0.0001795758718190386, 'epoch': 4.11}                                                                                                       
{'loss': 0.1818, 'learning_rate': 0.0001794816211121583, 'epoch': 4.11}                                                                                                       
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                          | 13300/32330 [21:14:48<2:31:19,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6859697900240684, 'eval_cer': 0.40975451263537904, 'eval_runtime': 528.2491, 'eval_samples_per_second': 18.132, 'eval_steps_per_second': 2.268, 'epoch': 4.11}                                                                                                                                                             
{'loss': 0.2446, 'learning_rate': 0.00017938737040527802, 'epoch': 4.12}                                                                                                      
{'loss': 0.2524, 'learning_rate': 0.00017929311969839772, 'epoch': 4.12}                                                                                                      
{'loss': 0.3482, 'learning_rate': 0.00017919886899151743, 'epoch': 4.12}                                                                                                      
{'loss': 0.342, 'learning_rate': 0.00017910461828463714, 'epoch': 4.13}                                                                                                       
{'loss': 0.1917, 'learning_rate': 0.00017901036757775682, 'epoch': 4.13}                                                                                                      
{'loss': 0.2113, 'learning_rate': 0.00017891611687087652, 'epoch': 4.13}                                                                                                      
{'loss': 0.285, 'learning_rate': 0.0001788218661639962, 'epoch': 4.14}                                                                                                        
{'loss': 0.3175, 'learning_rate': 0.0001787276154571159, 'epoch': 4.14}                                                                                                       
{'loss': 0.6364, 'learning_rate': 0.00017863336475023559, 'epoch': 4.14}                                                                                                      
{'loss': 0.3111, 'learning_rate': 0.00017853911404335532, 'epoch': 4.14}                                                                                                      
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                         | 13400/32330 [21:24:22<2:26:49,  2.15it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6819860569341855, 'eval_cer': 0.4099350180505415, 'eval_runtime': 536.7573, 'eval_samples_per_second': 17.844, 'eval_steps_per_second': 2.232, 'epoch': 4.14}                                                                                                                                                              
{'loss': 0.1757, 'learning_rate': 0.00017844486333647502, 'epoch': 4.15}                                                                                                      
{'loss': 0.2088, 'learning_rate': 0.0001783506126295947, 'epoch': 4.15}                                                                                                       
{'loss': 0.3523, 'learning_rate': 0.0001782563619227144, 'epoch': 4.15}                                                                                                       
{'loss': 0.2849, 'learning_rate': 0.00017816211121583412, 'epoch': 4.16}                                                                                                      
{'loss': 0.1915, 'learning_rate': 0.00017807728557964184, 'epoch': 4.16}                                                                                                      
{'loss': 0.2383, 'learning_rate': 0.00017798303487276152, 'epoch': 4.16}                                                                                                      
{'loss': 0.2714, 'learning_rate': 0.00017788878416588122, 'epoch': 4.17}                                                                                                      
{'loss': 0.2571, 'learning_rate': 0.00017779453345900093, 'epoch': 4.17}                                                                                                      
{'loss': 0.3305, 'learning_rate': 0.0001777002827521206, 'epoch': 4.17}                                                                                                       
{'loss': 0.3076, 'learning_rate': 0.00017760603204524032, 'epoch': 4.18}                                                                                                      
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                         | 13500/32330 [21:34:05<2:23:07,  2.19it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6926715910034028, 'eval_cer': 0.4101612515042118, 'eval_runtime': 537.2236, 'eval_samples_per_second': 17.829, 'eval_steps_per_second': 2.23, 'epoch': 4.18}                                                                                                                                                               
{'loss': 0.1342, 'learning_rate': 0.00017751178133836005, 'epoch': 4.18}                                                                                                      
{'loss': 0.2959, 'learning_rate': 0.00017741753063147973, 'epoch': 4.18}                                                                                                      
{'loss': 0.3071, 'learning_rate': 0.00017732327992459943, 'epoch': 4.18}                                                                                                      
{'loss': 0.3001, 'learning_rate': 0.0001772290292177191, 'epoch': 4.19}                                                                                                       
{'loss': 0.246, 'learning_rate': 0.00017713477851083882, 'epoch': 4.19}                                                                                                       
{'loss': 0.1874, 'learning_rate': 0.0001770405278039585, 'epoch': 4.19}                                                                                                       
{'loss': 0.2182, 'learning_rate': 0.0001769462770970782, 'epoch': 4.2}                                                                                                        
{'loss': 0.3294, 'learning_rate': 0.0001768520263901979, 'epoch': 4.2}                                                                                                        
{'loss': 0.5125, 'learning_rate': 0.0001767577756833176, 'epoch': 4.2}                                                                                                        
{'loss': 0.2413, 'learning_rate': 0.00017666352497643732, 'epoch': 4.21}                                                                                                      
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                         | 13600/32330 [21:43:47<2:25:34,  2.14it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6901195119926965, 'eval_cer': 0.4106064981949458, 'eval_runtime': 538.0539, 'eval_samples_per_second': 17.801, 'eval_steps_per_second': 2.227, 'epoch': 4.21}                                                                                                                                                              
{'loss': 0.1965, 'learning_rate': 0.00017656927426955703, 'epoch': 4.21}                                                                                                      
{'loss': 0.2388, 'learning_rate': 0.0001764750235626767, 'epoch': 4.21}                                                                                                       
{'loss': 0.2946, 'learning_rate': 0.0001763807728557964, 'epoch': 4.22}                                                                                                       
{'loss': 0.7284, 'learning_rate': 0.0001762865221489161, 'epoch': 4.22}                                                                                                       
{'loss': 0.3097, 'learning_rate': 0.00017620169651272384, 'epoch': 4.22}                                                                                                      
{'loss': 0.1627, 'learning_rate': 0.00017610744580584352, 'epoch': 4.23}                                                                                                      
{'loss': 0.2982, 'learning_rate': 0.00017601319509896323, 'epoch': 4.23}                                                                                                      
{'loss': 0.2394, 'learning_rate': 0.0001759189443920829, 'epoch': 4.23}                                                                                                       
{'loss': 0.3368, 'learning_rate': 0.0001758246936852026, 'epoch': 4.23}                                                                                                       
{'loss': 0.2157, 'learning_rate': 0.00017573044297832232, 'epoch': 4.24}                                                                                                      
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                        | 13700/32330 [21:53:31<2:23:38,  2.16it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6843928956759897, 'eval_cer': 0.40938628158844764, 'eval_runtime': 532.0904, 'eval_samples_per_second': 18.001, 'eval_steps_per_second': 2.251, 'epoch': 4.24}                                                                                                                                                             
{'loss': 0.2811, 'learning_rate': 0.00017563619227144202, 'epoch': 4.24}                                                                                                      
{'loss': 0.2631, 'learning_rate': 0.00017554194156456173, 'epoch': 4.24}                                                                                                      
{'loss': 0.4131, 'learning_rate': 0.00017544769085768144, 'epoch': 4.25}                                                                                                      
{'loss': 0.3441, 'learning_rate': 0.00017535344015080111, 'epoch': 4.25}                                                                                                      
{'loss': 0.2879, 'learning_rate': 0.00017525918944392082, 'epoch': 4.25}                                                                                                      
{'loss': 0.1947, 'learning_rate': 0.0001751649387370405, 'epoch': 4.26}                                                                                                       
{'loss': 0.1888, 'learning_rate': 0.0001750706880301602, 'epoch': 4.26}                                                                                                       
{'loss': 0.3475, 'learning_rate': 0.00017497643732327988, 'epoch': 4.26}                                                                                                      
{'loss': 0.3061, 'learning_rate': 0.00017488218661639962, 'epoch': 4.27}                                                                                                      
{'loss': 0.2337, 'learning_rate': 0.00017478793590951932, 'epoch': 4.27}                                                                                                      
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                        | 13800/32330 [22:03:09<2:28:09,  2.08it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6809901236617146, 'eval_cer': 0.40966064981949457, 'eval_runtime': 532.2989, 'eval_samples_per_second': 17.994, 'eval_steps_per_second': 2.251, 'epoch': 4.27}                                                                                                                                                             
{'loss': 0.2328, 'learning_rate': 0.000174693685202639, 'epoch': 4.27}                                                                                                        
{'loss': 0.2448, 'learning_rate': 0.0001745994344957587, 'epoch': 4.27}                                                                                                       
{'loss': 0.358, 'learning_rate': 0.0001745051837888784, 'epoch': 4.28}                                                                                                        
{'loss': 0.3163, 'learning_rate': 0.0001744109330819981, 'epoch': 4.28}                                                                                                       
{'loss': 0.24, 'learning_rate': 0.0001743166823751178, 'epoch': 4.28}                                                                                                         
{'loss': 0.2132, 'learning_rate': 0.00017422243166823748, 'epoch': 4.29}                                                                                                      
{'loss': 0.2803, 'learning_rate': 0.0001741281809613572, 'epoch': 4.29}                                                                                                       
{'loss': 0.3976, 'learning_rate': 0.00017403393025447692, 'epoch': 4.29}                                                                                                      
{'loss': 0.296, 'learning_rate': 0.0001739396795475966, 'epoch': 4.3}                                                                                                         
{'loss': 0.239, 'learning_rate': 0.0001738454288407163, 'epoch': 4.3}                                                                                                         
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                       | 13900/32330 [22:12:48<2:24:09,  2.13it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6792264918250477, 'eval_cer': 0.40726594464500604, 'eval_runtime': 538.3955, 'eval_samples_per_second': 17.79, 'eval_steps_per_second': 2.225, 'epoch': 4.3}                                                                                                                                                               
{'loss': 0.1768, 'learning_rate': 0.00017375117813383598, 'epoch': 4.3}                                                                                                       
{'loss': 0.2265, 'learning_rate': 0.00017365692742695569, 'epoch': 4.31}                                                                                                      
{'loss': 0.2863, 'learning_rate': 0.00017356267672007537, 'epoch': 4.31}                                                                                                      
{'loss': 0.2968, 'learning_rate': 0.00017346842601319507, 'epoch': 4.31}                                                                                                      
{'loss': 0.2029, 'learning_rate': 0.00017337417530631478, 'epoch': 4.31}                                                                                                      
{'loss': 0.2016, 'learning_rate': 0.00017327992459943448, 'epoch': 4.32}                                                                                                      
{'loss': 0.2765, 'learning_rate': 0.0001731856738925542, 'epoch': 4.32}                                                                                                       
{'loss': 0.2968, 'learning_rate': 0.0001730914231856739, 'epoch': 4.32}                                                                                                       
{'loss': 0.2909, 'learning_rate': 0.00017299717247879357, 'epoch': 4.33}                                                                                                      
{'loss': 0.1737, 'learning_rate': 0.00017290292177191328, 'epoch': 4.33}                                                                                                      
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                       | 14000/32330 [22:22:32<2:19:22,  2.19it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6799111959498714, 'eval_cer': 0.40670276774969916, 'eval_runtime': 534.4053, 'eval_samples_per_second': 17.923, 'eval_steps_per_second': 2.242, 'epoch': 4.33}                                                                                                                                                             
{'loss': 0.1919, 'learning_rate': 0.00017280867106503296, 'epoch': 4.33}                                                                                                      
{'loss': 0.2168, 'learning_rate': 0.00017271442035815266, 'epoch': 4.34}                                                                                                      
{'loss': 0.3399, 'learning_rate': 0.00017262016965127234, 'epoch': 4.34}                                                                                                      
{'loss': 0.2882, 'learning_rate': 0.00017252591894439208, 'epoch': 4.34}                                                                                                      
{'loss': 0.1971, 'learning_rate': 0.00017243166823751178, 'epoch': 4.35}                                                                                                      
{'loss': 0.1889, 'learning_rate': 0.00017233741753063146, 'epoch': 4.35}                                                                                                      
{'loss': 0.2272, 'learning_rate': 0.00017224316682375117, 'epoch': 4.35}                                                                                                      
{'loss': 0.2239, 'learning_rate': 0.00017214891611687087, 'epoch': 4.36}                                                                                                      
{'loss': 0.3468, 'learning_rate': 0.00017205466540999055, 'epoch': 4.36}                                                                                                      
{'loss': 0.2478, 'learning_rate': 0.00017196041470311026, 'epoch': 4.36}                                                                                                      
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                       | 14100/32330 [22:32:12<2:20:08,  2.17it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6781475641132044, 'eval_cer': 0.4075090252707581, 'eval_runtime': 532.3894, 'eval_samples_per_second': 17.991, 'eval_steps_per_second': 2.25, 'epoch': 4.36}                                                                                                                                                               
{'loss': 0.2334, 'learning_rate': 0.00017186616399622994, 'epoch': 4.36}                                                                                                      
{'loss': 0.2654, 'learning_rate': 0.00017177191328934964, 'epoch': 4.37}                                                                                                      
{'loss': 0.3106, 'learning_rate': 0.00017167766258246938, 'epoch': 4.37}                                                                                                      
{'loss': 0.4172, 'learning_rate': 0.00017158341187558905, 'epoch': 4.37}                                                                                                      
{'loss': 0.2267, 'learning_rate': 0.00017148916116870876, 'epoch': 4.38}                                                                                                      
{'loss': 0.2423, 'learning_rate': 0.00017139491046182844, 'epoch': 4.38}                                                                                                      
{'loss': 0.2327, 'learning_rate': 0.00017130065975494815, 'epoch': 4.38}                                                                                                      
{'loss': 0.3381, 'learning_rate': 0.00017120640904806785, 'epoch': 4.39}                                                                                                      
{'loss': 0.3081, 'learning_rate': 0.00017111215834118753, 'epoch': 4.39}                                                                                                      
{'loss': 0.2224, 'learning_rate': 0.00017101790763430724, 'epoch': 4.39}                                                                                                      
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                      | 14200/32330 [22:41:50<2:25:59,  2.07it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6715287575732426, 'eval_cer': 0.4052202166064982, 'eval_runtime': 537.8482, 'eval_samples_per_second': 17.808, 'eval_steps_per_second': 2.227, 'epoch': 4.39}                                                                                                                                                              
{'loss': 0.1699, 'learning_rate': 0.00017092365692742694, 'epoch': 4.4}                                                                                                       
{'loss': 0.2801, 'learning_rate': 0.00017082940622054665, 'epoch': 4.4}                                                                                                       
{'loss': 0.3705, 'learning_rate': 0.00017073515551366635, 'epoch': 4.4}                                                                                                       
{'loss': 0.3338, 'learning_rate': 0.00017064090480678603, 'epoch': 4.4}                                                                                                       
{'loss': 0.2128, 'learning_rate': 0.00017054665409990574, 'epoch': 4.41}                                                                                                      
{'loss': 0.2672, 'learning_rate': 0.00017045240339302542, 'epoch': 4.41}                                                                                                      
{'loss': 0.1889, 'learning_rate': 0.00017035815268614512, 'epoch': 4.41}                                                                                                      
{'loss': 0.3503, 'learning_rate': 0.0001702639019792648, 'epoch': 4.42}                                                                                                       
{'loss': 0.3471, 'learning_rate': 0.00017016965127238454, 'epoch': 4.42}                                                                                                      
{'loss': 0.2399, 'learning_rate': 0.00017007540056550424, 'epoch': 4.42}                                                                                                      
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                      | 14300/32330 [22:51:33<2:18:53,  2.16it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6848078678728525, 'eval_cer': 0.4084187725631769, 'eval_runtime': 538.6993, 'eval_samples_per_second': 17.78, 'eval_steps_per_second': 2.224, 'epoch': 4.42}                                                                                                                                                               
{'loss': 0.2366, 'learning_rate': 0.00016998114985862392, 'epoch': 4.43}                                                                                                      
{'loss': 0.2395, 'learning_rate': 0.00016988689915174363, 'epoch': 4.43}                                                                                                      
{'loss': 0.3098, 'learning_rate': 0.00016979264844486333, 'epoch': 4.43}                                                                                                      
{'loss': 0.3189, 'learning_rate': 0.000169698397737983, 'epoch': 4.44}                                                                                                        
{'loss': 0.2031, 'learning_rate': 0.00016960414703110272, 'epoch': 4.44}                                                                                                      
{'loss': 0.2327, 'learning_rate': 0.0001695098963242224, 'epoch': 4.44}                                                                                                       
{'loss': 0.1971, 'learning_rate': 0.0001694156456173421, 'epoch': 4.44}                                                                                                       
{'loss': 0.2572, 'learning_rate': 0.00016932139491046184, 'epoch': 4.45}                                                                                                      
{'loss': 0.3743, 'learning_rate': 0.00016922714420358151, 'epoch': 4.45}                                                                                                      
{'loss': 0.2469, 'learning_rate': 0.00016913289349670122, 'epoch': 4.45}                                                                                                      
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                      | 14400/32330 [23:01:17<2:18:33,  2.16it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6771101336210474, 'eval_cer': 0.40865222623345365, 'eval_runtime': 532.4007, 'eval_samples_per_second': 17.99, 'eval_steps_per_second': 2.25, 'epoch': 4.45}                                                                                                                                                               
{'loss': 0.2111, 'learning_rate': 0.0001690386427898209, 'epoch': 4.46}                                                                                                       
{'loss': 0.2759, 'learning_rate': 0.0001689443920829406, 'epoch': 4.46}                                                                                                       
{'loss': 0.2554, 'learning_rate': 0.0001688501413760603, 'epoch': 4.46}                                                                                                       
{'loss': 0.3624, 'learning_rate': 0.00016875589066918, 'epoch': 4.47}                                                                                                         
{'loss': 0.2688, 'learning_rate': 0.0001686616399622997, 'epoch': 4.47}                                                                                                       
{'loss': 0.2581, 'learning_rate': 0.00016856738925541943, 'epoch': 4.47}                                                                                                      
{'loss': 0.2668, 'learning_rate': 0.0001684731385485391, 'epoch': 4.48}                                                                                                       
{'loss': 0.2523, 'learning_rate': 0.00016837888784165881, 'epoch': 4.48}                                                                                                      
{'loss': 0.3328, 'learning_rate': 0.0001682846371347785, 'epoch': 4.48}                                                                                                       
{'loss': 0.183, 'learning_rate': 0.0001681903864278982, 'epoch': 4.48}                                                                                                        
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                     | 14500/32330 [23:10:55<2:15:50,  2.19it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6722342103079094, 'eval_cer': 0.4065222623345367, 'eval_runtime': 533.2269, 'eval_samples_per_second': 17.962, 'eval_steps_per_second': 2.247, 'epoch': 4.48}                                                                                                                                                              
{'loss': 0.1654, 'learning_rate': 0.00016809613572101788, 'epoch': 4.49}                                                                                                      
{'loss': 0.1894, 'learning_rate': 0.00016800188501413758, 'epoch': 4.49}                                                                                                      
{'loss': 0.3586, 'learning_rate': 0.0001679076343072573, 'epoch': 4.49}                                                                                                       
{'loss': 0.3698, 'learning_rate': 0.00016781338360037697, 'epoch': 4.5}                                                                                                       
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                     | 14544/32330 [23:20:08<2:39:57,  1.85it/s]Saving model checkpoint to turkish_clean/checkpoint-14544
Configuration saved in turkish_clean/checkpoint-14544/config.json
Model weights saved in turkish_clean/checkpoint-14544/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-14544/preprocessor_config.json
Deleting older checkpoint [turkish_clean/checkpoint-4848] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2052, 'learning_rate': 0.0001677191328934967, 'epoch': 4.5}                                                                                                        
{'loss': 0.2601, 'learning_rate': 0.00016762488218661638, 'epoch': 4.5}                                                                                                       
{'loss': 0.2405, 'learning_rate': 0.00016753063147973609, 'epoch': 4.51}                                                                                                      
{'loss': 0.332, 'learning_rate': 0.0001674363807728558, 'epoch': 4.51}                                                                                                        
{'loss': 0.3082, 'learning_rate': 0.00016734213006597547, 'epoch': 4.51}                                                                                                      
{'loss': 0.2291, 'learning_rate': 0.00016724787935909518, 'epoch': 4.52}                                                                                                      
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                     | 14600/32330 [23:20:36<2:20:47,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6776703460868122, 'eval_cer': 0.40769193742478943, 'eval_runtime': 534.0615, 'eval_samples_per_second': 17.934, 'eval_steps_per_second': 2.243, 'epoch': 4.52}                                                                                                                                                             
{'loss': 0.1667, 'learning_rate': 0.00016715362865221486, 'epoch': 4.52}                                                                                                      
{'loss': 0.2688, 'learning_rate': 0.00016705937794533456, 'epoch': 4.52}                                                                                                      
{'loss': 0.3476, 'learning_rate': 0.0001669651272384543, 'epoch': 4.53}                                                                                                       
{'loss': 0.3809, 'learning_rate': 0.00016687087653157397, 'epoch': 4.53}                                                                                                      
{'loss': 0.2238, 'learning_rate': 0.00016677662582469368, 'epoch': 4.53}                                                                                                      
{'loss': 0.1827, 'learning_rate': 0.00016668237511781336, 'epoch': 4.53}                                                                                                      
{'loss': 0.2389, 'learning_rate': 0.00016658812441093306, 'epoch': 4.54}                                                                                                      
{'loss': 0.3027, 'learning_rate': 0.00016649387370405277, 'epoch': 4.54}                                                                                                      
{'loss': 0.331, 'learning_rate': 0.00016639962299717245, 'epoch': 4.54}                                                                                                       
{'loss': 0.2166, 'learning_rate': 0.00016630537229029216, 'epoch': 4.55}                                                                                                      
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                    | 14700/32330 [23:30:16<2:19:59,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6749937754170471, 'eval_cer': 0.407309265944645, 'eval_runtime': 533.3823, 'eval_samples_per_second': 17.957, 'eval_steps_per_second': 2.246, 'epoch': 4.55}                                                                                                                                                               
{'loss': 0.2555, 'learning_rate': 0.0001662111215834119, 'epoch': 4.55}                                                                                                       
{'loss': 0.2186, 'learning_rate': 0.00016611687087653157, 'epoch': 4.55}                                                                                                      
{'loss': 0.2914, 'learning_rate': 0.00016602262016965127, 'epoch': 4.56}                                                                                                      
{'loss': 0.3272, 'learning_rate': 0.00016592836946277095, 'epoch': 4.56}                                                                                                      
{'loss': 0.2233, 'learning_rate': 0.00016583411875589066, 'epoch': 4.56}                                                                                                      
{'loss': 0.2122, 'learning_rate': 0.00016573986804901034, 'epoch': 4.57}                                                                                                      
{'loss': 0.1931, 'learning_rate': 0.00016564561734213004, 'epoch': 4.57}                                                                                                      
{'loss': 0.2762, 'learning_rate': 0.00016555136663524975, 'epoch': 4.57}                                                                                                      
{'loss': 0.4245, 'learning_rate': 0.00016545711592836943, 'epoch': 4.57}                                                                                                      
{'loss': 0.2446, 'learning_rate': 0.00016536286522148916, 'epoch': 4.58}                                                                                                      
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                    | 14800/32330 [23:39:54<2:16:45,  2.14it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6813635986388912, 'eval_cer': 0.4083610108303249, 'eval_runtime': 531.3643, 'eval_samples_per_second': 18.025, 'eval_steps_per_second': 2.255, 'epoch': 4.58}                                                                                                                                                              
{'loss': 0.2642, 'learning_rate': 0.00016526861451460887, 'epoch': 4.58}                                                                                                      
{'loss': 0.2452, 'learning_rate': 0.00016517436380772855, 'epoch': 4.58}                                                                                                      
{'loss': 0.2632, 'learning_rate': 0.00016508011310084825, 'epoch': 4.59}                                                                                                      
{'loss': 0.3863, 'learning_rate': 0.00016498586239396793, 'epoch': 4.59}                                                                                                      
{'loss': 0.2016, 'learning_rate': 0.00016489161168708764, 'epoch': 4.59}                                                                                                      
{'loss': 0.1728, 'learning_rate': 0.00016479736098020732, 'epoch': 4.6}                                                                                                       
{'loss': 0.2659, 'learning_rate': 0.00016470311027332702, 'epoch': 4.6}                                                                                                       
{'loss': 0.3282, 'learning_rate': 0.00016460885956644675, 'epoch': 4.6}                                                                                                       
{'loss': 0.3488, 'learning_rate': 0.00016451460885956643, 'epoch': 4.61}                                                                                                      
{'loss': 0.2514, 'learning_rate': 0.00016442035815268614, 'epoch': 4.61}                                                                                                      
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                    | 14900/32330 [23:49:31<2:13:13,  2.18it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6988754253465018, 'eval_cer': 0.4082503008423586, 'eval_runtime': 538.276, 'eval_samples_per_second': 17.794, 'eval_steps_per_second': 2.226, 'epoch': 4.61}                                                                                                                                                               
{'loss': 0.1756, 'learning_rate': 0.00016432610744580585, 'epoch': 4.61}                                                                                                      
{'loss': 0.229, 'learning_rate': 0.00016423185673892552, 'epoch': 4.61}                                                                                                       
{'loss': 0.3473, 'learning_rate': 0.00016413760603204523, 'epoch': 4.62}                                                                                                      
{'loss': 0.3721, 'learning_rate': 0.0001640433553251649, 'epoch': 4.62}                                                                                                       
{'loss': 0.2584, 'learning_rate': 0.00016394910461828461, 'epoch': 4.62}                                                                                                      
{'loss': 0.2188, 'learning_rate': 0.0001638548539114043, 'epoch': 4.63}                                                                                                       
{'loss': 0.2877, 'learning_rate': 0.00016376060320452403, 'epoch': 4.63}                                                                                                      
{'loss': 0.3285, 'learning_rate': 0.00016366635249764373, 'epoch': 4.63}                                                                                                      
{'loss': 0.3656, 'learning_rate': 0.0001635721017907634, 'epoch': 4.64}                                                                                                       
{'loss': 0.2117, 'learning_rate': 0.00016347785108388312, 'epoch': 4.64}                                                                                                      
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                   | 15000/32330 [23:59:15<2:17:14,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6750560212465765, 'eval_cer': 0.40411552346570395, 'eval_runtime': 533.3214, 'eval_samples_per_second': 17.959, 'eval_steps_per_second': 2.246, 'epoch': 4.64}                                                                                                                                                             
{'loss': 0.1999, 'learning_rate': 0.00016338360037700282, 'epoch': 4.64}                                                                                                      
{'loss': 0.2217, 'learning_rate': 0.0001632893496701225, 'epoch': 4.65}                                                                                                       
{'loss': 0.2912, 'learning_rate': 0.0001631950989632422, 'epoch': 4.65}                                                                                                       
{'loss': 0.4151, 'learning_rate': 0.0001631008482563619, 'epoch': 4.65}                                                                                                       
{'loss': 0.2213, 'learning_rate': 0.00016300659754948162, 'epoch': 4.66}                                                                                                      
{'loss': 0.2374, 'learning_rate': 0.00016291234684260133, 'epoch': 4.66}                                                                                                      
{'loss': 0.2408, 'learning_rate': 0.000162818096135721, 'epoch': 4.66}                                                                                                        
{'loss': 0.386, 'learning_rate': 0.0001627238454288407, 'epoch': 4.66}                                                                                                        
{'loss': 0.3446, 'learning_rate': 0.0001626295947219604, 'epoch': 4.67}                                                                                                       
{'loss': 0.2364, 'learning_rate': 0.0001625353440150801, 'epoch': 4.67}                                                                                                       
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                   | 15100/32330 [24:08:54<2:19:30,  2.06it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7107643787866212, 'eval_cer': 0.4133068592057762, 'eval_runtime': 541.0098, 'eval_samples_per_second': 17.704, 'eval_steps_per_second': 2.214, 'epoch': 4.67}                                                                                                                                                              
{'loss': 0.2523, 'learning_rate': 0.00016244109330819977, 'epoch': 4.67}                                                                                                      
{'loss': 0.2493, 'learning_rate': 0.00016234684260131948, 'epoch': 4.68}                                                                                                      
{'loss': 0.2726, 'learning_rate': 0.00016225259189443921, 'epoch': 4.68}                                                                                                      
{'loss': 0.339, 'learning_rate': 0.0001621583411875589, 'epoch': 4.68}                                                                                                        
{'loss': 0.2048, 'learning_rate': 0.0001620640904806786, 'epoch': 4.69}                                                                                                       
{'loss': 0.2162, 'learning_rate': 0.0001619698397737983, 'epoch': 4.69}                                                                                                       
{'loss': 0.1815, 'learning_rate': 0.00016187558906691798, 'epoch': 4.69}                                                                                                      
{'loss': 0.4332, 'learning_rate': 0.0001617813383600377, 'epoch': 4.7}                                                                                                        
{'loss': 0.411, 'learning_rate': 0.00016168708765315737, 'epoch': 4.7}                                                                                                        
{'loss': 0.2799, 'learning_rate': 0.00016159283694627707, 'epoch': 4.7}                                                                                                       
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                  | 15200/32330 [24:18:40<2:10:19,  2.19it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7708316042825131, 'eval_cer': 0.4230902527075812, 'eval_runtime': 539.5848, 'eval_samples_per_second': 17.751, 'eval_steps_per_second': 2.22, 'epoch': 4.7}                                                                                                                                                                
{'loss': 0.3377, 'learning_rate': 0.00016149858623939675, 'epoch': 4.7}                                                                                                       
{'loss': 0.3733, 'learning_rate': 0.00016140433553251649, 'epoch': 4.71}                                                                                                      
{'loss': 0.4071, 'learning_rate': 0.0001613100848256362, 'epoch': 4.71}                                                                                                       
{'loss': 0.6219, 'learning_rate': 0.00016121583411875587, 'epoch': 4.71}                                                                                                      
{'loss': 0.4496, 'learning_rate': 0.00016112158341187558, 'epoch': 4.72}                                                                                                      
{'loss': 0.3511, 'learning_rate': 0.00016102733270499528, 'epoch': 4.72}                                                                                                      
{'loss': 0.3322, 'learning_rate': 0.00016093308199811496, 'epoch': 4.72}                                                                                                      
{'loss': 0.4475, 'learning_rate': 0.00016083883129123467, 'epoch': 4.73}                                                                                                      
{'loss': 0.4874, 'learning_rate': 0.00016074458058435435, 'epoch': 4.73}                                                                                                      
{'loss': 0.3322, 'learning_rate': 0.00016065032987747408, 'epoch': 4.73}                                                                                                      
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                  | 15300/32330 [24:28:25<2:08:54,  2.20it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7157855423686613, 'eval_cer': 0.4179326113116727, 'eval_runtime': 538.0512, 'eval_samples_per_second': 17.801, 'eval_steps_per_second': 2.227, 'epoch': 4.73}                                                                                                                                                              
{'loss': 0.3123, 'learning_rate': 0.00016055607917059379, 'epoch': 4.74}                                                                                                      
{'loss': 0.3808, 'learning_rate': 0.00016046182846371346, 'epoch': 4.74}                                                                                                      
{'loss': 0.3327, 'learning_rate': 0.00016036757775683317, 'epoch': 4.74}                                                                                                      
{'loss': 0.4694, 'learning_rate': 0.00016027332704995285, 'epoch': 4.74}                                                                                                      
{'loss': 0.3543, 'learning_rate': 0.00016017907634307256, 'epoch': 4.75}                                                                                                      
{'loss': 0.3199, 'learning_rate': 0.00016008482563619226, 'epoch': 4.75}                                                                                                      
{'loss': 0.3664, 'learning_rate': 0.00015999057492931194, 'epoch': 4.75}                                                                                                      
{'loss': 0.4938, 'learning_rate': 0.00015989632422243165, 'epoch': 4.76}                                                                                                      
{'loss': 0.424, 'learning_rate': 0.00015980207351555135, 'epoch': 4.76}                                                                                                       
{'loss': 0.3368, 'learning_rate': 0.00015970782280867106, 'epoch': 4.76}                                                                                                      
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                  | 15400/32330 [24:38:09<2:14:04,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.8317287741721304, 'eval_cer': 0.4352274368231047, 'eval_runtime': 538.98, 'eval_samples_per_second': 17.771, 'eval_steps_per_second': 2.223, 'epoch': 4.76}                                                                                                                                                                
{'loss': 0.3192, 'learning_rate': 0.00015961357210179076, 'epoch': 4.77}                                                                                                      
{'loss': 0.3524, 'learning_rate': 0.00015951932139491044, 'epoch': 4.77}                                                                                                      
{'loss': 0.3556, 'learning_rate': 0.00015942507068803015, 'epoch': 4.77}                                                                                                      
{'loss': 0.4309, 'learning_rate': 0.00015933081998114983, 'epoch': 4.78}                                                                                                      
{'loss': 0.3722, 'learning_rate': 0.00015923656927426953, 'epoch': 4.78}                                                                                                      
{'loss': 0.3638, 'learning_rate': 0.00015914231856738924, 'epoch': 4.78}                                                                                                      
{'loss': 0.3168, 'learning_rate': 0.00015904806786050895, 'epoch': 4.78}                                                                                                      
{'loss': 0.5069, 'learning_rate': 0.00015895381715362865, 'epoch': 4.79}                                                                                                      
{'loss': 0.5525, 'learning_rate': 0.00015885956644674833, 'epoch': 4.79}                                                                                                      
{'loss': 0.3068, 'learning_rate': 0.00015876531573986804, 'epoch': 4.79}                                                                                                      
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                 | 15500/32330 [24:47:53<2:10:20,  2.15it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6926508423935597, 'eval_cer': 0.4117424789410349, 'eval_runtime': 536.7285, 'eval_samples_per_second': 17.845, 'eval_steps_per_second': 2.232, 'epoch': 4.79}                                                                                                                                                              
{'loss': 0.3445, 'learning_rate': 0.00015867106503298774, 'epoch': 4.8}                                                                                                       
{'loss': 0.2277, 'learning_rate': 0.00015857681432610742, 'epoch': 4.8}                                                                                                       
{'loss': 0.3841, 'learning_rate': 0.00015848256361922713, 'epoch': 4.8}                                                                                                       
{'loss': 0.418, 'learning_rate': 0.0001583883129123468, 'epoch': 4.81}                                                                                                        
{'loss': 0.2811, 'learning_rate': 0.00015829406220546654, 'epoch': 4.81}                                                                                                      
{'loss': 0.273, 'learning_rate': 0.00015819981149858625, 'epoch': 4.81}                                                                                                       
{'loss': 0.3417, 'learning_rate': 0.00015810556079170592, 'epoch': 4.82}                                                                                                      
{'loss': 0.3544, 'learning_rate': 0.00015801131008482563, 'epoch': 4.82}                                                                                                      
{'loss': 0.4534, 'learning_rate': 0.0001579170593779453, 'epoch': 4.82}                                                                                                       
{'loss': 0.3262, 'learning_rate': 0.00015782280867106501, 'epoch': 4.83}                                                                                                      
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                 | 15600/32330 [24:57:36<2:16:46,  2.04it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7484853514814508, 'eval_cer': 0.422676293622142, 'eval_runtime': 538.1726, 'eval_samples_per_second': 17.797, 'eval_steps_per_second': 2.226, 'epoch': 4.83}                                                                                                                                                               
{'loss': 0.3293, 'learning_rate': 0.00015772855796418472, 'epoch': 4.83}                                                                                                      
{'loss': 0.3112, 'learning_rate': 0.0001576343072573044, 'epoch': 4.83}                                                                                                       
{'loss': 0.4018, 'learning_rate': 0.0001575400565504241, 'epoch': 4.83}                                                                                                       
{'loss': 0.4505, 'learning_rate': 0.00015744580584354384, 'epoch': 4.84}                                                                                                      
{'loss': 0.2764, 'learning_rate': 0.00015735155513666352, 'epoch': 4.84}                                                                                                      
{'loss': 0.2683, 'learning_rate': 0.00015725730442978322, 'epoch': 4.84}                                                                                                      
{'loss': 0.2286, 'learning_rate': 0.0001571630537229029, 'epoch': 4.85}                                                                                                       
{'loss': 0.3159, 'learning_rate': 0.0001570688030160226, 'epoch': 4.85}                                                                                                       
{'loss': 0.4085, 'learning_rate': 0.0001569745523091423, 'epoch': 4.85}                                                                                                       
{'loss': 0.2341, 'learning_rate': 0.000156880301602262, 'epoch': 4.86}                                                                                                        
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                | 15700/32330 [25:07:20<2:11:59,  2.10it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.690202506432069, 'eval_cer': 0.40994464500601685, 'eval_runtime': 533.9618, 'eval_samples_per_second': 17.938, 'eval_steps_per_second': 2.244, 'epoch': 4.86}                                                                                                                                                              
{'loss': 0.2074, 'learning_rate': 0.0001567860508953817, 'epoch': 4.86}                                                                                                       
{'loss': 0.2309, 'learning_rate': 0.0001566918001885014, 'epoch': 4.86}                                                                                                       
{'loss': 0.4857, 'learning_rate': 0.0001565975494816211, 'epoch': 4.87}                                                                                                       
{'loss': 1.4267, 'learning_rate': 0.00015650329877474082, 'epoch': 4.87}                                                                                                      
{'loss': 0.2671, 'learning_rate': 0.0001564090480678605, 'epoch': 4.87}                                                                                                       
{'loss': 0.3037, 'learning_rate': 0.0001563147973609802, 'epoch': 4.87}                                                                                                       
{'loss': 0.2854, 'learning_rate': 0.00015622054665409988, 'epoch': 4.88}                                                                                                      
{'loss': 0.3386, 'learning_rate': 0.0001561262959472196, 'epoch': 4.88}                                                                                                       
{'loss': 0.3931, 'learning_rate': 0.00015603204524033927, 'epoch': 4.88}                                                                                                      
{'loss': 0.2676, 'learning_rate': 0.00015593779453345897, 'epoch': 4.89}                                                                                                      
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                | 15800/32330 [25:16:59<2:09:51,  2.12it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7325919163416051, 'eval_cer': 0.4169723225030084, 'eval_runtime': 538.1751, 'eval_samples_per_second': 17.797, 'eval_steps_per_second': 2.226, 'epoch': 4.89}                                                                                                                                                              
{'loss': 0.2374, 'learning_rate': 0.0001558435438265787, 'epoch': 4.89}                                                                                                       
{'loss': 0.4032, 'learning_rate': 0.00015574929311969838, 'epoch': 4.89}                                                                                                      
{'loss': 0.4211, 'learning_rate': 0.0001556550424128181, 'epoch': 4.9}                                                                                                        
{'loss': 0.5915, 'learning_rate': 0.00015556079170593777, 'epoch': 4.9}                                                                                                       
{'loss': 0.741, 'learning_rate': 0.00015546654099905747, 'epoch': 4.9}                                                                                                        
{'loss': 0.3166, 'learning_rate': 0.00015537229029217718, 'epoch': 4.91}                                                                                                      
{'loss': 0.314, 'learning_rate': 0.00015527803958529686, 'epoch': 4.91}                                                                                                       
{'loss': 0.414, 'learning_rate': 0.00015518378887841657, 'epoch': 4.91}                                                                                                       
{'loss': 0.4681, 'learning_rate': 0.0001550895381715363, 'epoch': 4.91}                                                                                                       
{'loss': 0.3569, 'learning_rate': 0.00015499528746465598, 'epoch': 4.92}                                                                                                      
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                | 15900/32330 [25:26:43<2:07:16,  2.15it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7392937173209395, 'eval_cer': 0.420748495788207, 'eval_runtime': 533.897, 'eval_samples_per_second': 17.94, 'eval_steps_per_second': 2.244, 'epoch': 4.92}                                                                                                                                                                 
{'loss': 0.3316, 'learning_rate': 0.00015490103675777568, 'epoch': 4.92}                                                                                                      
{'loss': 0.3454, 'learning_rate': 0.00015480678605089536, 'epoch': 4.92}                                                                                                      
{'loss': 0.4002, 'learning_rate': 0.00015471253534401507, 'epoch': 4.93}                                                                                                      
{'loss': 0.4728, 'learning_rate': 0.00015461828463713475, 'epoch': 4.93}                                                                                                      
{'loss': 0.3321, 'learning_rate': 0.00015452403393025445, 'epoch': 4.93}                                                                                                      
{'loss': 0.3256, 'learning_rate': 0.00015442978322337416, 'epoch': 4.94}                                                                                                      
{'loss': 0.2749, 'learning_rate': 0.00015433553251649386, 'epoch': 4.94}                                                                                                      
{'loss': 0.3551, 'learning_rate': 0.00015424128180961357, 'epoch': 4.94}                                                                                                      
{'loss': 0.4073, 'learning_rate': 0.00015414703110273328, 'epoch': 4.95}                                                                                                      
{'loss': 0.2657, 'learning_rate': 0.00015405278039585296, 'epoch': 4.95}                                                                                                      
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                               | 16000/32330 [25:36:21<2:00:03,  2.27it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7316167316789776, 'eval_cer': 0.4175210589651023, 'eval_runtime': 533.0522, 'eval_samples_per_second': 17.968, 'eval_steps_per_second': 2.247, 'epoch': 4.95}                                                                                                                                                              
{'loss': 0.2446, 'learning_rate': 0.00015395852968897266, 'epoch': 4.95}                                                                                                      
{'loss': 0.4096, 'learning_rate': 0.00015386427898209234, 'epoch': 4.96}                                                                                                      
{'loss': 0.5434, 'learning_rate': 0.00015377002827521205, 'epoch': 4.96}                                                                                                      
{'loss': 0.4126, 'learning_rate': 0.00015367577756833173, 'epoch': 4.96}                                                                                                      
{'loss': 0.2834, 'learning_rate': 0.00015358152686145143, 'epoch': 4.96}                                                                                                      
{'loss': 0.2551, 'learning_rate': 0.00015348727615457116, 'epoch': 4.97}                                                                                                      
{'loss': 0.3169, 'learning_rate': 0.00015339302544769084, 'epoch': 4.97}                                                                                                      
{'loss': 0.3572, 'learning_rate': 0.00015329877474081055, 'epoch': 4.97}                                                                                                      
{'loss': 0.3832, 'learning_rate': 0.00015320452403393026, 'epoch': 4.98}                                                                                                      
{'loss': 0.2641, 'learning_rate': 0.00015311027332704993, 'epoch': 4.98}                                                                                                      
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                               | 16100/32330 [25:46:00<1:58:32,  2.28it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7003070794256785, 'eval_cer': 0.41381227436823104, 'eval_runtime': 532.2908, 'eval_samples_per_second': 17.994, 'eval_steps_per_second': 2.251, 'epoch': 4.98}                                                                                                                                                             
{'loss': 0.2441, 'learning_rate': 0.00015301602262016964, 'epoch': 4.98}                                                                                                      
{'loss': 0.3477, 'learning_rate': 0.00015292177191328932, 'epoch': 4.99}                                                                                                      
{'loss': 0.3475, 'learning_rate': 0.00015282752120640902, 'epoch': 4.99}                                                                                                      
{'loss': 0.4392, 'learning_rate': 0.00015273327049952876, 'epoch': 4.99}                                                                                                      
{'loss': 0.2136, 'learning_rate': 0.00015263901979264844, 'epoch': 5.0}                                                                                                       
{'loss': 0.2746, 'learning_rate': 0.00015254476908576814, 'epoch': 5.0}                                                                                                       
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                               | 16160/32330 [25:55:17<1:36:23,  2.80it/s]Saving model checkpoint to turkish_clean/checkpoint-16160
Configuration saved in turkish_clean/checkpoint-16160/config.json
Model weights saved in turkish_clean/checkpoint-16160/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-16160/preprocessor_config.json
Deleting older checkpoint [turkish_clean/checkpoint-6464] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4129, 'learning_rate': 0.00015245051837888782, 'epoch': 5.0}                                                                                                       
{'loss': 0.3092, 'learning_rate': 0.00015235626767200753, 'epoch': 5.0}                                                                                                       
{'loss': 0.2261, 'learning_rate': 0.00015226201696512723, 'epoch': 5.01}                                                                                                      
{'loss': 0.3088, 'learning_rate': 0.0001521677662582469, 'epoch': 5.01}                                                                                                       
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                              | 16200/32330 [25:55:39<1:38:16,  2.74it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7149141007552494, 'eval_cer': 0.41611793020457283, 'eval_runtime': 535.838, 'eval_samples_per_second': 17.875, 'eval_steps_per_second': 2.236, 'epoch': 5.01}                                                                                                                                                              
{'loss': 0.334, 'learning_rate': 0.00015207351555136662, 'epoch': 5.01}                                                                                                       
{'loss': 0.4229, 'learning_rate': 0.0001519792648444863, 'epoch': 5.02}                                                                                                       
{'loss': 0.2203, 'learning_rate': 0.00015188501413760603, 'epoch': 5.02}                                                                                                      
{'loss': 0.2567, 'learning_rate': 0.00015179076343072574, 'epoch': 5.02}                                                                                                      
{'loss': 0.2838, 'learning_rate': 0.00015169651272384541, 'epoch': 5.03}                                                                                                      
{'loss': 0.3452, 'learning_rate': 0.00015160226201696512, 'epoch': 5.03}                                                                                                      
{'loss': 0.3633, 'learning_rate': 0.0001515080113100848, 'epoch': 5.03}                                                                                                       
{'loss': 0.2544, 'learning_rate': 0.0001514137606032045, 'epoch': 5.04}                                                                                                       
{'loss': 0.2379, 'learning_rate': 0.00015131950989632418, 'epoch': 5.04}                                                                                                      
{'loss': 0.3049, 'learning_rate': 0.0001512252591894439, 'epoch': 5.04}                                                                                                       
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                              | 16300/32330 [26:05:21<1:42:14,  2.61it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.699207403103992, 'eval_cer': 0.4111768953068592, 'eval_runtime': 534.2696, 'eval_samples_per_second': 17.927, 'eval_steps_per_second': 2.242, 'epoch': 5.04}                                                                                                                                                               
{'loss': 0.25, 'learning_rate': 0.00015113100848256362, 'epoch': 5.04}                                                                                                        
{'loss': 0.3652, 'learning_rate': 0.0001510367577756833, 'epoch': 5.05}                                                                                                       
{'loss': 0.2587, 'learning_rate': 0.000150942507068803, 'epoch': 5.05}                                                                                                        
{'loss': 0.1999, 'learning_rate': 0.00015084825636192271, 'epoch': 5.05}                                                                                                      
{'loss': 0.2978, 'learning_rate': 0.0001507540056550424, 'epoch': 5.06}                                                                                                       
{'loss': 0.2289, 'learning_rate': 0.0001506597549481621, 'epoch': 5.06}                                                                                                       
{'loss': 0.4783, 'learning_rate': 0.00015056550424128178, 'epoch': 5.06}                                                                                                      
{'loss': 0.3101, 'learning_rate': 0.00015047125353440148, 'epoch': 5.07}                                                                                                      
{'loss': 0.1777, 'learning_rate': 0.00015037700282752122, 'epoch': 5.07}                                                                                                      
{'loss': 0.2477, 'learning_rate': 0.0001502827521206409, 'epoch': 5.07}                                                                                                       
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                              | 16400/32330 [26:15:00<1:40:23,  2.64it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7182753755498381, 'eval_cer': 0.41535499398315284, 'eval_runtime': 540.402, 'eval_samples_per_second': 17.724, 'eval_steps_per_second': 2.217, 'epoch': 5.07}                                                                                                                                                              
{'loss': 0.2952, 'learning_rate': 0.0001501885014137606, 'epoch': 5.08}                                                                                                       
{'loss': 0.4457, 'learning_rate': 0.00015009425070688028, 'epoch': 5.08}                                                                                                      
{'loss': 0.2451, 'learning_rate': 0.00015, 'epoch': 5.08}                                                                                                                     
{'loss': 0.2349, 'learning_rate': 0.0001499057492931197, 'epoch': 5.09}                                                                                                       
{'loss': 0.28, 'learning_rate': 0.00014981149858623937, 'epoch': 5.09}                                                                                                        
{'loss': 0.2567, 'learning_rate': 0.00014971724787935908, 'epoch': 5.09}                                                                                                      
{'loss': 0.3466, 'learning_rate': 0.00014962299717247878, 'epoch': 5.09}                                                                                                      
{'loss': 0.2378, 'learning_rate': 0.00014952874646559846, 'epoch': 5.1}                                                                                                       
{'loss': 0.2988, 'learning_rate': 0.00014943449575871817, 'epoch': 5.1}                                                                                                       
{'loss': 0.2069, 'learning_rate': 0.00014934024505183787, 'epoch': 5.1}                                                                                                       
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                             | 16500/32330 [26:24:47<1:41:45,  2.59it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7177774089136028, 'eval_cer': 0.4122864019253911, 'eval_runtime': 533.2533, 'eval_samples_per_second': 17.961, 'eval_steps_per_second': 2.247, 'epoch': 5.1}                                                                                                                                                               
{'loss': 0.255, 'learning_rate': 0.00014924599434495758, 'epoch': 5.11}                                                                                                       
{'loss': 0.4751, 'learning_rate': 0.00014915174363807726, 'epoch': 5.11}                                                                                                      
{'loss': 0.268, 'learning_rate': 0.00014905749293119697, 'epoch': 5.11}                                                                                                       
{'loss': 0.2316, 'learning_rate': 0.00014896324222431667, 'epoch': 5.12}                                                                                                      
{'loss': 0.3176, 'learning_rate': 0.00014886899151743638, 'epoch': 5.12}                                                                                                      
{'loss': 0.2514, 'learning_rate': 0.00014877474081055606, 'epoch': 5.12}                                                                                                      
{'loss': 0.5506, 'learning_rate': 0.00014868049010367576, 'epoch': 5.13}                                                                                                      
{'loss': 0.2921, 'learning_rate': 0.00014858623939679547, 'epoch': 5.13}                                                                                                      
{'loss': 0.2416, 'learning_rate': 0.00014849198868991517, 'epoch': 5.13}                                                                                                      
{'loss': 0.1753, 'learning_rate': 0.00014839773798303485, 'epoch': 5.13}                                                                                                      
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                             | 16600/32330 [26:34:26<1:41:59,  2.57it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6975060170968546, 'eval_cer': 0.41243080625752104, 'eval_runtime': 540.1847, 'eval_samples_per_second': 17.731, 'eval_steps_per_second': 2.218, 'epoch': 5.13}                                                                                                                                                             
{'loss': 0.2134, 'learning_rate': 0.00014830348727615456, 'epoch': 5.14}                                                                                                      
{'loss': 0.5485, 'learning_rate': 0.00014820923656927426, 'epoch': 5.14}                                                                                                      
{'loss': 0.2766, 'learning_rate': 0.00014811498586239397, 'epoch': 5.14}                                                                                                      
{'loss': 0.2212, 'learning_rate': 0.00014802073515551365, 'epoch': 5.15}                                                                                                      
{'loss': 0.209, 'learning_rate': 0.00014792648444863336, 'epoch': 5.15}                                                                                                       
{'loss': 0.2526, 'learning_rate': 0.00014783223374175303, 'epoch': 5.15}                                                                                                      
{'loss': 0.3556, 'learning_rate': 0.00014773798303487274, 'epoch': 5.16}                                                                                                      
{'loss': 0.2813, 'learning_rate': 0.00014764373232799245, 'epoch': 5.16}                                                                                                      
{'loss': 0.1807, 'learning_rate': 0.00014754948162111215, 'epoch': 5.16}                                                                                                      
{'loss': 0.3277, 'learning_rate': 0.00014745523091423183, 'epoch': 5.17}                                                                                                      
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                             | 16700/32330 [26:44:12<1:37:03,  2.68it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7027761639970121, 'eval_cer': 0.41465703971119133, 'eval_runtime': 538.165, 'eval_samples_per_second': 17.798, 'eval_steps_per_second': 2.226, 'epoch': 5.17}                                                                                                                                                              
{'loss': 0.2833, 'learning_rate': 0.00014736098020735154, 'epoch': 5.17}                                                                                                      
{'loss': 0.6074, 'learning_rate': 0.00014726672950047124, 'epoch': 5.17}                                                                                                      
{'loss': 0.288, 'learning_rate': 0.00014717247879359095, 'epoch': 5.17}                                                                                                       
{'loss': 0.212, 'learning_rate': 0.00014707822808671063, 'epoch': 5.18}                                                                                                       
{'loss': 0.2722, 'learning_rate': 0.00014698397737983033, 'epoch': 5.18}                                                                                                      
{'loss': 0.2623, 'learning_rate': 0.00014688972667295004, 'epoch': 5.18}                                                                                                      
{'loss': 0.4772, 'learning_rate': 0.00014679547596606972, 'epoch': 5.19}                                                                                                      
{'loss': 0.2801, 'learning_rate': 0.00014670122525918942, 'epoch': 5.19}                                                                                                      
{'loss': 0.1918, 'learning_rate': 0.00014660697455230913, 'epoch': 5.19}                                                                                                      
{'loss': 0.3404, 'learning_rate': 0.00014651272384542884, 'epoch': 5.2}                                                                                                       
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                            | 16800/32330 [26:53:56<1:38:32,  2.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7072786123329737, 'eval_cer': 0.4146016847172082, 'eval_runtime': 535.8052, 'eval_samples_per_second': 17.876, 'eval_steps_per_second': 2.236, 'epoch': 5.2}                                                                                                                                                               
{'loss': 0.3189, 'learning_rate': 0.00014641847313854852, 'epoch': 5.2}                                                                                                       
{'loss': 0.4523, 'learning_rate': 0.00014632422243166822, 'epoch': 5.2}                                                                                                       
{'loss': 0.2961, 'learning_rate': 0.00014622997172478793, 'epoch': 5.21}                                                                                                      
{'loss': 0.2816, 'learning_rate': 0.00014613572101790763, 'epoch': 5.21}                                                                                                      
{'loss': 0.328, 'learning_rate': 0.0001460414703110273, 'epoch': 5.21}                                                                                                        
{'loss': 0.354, 'learning_rate': 0.00014594721960414702, 'epoch': 5.21}                                                                                                       
{'loss': 0.4668, 'learning_rate': 0.0001458529688972667, 'epoch': 5.22}                                                                                                       
{'loss': 0.2814, 'learning_rate': 0.00014575871819038643, 'epoch': 5.22}                                                                                                      
{'loss': 0.2371, 'learning_rate': 0.0001456644674835061, 'epoch': 5.22}                                                                                                       
{'loss': 0.2448, 'learning_rate': 0.00014557021677662581, 'epoch': 5.23}                                                                                                      
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                            | 16900/32330 [27:03:38<1:37:50,  2.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6901402606025396, 'eval_cer': 0.41065703971119133, 'eval_runtime': 537.91, 'eval_samples_per_second': 17.806, 'eval_steps_per_second': 2.227, 'epoch': 5.23}                                                                                                                                                               
{'loss': 0.2525, 'learning_rate': 0.0001454759660697455, 'epoch': 5.23}                                                                                                       
{'loss': 0.3622, 'learning_rate': 0.00014538171536286523, 'epoch': 5.23}                                                                                                      
{'loss': 0.2577, 'learning_rate': 0.0001452874646559849, 'epoch': 5.24}                                                                                                       
{'loss': 0.2071, 'learning_rate': 0.0001451932139491046, 'epoch': 5.24}                                                                                                       
{'loss': 0.2417, 'learning_rate': 0.0001450989632422243, 'epoch': 5.24}                                                                                                       
{'loss': 0.2424, 'learning_rate': 0.000145004712535344, 'epoch': 5.25}                                                                                                        
{'loss': 0.2799, 'learning_rate': 0.0001449104618284637, 'epoch': 5.25}                                                                                                       
{'loss': 0.2606, 'learning_rate': 0.0001448162111215834, 'epoch': 5.25}                                                                                                       
{'loss': 0.2217, 'learning_rate': 0.0001447219604147031, 'epoch': 5.26}                                                                                                       
{'loss': 0.2485, 'learning_rate': 0.0001446277097078228, 'epoch': 5.26}                                                                                                       
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                           | 17000/32330 [27:13:22<1:36:38,  2.64it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.7001203419370902, 'eval_cer': 0.41118170878459687, 'eval_runtime': 534.8077, 'eval_samples_per_second': 17.909, 'eval_steps_per_second': 2.24, 'epoch': 5.26}                                                                                                                                                              
{'loss': 0.393, 'learning_rate': 0.0001445334590009425, 'epoch': 5.26}                                                                                                        
{'loss': 0.4622, 'learning_rate': 0.0001444392082940622, 'epoch': 5.26}                                                                                                       
{'loss': 0.2458, 'learning_rate': 0.00014434495758718188, 'epoch': 5.27}                                                                                                      
{'loss': 0.2665, 'learning_rate': 0.0001442507068803016, 'epoch': 5.27}                                                                                                       
{'loss': 0.2814, 'learning_rate': 0.0001441564561734213, 'epoch': 5.27}                                                                                                       
{'loss': 0.2921, 'learning_rate': 0.00014406220546654097, 'epoch': 5.28}                                                                                                      
{'loss': 0.3939, 'learning_rate': 0.00014396795475966068, 'epoch': 5.28}                                                                                                      
{'loss': 0.3195, 'learning_rate': 0.0001438737040527804, 'epoch': 5.28}                                                                                                       
{'loss': 0.2237, 'learning_rate': 0.0001437794533459001, 'epoch': 5.29}                                                                                                       
{'loss': 0.2582, 'learning_rate': 0.00014368520263901977, 'epoch': 5.29}                                                                                                      
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                           | 17100/32330 [27:23:02<1:35:02,  2.67it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6859075441945389, 'eval_cer': 0.41026233453670274, 'eval_runtime': 542.5408, 'eval_samples_per_second': 17.654, 'eval_steps_per_second': 2.208, 'epoch': 5.29}                                                                                                                                                             
{'loss': 0.2696, 'learning_rate': 0.00014359095193213948, 'epoch': 5.29}                                                                                                      
{'loss': 0.327, 'learning_rate': 0.00014349670122525916, 'epoch': 5.3}                                                                                                        
{'loss': 0.2311, 'learning_rate': 0.0001434024505183789, 'epoch': 5.3}                                                                                                        
{'loss': 0.1772, 'learning_rate': 0.00014330819981149857, 'epoch': 5.3}                                                                                                       
{'loss': 0.2078, 'learning_rate': 0.00014321394910461827, 'epoch': 5.3}                                                                                                       
{'loss': 0.3161, 'learning_rate': 0.00014311969839773795, 'epoch': 5.31}                                                                                                      
{'loss': 0.3359, 'learning_rate': 0.00014302544769085769, 'epoch': 5.31}                                                                                                      
{'loss': 0.2218, 'learning_rate': 0.00014293119698397737, 'epoch': 5.31}                                                                                                      
{'loss': 0.2039, 'learning_rate': 0.00014283694627709707, 'epoch': 5.32}                                                                                                      
{'loss': 0.265, 'learning_rate': 0.00014274269557021675, 'epoch': 5.32}                                                                                                       
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                           | 17200/32330 [27:32:49<1:34:23,  2.67it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6927753340526185, 'eval_cer': 0.4097906137184116, 'eval_runtime': 538.1258, 'eval_samples_per_second': 17.799, 'eval_steps_per_second': 2.226, 'epoch': 5.32}                                                                                                                                                              
{'loss': 0.2509, 'learning_rate': 0.00014264844486333648, 'epoch': 5.32}                                                                                                      
{'loss': 0.3246, 'learning_rate': 0.00014255419415645616, 'epoch': 5.33}                                                                                                      
{'loss': 0.2806, 'learning_rate': 0.00014245994344957587, 'epoch': 5.33}                                                                                                      
{'loss': 0.2658, 'learning_rate': 0.00014236569274269555, 'epoch': 5.33}                                                                                                      
{'loss': 0.2837, 'learning_rate': 0.00014227144203581525, 'epoch': 5.34}                                                                                                      
{'loss': 0.2681, 'learning_rate': 0.00014217719132893496, 'epoch': 5.34}                                                                                                      
{'loss': 0.3003, 'learning_rate': 0.00014208294062205466, 'epoch': 5.34}                                                                                                      
{'loss': 0.2871, 'learning_rate': 0.00014198868991517434, 'epoch': 5.34}                                                                                                      
{'loss': 0.2314, 'learning_rate': 0.00014189443920829405, 'epoch': 5.35}                                                                                                      
{'loss': 0.2901, 'learning_rate': 0.00014180018850141376, 'epoch': 5.35}                                                                                                      
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                          | 17300/32330 [27:42:31<1:35:46,  2.62it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6855548178272056, 'eval_cer': 0.40834416365824305, 'eval_runtime': 538.0377, 'eval_samples_per_second': 17.802, 'eval_steps_per_second': 2.227, 'epoch': 5.35}                                                                                                                                                             
{'loss': 0.3394, 'learning_rate': 0.00014170593779453343, 'epoch': 5.35}                                                                                                      
{'loss': 0.4895, 'learning_rate': 0.00014161168708765314, 'epoch': 5.36}                                                                                                      
{'loss': 0.2301, 'learning_rate': 0.00014151743638077285, 'epoch': 5.36}                                                                                                      
{'loss': 0.1766, 'learning_rate': 0.00014142318567389255, 'epoch': 5.36}                                                                                                      
{'loss': 0.1577, 'learning_rate': 0.00014132893496701223, 'epoch': 5.37}                                                                                                      
{'loss': 0.3612, 'learning_rate': 0.00014123468426013194, 'epoch': 5.37}                                                                                                      
{'loss': 0.3625, 'learning_rate': 0.00014114043355325164, 'epoch': 5.37}                                                                                                      
{'loss': 0.2376, 'learning_rate': 0.00014104618284637135, 'epoch': 5.38}                                                                                                      
{'loss': 0.1929, 'learning_rate': 0.00014095193213949103, 'epoch': 5.38}                                                                                                      
{'loss': 0.2334, 'learning_rate': 0.00014085768143261073, 'epoch': 5.38}                                                                                                      
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                          | 17400/32330 [27:52:15<1:31:03,  2.73it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.682961241596813, 'eval_cer': 0.4073646209386282, 'eval_runtime': 532.76, 'eval_samples_per_second': 17.978, 'eval_steps_per_second': 2.249, 'epoch': 5.38}                                                                                                                                                                 
{'loss': 0.2824, 'learning_rate': 0.0001407634307257304, 'epoch': 5.39}                                                                                                       
{'loss': 0.3621, 'learning_rate': 0.00014066918001885015, 'epoch': 5.39}                                                                                                      
{'loss': 0.2503, 'learning_rate': 0.00014057492931196982, 'epoch': 5.39}                                                                                                      
{'loss': 0.2913, 'learning_rate': 0.00014048067860508953, 'epoch': 5.39}                                                                                                      
{'loss': 0.2095, 'learning_rate': 0.0001403864278982092, 'epoch': 5.4}                                                                                                        
{'loss': 0.2861, 'learning_rate': 0.00014029217719132894, 'epoch': 5.4}                                                                                                       
{'loss': 0.351, 'learning_rate': 0.00014019792648444862, 'epoch': 5.4}                                                                                                        
{'loss': 0.2145, 'learning_rate': 0.00014010367577756833, 'epoch': 5.41}                                                                                                      
{'loss': 0.2212, 'learning_rate': 0.000140009425070688, 'epoch': 5.41}                                                                                                        
{'loss': 0.2775, 'learning_rate': 0.0001399151743638077, 'epoch': 5.41}                                                                                                       
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                         | 17500/32330 [28:01:54<1:37:01,  2.55it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6834177110133621, 'eval_cer': 0.4102190132370638, 'eval_runtime': 533.0461, 'eval_samples_per_second': 17.968, 'eval_steps_per_second': 2.247, 'epoch': 5.41}                                                                                                                                                              
{'loss': 0.2693, 'learning_rate': 0.00013982092365692742, 'epoch': 5.42}                                                                                                      
{'loss': 0.3707, 'learning_rate': 0.00013972667295004712, 'epoch': 5.42}                                                                                                      
{'loss': 0.234, 'learning_rate': 0.0001396324222431668, 'epoch': 5.42}                                                                                                        
{'loss': 0.1749, 'learning_rate': 0.0001395381715362865, 'epoch': 5.43}                                                                                                       
{'loss': 0.1883, 'learning_rate': 0.00013944392082940621, 'epoch': 5.43}                                                                                                      
{'loss': 0.3731, 'learning_rate': 0.00013934967012252592, 'epoch': 5.43}                                                                                                      
{'loss': 0.3446, 'learning_rate': 0.0001392554194156456, 'epoch': 5.43}                                                                                                       
{'loss': 0.23, 'learning_rate': 0.0001391611687087653, 'epoch': 5.44}                                                                                                         
{'loss': 0.2462, 'learning_rate': 0.000139066918001885, 'epoch': 5.44}                                                                                                        
{'loss': 0.2444, 'learning_rate': 0.0001389726672950047, 'epoch': 5.44}                                                                                                       
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                         | 17600/32330 [28:11:33<1:32:42,  2.65it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6801186820483027, 'eval_cer': 0.40772322503008424, 'eval_runtime': 538.6323, 'eval_samples_per_second': 17.782, 'eval_steps_per_second': 2.224, 'epoch': 5.44}                                                                                                                                                             
{'loss': 0.2624, 'learning_rate': 0.0001388784165881244, 'epoch': 5.45}                                                                                                       
{'loss': 0.4127, 'learning_rate': 0.0001387841658812441, 'epoch': 5.45}                                                                                                       
{'loss': 0.2517, 'learning_rate': 0.0001386899151743638, 'epoch': 5.45}                                                                                                       
{'loss': 0.1832, 'learning_rate': 0.0001385956644674835, 'epoch': 5.46}                                                                                                       
{'loss': 0.2199, 'learning_rate': 0.0001385014137606032, 'epoch': 5.46}                                                                                                       
{'loss': 0.2338, 'learning_rate': 0.0001384071630537229, 'epoch': 5.46}                                                                                                       
{'loss': 0.3423, 'learning_rate': 0.0001383129123468426, 'epoch': 5.47}                                                                                                       
{'loss': 0.267, 'learning_rate': 0.0001382280867106503, 'epoch': 5.47}                                                                                                        
{'loss': 0.1523, 'learning_rate': 0.00013813383600377, 'epoch': 5.47}                                                                                                         
{'loss': 0.2374, 'learning_rate': 0.00013803958529688971, 'epoch': 5.47}                                                                                                      
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                         | 17700/32330 [28:21:17<1:31:58,  2.65it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6853680803386173, 'eval_cer': 0.40867870036101084, 'eval_runtime': 538.5357, 'eval_samples_per_second': 17.785, 'eval_steps_per_second': 2.225, 'epoch': 5.47}                                                                                                                                                             
{'loss': 0.2632, 'learning_rate': 0.00013794533459000942, 'epoch': 5.48}                                                                                                      
{'loss': 0.5154, 'learning_rate': 0.0001378510838831291, 'epoch': 5.48}                                                                                                       
{'loss': 0.2173, 'learning_rate': 0.0001377568331762488, 'epoch': 5.48}                                                                                                       
{'loss': 0.1858, 'learning_rate': 0.0001376625824693685, 'epoch': 5.49}                                                                                                       
{'loss': 0.1946, 'learning_rate': 0.00013756833176248822, 'epoch': 5.49}                                                                                                      
{'loss': 0.2622, 'learning_rate': 0.0001374740810556079, 'epoch': 5.49}                                                                                                       
{'loss': 0.3839, 'learning_rate': 0.0001373798303487276, 'epoch': 5.5}                                                                                                        
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                        | 17776/32330 [28:30:52<2:20:13,  1.73it/s]Saving model checkpoint to turkish_clean/checkpoint-17776
Configuration saved in turkish_clean/checkpoint-17776/config.json
Model weights saved in turkish_clean/checkpoint-17776/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-17776/preprocessor_config.json
Deleting older checkpoint [turkish_clean/checkpoint-8080] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2613, 'learning_rate': 0.0001372855796418473, 'epoch': 5.5}                                                                                                        
{'loss': 0.2274, 'learning_rate': 0.00013719132893496701, 'epoch': 5.5}                                                                                                       
{'loss': 0.175, 'learning_rate': 0.0001370970782280867, 'epoch': 5.51}                                                                                                        
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                        | 17800/32330 [28:31:04<1:35:00,  2.55it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6764461781060669, 'eval_cer': 0.4073598074608905, 'eval_runtime': 537.8628, 'eval_samples_per_second': 17.808, 'eval_steps_per_second': 2.227, 'epoch': 5.51}                                                                                                                                                              
{'loss': 0.3359, 'learning_rate': 0.0001370028275212064, 'epoch': 5.51}                                                                                                       
{'loss': 0.2852, 'learning_rate': 0.00013690857681432608, 'epoch': 5.51}                                                                                                      
{'loss': 0.2056, 'learning_rate': 0.0001368143261074458, 'epoch': 5.51}                                                                                                       
{'loss': 0.1864, 'learning_rate': 0.0001367200754005655, 'epoch': 5.52}                                                                                                       
{'loss': 0.1648, 'learning_rate': 0.0001366258246936852, 'epoch': 5.52}                                                                                                       
{'loss': 0.2012, 'learning_rate': 0.00013653157398680487, 'epoch': 5.52}                                                                                                      
{'loss': 0.3594, 'learning_rate': 0.00013643732327992458, 'epoch': 5.53}                                                                                                      
{'loss': 0.2543, 'learning_rate': 0.0001363430725730443, 'epoch': 5.53}                                                                                                       
{'loss': 0.2259, 'learning_rate': 0.000136248821866164, 'epoch': 5.53}                                                                                                        
{'loss': 0.2493, 'learning_rate': 0.00013615457115928367, 'epoch': 5.54}                                                                                                      
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                        | 17900/32330 [28:40:49<1:29:33,  2.69it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6691634160511246, 'eval_cer': 0.4057906137184116, 'eval_runtime': 531.5155, 'eval_samples_per_second': 18.02, 'eval_steps_per_second': 2.254, 'epoch': 5.54}                                                                                                                                                               
{'loss': 0.3235, 'learning_rate': 0.00013606032045240338, 'epoch': 5.54}                                                                                                      
{'loss': 0.3694, 'learning_rate': 0.00013596606974552308, 'epoch': 5.54}                                                                                                      
{'loss': 0.2113, 'learning_rate': 0.0001358718190386428, 'epoch': 5.55}                                                                                                       
{'loss': 0.2015, 'learning_rate': 0.00013577756833176247, 'epoch': 5.55}                                                                                                      
{'loss': 0.255, 'learning_rate': 0.00013568331762488217, 'epoch': 5.55}                                                                                                       
{'loss': 0.302, 'learning_rate': 0.00013558906691800188, 'epoch': 5.56}                                                                                                       
{'loss': 0.5254, 'learning_rate': 0.00013549481621112156, 'epoch': 5.56}                                                                                                      
{'loss': 0.261, 'learning_rate': 0.00013540056550424126, 'epoch': 5.56}                                                                                                       
{'loss': 0.2215, 'learning_rate': 0.00013530631479736097, 'epoch': 5.56}                                                                                                      
{'loss': 0.2093, 'learning_rate': 0.00013521206409048068, 'epoch': 5.57}                                                                                                      
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                       | 18000/32330 [28:50:26<1:30:01,  2.65it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6858245497551664, 'eval_cer': 0.40684717208182913, 'eval_runtime': 532.981, 'eval_samples_per_second': 17.971, 'eval_steps_per_second': 2.248, 'epoch': 5.57}                                                                                                                                                              
{'loss': 0.2491, 'learning_rate': 0.00013511781338360036, 'epoch': 5.57}                                                                                                      
{'loss': 0.3195, 'learning_rate': 0.00013502356267672006, 'epoch': 5.57}                                                                                                      
{'loss': 0.5026, 'learning_rate': 0.00013492931196983974, 'epoch': 5.58}                                                                                                      
{'loss': 0.1906, 'learning_rate': 0.00013483506126295947, 'epoch': 5.58}                                                                                                      
{'loss': 0.2558, 'learning_rate': 0.00013474081055607915, 'epoch': 5.58}                                                                                                      
{'loss': 0.2234, 'learning_rate': 0.00013464655984919886, 'epoch': 5.59}                                                                                                      
{'loss': 0.3573, 'learning_rate': 0.00013455230914231854, 'epoch': 5.59}                                                                                                      
{'loss': 0.2326, 'learning_rate': 0.00013445805843543827, 'epoch': 5.59}                                                                                                      
{'loss': 0.2159, 'learning_rate': 0.00013436380772855795, 'epoch': 5.6}                                                                                                       
{'loss': 0.1882, 'learning_rate': 0.00013426955702167766, 'epoch': 5.6}                                                                                                       
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                       | 18100/32330 [29:00:05<1:31:22,  2.60it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6619428998257116, 'eval_cer': 0.40495066185318895, 'eval_runtime': 536.181, 'eval_samples_per_second': 17.863, 'eval_steps_per_second': 2.234, 'epoch': 5.6}                                                                                                                                                               
{'loss': 0.2577, 'learning_rate': 0.00013417530631479733, 'epoch': 5.6}                                                                                                       
{'loss': 0.3409, 'learning_rate': 0.00013408105560791707, 'epoch': 5.6}                                                                                                       
{'loss': 0.1767, 'learning_rate': 0.00013398680490103675, 'epoch': 5.61}                                                                                                      
{'loss': 0.1644, 'learning_rate': 0.00013389255419415645, 'epoch': 5.61}                                                                                                      
{'loss': 0.1777, 'learning_rate': 0.00013379830348727613, 'epoch': 5.61}                                                                                                      
{'loss': 0.1946, 'learning_rate': 0.00013370405278039584, 'epoch': 5.62}                                                                                                      
{'loss': 0.2897, 'learning_rate': 0.00013360980207351554, 'epoch': 5.62}                                                                                                      
{'loss': 0.2096, 'learning_rate': 0.00013351555136663525, 'epoch': 5.62}                                                                                                      
{'loss': 0.2308, 'learning_rate': 0.00013342130065975493, 'epoch': 5.63}                                                                                                      
{'loss': 0.1664, 'learning_rate': 0.00013332704995287463, 'epoch': 5.63}                                                                                                      
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                       | 18200/32330 [29:09:48<1:28:29,  2.66it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6799111959498714, 'eval_cer': 0.40805294825511434, 'eval_runtime': 536.6666, 'eval_samples_per_second': 17.847, 'eval_steps_per_second': 2.232, 'epoch': 5.63}                                                                                                                                                             
{'loss': 0.2521, 'learning_rate': 0.00013323279924599434, 'epoch': 5.63}                                                                                                      
{'loss': 0.5258, 'learning_rate': 0.00013313854853911402, 'epoch': 5.64}                                                                                                      
{'loss': 0.2404, 'learning_rate': 0.00013304429783223372, 'epoch': 5.64}                                                                                                      
{'loss': 0.176, 'learning_rate': 0.00013295004712535343, 'epoch': 5.64}                                                                                                       
{'loss': 0.1934, 'learning_rate': 0.00013285579641847314, 'epoch': 5.64}                                                                                                      
{'loss': 0.2066, 'learning_rate': 0.00013276154571159282, 'epoch': 5.65}                                                                                                      
{'loss': 0.2915, 'learning_rate': 0.00013266729500471252, 'epoch': 5.65}                                                                                                      
{'loss': 0.2199, 'learning_rate': 0.00013257304429783223, 'epoch': 5.65}                                                                                                      
{'loss': 0.1487, 'learning_rate': 0.00013247879359095193, 'epoch': 5.66}                                                                                                      
{'loss': 0.1584, 'learning_rate': 0.0001323845428840716, 'epoch': 5.66}                                                                                                       
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                      | 18300/32330 [29:19:31<1:30:11,  2.59it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.669225661880654, 'eval_cer': 0.40567990373044527, 'eval_runtime': 538.9671, 'eval_samples_per_second': 17.771, 'eval_steps_per_second': 2.223, 'epoch': 5.66}                                                                                                                                                              
{'loss': 0.2358, 'learning_rate': 0.00013229029217719132, 'epoch': 5.66}                                                                                                      
{'loss': 0.3817, 'learning_rate': 0.000132196041470311, 'epoch': 5.67}                                                                                                        
{'loss': 0.2072, 'learning_rate': 0.00013210179076343073, 'epoch': 5.67}                                                                                                      
{'loss': 0.1977, 'learning_rate': 0.0001320075400565504, 'epoch': 5.67}                                                                                                       
{'loss': 0.214, 'learning_rate': 0.00013191328934967011, 'epoch': 5.68}                                                                                                       
{'loss': 0.1741, 'learning_rate': 0.0001318190386427898, 'epoch': 5.68}                                                                                                       
{'loss': 0.3241, 'learning_rate': 0.00013172478793590953, 'epoch': 5.68}                                                                                                      
{'loss': 0.2392, 'learning_rate': 0.0001316305372290292, 'epoch': 5.69}                                                                                                       
{'loss': 0.1499, 'learning_rate': 0.0001315362865221489, 'epoch': 5.69}                                                                                                       
{'loss': 0.2068, 'learning_rate': 0.0001314420358152686, 'epoch': 5.69}                                                                                                       
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                      | 18400/32330 [29:29:15<1:27:34,  2.65it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6711967798157523, 'eval_cer': 0.4064259927797834, 'eval_runtime': 538.0406, 'eval_samples_per_second': 17.802, 'eval_steps_per_second': 2.227, 'epoch': 5.69}                                                                                                                                                              
{'loss': 0.2583, 'learning_rate': 0.0001313477851083883, 'epoch': 5.69}                                                                                                       
{'loss': 0.3265, 'learning_rate': 0.000131253534401508, 'epoch': 5.7}                                                                                                         
{'loss': 0.2296, 'learning_rate': 0.0001311592836946277, 'epoch': 5.7}                                                                                                        
{'loss': 0.2832, 'learning_rate': 0.0001310650329877474, 'epoch': 5.7}                                                                                                        
{'loss': 0.2403, 'learning_rate': 0.0001309707822808671, 'epoch': 5.71}                                                                                                       
{'loss': 0.2798, 'learning_rate': 0.0001308765315739868, 'epoch': 5.71}                                                                                                       
{'loss': 0.2872, 'learning_rate': 0.0001307822808671065, 'epoch': 5.71}                                                                                                       
{'loss': 0.2298, 'learning_rate': 0.00013069745523091423, 'epoch': 5.72}                                                                                                      
{'loss': 0.1456, 'learning_rate': 0.00013060320452403394, 'epoch': 5.72}                                                                                                      
{'loss': 0.1912, 'learning_rate': 0.00013050895381715361, 'epoch': 5.72}                                                                                                      
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                      | 18500/32330 [29:38:58<1:27:39,  2.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6686239521952029, 'eval_cer': 0.4035018050541516, 'eval_runtime': 539.2968, 'eval_samples_per_second': 17.76, 'eval_steps_per_second': 2.221, 'epoch': 5.72}                                                                                                                                                               
{'loss': 0.243, 'learning_rate': 0.00013041470311027332, 'epoch': 5.73}                                                                                                       
{'loss': 0.3497, 'learning_rate': 0.00013032045240339303, 'epoch': 5.73}                                                                                                      
{'loss': 0.18, 'learning_rate': 0.0001302262016965127, 'epoch': 5.73}                                                                                                         
{'loss': 0.1556, 'learning_rate': 0.0001301319509896324, 'epoch': 5.73}                                                                                                       
{'loss': 0.2331, 'learning_rate': 0.00013003770028275212, 'epoch': 5.74}                                                                                                      
{'loss': 0.2022, 'learning_rate': 0.0001299434495758718, 'epoch': 5.74}                                                                                                       
{'loss': 0.4284, 'learning_rate': 0.0001298491988689915, 'epoch': 5.74}                                                                                                       
{'loss': 0.1928, 'learning_rate': 0.0001297549481621112, 'epoch': 5.75}                                                                                                       
{'loss': 0.183, 'learning_rate': 0.0001296606974552309, 'epoch': 5.75}                                                                                                        
{'loss': 0.2656, 'learning_rate': 0.0001295664467483506, 'epoch': 5.75}                                                                                                       
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                     | 18600/32330 [29:48:42<1:24:50,  2.70it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6684787119263009, 'eval_cer': 0.40608664259927796, 'eval_runtime': 535.9802, 'eval_samples_per_second': 17.87, 'eval_steps_per_second': 2.235, 'epoch': 5.75}                                                                                                                                                              
{'loss': 0.2784, 'learning_rate': 0.0001294721960414703, 'epoch': 5.76}                                                                                                       
{'loss': 0.3471, 'learning_rate': 0.00012937794533459, 'epoch': 5.76}                                                                                                         
{'loss': 0.1966, 'learning_rate': 0.00012928369462770968, 'epoch': 5.76}                                                                                                      
{'loss': 0.1847, 'learning_rate': 0.0001291894439208294, 'epoch': 5.77}                                                                                                       
{'loss': 0.1831, 'learning_rate': 0.0001290951932139491, 'epoch': 5.77}                                                                                                       
{'loss': 0.2349, 'learning_rate': 0.0001290009425070688, 'epoch': 5.77}                                                                                                       
{'loss': 0.33, 'learning_rate': 0.00012890669180018848, 'epoch': 5.77}                                                                                                        
{'loss': 0.2863, 'learning_rate': 0.00012881244109330819, 'epoch': 5.78}                                                                                                      
{'loss': 0.199, 'learning_rate': 0.0001287181903864279, 'epoch': 5.78}                                                                                                        
{'loss': 0.1829, 'learning_rate': 0.0001286239396795476, 'epoch': 5.78}                                                                                                       
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                     | 18700/32330 [29:58:24<1:28:23,  2.57it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6696406340775168, 'eval_cer': 0.4049771359807461, 'eval_runtime': 540.536, 'eval_samples_per_second': 17.719, 'eval_steps_per_second': 2.216, 'epoch': 5.78}                                                                                                                                                               
{'loss': 0.2189, 'learning_rate': 0.00012852968897266728, 'epoch': 5.79}                                                                                                      
{'loss': 0.3956, 'learning_rate': 0.00012843543826578698, 'epoch': 5.79}                                                                                                      
{'loss': 0.2027, 'learning_rate': 0.0001283411875589067, 'epoch': 5.79}                                                                                                       
{'loss': 0.1683, 'learning_rate': 0.0001282469368520264, 'epoch': 5.8}                                                                                                        
{'loss': 0.2489, 'learning_rate': 0.00012815268614514607, 'epoch': 5.8}                                                                                                       
{'loss': 0.1636, 'learning_rate': 0.00012805843543826578, 'epoch': 5.8}                                                                                                       
{'loss': 0.3348, 'learning_rate': 0.00012796418473138546, 'epoch': 5.81}                                                                                                      
{'loss': 0.2145, 'learning_rate': 0.00012786993402450516, 'epoch': 5.81}                                                                                                      
{'loss': 0.1529, 'learning_rate': 0.00012777568331762487, 'epoch': 5.81}                                                                                                      
{'loss': 0.2151, 'learning_rate': 0.00012768143261074458, 'epoch': 5.81}                                                                                                      
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                    | 18800/32330 [30:08:10<1:26:39,  2.60it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6566520043157108, 'eval_cer': 0.4037521058965102, 'eval_runtime': 538.7677, 'eval_samples_per_second': 17.778, 'eval_steps_per_second': 2.224, 'epoch': 5.81}                                                                                                                                                              
{'loss': 0.2754, 'learning_rate': 0.00012758718190386426, 'epoch': 5.82}                                                                                                      
{'loss': 1.2444, 'learning_rate': 0.00012749293119698396, 'epoch': 5.82}                                                                                                      
{'loss': 0.2364, 'learning_rate': 0.00012739868049010367, 'epoch': 5.82}                                                                                                      
{'loss': 0.1743, 'learning_rate': 0.00012730442978322337, 'epoch': 5.83}                                                                                                      
{'loss': 0.1842, 'learning_rate': 0.00012721017907634305, 'epoch': 5.83}                                                                                                      
{'loss': 0.2551, 'learning_rate': 0.00012711592836946276, 'epoch': 5.83}                                                                                                      
{'loss': 0.2903, 'learning_rate': 0.00012702167766258246, 'epoch': 5.84}                                                                                                      
{'loss': 0.1538, 'learning_rate': 0.00012692742695570214, 'epoch': 5.84}                                                                                                      
{'loss': 0.2072, 'learning_rate': 0.00012683317624882185, 'epoch': 5.84}                                                                                                      
{'loss': 0.2072, 'learning_rate': 0.00012673892554194155, 'epoch': 5.85}                                                                                                      
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                    | 18900/32330 [30:17:53<1:25:02,  2.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6669433147979086, 'eval_cer': 0.40586281588447654, 'eval_runtime': 536.721, 'eval_samples_per_second': 17.845, 'eval_steps_per_second': 2.232, 'epoch': 5.85}                                                                                                                                                              
{'loss': 0.2755, 'learning_rate': 0.00012664467483506126, 'epoch': 5.85}                                                                                                      
{'loss': 0.4034, 'learning_rate': 0.00012655042412818094, 'epoch': 5.85}                                                                                                      
{'loss': 0.1889, 'learning_rate': 0.00012645617342130065, 'epoch': 5.86}                                                                                                      
{'loss': 0.1907, 'learning_rate': 0.00012636192271442035, 'epoch': 5.86}                                                                                                      
{'loss': 0.1812, 'learning_rate': 0.00012626767200754006, 'epoch': 5.86}                                                                                                      
{'loss': 0.31, 'learning_rate': 0.00012617342130065974, 'epoch': 5.86}                                                                                                        
{'loss': 0.3523, 'learning_rate': 0.00012607917059377944, 'epoch': 5.87}                                                                                                      
{'loss': 0.1874, 'learning_rate': 0.00012598491988689912, 'epoch': 5.87}                                                                                                      
{'loss': 0.1469, 'learning_rate': 0.00012589066918001885, 'epoch': 5.87}                                                                                                      
{'loss': 0.1793, 'learning_rate': 0.00012579641847313853, 'epoch': 5.88}                                                                                                      
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                    | 19000/32330 [30:27:36<1:22:40,  2.69it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6683127230475558, 'eval_cer': 0.4046401925391095, 'eval_runtime': 539.7089, 'eval_samples_per_second': 17.747, 'eval_steps_per_second': 2.22, 'epoch': 5.88}                                                                                                                                                               
{'loss': 0.1878, 'learning_rate': 0.00012570216776625824, 'epoch': 5.88}                                                                                                      
{'loss': 0.3484, 'learning_rate': 0.00012560791705937792, 'epoch': 5.88}                                                                                                      
{'loss': 0.2075, 'learning_rate': 0.00012551366635249765, 'epoch': 5.89}                                                                                                      
{'loss': 0.1641, 'learning_rate': 0.00012541941564561733, 'epoch': 5.89}                                                                                                      
{'loss': 0.2033, 'learning_rate': 0.00012532516493873704, 'epoch': 5.89}                                                                                                      
{'loss': 0.1799, 'learning_rate': 0.00012523091423185671, 'epoch': 5.9}                                                                                                       
{'loss': 0.3584, 'learning_rate': 0.00012513666352497642, 'epoch': 5.9}                                                                                                       
{'loss': 0.2713, 'learning_rate': 0.00012504241281809613, 'epoch': 5.9}                                                                                                       
{'loss': 0.1353, 'learning_rate': 0.00012494816211121583, 'epoch': 5.9}                                                                                                       
{'loss': 0.2545, 'learning_rate': 0.0001248539114043355, 'epoch': 5.91}                                                                                                       
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 19100/32330 [30:37:21<1:23:03,  2.65it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6561955348991617, 'eval_cer': 0.40176654632972325, 'eval_runtime': 534.3545, 'eval_samples_per_second': 17.924, 'eval_steps_per_second': 2.242, 'epoch': 5.91}                                                                                                                                                             
{'loss': 0.3583, 'learning_rate': 0.00012475966069745522, 'epoch': 5.91}                                                                                                      
{'loss': 0.2527, 'learning_rate': 0.00012466540999057492, 'epoch': 5.91}                                                                                                      
{'loss': 0.2351, 'learning_rate': 0.0001245711592836946, 'epoch': 5.92}                                                                                                       
{'loss': 0.1878, 'learning_rate': 0.0001244769085768143, 'epoch': 5.92}                                                                                                       
{'loss': 0.1674, 'learning_rate': 0.00012438265786993401, 'epoch': 5.92}                                                                                                      
{'loss': 0.1941, 'learning_rate': 0.00012428840716305372, 'epoch': 5.93}                                                                                                      
{'loss': 0.2756, 'learning_rate': 0.0001241941564561734, 'epoch': 5.93}                                                                                                       
{'loss': 0.2102, 'learning_rate': 0.0001240999057492931, 'epoch': 5.93}                                                                                                       
{'loss': 0.1519, 'learning_rate': 0.0001240056550424128, 'epoch': 5.94}                                                                                                       
{'loss': 0.1879, 'learning_rate': 0.00012391140433553252, 'epoch': 5.94}                                                                                                      
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 19200/32330 [30:47:02<1:24:13,  2.60it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.673354635239439, 'eval_cer': 0.40433694344163656, 'eval_runtime': 534.4847, 'eval_samples_per_second': 17.92, 'eval_steps_per_second': 2.241, 'epoch': 5.94}                                                                                                                                                               
{'loss': 0.216, 'learning_rate': 0.0001238171536286522, 'epoch': 5.94}                                                                                                        
{'loss': 0.4547, 'learning_rate': 0.0001237229029217719, 'epoch': 5.94}                                                                                                       
{'loss': 0.2279, 'learning_rate': 0.00012362865221489158, 'epoch': 5.95}                                                                                                      
{'loss': 0.1926, 'learning_rate': 0.00012353440150801131, 'epoch': 5.95}                                                                                                      
{'loss': 0.2671, 'learning_rate': 0.000123440150801131, 'epoch': 5.95}                                                                                                        
{'loss': 0.2574, 'learning_rate': 0.0001233459000942507, 'epoch': 5.96}                                                                                                       
{'loss': 0.3628, 'learning_rate': 0.00012325164938737038, 'epoch': 5.96}                                                                                                      
{'loss': 0.2218, 'learning_rate': 0.0001231573986804901, 'epoch': 5.96}                                                                                                       
{'loss': 0.1476, 'learning_rate': 0.0001230631479736098, 'epoch': 5.97}                                                                                                       
{'loss': 0.2706, 'learning_rate': 0.0001229688972667295, 'epoch': 5.97}                                                                                                       
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                  | 19300/32330 [30:56:42<1:21:37,  2.66it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6621296373143, 'eval_cer': 0.40459446450060166, 'eval_runtime': 536.7417, 'eval_samples_per_second': 17.845, 'eval_steps_per_second': 2.232, 'epoch': 5.97}                                                                                                                                                                
{'loss': 0.2624, 'learning_rate': 0.00012287464655984917, 'epoch': 5.97}                                                                                                      
{'loss': 0.3269, 'learning_rate': 0.00012278039585296888, 'epoch': 5.98}                                                                                                      
{'loss': 0.2306, 'learning_rate': 0.00012268614514608859, 'epoch': 5.98}                                                                                                      
{'loss': 0.1552, 'learning_rate': 0.0001225918944392083, 'epoch': 5.98}                                                                                                       
{'loss': 0.2044, 'learning_rate': 0.00012249764373232797, 'epoch': 5.99}                                                                                                      
{'loss': 0.3221, 'learning_rate': 0.00012240339302544768, 'epoch': 5.99}                                                                                                      
{'loss': 0.3453, 'learning_rate': 0.00012230914231856738, 'epoch': 5.99}                                                                                                      
{'loss': 0.1761, 'learning_rate': 0.0001222148916116871, 'epoch': 5.99}                                                                                                       
{'loss': 0.2273, 'learning_rate': 0.00012212064090480677, 'epoch': 6.0}                                                                                                       
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                  | 19392/32330 [31:06:20<1:18:30,  2.75it/s]Saving model checkpoint to turkish_clean/checkpoint-19392
Configuration saved in turkish_clean/checkpoint-19392/config.json
Model weights saved in turkish_clean/checkpoint-19392/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-19392/preprocessor_config.json
Deleting older checkpoint [turkish_clean/checkpoint-9696] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3126, 'learning_rate': 0.00012202639019792646, 'epoch': 6.0}                                                                                                       
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                  | 19400/32330 [31:06:26<2:33:27,  1.40it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6527305170553573, 'eval_cer': 0.4026835138387485, 'eval_runtime': 538.4606, 'eval_samples_per_second': 17.788, 'eval_steps_per_second': 2.225, 'epoch': 6.0}                                                                                                                                                               
{'loss': 0.216, 'learning_rate': 0.00012193213949104618, 'epoch': 6.0}                                                                                                        
{'loss': 0.1181, 'learning_rate': 0.00012183788878416587, 'epoch': 6.01}                                                                                                      
{'loss': 0.1359, 'learning_rate': 0.00012174363807728556, 'epoch': 6.01}                                                                                                      
{'loss': 0.186, 'learning_rate': 0.00012164938737040526, 'epoch': 6.01}                                                                                                       
{'loss': 0.3725, 'learning_rate': 0.00012155513666352498, 'epoch': 6.02}                                                                                                      
{'loss': 0.1883, 'learning_rate': 0.00012146088595664467, 'epoch': 6.02}                                                                                                      
{'loss': 0.1617, 'learning_rate': 0.00012136663524976436, 'epoch': 6.02}                                                                                                      
{'loss': 0.2207, 'learning_rate': 0.00012127238454288405, 'epoch': 6.03}                                                                                                      
{'loss': 0.1864, 'learning_rate': 0.00012117813383600376, 'epoch': 6.03}                                                                                                      
{'loss': 0.3153, 'learning_rate': 0.00012108388312912347, 'epoch': 6.03}                                                                                                      
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                  | 19500/32330 [31:16:11<2:10:29,  1.64it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6633538052950453, 'eval_cer': 0.40367990373044527, 'eval_runtime': 533.8557, 'eval_samples_per_second': 17.941, 'eval_steps_per_second': 2.244, 'epoch': 6.03}                                                                                                                                                             
{'loss': 0.1764, 'learning_rate': 0.00012098963242224316, 'epoch': 6.03}                                                                                                      
{'loss': 0.211, 'learning_rate': 0.00012089538171536285, 'epoch': 6.04}                                                                                                       
{'loss': 0.1752, 'learning_rate': 0.00012080113100848256, 'epoch': 6.04}                                                                                                      
{'loss': 0.2589, 'learning_rate': 0.00012070688030160225, 'epoch': 6.04}                                                                                                      
{'loss': 0.3784, 'learning_rate': 0.00012061262959472195, 'epoch': 6.05}                                                                                                      
{'loss': 0.266, 'learning_rate': 0.00012051837888784165, 'epoch': 6.05}                                                                                                       
{'loss': 0.1629, 'learning_rate': 0.00012042412818096135, 'epoch': 6.05}                                                                                                      
{'loss': 0.1776, 'learning_rate': 0.00012032987747408105, 'epoch': 6.06}                                                                                                      
{'loss': 0.1782, 'learning_rate': 0.00012023562676720074, 'epoch': 6.06}                                                                                                      
{'loss': 0.2959, 'learning_rate': 0.00012014137606032044, 'epoch': 6.06}                                                                                                      
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                 | 19600/32330 [31:25:51<2:11:33,  1.61it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.649286247821396, 'eval_cer': 0.40140794223826715, 'eval_runtime': 538.9459, 'eval_samples_per_second': 17.772, 'eval_steps_per_second': 2.223, 'epoch': 6.06}                                                                                                                                                              
{'loss': 0.1672, 'learning_rate': 0.00012004712535344014, 'epoch': 6.07}                                                                                                      
{'loss': 0.1798, 'learning_rate': 0.00011995287464655984, 'epoch': 6.07}                                                                                                      
{'loss': 0.1583, 'learning_rate': 0.00011985862393967953, 'epoch': 6.07}                                                                                                      
{'loss': 0.1846, 'learning_rate': 0.00011976437323279923, 'epoch': 6.07}                                                                                                      
{'loss': 0.342, 'learning_rate': 0.00011967012252591893, 'epoch': 6.08}                                                                                                       
{'loss': 0.2281, 'learning_rate': 0.00011957587181903864, 'epoch': 6.08}                                                                                                      
{'loss': 0.2004, 'learning_rate': 0.00011948162111215833, 'epoch': 6.08}                                                                                                      
{'loss': 0.171, 'learning_rate': 0.00011938737040527802, 'epoch': 6.09}                                                                                                       
{'loss': 0.2094, 'learning_rate': 0.00011929311969839772, 'epoch': 6.09}                                                                                                      
{'loss': 0.2381, 'learning_rate': 0.00011919886899151744, 'epoch': 6.09}                                                                                                      
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                 | 19700/32330 [31:35:35<2:02:03,  1.72it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.663457548344261, 'eval_cer': 0.4034271961492178, 'eval_runtime': 537.5089, 'eval_samples_per_second': 17.819, 'eval_steps_per_second': 2.229, 'epoch': 6.09}                                                                                                                                                               
{'loss': 0.1738, 'learning_rate': 0.00011910461828463713, 'epoch': 6.1}                                                                                                       
{'loss': 0.1744, 'learning_rate': 0.00011901036757775682, 'epoch': 6.1}                                                                                                       
{'loss': 0.2028, 'learning_rate': 0.00011891611687087651, 'epoch': 6.1}                                                                                                       
{'loss': 0.1869, 'learning_rate': 0.00011882186616399623, 'epoch': 6.11}                                                                                                      
{'loss': 0.3739, 'learning_rate': 0.00011872761545711593, 'epoch': 6.11}                                                                                                      
{'loss': 0.1941, 'learning_rate': 0.00011863336475023562, 'epoch': 6.11}                                                                                                      
{'loss': 0.1379, 'learning_rate': 0.00011853911404335531, 'epoch': 6.12}                                                                                                      
{'loss': 0.1717, 'learning_rate': 0.00011844486333647502, 'epoch': 6.12}                                                                                                      
{'loss': 0.2042, 'learning_rate': 0.00011835061262959472, 'epoch': 6.12}                                                                                                      
{'loss': 0.3517, 'learning_rate': 0.00011825636192271441, 'epoch': 6.12}                                                                                                      
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                | 19800/32330 [31:45:17<2:05:07,  1.67it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.665988878745124, 'eval_cer': 0.4037617328519856, 'eval_runtime': 539.7465, 'eval_samples_per_second': 17.745, 'eval_steps_per_second': 2.22, 'epoch': 6.12}                                                                                                                                                                
{'loss': 0.1541, 'learning_rate': 0.00011816211121583411, 'epoch': 6.13}                                                                                                      
{'loss': 0.1667, 'learning_rate': 0.0001180678605089538, 'epoch': 6.13}                                                                                                       
{'loss': 0.1613, 'learning_rate': 0.0001179736098020735, 'epoch': 6.13}                                                                                                       
{'loss': 0.21, 'learning_rate': 0.0001178793590951932, 'epoch': 6.14}                                                                                                         
{'loss': 0.3286, 'learning_rate': 0.0001177851083883129, 'epoch': 6.14}                                                                                                       
{'loss': 0.2276, 'learning_rate': 0.0001176908576814326, 'epoch': 6.14}                                                                                                       
{'loss': 0.1822, 'learning_rate': 0.0001175966069745523, 'epoch': 6.15}                                                                                                       
{'loss': 0.1656, 'learning_rate': 0.000117502356267672, 'epoch': 6.15}                                                                                                        
{'loss': 0.1496, 'learning_rate': 0.00011740810556079169, 'epoch': 6.15}                                                                                                      
{'loss': 0.2766, 'learning_rate': 0.00011731385485391139, 'epoch': 6.16}                                                                                                      
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                | 19900/32330 [31:55:01<2:13:08,  1.56it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.660511245746535, 'eval_cer': 0.40470276774969915, 'eval_runtime': 538.1909, 'eval_samples_per_second': 17.797, 'eval_steps_per_second': 2.226, 'epoch': 6.16}                                                                                                                                                              
{'loss': 0.1885, 'learning_rate': 0.0001172196041470311, 'epoch': 6.16}                                                                                                       
{'loss': 0.1726, 'learning_rate': 0.00011712535344015079, 'epoch': 6.16}                                                                                                      
{'loss': 0.1637, 'learning_rate': 0.00011703110273327048, 'epoch': 6.16}                                                                                                      
{'loss': 0.1669, 'learning_rate': 0.00011693685202639018, 'epoch': 6.17}                                                                                                      
{'loss': 0.2292, 'learning_rate': 0.0001168426013195099, 'epoch': 6.17}                                                                                                       
{'loss': 0.1766, 'learning_rate': 0.00011674835061262959, 'epoch': 6.17}                                                                                                      
{'loss': 0.306, 'learning_rate': 0.00011665409990574928, 'epoch': 6.18}                                                                                                       
{'loss': 0.205, 'learning_rate': 0.00011655984919886897, 'epoch': 6.18}                                                                                                       
{'loss': 0.1941, 'learning_rate': 0.00011646559849198869, 'epoch': 6.18}                                                                                                      
{'loss': 0.3827, 'learning_rate': 0.00011637134778510838, 'epoch': 6.19}                                                                                                      
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                | 20000/32330 [32:04:47<2:07:41,  1.61it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6557390654826126, 'eval_cer': 0.40538628158844764, 'eval_runtime': 539.8277, 'eval_samples_per_second': 17.743, 'eval_steps_per_second': 2.219, 'epoch': 6.19}                                                                                                                                                             
{'loss': 0.1917, 'learning_rate': 0.00011627709707822808, 'epoch': 6.19}                                                                                                      
{'loss': 0.179, 'learning_rate': 0.00011618284637134777, 'epoch': 6.19}                                                                                                       
{'loss': 0.1845, 'learning_rate': 0.00011608859566446746, 'epoch': 6.2}                                                                                                       
{'loss': 0.2134, 'learning_rate': 0.00011599434495758718, 'epoch': 6.2}                                                                                                       
{'loss': 0.2726, 'learning_rate': 0.00011590009425070687, 'epoch': 6.2}                                                                                                       
{'loss': 0.2602, 'learning_rate': 0.00011580584354382657, 'epoch': 6.2}                                                                                                       
{'loss': 0.1478, 'learning_rate': 0.00011571159283694626, 'epoch': 6.21}                                                                                                      
{'loss': 0.1452, 'learning_rate': 0.00011561734213006596, 'epoch': 6.21}                                                                                                      
{'loss': 0.1795, 'learning_rate': 0.00011552309142318567, 'epoch': 6.21}                                                                                                      
{'loss': 0.4082, 'learning_rate': 0.00011542884071630536, 'epoch': 6.22}                                                                                                      
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                               | 20100/32330 [32:14:33<2:11:12,  1.55it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6599925305004565, 'eval_cer': 0.40438748495788207, 'eval_runtime': 540.3926, 'eval_samples_per_second': 17.724, 'eval_steps_per_second': 2.217, 'epoch': 6.22}                                                                                                                                                             
{'loss': 0.2129, 'learning_rate': 0.00011533459000942506, 'epoch': 6.22}                                                                                                      
{'loss': 0.2023, 'learning_rate': 0.00011524033930254476, 'epoch': 6.22}                                                                                                      
{'loss': 0.1857, 'learning_rate': 0.00011514608859566445, 'epoch': 6.23}                                                                                                      
{'loss': 0.1487, 'learning_rate': 0.00011505183788878416, 'epoch': 6.23}                                                                                                      
{'loss': 0.3202, 'learning_rate': 0.00011495758718190385, 'epoch': 6.23}                                                                                                      
{'loss': 0.1812, 'learning_rate': 0.00011486333647502356, 'epoch': 6.24}                                                                                                      
{'loss': 0.123, 'learning_rate': 0.00011476908576814325, 'epoch': 6.24}                                                                                                       
{'loss': 0.1597, 'learning_rate': 0.00011467483506126294, 'epoch': 6.24}                                                                                                      
{'loss': 0.2759, 'learning_rate': 0.00011458058435438265, 'epoch': 6.24}                                                                                                      
{'loss': 0.2793, 'learning_rate': 0.00011448633364750235, 'epoch': 6.25}                                                                                                      
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                               | 20200/32330 [32:24:18<1:53:03,  1.79it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6537886961573575, 'eval_cer': 0.4012202166064982, 'eval_runtime': 532.8855, 'eval_samples_per_second': 17.974, 'eval_steps_per_second': 2.248, 'epoch': 6.25}                                                                                                                                                              
{'loss': 0.2004, 'learning_rate': 0.00011439208294062205, 'epoch': 6.25}                                                                                                      
{'loss': 0.0732, 'learning_rate': 0.00011429783223374174, 'epoch': 6.25}                                                                                                      
{'loss': 0.2291, 'learning_rate': 0.00011420358152686143, 'epoch': 6.26}                                                                                                      
{'loss': 0.1988, 'learning_rate': 0.00011410933081998114, 'epoch': 6.26}                                                                                                      
{'loss': 0.3095, 'learning_rate': 0.00011401508011310084, 'epoch': 6.26}                                                                                                      
{'loss': 0.1913, 'learning_rate': 0.00011392082940622054, 'epoch': 6.27}                                                                                                      
{'loss': 0.1695, 'learning_rate': 0.00011382657869934023, 'epoch': 6.27}                                                                                                      
{'loss': 0.1388, 'learning_rate': 0.00011373232799245992, 'epoch': 6.27}                                                                                                      
{'loss': 0.182, 'learning_rate': 0.00011363807728557964, 'epoch': 6.28}                                                                                                       
{'loss': 0.3173, 'learning_rate': 0.00011354382657869933, 'epoch': 6.28}                                                                                                      
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                               | 20300/32330 [32:33:56<1:56:15,  1.72it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6543489086231222, 'eval_cer': 0.40245006016847173, 'eval_runtime': 532.6456, 'eval_samples_per_second': 17.982, 'eval_steps_per_second': 2.249, 'epoch': 6.28}                                                                                                                                                             
{'loss': 0.1804, 'learning_rate': 0.00011344957587181903, 'epoch': 6.28}                                                                                                      
{'loss': 0.1911, 'learning_rate': 0.00011335532516493872, 'epoch': 6.29}                                                                                                      
{'loss': 0.1729, 'learning_rate': 0.00011326107445805844, 'epoch': 6.29}                                                                                                      
{'loss': 0.2823, 'learning_rate': 0.00011316682375117813, 'epoch': 6.29}                                                                                                      
{'loss': 0.2882, 'learning_rate': 0.00011307257304429782, 'epoch': 6.29}                                                                                                      
{'loss': 0.1918, 'learning_rate': 0.00011297832233741751, 'epoch': 6.3}                                                                                                       
{'loss': 0.2069, 'learning_rate': 0.00011288407163053722, 'epoch': 6.3}                                                                                                       
{'loss': 0.2091, 'learning_rate': 0.00011278982092365693, 'epoch': 6.3}                                                                                                       
{'loss': 0.1698, 'learning_rate': 0.00011269557021677662, 'epoch': 6.31}                                                                                                      
{'loss': 0.3129, 'learning_rate': 0.00011260131950989631, 'epoch': 6.31}                                                                                                      
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                              | 20400/32330 [32:43:35<2:01:38,  1.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6602830110382605, 'eval_cer': 0.4034801444043321, 'eval_runtime': 532.8315, 'eval_samples_per_second': 17.976, 'eval_steps_per_second': 2.248, 'epoch': 6.31}                                                                                                                                                              
{'loss': 1.0937, 'learning_rate': 0.00011250706880301602, 'epoch': 6.31}                                                                                                      
{'loss': 0.1895, 'learning_rate': 0.00011241281809613571, 'epoch': 6.32}                                                                                                      
{'loss': 0.1541, 'learning_rate': 0.00011231856738925542, 'epoch': 6.32}                                                                                                      
{'loss': 0.1726, 'learning_rate': 0.00011222431668237511, 'epoch': 6.32}                                                                                                      
{'loss': 0.2934, 'learning_rate': 0.0001121300659754948, 'epoch': 6.33}                                                                                                       
{'loss': 0.1839, 'learning_rate': 0.00011203581526861451, 'epoch': 6.33}                                                                                                      
{'loss': 0.1794, 'learning_rate': 0.0001119415645617342, 'epoch': 6.33}                                                                                                       
{'loss': 0.1656, 'learning_rate': 0.00011184731385485389, 'epoch': 6.33}                                                                                                      
{'loss': 0.1795, 'learning_rate': 0.0001117530631479736, 'epoch': 6.34}                                                                                                       
{'loss': 0.3158, 'learning_rate': 0.0001116588124410933, 'epoch': 6.34}                                                                                                       
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                              | 20500/32330 [32:53:14<2:04:04,  1.59it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6506556560710433, 'eval_cer': 0.40166546329723224, 'eval_runtime': 532.0376, 'eval_samples_per_second': 18.002, 'eval_steps_per_second': 2.252, 'epoch': 6.34}                                                                                                                                                             
{'loss': 0.1768, 'learning_rate': 0.000111564561734213, 'epoch': 6.34}                                                                                                        
{'loss': 0.167, 'learning_rate': 0.00011147031102733269, 'epoch': 6.35}                                                                                                       
{'loss': 0.1621, 'learning_rate': 0.00011137606032045238, 'epoch': 6.35}                                                                                                      
{'loss': 0.19, 'learning_rate': 0.0001112818096135721, 'epoch': 6.35}                                                                                                         
{'loss': 0.6097, 'learning_rate': 0.00011118755890669179, 'epoch': 6.36}                                                                                                      
{'loss': 0.1906, 'learning_rate': 0.00011109330819981149, 'epoch': 6.36}                                                                                                      
{'loss': 0.1401, 'learning_rate': 0.00011099905749293118, 'epoch': 6.36}                                                                                                      
{'loss': 0.1492, 'learning_rate': 0.0001109048067860509, 'epoch': 6.37}                                                                                                       
{'loss': 0.1629, 'learning_rate': 0.00011081055607917059, 'epoch': 6.37}                                                                                                      
{'loss': 0.3375, 'learning_rate': 0.00011071630537229028, 'epoch': 6.37}                                                                                                      
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                             | 20600/32330 [33:02:52<1:57:14,  1.67it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6512573657564943, 'eval_cer': 0.4022864019253911, 'eval_runtime': 536.7846, 'eval_samples_per_second': 17.843, 'eval_steps_per_second': 2.232, 'epoch': 6.37}                                                                                                                                                              
{'loss': 0.1742, 'learning_rate': 0.00011062205466540997, 'epoch': 6.37}                                                                                                      
{'loss': 0.1927, 'learning_rate': 0.00011052780395852968, 'epoch': 6.38}                                                                                                      
{'loss': 0.1647, 'learning_rate': 0.00011043355325164939, 'epoch': 6.38}                                                                                                      
{'loss': 0.2262, 'learning_rate': 0.00011033930254476908, 'epoch': 6.38}                                                                                                      
{'loss': 0.3433, 'learning_rate': 0.00011024505183788877, 'epoch': 6.39}                                                                                                      
{'loss': 0.1633, 'learning_rate': 0.00011015080113100846, 'epoch': 6.39}                                                                                                      
{'loss': 0.1443, 'learning_rate': 0.00011005655042412817, 'epoch': 6.39}                                                                                                      
{'loss': 0.1679, 'learning_rate': 0.00010996229971724788, 'epoch': 6.4}                                                                                                       
{'loss': 0.1516, 'learning_rate': 0.00010986804901036757, 'epoch': 6.4}                                                                                                       
{'loss': 0.3128, 'learning_rate': 0.00010977379830348726, 'epoch': 6.4}                                                                                                       
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                             | 20700/32330 [33:12:34<1:59:58,  1.62it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6511951199269649, 'eval_cer': 0.40131167268351386, 'eval_runtime': 545.9465, 'eval_samples_per_second': 17.544, 'eval_steps_per_second': 2.194, 'epoch': 6.4}                                                                                                                                                              
{'loss': 0.2693, 'learning_rate': 0.000109688972667295, 'epoch': 6.41}                                                                                                        
{'loss': 0.161, 'learning_rate': 0.00010959472196041469, 'epoch': 6.41}                                                                                                       
{'loss': 0.155, 'learning_rate': 0.0001095004712535344, 'epoch': 6.41}                                                                                                        
{'loss': 0.1494, 'learning_rate': 0.00010940622054665409, 'epoch': 6.42}                                                                                                      
{'loss': 0.297, 'learning_rate': 0.0001093119698397738, 'epoch': 6.42}                                                                                                        
{'loss': 0.1645, 'learning_rate': 0.00010921771913289349, 'epoch': 6.42}                                                                                                      
{'loss': 0.1868, 'learning_rate': 0.00010912346842601318, 'epoch': 6.42}                                                                                                      
{'loss': 0.1379, 'learning_rate': 0.00010902921771913289, 'epoch': 6.43}                                                                                                      
{'loss': 0.2196, 'learning_rate': 0.00010893496701225258, 'epoch': 6.43}                                                                                                      
{'loss': 0.3362, 'learning_rate': 0.00010884071630537227, 'epoch': 6.43}                                                                                                      
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                             | 20800/32330 [33:22:25<2:01:25,  1.58it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6520873101502199, 'eval_cer': 0.40018772563176896, 'eval_runtime': 540.3928, 'eval_samples_per_second': 17.724, 'eval_steps_per_second': 2.217, 'epoch': 6.43}                                                                                                                                                             
{'loss': 0.1575, 'learning_rate': 0.00010874646559849198, 'epoch': 6.44}                                                                                                      
{'loss': 0.1486, 'learning_rate': 0.00010865221489161168, 'epoch': 6.44}                                                                                                      
{'loss': 0.1749, 'learning_rate': 0.00010855796418473138, 'epoch': 6.44}                                                                                                      
{'loss': 0.1621, 'learning_rate': 0.00010846371347785107, 'epoch': 6.45}                                                                                                      
{'loss': 0.3569, 'learning_rate': 0.00010836946277097076, 'epoch': 6.45}                                                                                                      
{'loss': 0.1677, 'learning_rate': 0.00010827521206409048, 'epoch': 6.45}                                                                                                      
{'loss': 0.1685, 'learning_rate': 0.00010818096135721017, 'epoch': 6.46}                                                                                                      
{'loss': 0.1597, 'learning_rate': 0.00010808671065032986, 'epoch': 6.46}                                                                                                      
{'loss': 0.2681, 'learning_rate': 0.00010799245994344956, 'epoch': 6.46}                                                                                                      
{'loss': 0.3834, 'learning_rate': 0.00010789820923656928, 'epoch': 6.46}                                                                                                      
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                            | 20900/32330 [33:32:11<1:58:10,  1.61it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6503444269233961, 'eval_cer': 0.4009626955475331, 'eval_runtime': 539.6087, 'eval_samples_per_second': 17.75, 'eval_steps_per_second': 2.22, 'epoch': 6.46}                                                                                                                                                                
{'loss': 0.1928, 'learning_rate': 0.00010780395852968897, 'epoch': 6.47}                                                                                                      
{'loss': 0.1902, 'learning_rate': 0.00010770970782280866, 'epoch': 6.47}                                                                                                      
{'loss': 0.207, 'learning_rate': 0.00010761545711592835, 'epoch': 6.47}                                                                                                       
{'loss': 0.2452, 'learning_rate': 0.00010752120640904807, 'epoch': 6.48}                                                                                                      
{'loss': 0.3428, 'learning_rate': 0.00010742695570216777, 'epoch': 6.48}                                                                                                      
{'loss': 0.2391, 'learning_rate': 0.00010733270499528746, 'epoch': 6.48}                                                                                                      
{'loss': 0.1543, 'learning_rate': 0.00010723845428840715, 'epoch': 6.49}                                                                                                      
{'loss': 0.1457, 'learning_rate': 0.00010714420358152684, 'epoch': 6.49}                                                                                                      
{'loss': 0.1949, 'learning_rate': 0.00010704995287464655, 'epoch': 6.49}                                                                                                      
{'loss': 0.277, 'learning_rate': 0.00010695570216776625, 'epoch': 6.5}                                                                                                        
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                            | 21000/32330 [33:41:56<1:55:58,  1.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6407793177857084, 'eval_cer': 0.3982671480144404, 'eval_runtime': 536.2033, 'eval_samples_per_second': 17.863, 'eval_steps_per_second': 2.234, 'epoch': 6.5}                                                                                                                                                               
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                           | 21008/32330 [33:50:58<43:34:52, 13.86s/it]Saving model checkpoint to turkish_clean/checkpoint-21008                                                                                                                     
Configuration saved in turkish_clean/checkpoint-21008/config.json
Model weights saved in turkish_clean/checkpoint-21008/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-21008/preprocessor_config.json
Deleting older checkpoint [turkish_clean/checkpoint-11312] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.219, 'learning_rate': 0.00010686145146088595, 'epoch': 6.5}                                                                                                        
{'loss': 0.13, 'learning_rate': 0.00010676720075400564, 'epoch': 6.5}                                                                                                         
{'loss': 0.192, 'learning_rate': 0.00010667295004712535, 'epoch': 6.5}                                                                                                        
{'loss': 0.2124, 'learning_rate': 0.00010657869934024504, 'epoch': 6.51}                                                                                                      
{'loss': 0.336, 'learning_rate': 0.00010648444863336474, 'epoch': 6.51}                                                                                                       
{'loss': 0.1795, 'learning_rate': 0.00010639019792648444, 'epoch': 6.51}                                                                                                      
{'loss': 0.1579, 'learning_rate': 0.00010629594721960414, 'epoch': 6.52}                                                                                                      
{'loss': 0.1687, 'learning_rate': 0.00010620169651272383, 'epoch': 6.52}                                                                                                      
{'loss': 0.2183, 'learning_rate': 0.00010610744580584353, 'epoch': 6.52}                                                                                                      
{'loss': 0.2851, 'learning_rate': 0.00010601319509896323, 'epoch': 6.53}                                                                                                      
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                           | 21100/32330 [33:51:41<2:01:59,  1.53it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6449497883641796, 'eval_cer': 0.4000890493381468, 'eval_runtime': 538.0124, 'eval_samples_per_second': 17.803, 'eval_steps_per_second': 2.227, 'epoch': 6.53}                                                                                                                                                              
{'loss': 0.184, 'learning_rate': 0.00010591894439208294, 'epoch': 6.53}                                                                                                       
{'loss': 0.0959, 'learning_rate': 0.00010582469368520263, 'epoch': 6.53}                                                                                                      
{'loss': 0.1497, 'learning_rate': 0.00010573044297832232, 'epoch': 6.54}                                                                                                      
{'loss': 0.2301, 'learning_rate': 0.00010563619227144202, 'epoch': 6.54}                                                                                                      
{'loss': 0.3169, 'learning_rate': 0.00010554194156456174, 'epoch': 6.54}                                                                                                      
{'loss': 0.1576, 'learning_rate': 0.00010544769085768143, 'epoch': 6.54}                                                                                                      
{'loss': 0.1492, 'learning_rate': 0.00010535344015080112, 'epoch': 6.55}                                                                                                      
{'loss': 0.1434, 'learning_rate': 0.00010525918944392081, 'epoch': 6.55}                                                                                                      
{'loss': 0.1447, 'learning_rate': 0.0001051649387370405, 'epoch': 6.55}                                                                                                       
{'loss': 0.2617, 'learning_rate': 0.00010507068803016022, 'epoch': 6.56}                                                                                                      
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                           | 21200/32330 [34:01:26<1:50:01,  1.69it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6444725703377874, 'eval_cer': 0.40015884476534297, 'eval_runtime': 537.2769, 'eval_samples_per_second': 17.827, 'eval_steps_per_second': 2.23, 'epoch': 6.56}                                                                                                                                                              
{'loss': 0.1423, 'learning_rate': 0.00010497643732327992, 'epoch': 6.56}                                                                                                      
{'loss': 0.1953, 'learning_rate': 0.00010488218661639961, 'epoch': 6.56}                                                                                                      
{'loss': 0.145, 'learning_rate': 0.0001047879359095193, 'epoch': 6.57}                                                                                                        
{'loss': 0.1624, 'learning_rate': 0.00010469368520263902, 'epoch': 6.57}                                                                                                      
{'loss': 0.3019, 'learning_rate': 0.00010459943449575871, 'epoch': 6.57}                                                                                                      
{'loss': 0.1771, 'learning_rate': 0.0001045051837888784, 'epoch': 6.58}                                                                                                       
{'loss': 0.1228, 'learning_rate': 0.0001044109330819981, 'epoch': 6.58}                                                                                                       
{'loss': 0.2042, 'learning_rate': 0.0001043166823751178, 'epoch': 6.58}                                                                                                       
{'loss': 0.2521, 'learning_rate': 0.00010422243166823751, 'epoch': 6.59}                                                                                                      
{'loss': 0.2467, 'learning_rate': 0.0001041281809613572, 'epoch': 6.59}                                                                                                       
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                           | 21300/32330 [34:11:08<1:53:30,  1.62it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.647377375715827, 'eval_cer': 0.4000673886883273, 'eval_runtime': 538.8534, 'eval_samples_per_second': 17.775, 'eval_steps_per_second': 2.223, 'epoch': 6.59}                                                                                                                                                               
{'loss': 0.1794, 'learning_rate': 0.0001040339302544769, 'epoch': 6.59}                                                                                                       
{'loss': 0.1751, 'learning_rate': 0.0001039396795475966, 'epoch': 6.59}                                                                                                       
{'loss': 0.2203, 'learning_rate': 0.0001038454288407163, 'epoch': 6.6}                                                                                                        
{'loss': 0.236, 'learning_rate': 0.000103751178133836, 'epoch': 6.6}                                                                                                          
{'loss': 0.2693, 'learning_rate': 0.00010365692742695569, 'epoch': 6.6}                                                                                                       
{'loss': 0.2105, 'learning_rate': 0.00010357210179076342, 'epoch': 6.61}                                                                                                      
{'loss': 0.1301, 'learning_rate': 0.00010347785108388312, 'epoch': 6.61}                                                                                                      
{'loss': 0.1649, 'learning_rate': 0.00010338360037700282, 'epoch': 6.61}                                                                                                      
{'loss': 0.2196, 'learning_rate': 0.00010328934967012252, 'epoch': 6.62}                                                                                                      
{'loss': 0.2515, 'learning_rate': 0.00010319509896324221, 'epoch': 6.62}                                                                                                      
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                          | 21400/32330 [34:20:53<1:52:22,  1.62it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6553655905054362, 'eval_cer': 0.40078700361010833, 'eval_runtime': 534.168, 'eval_samples_per_second': 17.931, 'eval_steps_per_second': 2.243, 'epoch': 6.62}                                                                                                                                                              
{'loss': 0.171, 'learning_rate': 0.0001031008482563619, 'epoch': 6.62}                                                                                                        
{'loss': 0.155, 'learning_rate': 0.00010300659754948161, 'epoch': 6.63}                                                                                                       
{'loss': 0.1701, 'learning_rate': 0.00010291234684260132, 'epoch': 6.63}                                                                                                      
{'loss': 0.248, 'learning_rate': 0.00010281809613572101, 'epoch': 6.63}                                                                                                       
{'loss': 0.3005, 'learning_rate': 0.0001027238454288407, 'epoch': 6.63}                                                                                                       
{'loss': 0.1724, 'learning_rate': 0.0001026295947219604, 'epoch': 6.64}                                                                                                       
{'loss': 0.1476, 'learning_rate': 0.00010253534401508011, 'epoch': 6.64}                                                                                                      
{'loss': 0.1301, 'learning_rate': 0.00010244109330819981, 'epoch': 6.64}                                                                                                      
{'loss': 0.1756, 'learning_rate': 0.0001023468426013195, 'epoch': 6.65}                                                                                                       
{'loss': 0.296, 'learning_rate': 0.00010225259189443919, 'epoch': 6.65}                                                                                                       
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                          | 21500/32330 [34:30:33<1:54:30,  1.58it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6491202589426508, 'eval_cer': 0.4006281588447653, 'eval_runtime': 539.412, 'eval_samples_per_second': 17.756, 'eval_steps_per_second': 2.221, 'epoch': 6.65}                                                                                                                                                               
{'loss': 0.1796, 'learning_rate': 0.00010215834118755888, 'epoch': 6.65}                                                                                                      
{'loss': 0.1836, 'learning_rate': 0.0001020640904806786, 'epoch': 6.66}                                                                                                       
{'loss': 0.1574, 'learning_rate': 0.0001019698397737983, 'epoch': 6.66}                                                                                                       
{'loss': 0.1935, 'learning_rate': 0.00010187558906691799, 'epoch': 6.66}                                                                                                      
{'loss': 0.2739, 'learning_rate': 0.00010178133836003768, 'epoch': 6.67}                                                                                                      
{'loss': 0.1703, 'learning_rate': 0.0001016870876531574, 'epoch': 6.67}                                                                                                       
{'loss': 0.1635, 'learning_rate': 0.00010159283694627709, 'epoch': 6.67}                                                                                                      
{'loss': 0.1287, 'learning_rate': 0.00010149858623939679, 'epoch': 6.67}                                                                                                      
{'loss': 0.1866, 'learning_rate': 0.00010140433553251648, 'epoch': 6.68}                                                                                                      
{'loss': 0.3033, 'learning_rate': 0.00010131008482563618, 'epoch': 6.68}                                                                                                      
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                         | 21600/32330 [34:40:19<1:47:28,  1.66it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6403643455888456, 'eval_cer': 0.39984837545126356, 'eval_runtime': 533.5773, 'eval_samples_per_second': 17.951, 'eval_steps_per_second': 2.245, 'epoch': 6.68}                                                                                                                                                             
{'loss': 0.1706, 'learning_rate': 0.00010121583411875589, 'epoch': 6.68}                                                                                                      
{'loss': 0.1788, 'learning_rate': 0.00010112158341187558, 'epoch': 6.69}                                                                                                      
{'loss': 0.1494, 'learning_rate': 0.00010102733270499527, 'epoch': 6.69}                                                                                                      
{'loss': 0.1323, 'learning_rate': 0.00010093308199811498, 'epoch': 6.69}                                                                                                      
{'loss': 0.2911, 'learning_rate': 0.00010083883129123467, 'epoch': 6.7}                                                                                                       
{'loss': 0.2182, 'learning_rate': 0.00010074458058435438, 'epoch': 6.7}                                                                                                       
{'loss': 0.1628, 'learning_rate': 0.00010065032987747407, 'epoch': 6.7}                                                                                                       
{'loss': 0.1524, 'learning_rate': 0.00010055607917059378, 'epoch': 6.71}                                                                                                      
{'loss': 0.1692, 'learning_rate': 0.00010046182846371347, 'epoch': 6.71}                                                                                                      
{'loss': 0.3554, 'learning_rate': 0.00010036757775683316, 'epoch': 6.71}                                                                                                      
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                         | 21700/32330 [34:49:59<1:54:14,  1.55it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6421487260353557, 'eval_cer': 0.39978339350180503, 'eval_runtime': 540.4077, 'eval_samples_per_second': 17.724, 'eval_steps_per_second': 2.217, 'epoch': 6.71}                                                                                                                                                             
{'loss': 0.1983, 'learning_rate': 0.00010027332704995287, 'epoch': 6.72}                                                                                                      
{'loss': 0.2151, 'learning_rate': 0.00010017907634307256, 'epoch': 6.72}                                                                                                      
{'loss': 0.1155, 'learning_rate': 0.00010008482563619227, 'epoch': 6.72}                                                                                                      
{'loss': 0.1661, 'learning_rate': 9.999057492931196e-05, 'epoch': 6.72}                                                                                                       
{'loss': 0.289, 'learning_rate': 9.989632422243165e-05, 'epoch': 6.73}                                                                                                        
{'loss': 0.1869, 'learning_rate': 9.980207351555134e-05, 'epoch': 6.73}                                                                                                       
{'loss': 0.1666, 'learning_rate': 9.970782280867106e-05, 'epoch': 6.73}                                                                                                       
{'loss': 0.1395, 'learning_rate': 9.961357210179076e-05, 'epoch': 6.74}                                                                                                       
{'loss': 0.173, 'learning_rate': 9.951932139491045e-05, 'epoch': 6.74}                                                                                                        
{'loss': 0.3064, 'learning_rate': 9.942507068803014e-05, 'epoch': 6.74}                                                                                                       
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                         | 21800/32330 [34:59:46<1:47:45,  1.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6401153622707279, 'eval_cer': 0.39926594464500603, 'eval_runtime': 539.7929, 'eval_samples_per_second': 17.744, 'eval_steps_per_second': 2.219, 'epoch': 6.74}                                                                                                                                                             
{'loss': 0.1722, 'learning_rate': 9.933081998114986e-05, 'epoch': 6.75}                                                                                                       
{'loss': 0.1173, 'learning_rate': 9.923656927426955e-05, 'epoch': 6.75}                                                                                                       
{'loss': 0.1445, 'learning_rate': 9.914231856738925e-05, 'epoch': 6.75}                                                                                                       
{'loss': 0.1678, 'learning_rate': 9.904806786050894e-05, 'epoch': 6.76}                                                                                                       
{'loss': 0.2736, 'learning_rate': 9.895381715362866e-05, 'epoch': 6.76}                                                                                                       
{'loss': 0.1732, 'learning_rate': 9.885956644674835e-05, 'epoch': 6.76}                                                                                                       
{'loss': 0.1203, 'learning_rate': 9.876531573986804e-05, 'epoch': 6.76}                                                                                                       
{'loss': 0.1885, 'learning_rate': 9.867106503298773e-05, 'epoch': 6.77}                                                                                                       
{'loss': 0.2373, 'learning_rate': 9.857681432610744e-05, 'epoch': 6.77}                                                                                                       
{'loss': 0.2923, 'learning_rate': 9.848256361922715e-05, 'epoch': 6.77}                                                                                                       
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                        | 21900/32330 [35:09:32<1:46:32,  1.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6527927628848867, 'eval_cer': 0.4010012033694344, 'eval_runtime': 541.0347, 'eval_samples_per_second': 17.703, 'eval_steps_per_second': 2.214, 'epoch': 6.77}                                                                                                                                                              
{'loss': 0.2078, 'learning_rate': 9.838831291234684e-05, 'epoch': 6.78}                                                                                                       
{'loss': 0.1076, 'learning_rate': 9.829406220546653e-05, 'epoch': 6.78}                                                                                                       
{'loss': 0.239, 'learning_rate': 9.819981149858622e-05, 'epoch': 6.78}                                                                                                        
{'loss': 0.1694, 'learning_rate': 9.810556079170593e-05, 'epoch': 6.79}                                                                                                       
{'loss': 0.3786, 'learning_rate': 9.801131008482562e-05, 'epoch': 6.79}                                                                                                       
{'loss': 0.1692, 'learning_rate': 9.791705937794533e-05, 'epoch': 6.79}                                                                                                       
{'loss': 0.2162, 'learning_rate': 9.782280867106502e-05, 'epoch': 6.8}                                                                                                        
{'loss': 0.184, 'learning_rate': 9.772855796418473e-05, 'epoch': 6.8}                                                                                                         
{'loss': 0.2288, 'learning_rate': 9.763430725730442e-05, 'epoch': 6.8}                                                                                                        
{'loss': 0.35, 'learning_rate': 9.754005655042411e-05, 'epoch': 6.8}                                                                                                          
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                        | 22000/32330 [35:19:17<1:47:53,  1.60it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6459872188563366, 'eval_cer': 0.3994729241877256, 'eval_runtime': 539.6568, 'eval_samples_per_second': 17.748, 'eval_steps_per_second': 2.22, 'epoch': 6.8}                                                                                                                                                                
{'loss': 0.1577, 'learning_rate': 9.744580584354382e-05, 'epoch': 6.81}                                                                                                       
{'loss': 0.1726, 'learning_rate': 9.735155513666352e-05, 'epoch': 6.81}                                                                                                       
{'loss': 0.1341, 'learning_rate': 9.725730442978322e-05, 'epoch': 6.81}                                                                                                       
{'loss': 0.2256, 'learning_rate': 9.716305372290291e-05, 'epoch': 6.82}                                                                                                       
{'loss': 0.2696, 'learning_rate': 9.70688030160226e-05, 'epoch': 6.82}                                                                                                        
{'loss': 0.258, 'learning_rate': 9.697455230914232e-05, 'epoch': 6.82}                                                                                                        
{'loss': 0.1453, 'learning_rate': 9.688030160226201e-05, 'epoch': 6.83}                                                                                                       
{'loss': 0.2034, 'learning_rate': 9.67860508953817e-05, 'epoch': 6.83}                                                                                                        
{'loss': 0.2487, 'learning_rate': 9.66918001885014e-05, 'epoch': 6.83}                                                                                                        
{'loss': 0.3142, 'learning_rate': 9.659754948162112e-05, 'epoch': 6.84}                                                                                                       
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 22100/32330 [35:29:03<1:41:28,  1.68it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.646775666030376, 'eval_cer': 0.40194464500601684, 'eval_runtime': 538.5257, 'eval_samples_per_second': 17.786, 'eval_steps_per_second': 2.225, 'epoch': 6.84}                                                                                                                                                              
{'loss': 0.2238, 'learning_rate': 9.650329877474081e-05, 'epoch': 6.84}                                                                                                       
{'loss': 0.1555, 'learning_rate': 9.64090480678605e-05, 'epoch': 6.84}                                                                                                        
{'loss': 0.2007, 'learning_rate': 9.63147973609802e-05, 'epoch': 6.84}                                                                                                        
{'loss': 0.2034, 'learning_rate': 9.622054665409989e-05, 'epoch': 6.85}                                                                                                       
{'loss': 0.3664, 'learning_rate': 9.61262959472196e-05, 'epoch': 6.85}                                                                                                        
{'loss': 0.1867, 'learning_rate': 9.60320452403393e-05, 'epoch': 6.85}                                                                                                        
{'loss': 0.1488, 'learning_rate': 9.593779453345899e-05, 'epoch': 6.86}                                                                                                       
{'loss': 0.1708, 'learning_rate': 9.584354382657868e-05, 'epoch': 6.86}                                                                                                       
{'loss': 0.2423, 'learning_rate': 9.574929311969839e-05, 'epoch': 6.86}                                                                                                       
{'loss': 0.3816, 'learning_rate': 9.56550424128181e-05, 'epoch': 6.87}                                                                                                        
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                       | 22200/32330 [35:38:48<1:47:22,  1.57it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6391609262179434, 'eval_cer': 0.3986546329723225, 'eval_runtime': 539.0106, 'eval_samples_per_second': 17.77, 'eval_steps_per_second': 2.223, 'epoch': 6.87}                                                                                                                                                               
{'loss': 0.1773, 'learning_rate': 9.556079170593779e-05, 'epoch': 6.87}                                                                                                       
{'loss': 0.1373, 'learning_rate': 9.546654099905748e-05, 'epoch': 6.87}                                                                                                       
{'loss': 0.1869, 'learning_rate': 9.537229029217719e-05, 'epoch': 6.88}                                                                                                       
{'loss': 0.1509, 'learning_rate': 9.527803958529688e-05, 'epoch': 6.88}                                                                                                       
{'loss': 0.321, 'learning_rate': 9.518378887841658e-05, 'epoch': 6.88}                                                                                                        
{'loss': 0.1996, 'learning_rate': 9.508953817153628e-05, 'epoch': 6.89}                                                                                                       
{'loss': 0.2588, 'learning_rate': 9.499528746465598e-05, 'epoch': 6.89}                                                                                                       
{'loss': 0.1582, 'learning_rate': 9.490103675777567e-05, 'epoch': 6.89}                                                                                                       
{'loss': 0.2771, 'learning_rate': 9.480678605089537e-05, 'epoch': 6.89}                                                                                                       
{'loss': 0.2644, 'learning_rate': 9.471253534401507e-05, 'epoch': 6.9}                                                                                                        
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                       | 22300/32330 [35:48:33<1:45:00,  1.59it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6388911942899825, 'eval_cer': 0.3985655836341757, 'eval_runtime': 539.9878, 'eval_samples_per_second': 17.737, 'eval_steps_per_second': 2.219, 'epoch': 6.9}                                                                                                                                                               
{'loss': 0.1798, 'learning_rate': 9.461828463713478e-05, 'epoch': 6.9}                                                                                                        
{'loss': 0.1604, 'learning_rate': 9.452403393025447e-05, 'epoch': 6.9}                                                                                                        
{'loss': 0.2452, 'learning_rate': 9.442978322337416e-05, 'epoch': 6.91}                                                                                                       
{'loss': 0.1761, 'learning_rate': 9.433553251649386e-05, 'epoch': 6.91}                                                                                                       
{'loss': 0.3122, 'learning_rate': 9.424128180961356e-05, 'epoch': 6.91}                                                                                                       
{'loss': 0.1568, 'learning_rate': 9.414703110273327e-05, 'epoch': 6.92}                                                                                                       
{'loss': 0.1546, 'learning_rate': 9.405278039585296e-05, 'epoch': 6.92}                                                                                                       
{'loss': 0.1489, 'learning_rate': 9.395852968897265e-05, 'epoch': 6.92}                                                                                                       
{'loss': 0.1417, 'learning_rate': 9.386427898209235e-05, 'epoch': 6.93}                                                                                                       
{'loss': 0.3496, 'learning_rate': 9.377002827521207e-05, 'epoch': 6.93}                                                                                                       
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                      | 22400/32330 [35:58:19<1:41:35,  1.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.643393642625944, 'eval_cer': 0.3990565583634176, 'eval_runtime': 539.3153, 'eval_samples_per_second': 17.76, 'eval_steps_per_second': 2.221, 'epoch': 6.93}                                                                                                                                                                
{'loss': 0.1744, 'learning_rate': 9.367577756833176e-05, 'epoch': 6.93}                                                                                                       
{'loss': 0.1361, 'learning_rate': 9.358152686145145e-05, 'epoch': 6.93}                                                                                                       
{'loss': 0.1659, 'learning_rate': 9.348727615457114e-05, 'epoch': 6.94}                                                                                                       
{'loss': 0.1839, 'learning_rate': 9.339302544769086e-05, 'epoch': 6.94}                                                                                                       
{'loss': 0.2446, 'learning_rate': 9.329877474081055e-05, 'epoch': 6.94}                                                                                                       
{'loss': 0.175, 'learning_rate': 9.320452403393025e-05, 'epoch': 6.95}                                                                                                        
{'loss': 0.1617, 'learning_rate': 9.311027332704994e-05, 'epoch': 6.95}                                                                                                       
{'loss': 0.1853, 'learning_rate': 9.301602262016965e-05, 'epoch': 6.95}                                                                                                       
{'loss': 0.2057, 'learning_rate': 9.292177191328935e-05, 'epoch': 6.96}                                                                                                       
{'loss': 0.2948, 'learning_rate': 9.282752120640904e-05, 'epoch': 6.96}                                                                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                      | 22500/32330 [36:08:03<1:40:18,  1.63it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6398041331230807, 'eval_cer': 0.39922984356197355, 'eval_runtime': 540.6748, 'eval_samples_per_second': 17.715, 'eval_steps_per_second': 2.216, 'epoch': 6.96}                                                                                                                                                             
{'loss': 0.2134, 'learning_rate': 9.273327049952874e-05, 'epoch': 6.96}                                                                                                       
{'loss': 0.1678, 'learning_rate': 9.263901979264844e-05, 'epoch': 6.97}                                                                                                       
{'loss': 0.1647, 'learning_rate': 9.254476908576813e-05, 'epoch': 6.97}                                                                                                       
{'loss': 0.2151, 'learning_rate': 9.245051837888783e-05, 'epoch': 6.97}                                                                                                       
{'loss': 0.212, 'learning_rate': 9.235626767200753e-05, 'epoch': 6.97}                                                                                                        
{'loss': 0.2057, 'learning_rate': 9.226201696512723e-05, 'epoch': 6.98}                                                                                                       
{'loss': 0.1617, 'learning_rate': 9.216776625824693e-05, 'epoch': 6.98}                                                                                                       
{'loss': 0.2475, 'learning_rate': 9.207351555136662e-05, 'epoch': 6.98}                                                                                                       
{'loss': 0.1864, 'learning_rate': 9.197926484448632e-05, 'epoch': 6.99}                                                                                                       
{'loss': 0.2911, 'learning_rate': 9.188501413760602e-05, 'epoch': 6.99}                                                                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                      | 22600/32330 [36:17:50<1:41:03,  1.60it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.635550668105237, 'eval_cer': 0.39787725631768955, 'eval_runtime': 541.1713, 'eval_samples_per_second': 17.699, 'eval_steps_per_second': 2.214, 'epoch': 6.99}                                                                                                                                                              
{'loss': 0.2023, 'learning_rate': 9.179076343072573e-05, 'epoch': 6.99}                                                                                                       
{'loss': 0.1282, 'learning_rate': 9.169651272384542e-05, 'epoch': 7.0}                                                                                                        
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                     | 22624/32330 [36:27:03<1:09:17,  2.33it/s]Saving model checkpoint to turkish_clean/checkpoint-22624
Configuration saved in turkish_clean/checkpoint-22624/config.json
Model weights saved in turkish_clean/checkpoint-22624/pytorch_model.bin
Feature extractor saved in turkish_clean/checkpoint-22624/preprocessor_config.json
Deleting older checkpoint [turkish_clean/checkpoint-12928] due to args.save_total_limit
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2825, 'learning_rate': 9.160226201696511e-05, 'epoch': 7.0}                                                                                                        
{'loss': 0.2849, 'learning_rate': 9.15080113100848e-05, 'epoch': 7.0}                                                                                                         
{'loss': 0.1539, 'learning_rate': 9.141376060320452e-05, 'epoch': 7.01}                                                                                                       
{'loss': 0.1882, 'learning_rate': 9.131950989632422e-05, 'epoch': 7.01}                                                                                                       
{'loss': 0.2067, 'learning_rate': 9.122525918944391e-05, 'epoch': 7.01}                                                                                                       
{'loss': 0.2744, 'learning_rate': 9.11310084825636e-05, 'epoch': 7.02}                                                                                                        
{'loss': 0.1848, 'learning_rate': 9.103675777568332e-05, 'epoch': 7.02}                                                                                                       
{'loss': 0.1331, 'learning_rate': 9.094250706880301e-05, 'epoch': 7.02}                                                                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                     | 22700/32330 [36:27:42<1:13:36,  2.18it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6365051041580214, 'eval_cer': 0.3980746089049338, 'eval_runtime': 533.9109, 'eval_samples_per_second': 17.939, 'eval_steps_per_second': 2.244, 'epoch': 7.02}                                                                                                                                                              
{'loss': 0.1437, 'learning_rate': 9.08482563619227e-05, 'epoch': 7.02}                                                                                                        
{'loss': 0.1574, 'learning_rate': 9.07540056550424e-05, 'epoch': 7.03}                                                                                                        
{'loss': 0.2467, 'learning_rate': 9.06597549481621e-05, 'epoch': 7.03}                                                                                                        
{'loss': 0.1763, 'learning_rate': 9.056550424128181e-05, 'epoch': 7.03}                                                                                                       
{'loss': 0.1374, 'learning_rate': 9.04712535344015e-05, 'epoch': 7.04}                                                                                                        
{'loss': 0.1723, 'learning_rate': 9.03770028275212e-05, 'epoch': 7.04}                                                                                                        
{'loss': 0.1852, 'learning_rate': 9.028275212064089e-05, 'epoch': 7.04}                                                                                                       
{'loss': 0.2384, 'learning_rate': 9.01885014137606e-05, 'epoch': 7.05}                                                                                                        
{'loss': 0.2639, 'learning_rate': 9.00942507068803e-05, 'epoch': 7.05}                                                                                                        
{'loss': 0.1326, 'learning_rate': 8.999999999999999e-05, 'epoch': 7.05}                                                                                                       
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                     | 22800/32330 [36:37:21<1:07:45,  2.34it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6343472487343348, 'eval_cer': 0.39723706377858004, 'eval_runtime': 537.1218, 'eval_samples_per_second': 17.832, 'eval_steps_per_second': 2.23, 'epoch': 7.05}                                                                                                                                                              
{'loss': 0.1826, 'learning_rate': 8.990574929311968e-05, 'epoch': 7.06}                                                                                                       
{'loss': 0.1549, 'learning_rate': 8.981149858623939e-05, 'epoch': 7.06}                                                                                                       
{'loss': 0.2815, 'learning_rate': 8.971724787935908e-05, 'epoch': 7.06}                                                                                                       
{'loss': 0.2158, 'learning_rate': 8.962299717247879e-05, 'epoch': 7.06}                                                                                                       
{'loss': 0.1386, 'learning_rate': 8.952874646559848e-05, 'epoch': 7.07}                                                                                                       
{'loss': 0.1873, 'learning_rate': 8.943449575871819e-05, 'epoch': 7.07}                                                                                                       
{'loss': 0.1634, 'learning_rate': 8.934024505183788e-05, 'epoch': 7.07}                                                                                                       
{'loss': 0.2333, 'learning_rate': 8.924599434495757e-05, 'epoch': 7.08}                                                                                                       
{'loss': 0.2099, 'learning_rate': 8.915174363807728e-05, 'epoch': 7.08}                                                                                                       
{'loss': 0.1598, 'learning_rate': 8.905749293119698e-05, 'epoch': 7.08}                                                                                                       
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                    | 22900/32330 [36:47:04<1:12:47,  2.16it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6319404099925305, 'eval_cer': 0.39754993983152825, 'eval_runtime': 538.1595, 'eval_samples_per_second': 17.798, 'eval_steps_per_second': 2.226, 'epoch': 7.08}                                                                                                                                                             
{'loss': 0.1369, 'learning_rate': 8.896324222431668e-05, 'epoch': 7.09}                                                                                                       
{'loss': 0.1971, 'learning_rate': 8.886899151743637e-05, 'epoch': 7.09}                                                                                                       
{'loss': 0.2551, 'learning_rate': 8.877474081055606e-05, 'epoch': 7.09}                                                                                                       
{'loss': 0.3333, 'learning_rate': 8.868049010367578e-05, 'epoch': 7.1}                                                                                                        
{'loss': 0.1908, 'learning_rate': 8.858623939679547e-05, 'epoch': 7.1}                                                                                                        
{'loss': 0.1143, 'learning_rate': 8.849198868991517e-05, 'epoch': 7.1}                                                                                                        
{'loss': 0.1766, 'learning_rate': 8.839773798303486e-05, 'epoch': 7.1}                                                                                                        
{'loss': 0.1903, 'learning_rate': 8.830348727615455e-05, 'epoch': 7.11}                                                                                                       
{'loss': 0.2505, 'learning_rate': 8.820923656927427e-05, 'epoch': 7.11}                                                                                                       
{'loss': 0.1583, 'learning_rate': 8.811498586239396e-05, 'epoch': 7.11}                                                                                                       
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                    | 23000/32330 [36:56:50<1:14:57,  2.07it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6329778404846875, 'eval_cer': 0.3978748495788207, 'eval_runtime': 538.5547, 'eval_samples_per_second': 17.785, 'eval_steps_per_second': 2.224, 'epoch': 7.11}                                                                                                                                                              
{'loss': 0.1523, 'learning_rate': 8.802073515551365e-05, 'epoch': 7.12}                                                                                                       
{'loss': 0.1588, 'learning_rate': 8.792648444863335e-05, 'epoch': 7.12}                                                                                                       
{'loss': 0.2346, 'learning_rate': 8.783223374175307e-05, 'epoch': 7.12}                                                                                                       
{'loss': 0.2314, 'learning_rate': 8.773798303487276e-05, 'epoch': 7.13}                                                                                                       
{'loss': 0.1322, 'learning_rate': 8.764373232799245e-05, 'epoch': 7.13}                                                                                                       
{'loss': 0.1684, 'learning_rate': 8.754948162111214e-05, 'epoch': 7.13}                                                                                                       
{'loss': 0.1141, 'learning_rate': 8.745523091423185e-05, 'epoch': 7.14}                                                                                                       
{'loss': 0.1645, 'learning_rate': 8.736098020735156e-05, 'epoch': 7.14}                                                                                                       
{'loss': 0.207, 'learning_rate': 8.726672950047125e-05, 'epoch': 7.14}                                                                                                        
{'loss': 0.183, 'learning_rate': 8.717247879359094e-05, 'epoch': 7.15}                                                                                                        
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                    | 23100/32330 [37:06:34<1:11:02,  2.17it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6371068138434725, 'eval_cer': 0.3984837545126354, 'eval_runtime': 534.0125, 'eval_samples_per_second': 17.936, 'eval_steps_per_second': 2.243, 'epoch': 7.15}                                                                                                                                                              
{'loss': 0.142, 'learning_rate': 8.707822808671065e-05, 'epoch': 7.15}                                                                                                        
{'loss': 0.1825, 'learning_rate': 8.698397737983034e-05, 'epoch': 7.15}                                                                                                       
{'loss': 0.2158, 'learning_rate': 8.688972667295005e-05, 'epoch': 7.15}                                                                                                       
{'loss': 0.2332, 'learning_rate': 8.679547596606974e-05, 'epoch': 7.16}                                                                                                       
{'loss': 0.1254, 'learning_rate': 8.670122525918944e-05, 'epoch': 7.16}                                                                                                       
{'loss': 0.1348, 'learning_rate': 8.660697455230914e-05, 'epoch': 7.16}                                                                                                       
{'loss': 0.165, 'learning_rate': 8.651272384542883e-05, 'epoch': 7.17}                                                                                                        
{'loss': 0.3291, 'learning_rate': 8.641847313854852e-05, 'epoch': 7.17}                                                                                                       
{'loss': 0.1984, 'learning_rate': 8.632422243166823e-05, 'epoch': 7.17}                                                                                                       
{'loss': 0.1744, 'learning_rate': 8.622997172478793e-05, 'epoch': 7.18}                                                                                                       
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 23200/32330 [37:16:14<1:11:44,  2.12it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6342435056851191, 'eval_cer': 0.3986594464500602, 'eval_runtime': 539.9784, 'eval_samples_per_second': 17.738, 'eval_steps_per_second': 2.219, 'epoch': 7.18}                                                                                                                                                              
{'loss': 0.1241, 'learning_rate': 8.613572101790763e-05, 'epoch': 7.18}                                                                                                       
{'loss': 0.141, 'learning_rate': 8.604147031102732e-05, 'epoch': 7.18}                                                                                                        
{'loss': 0.2986, 'learning_rate': 8.594721960414701e-05, 'epoch': 7.19}                                                                                                       
{'loss': 0.2416, 'learning_rate': 8.585296889726673e-05, 'epoch': 7.19}                                                                                                       
{'loss': 0.166, 'learning_rate': 8.575871819038642e-05, 'epoch': 7.19}                                                                                                        
{'loss': 0.1524, 'learning_rate': 8.566446748350611e-05, 'epoch': 7.19}                                                                                                       
{'loss': 0.1537, 'learning_rate': 8.55702167766258e-05, 'epoch': 7.2}                                                                                                         
{'loss': 0.2969, 'learning_rate': 8.547596606974553e-05, 'epoch': 7.2}                                                                                                        
{'loss': 0.2288, 'learning_rate': 8.538171536286522e-05, 'epoch': 7.2}                                                                                                        
{'loss': 0.1432, 'learning_rate': 8.528746465598491e-05, 'epoch': 7.21}                                                                                                       
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                   | 23300/32330 [37:26:00<1:07:52,  2.22it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6331438293634326, 'eval_cer': 0.39800240673886883, 'eval_runtime': 538.685, 'eval_samples_per_second': 17.78, 'eval_steps_per_second': 2.224, 'epoch': 7.21}                                                                                                                                                               
{'loss': 0.1143, 'learning_rate': 8.51932139491046e-05, 'epoch': 7.21}                                                                                                        
{'loss': 0.1607, 'learning_rate': 8.509896324222431e-05, 'epoch': 7.21}                                                                                                       
{'loss': 0.2099, 'learning_rate': 8.500471253534402e-05, 'epoch': 7.22}                                                                                                       
{'loss': 0.2158, 'learning_rate': 8.491046182846371e-05, 'epoch': 7.22}                                                                                                       
{'loss': 0.1571, 'learning_rate': 8.48162111215834e-05, 'epoch': 7.22}                                                                                                        
{'loss': 0.15, 'learning_rate': 8.47219604147031e-05, 'epoch': 7.23}                                                                                                          
{'loss': 0.1738, 'learning_rate': 8.46277097078228e-05, 'epoch': 7.23}                                                                                                        
{'loss': 0.2323, 'learning_rate': 8.45334590009425e-05, 'epoch': 7.23}                                                                                                        
{'loss': 0.214, 'learning_rate': 8.44392082940622e-05, 'epoch': 7.23}                                                                                                         
{'loss': 0.1773, 'learning_rate': 8.434495758718189e-05, 'epoch': 7.24}                                                                                                       
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                  | 23400/32330 [37:35:44<1:06:59,  2.22it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6243464187899411, 'eval_cer': 0.39620216606498193, 'eval_runtime': 538.0678, 'eval_samples_per_second': 17.801, 'eval_steps_per_second': 2.226, 'epoch': 7.24}                                                                                                                                                             
{'loss': 0.1456, 'learning_rate': 8.42507068803016e-05, 'epoch': 7.24}                                                                                                        
{'loss': 0.1595, 'learning_rate': 8.415645617342129e-05, 'epoch': 7.24}                                                                                                       
{'loss': 0.2148, 'learning_rate': 8.4062205466541e-05, 'epoch': 7.25}                                                                                                         
{'loss': 0.2156, 'learning_rate': 8.396795475966069e-05, 'epoch': 7.25}                                                                                                       
{'loss': 0.1167, 'learning_rate': 8.387370405278039e-05, 'epoch': 7.25}                                                                                                       
{'loss': 0.1348, 'learning_rate': 8.377945334590008e-05, 'epoch': 7.26}                                                                                                       
{'loss': 0.1674, 'learning_rate': 8.368520263901978e-05, 'epoch': 7.26}                                                                                                       
{'loss': 0.2544, 'learning_rate': 8.359095193213948e-05, 'epoch': 7.26}                                                                                                       
{'loss': 0.2142, 'learning_rate': 8.349670122525919e-05, 'epoch': 7.27}                                                                                                       
{'loss': 0.1586, 'learning_rate': 8.340245051837888e-05, 'epoch': 7.27}                                                                                                       
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                  | 23500/32330 [37:45:29<1:08:38,  2.14it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8
{'eval_loss': inf, 'eval_wer': 0.6320856502614325, 'eval_cer': 0.3968880866425993, 'eval_runtime': 540.1434, 'eval_samples_per_second': 17.732, 'eval_steps_per_second': 2.218, 'epoch': 7.27}                                                                                                                                                              
{'loss': 0.1663, 'learning_rate': 8.330819981149857e-05, 'epoch': 7.27}                                                                                                       
{'loss': 0.1936, 'learning_rate': 8.321394910461827e-05, 'epoch': 7.27}                                                                                                       
{'loss': 0.1753, 'learning_rate': 8.311969839773799e-05, 'epoch': 7.28}                                                                                                       
{'loss': 0.1466, 'learning_rate': 8.302544769085768e-05, 'epoch': 7.28}                                                                                                       
{'loss': 0.1532, 'learning_rate': 8.293119698397737e-05, 'epoch': 7.28}                                                                                                       
{'loss': 0.2026, 'learning_rate': 8.283694627709706e-05, 'epoch': 7.29}                                                                                                       
{'loss': 0.1374, 'learning_rate': 8.274269557021678e-05, 'epoch': 7.29}                                                                                                       
{'loss': 0.2135, 'learning_rate': 8.264844486333647e-05, 'epoch': 7.29}                                                                                                       
{'loss': 0.1995, 'learning_rate': 8.255419415645617e-05, 'epoch': 7.3}                                                                                                        
{'loss': 0.1526, 'learning_rate': 8.245994344957586e-05, 'epoch': 7.3}                                                                                                        
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  | 23600/32330 [37:55:14<1:05:14,  2.23it/s]***** Running Evaluation *****
  Num examples = 9578
  Batch size = 8

^CTraceback (most recent call last):â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1197/1198 [04:58<00:00,  4.29it/s]
  File "/home/or/Desktop/wav2vec2/main.py", line 317, in <module>
    trainer.train()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1501, in train
    return inner_training_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1826, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2089, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2796, in evaluate
    output = eval_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 3081, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
  File "/home/or/Desktop/wav2vec2/main.py", line 260, in compute_metrics
    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 139, in batch_decode
    return self.tokenizer.batch_decode(*args, **kwargs)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py", line 471, in batch_decode
    batch_decoded = [
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py", line 472, in <listcomp>
    self.decode(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py", line 586, in decode
    return self._decode(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py", line 395, in _decode
    string_output = self.convert_tokens_to_string(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py", line 275, in convert_tokens_to_string
    processed_chars = list(filter(lambda char: char != self.pad_token, chars))
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py", line 275, in <lambda>
    processed_chars = list(filter(lambda char: char != self.pad_token, chars))
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 1016, in pad_token
    if self._pad_token is None:
KeyboardInterrupt
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                 | 23600/32330 [38:01:45<14:04:03,  5.80s/it]

(base) or@anidjar:~/Desktop/wav2vec2$ ^C                                                                                                                                      
(base) or@anidjar:~/Desktop/wav2vec2$ ^C
(base) or@anidjar:~/Desktop/wav2vec2$ ^C
(base) or@anidjar:~/Desktop/wav2vec2$ 


