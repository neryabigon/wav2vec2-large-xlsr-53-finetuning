(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-b1d1c4e75dacebb7
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 532.20it/s]
Using custom data configuration default-a5f54108dd45233d
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 927.74it/s]
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-085b05f6c623f3f8.arrow
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0b8f5845c4d29140.arrow
^CTraceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 65, in <module>
    train['audio']
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2343, in __getitem__
    return self._getitem(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2328, in _getitem
    formatted_output = format_table(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 512, in format_table
    return formatter(pa_table, query_type)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 284, in __call__
    return self.format_column(pa_table)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 319, in format_column
    column = self.python_features_decoder.decode_column(column, pa_table.column_names[0])
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 225, in decode_column
    return self.features.decode_column(column, column_name) if self.features else column
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1811, in decode_column
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1811, in <listcomp>
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1262, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 145, in decode_example
    array, sampling_rate = self._decode_mp3(file if file else path)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 296, in _decode_mp3
    array, sampling_rate = self._decode_mp3_torchaudio(path_or_file)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 333, in _decode_mp3_torchaudio
    array = array.mean(axis=0)
  File "/home/or/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py", line 179, in _mean
    ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-b1d1c4e75dacebb7
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6990.51it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2160.90it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 746.98it/s]
Using custom data configuration default-a5f54108dd45233d
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16131.94it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3130.08it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1107.55it/s]
Casting the dataset:  67%|██████████████████████████████████████████████████████████████████████████████▋                                       | 2/3 [00:00<00:00, 21.34ba/s]
Casting the dataset:   0%|                                                                                                                              | 0/1 [00:00<?, ?ba/s]
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7f6aa86929d0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22862/22862 [00:00<00:00, 36511.95ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9629/9629 [00:00<00:00, 37096.05ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'я': 0, 'ю': 1, 'f': 2, '–': 3, 'e': 4, 'n': 5, 'h': 6, 'c': 7, 'э': 8, 'l': 9, 'с': 10, 'ъ': 11, 'й': 12, 'ь': 13, 'щ': 14, 'п': 15, 'о': 16, '«': 17, 'т': 18, 'p': 19, '…': 20, '−': 21, '‑': 22, 'z': 23, 'д': 24, 'б': 25, 'х': 26, 'в': 27, 'з': 28, '„': 29, 'е': 30, 'k': 31, 'н': 32, '(': 33, 'а': 34, 'ы': 35, "'": 36, 'o': 37, 'л': 38, 'x': 39, 'ф': 40, 'к': 41, 'г': 42, 'ё': 43, 'ц': 44, '—': 45, ')': 46, 'ч': 47, 'i': 48, 'a': 49, 'м': 50, 'и': 51, 'ж': 52, 'b': 53, 'r': 54, '»': 55, ' ': 56, 'ш': 57, 't': 58, 'у': 59, 'm': 60, 'р': 61}
Vocab_len: 64
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_ru_26426765.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_26426765.mp3', 'array': array([ 1.07707100e-15,  8.16166796e-14,  8.20455290e-14, ...,
       -2.91893434e-06,  1.16909966e-07,  1.00369357e-06], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_26426765.mp3', 'array': array([ 2.2830750e-14,  7.5313162e-14,  7.7842897e-14, ...,
        9.3801083e-07, -1.4542667e-06, -2.2241443e-06], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                            | 0/5716 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                            | 0/5715 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                    | 1/5715 [00:00<11:52,  8.02ex/s]
  warnings.warn(
#0:   0%|                                                                                                                                    | 1/5716 [00:00<13:14,  7.19ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5716/5716 [06:47<00:00, 14.02ex/s]
#3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5715/5715 [06:50<00:00, 13.93ex/s]
#0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5716/5716 [06:51<00:00, 13.88ex/s]
^CProcess ForkPoolWorker-4:█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍ | 5645/5715 [06:47<00:03, 21.36ex/s]
Process ForkPoolWorker-5:████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 5711/5715 [06:50<00:00, 62.58ex/s]
Traceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 165, in <module>
    train = train.map(prepare_dataset, remove_columns=train.column_names, num_proc=4)  # maybe we'll have to reduce to 1
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2685, in map
    transformed_shards[index] = async_result.get()
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 765, in get
    self.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 762, in wait
    self._event.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 581, in wait
    signaled = self._cond.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ clear
(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-b1d1c4e75dacebb7
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 550.43it/s]
Using custom data configuration default-a5f54108dd45233d
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 886.56it/s]
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-085b05f6c623f3f8.arrow
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0b8f5845c4d29140.arrow
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7f717a37cee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22862/22862 [00:00<00:00, 35592.12ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9629/9629 [00:00<00:00, 37034.65ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'в': 0, 'a': 1, 'ж': 2, 'p': 3, 'к': 4, 'n': 5, 'н': 6, 't': 7, 'т': 8, 'э': 9, 'z': 10, 'h': 11, 'о': 12, 'м': 13, "'": 14, '»': 15, 'ч': 16, 'с': 17, 'у': 18, 'и': 19, 'а': 20, 'я': 21, 'й': 22, 'k': 23, 'x': 24, 'ъ': 25, 'ц': 26, '‑': 27, 'е': 28, '…': 29, ' ': 30, '(': 31, 'ь': 32, 'ш': 33, '–': 34, '−': 35, 'm': 36, 'o': 37, '—': 38, 'щ': 39, 'д': 40, 'e': 41, 'п': 42, 'р': 43, 'з': 44, 'х': 45, 'c': 46, 'б': 47, 'b': 48, '«': 49, 'ы': 50, 'ё': 51, 'г': 52, 'ф': 53, 'i': 54, 'л': 55, 'l': 56, 'r': 57, '„': 58, 'f': 59, ')': 60, 'ю': 61}
Vocab_len: 64
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_ru_26426765.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_26426765.mp3', 'array': array([ 1.07707100e-15,  8.16166796e-14,  8.20455290e-14, ...,
       -2.91893434e-06,  1.16909966e-07,  1.00369357e-06], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_26426765.mp3', 'array': array([ 2.2830750e-14,  7.5313162e-14,  7.7842897e-14, ...,
        9.3801083e-07, -1.4542667e-06, -2.2241443e-06], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                           | 0/11431 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0:   0%|                                                                                                                                   | 2/11431 [00:00<14:01, 13.58ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11431/11431 [11:20<00:00, 16.80ex/s]
#1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11431/11431 [11:22<00:00, 16.75ex/s]
#0:   0%|                                                                                                                                            | 0/4815 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4815/4815 [04:59<00:00, 16.05ex/s]
#1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4814/4814 [05:00<00:00, 16.02ex/s]
#1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 4811/4814 [05:00<00:00, 23.17ex/s]

----------------- Preparing datasets complete. -----------------


----------------- saving datasets... -----------------
----------------- saving datasets complete. -----------


----------------- Loading Metrics... -----------------
/home/or/Desktop/wav2vec2/main_russian.py:246: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.weight', 'project_hid.weight', 'quantizer.weight_proj.bias', 'project_q.bias', 'project_q.weight', 'project_hid.bias', 'quantizer.codevectors']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 22862
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 16
  Gradient Accumulation steps = 2
  Total optimization steps = 14290
  Number of trainable parameters = 311294144
  0%|                                                                                                                                               | 0/14290 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 12.9956, 'learning_rate': 5.399999999999999e-06, 'epoch': 0.01}                                                                                                      
{'loss': 13.21, 'learning_rate': 1.14e-05, 'epoch': 0.01}                                                                                                                     
{'loss': 14.2027, 'learning_rate': 1.74e-05, 'epoch': 0.02}                                                                                                                   
{'loss': 16.4228, 'learning_rate': 2.28e-05, 'epoch': 0.03}                                                                                                                   
{'loss': 24.1598, 'learning_rate': 2.7599999999999997e-05, 'epoch': 0.03}                                                                                                     
{'loss': 11.9461, 'learning_rate': 3.36e-05, 'epoch': 0.04}                                                                                                                   
{'loss': 10.0068, 'learning_rate': 3.96e-05, 'epoch': 0.05}                                                                                                                   
{'loss': 8.1272, 'learning_rate': 4.56e-05, 'epoch': 0.06}                                                                                                                    
{'loss': 6.845, 'learning_rate': 5.1599999999999994e-05, 'epoch': 0.06}                                                                                                       
{'loss': 7.1165, 'learning_rate': 5.76e-05, 'epoch': 0.07}                                                                                                                    
  1%|▉                                                                                                                                  | 100/14290 [01:46<2:13:36,  1.77it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 4.628498077392578, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 396.2521, 'eval_samples_per_second': 24.3, 'eval_steps_per_second': 3.038, 'epoch': 0.07}                                                                                                                                                  
{'loss': 4.4418, 'learning_rate': 6.359999999999999e-05, 'epoch': 0.08}                                                                                                       
{'loss': 3.9354, 'learning_rate': 6.96e-05, 'epoch': 0.08}                                                                                                                    
{'loss': 3.6802, 'learning_rate': 7.56e-05, 'epoch': 0.09}                                                                                                                    
{'loss': 3.6005, 'learning_rate': 8.16e-05, 'epoch': 0.1}                                                                                                                     
{'loss': 3.6328, 'learning_rate': 8.759999999999999e-05, 'epoch': 0.1}                                                                                                        
{'loss': 3.4196, 'learning_rate': 9.36e-05, 'epoch': 0.11}                                                                                                                    
{'loss': 3.2844, 'learning_rate': 9.96e-05, 'epoch': 0.12}                                                                                                                    
{'loss': 3.2785, 'learning_rate': 0.00010559999999999998, 'epoch': 0.13}                                                                                                      
{'loss': 3.2473, 'learning_rate': 0.00011159999999999999, 'epoch': 0.13}                                                                                                      
{'loss': 3.322, 'learning_rate': 0.0001176, 'epoch': 0.14}                                                                                                                    
  1%|█▊                                                                                                                                 | 200/14290 [10:04<2:11:54,  1.78it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.323927164077759, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 395.2202, 'eval_samples_per_second': 24.364, 'eval_steps_per_second': 3.046, 'epoch': 0.14}                                                                                                                                                
{'loss': 3.3212, 'learning_rate': 0.0001236, 'epoch': 0.15}                                                                                                                   
{'loss': 3.1962, 'learning_rate': 0.00012959999999999998, 'epoch': 0.15}                                                                                                      
{'loss': 3.1902, 'learning_rate': 0.0001356, 'epoch': 0.16}                                                                                                                   
{'loss': 3.2078, 'learning_rate': 0.00014159999999999997, 'epoch': 0.17}                                                                                                      
{'loss': 3.3034, 'learning_rate': 0.00014759999999999998, 'epoch': 0.17}                                                                                                      
{'loss': 3.3574, 'learning_rate': 0.0001536, 'epoch': 0.18}                                                                                                                   
{'loss': 3.2027, 'learning_rate': 0.0001596, 'epoch': 0.19}                                                                                                                   
{'loss': 3.1631, 'learning_rate': 0.0001656, 'epoch': 0.2}                                                                                                                    
{'loss': 3.1581, 'learning_rate': 0.00017159999999999997, 'epoch': 0.2}                                                                                                       
{'loss': 3.2886, 'learning_rate': 0.00017759999999999998, 'epoch': 0.21}                                                                                                      
  2%|██▊                                                                                                                                | 300/14290 [18:22<2:09:53,  1.80it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.308337450027466, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 394.6017, 'eval_samples_per_second': 24.402, 'eval_steps_per_second': 3.051, 'epoch': 0.21}                                                                                                                                                
{'loss': 3.3236, 'learning_rate': 0.0001836, 'epoch': 0.22}                                                                                                                   
{'loss': 3.1927, 'learning_rate': 0.00018959999999999997, 'epoch': 0.22}                                                                                                      
{'loss': 3.158, 'learning_rate': 0.00019559999999999998, 'epoch': 0.23}                                                                                                       
{'loss': 3.1826, 'learning_rate': 0.0002016, 'epoch': 0.24}                                                                                                                   
{'loss': 3.2643, 'learning_rate': 0.00020759999999999998, 'epoch': 0.24}                                                                                                      
{'loss': 3.3196, 'learning_rate': 0.00021359999999999996, 'epoch': 0.25}                                                                                                      
{'loss': 3.1823, 'learning_rate': 0.00021959999999999997, 'epoch': 0.26}                                                                                                      
{'loss': 3.1989, 'learning_rate': 0.00022559999999999998, 'epoch': 0.27}                                                                                                      
{'loss': 3.1659, 'learning_rate': 0.0002316, 'epoch': 0.27}                                                                                                                   
{'loss': 3.2464, 'learning_rate': 0.0002376, 'epoch': 0.28}                                                                                                                   
  3%|███▋                                                                                                                               | 400/14290 [26:38<2:09:07,  1.79it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.28967022895813, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 396.8257, 'eval_samples_per_second': 24.265, 'eval_steps_per_second': 3.034, 'epoch': 0.28}                                                                                                                                                 
{'loss': 3.3052, 'learning_rate': 0.00024359999999999999, 'epoch': 0.29}                                                                                                      
{'loss': 3.1787, 'learning_rate': 0.00024959999999999994, 'epoch': 0.29}                                                                                                      
{'loss': 3.1492, 'learning_rate': 0.0002556, 'epoch': 0.3}                                                                                                                    
{'loss': 3.1648, 'learning_rate': 0.00026159999999999996, 'epoch': 0.31}                                                                                                      
{'loss': 3.2239, 'learning_rate': 0.0002676, 'epoch': 0.31}                                                                                                                   
{'loss': 3.3454, 'learning_rate': 0.0002736, 'epoch': 0.32}                                                                                                                   
{'loss': 3.182, 'learning_rate': 0.00027959999999999997, 'epoch': 0.33}                                                                                                       
{'loss': 3.1579, 'learning_rate': 0.00028559999999999995, 'epoch': 0.34}                                                                                                      
{'loss': 3.2044, 'learning_rate': 0.0002916, 'epoch': 0.34}                                                                                                                   
{'loss': 3.2449, 'learning_rate': 0.00029759999999999997, 'epoch': 0.35}                                                                                                      
  3%|████▌                                                                                                                              | 500/14290 [34:58<2:07:23,  1.80it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.302616834640503, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 395.075, 'eval_samples_per_second': 24.373, 'eval_steps_per_second': 3.048, 'epoch': 0.35}                                                                                                                                                 
{'loss': 3.5251, 'learning_rate': 0.0002998694706308919, 'epoch': 0.36}                                                                                                       
{'loss': 3.1467, 'learning_rate': 0.0002996519216823785, 'epoch': 0.36}                                                                                                       
{'loss': 3.1441, 'learning_rate': 0.0002994343727338651, 'epoch': 0.37}                                                                                                       
{'loss': 3.2073, 'learning_rate': 0.00029921682378535166, 'epoch': 0.38}                                                                                                      
{'loss': 3.2499, 'learning_rate': 0.0002989992748368383, 'epoch': 0.38}                                                                                                       
{'loss': 3.3467, 'learning_rate': 0.00029878172588832484, 'epoch': 0.39}                                                                                                      
{'loss': 3.1766, 'learning_rate': 0.0002985641769398114, 'epoch': 0.4}                                                                                                        
{'loss': 3.1742, 'learning_rate': 0.000298346627991298, 'epoch': 0.41}                                                                                                        
{'loss': 3.1475, 'learning_rate': 0.0002981290790427846, 'epoch': 0.41}                                                                                                       
{'loss': 3.2113, 'learning_rate': 0.0002979115300942712, 'epoch': 0.42}                                                                                                       
  4%|█████▌                                                                                                                             | 600/14290 [43:16<2:07:33,  1.79it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.345482587814331, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 389.6987, 'eval_samples_per_second': 24.709, 'eval_steps_per_second': 3.09, 'epoch': 0.42}                                                                                                                                                 
{'loss': 3.4262, 'learning_rate': 0.00029769398114575776, 'epoch': 0.43}                                                                                                      
{'loss': 3.1908, 'learning_rate': 0.0002974764321972444, 'epoch': 0.43}                                                                                                       
{'loss': 3.1454, 'learning_rate': 0.00029725888324873094, 'epoch': 0.44}                                                                                                      
{'loss': 3.1263, 'learning_rate': 0.0002970413343002175, 'epoch': 0.45}                                                                                                       
{'loss': 3.1863, 'learning_rate': 0.0002968237853517041, 'epoch': 0.45}                                                                                                       
{'loss': 3.3711, 'learning_rate': 0.0002966062364031907, 'epoch': 0.46}                                                                                                       
{'loss': 3.1804, 'learning_rate': 0.0002963886874546773, 'epoch': 0.47}                                                                                                       
{'loss': 3.1536, 'learning_rate': 0.00029617113850616386, 'epoch': 0.48}                                                                                                      
{'loss': 3.1359, 'learning_rate': 0.0002959535895576504, 'epoch': 0.48}                                                                                                       
{'loss': 3.1783, 'learning_rate': 0.00029573604060913704, 'epoch': 0.49}                                                                                                      
  5%|██████▍                                                                                                                            | 700/14290 [51:30<2:07:00,  1.78it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.3291783332824707, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 392.074, 'eval_samples_per_second': 24.559, 'eval_steps_per_second': 3.071, 'epoch': 0.49}                                                                                                                                                
{'loss': 3.421, 'learning_rate': 0.0002955184916606236, 'epoch': 0.5}                                                                                                         
{'loss': 3.2235, 'learning_rate': 0.0002953009427121102, 'epoch': 0.5}                                                                                                        
{'loss': 3.1171, 'learning_rate': 0.0002950833937635968, 'epoch': 0.51}                                                                                                       
{'loss': 3.121, 'learning_rate': 0.00029486584481508334, 'epoch': 0.52}                                                                                                       
{'loss': 3.156, 'learning_rate': 0.00029464829586656996, 'epoch': 0.52}                                                                                                       
{'loss': 3.3507, 'learning_rate': 0.0002944307469180565, 'epoch': 0.53}                                                                                                       
{'loss': 3.1771, 'learning_rate': 0.00029421319796954314, 'epoch': 0.54}                                                                                                      
{'loss': 3.1138, 'learning_rate': 0.0002939956490210297, 'epoch': 0.55}                                                                                                       
{'loss': 3.1139, 'learning_rate': 0.00029377810007251626, 'epoch': 0.55}                                                                                                      
{'loss': 3.2264, 'learning_rate': 0.0002935605511240029, 'epoch': 0.56}                                                                                                       
  6%|███████▎                                                                                                                           | 800/14290 [59:43<2:02:30,  1.84it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.2629711627960205, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 390.691, 'eval_samples_per_second': 24.646, 'eval_steps_per_second': 3.082, 'epoch': 0.56}                                                                                                                                                
{'loss': 3.2946, 'learning_rate': 0.00029334300217548944, 'epoch': 0.57}                                                                                                      
{'loss': 3.1533, 'learning_rate': 0.00029312545322697606, 'epoch': 0.57}                                                                                                      
{'loss': 3.1291, 'learning_rate': 0.0002929079042784626, 'epoch': 0.58}                                                                                                       
{'loss': 3.1176, 'learning_rate': 0.0002926903553299492, 'epoch': 0.59}                                                                                                       
{'loss': 3.1566, 'learning_rate': 0.0002924728063814358, 'epoch': 0.59}                                                                                                       
{'loss': 3.3678, 'learning_rate': 0.00029225525743292236, 'epoch': 0.6}                                                                                                       
{'loss': 3.1623, 'learning_rate': 0.000292037708484409, 'epoch': 0.61}                                                                                                        
{'loss': 3.1323, 'learning_rate': 0.00029182015953589554, 'epoch': 0.62}                                                                                                      
{'loss': 3.1228, 'learning_rate': 0.00029160261058738216, 'epoch': 0.62}                                                                                                      
{'loss': 3.1282, 'learning_rate': 0.0002913850616388687, 'epoch': 0.63}                                                                                                       
  6%|████████                                                                                                                         | 900/14290 [1:07:56<2:06:42,  1.76it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.227684497833252, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 390.5797, 'eval_samples_per_second': 24.653, 'eval_steps_per_second': 3.083, 'epoch': 0.63}                                                                                                                                                
{'loss': 3.2742, 'learning_rate': 0.0002911675126903553, 'epoch': 0.64}                                                                                                       
{'loss': 3.1422, 'learning_rate': 0.0002909499637418419, 'epoch': 0.64}                                                                                                       
{'loss': 3.1316, 'learning_rate': 0.00029073241479332846, 'epoch': 0.65}                                                                                                      
{'loss': 3.1086, 'learning_rate': 0.0002905148658448151, 'epoch': 0.66}                                                                                                       
{'loss': 3.1185, 'learning_rate': 0.00029029731689630164, 'epoch': 0.66}                                                                                                      
{'loss': 3.2718, 'learning_rate': 0.0002900797679477882, 'epoch': 0.67}                                                                                                       
{'loss': 3.1377, 'learning_rate': 0.0002898622189992748, 'epoch': 0.68}                                                                                                       
{'loss': 3.0902, 'learning_rate': 0.0002896446700507614, 'epoch': 0.69}                                                                                                       
{'loss': 3.1207, 'learning_rate': 0.000289427121102248, 'epoch': 0.69}                                                                                                        
{'loss': 3.0958, 'learning_rate': 0.00028920957215373456, 'epoch': 0.7}                                                                                                       
  7%|████████▉                                                                                                                       | 1000/14290 [1:16:10<2:02:58,  1.80it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.218885898590088, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 392.4677, 'eval_samples_per_second': 24.535, 'eval_steps_per_second': 3.068, 'epoch': 0.7}                                                                                                                                                 
{'loss': 3.2321, 'learning_rate': 0.0002889920232052211, 'epoch': 0.71}                                                                                                       
{'loss': 3.1236, 'learning_rate': 0.00028877447425670774, 'epoch': 0.71}                                                                                                      
{'loss': 3.1062, 'learning_rate': 0.0002885569253081943, 'epoch': 0.72}                                                                                                       
{'loss': 3.0924, 'learning_rate': 0.0002883393763596809, 'epoch': 0.73}                                                                                                       
{'loss': 3.074, 'learning_rate': 0.0002881218274111675, 'epoch': 0.73}                                                                                                        
{'loss': 3.1254, 'learning_rate': 0.00028790427846265404, 'epoch': 0.74}                                                                                                      
{'loss': 3.0915, 'learning_rate': 0.00028768672951414066, 'epoch': 0.75}                                                                                                      
{'loss': 3.0882, 'learning_rate': 0.0002874691805656272, 'epoch': 0.76}                                                                                                       
{'loss': 3.096, 'learning_rate': 0.00028725163161711384, 'epoch': 0.76}                                                                                                       
{'loss': 3.0741, 'learning_rate': 0.0002870340826686004, 'epoch': 0.77}                                                                                                       
  8%|█████████▊                                                                                                                      | 1100/14290 [1:24:25<2:01:28,  1.81it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.120669364929199, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 389.0293, 'eval_samples_per_second': 24.751, 'eval_steps_per_second': 3.095, 'epoch': 0.77}                                                                                                                                                
{'loss': 3.1202, 'learning_rate': 0.000286816533720087, 'epoch': 0.78}                                                                                                        
{'loss': 3.081, 'learning_rate': 0.0002865989847715736, 'epoch': 0.78}                                                                                                        
{'loss': 3.0906, 'learning_rate': 0.00028638143582306014, 'epoch': 0.79}                                                                                                      
{'loss': 3.0861, 'learning_rate': 0.00028616388687454676, 'epoch': 0.8}                                                                                                       
{'loss': 3.1033, 'learning_rate': 0.0002859463379260333, 'epoch': 0.8}                                                                                                        
{'loss': 3.1234, 'learning_rate': 0.00028572878897751994, 'epoch': 0.81}                                                                                                      
{'loss': 3.0975, 'learning_rate': 0.0002855112400290065, 'epoch': 0.82}                                                                                                       
{'loss': 3.1013, 'learning_rate': 0.00028529369108049306, 'epoch': 0.83}                                                                                                      
{'loss': 3.0677, 'learning_rate': 0.0002850761421319797, 'epoch': 0.83}                                                                                                       
{'loss': 3.0858, 'learning_rate': 0.00028485859318346624, 'epoch': 0.84}                                                                                                      
  8%|██████████▋                                                                                                                     | 1200/14290 [1:32:35<2:03:53,  1.76it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.0783140659332275, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 390.1732, 'eval_samples_per_second': 24.679, 'eval_steps_per_second': 3.086, 'epoch': 0.84}                                                                                                                                               
{'loss': 3.0865, 'learning_rate': 0.00028464104423495286, 'epoch': 0.85}                                                                                                      
{'loss': 3.0542, 'learning_rate': 0.0002844234952864394, 'epoch': 0.85}                                                                                                       
{'loss': 3.0286, 'learning_rate': 0.000284205946337926, 'epoch': 0.86}                                                                                                        
{'loss': 3.0213, 'learning_rate': 0.0002839883973894126, 'epoch': 0.87}                                                                                                       
{'loss': 2.9681, 'learning_rate': 0.00028377084844089916, 'epoch': 0.87}                                                                                                      
{'loss': 3.0296, 'learning_rate': 0.0002835532994923858, 'epoch': 0.88}                                                                                                       
{'loss': 2.9364, 'learning_rate': 0.00028333575054387234, 'epoch': 0.89}                                                                                                      
{'loss': 2.8274, 'learning_rate': 0.0002831182015953589, 'epoch': 0.9}                                                                                                        
{'loss': 2.7701, 'learning_rate': 0.0002829006526468455, 'epoch': 0.9}                                                                                                        
{'loss': 2.6925, 'learning_rate': 0.0002826831036983321, 'epoch': 0.91}                                                                                                       
  9%|███████████▋                                                                                                                    | 1300/14290 [1:40:49<1:58:34,  1.83it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 2.636476755142212, 'eval_wer': 0.9768635389378424, 'eval_cer': 0.9016582554706554, 'eval_runtime': 389.9847, 'eval_samples_per_second': 24.691, 'eval_steps_per_second': 3.087, 'epoch': 0.91}                                                                                                                                                
{'loss': 2.5755, 'learning_rate': 0.0002824655547498187, 'epoch': 0.92}                                                                                                       
{'loss': 2.4069, 'learning_rate': 0.00028224800580130526, 'epoch': 0.92}                                                                                                      
{'loss': 2.2318, 'learning_rate': 0.0002820304568527919, 'epoch': 0.93}                                                                                                       
{'loss': 2.0758, 'learning_rate': 0.00028181290790427844, 'epoch': 0.94}                                                                                                      
{'loss': 1.9954, 'learning_rate': 0.000281595358955765, 'epoch': 0.94}                                                                                                        
{'loss': 1.9103, 'learning_rate': 0.0002813778100072516, 'epoch': 0.95}                                                                                                       
{'loss': 1.791, 'learning_rate': 0.0002811602610587382, 'epoch': 0.96}                                                                                                        
{'loss': 1.7015, 'learning_rate': 0.0002809427121102248, 'epoch': 0.97}                                                                                                       
{'loss': 1.6307, 'learning_rate': 0.00028072516316171136, 'epoch': 0.97}                                                                                                      
{'loss': 1.5932, 'learning_rate': 0.0002805076142131979, 'epoch': 0.98}                                                                                                       
 10%|████████████▌                                                                                                                   | 1400/14290 [1:49:02<2:04:45,  1.72it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 1.4264476299285889, 'eval_wer': 0.9797809002143367, 'eval_cer': 0.4647422255551727, 'eval_runtime': 391.7819, 'eval_samples_per_second': 24.577, 'eval_steps_per_second': 3.073, 'epoch': 0.98}                                                                                                                                               
{'loss': 1.5693, 'learning_rate': 0.00028029006526468454, 'epoch': 0.99}                                                                                                      
{'loss': 1.4954, 'learning_rate': 0.0002800725163161711, 'epoch': 0.99}                                                                                                       
 10%|████████████▊                                                                                                                   | 1428/14290 [1:56:03<2:21:44,  1.51it/s]Saving model checkpoint to ./russian_augmented/checkpoint-1428
Configuration saved in ./russian_augmented/checkpoint-1428/config.json
Model weights saved in ./russian_augmented/checkpoint-1428/pytorch_model.bin
Feature extractor saved in ./russian_augmented/checkpoint-1428/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 1.4416, 'learning_rate': 0.0002798549673676577, 'epoch': 1.0}                                                                                                        
{'loss': 1.4602, 'learning_rate': 0.0002796374184191443, 'epoch': 1.01}                                                                                                       
{'loss': 1.4105, 'learning_rate': 0.00027941986947063084, 'epoch': 1.01}                                                                                                      
{'loss': 1.3417, 'learning_rate': 0.00027920232052211746, 'epoch': 1.02}                                                                                                      
{'loss': 1.3472, 'learning_rate': 0.000278984771573604, 'epoch': 1.03}                                                                                                        
{'loss': 1.3157, 'learning_rate': 0.00027876722262509064, 'epoch': 1.04}                                                                                                      
{'loss': 1.2877, 'learning_rate': 0.0002785496736765772, 'epoch': 1.04}                                                                                                       
{'loss': 1.2764, 'learning_rate': 0.00027833212472806376, 'epoch': 1.05}                                                                                                      
 10%|█████████████▍                                                                                                                  | 1500/14290 [1:57:26<3:58:48,  1.12s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 1.0288697481155396, 'eval_wer': 0.9660395332221957, 'eval_cer': 0.355994581703453, 'eval_runtime': 395.8137, 'eval_samples_per_second': 24.327, 'eval_steps_per_second': 3.042, 'epoch': 1.05}                                                                                                                                                
{'loss': 1.28, 'learning_rate': 0.0002781145757795504, 'epoch': 1.06}                                                                                                         
{'loss': 1.2643, 'learning_rate': 0.00027789702683103694, 'epoch': 1.06}                                                                                                      
{'loss': 1.2534, 'learning_rate': 0.00027767947788252356, 'epoch': 1.07}                                                                                                      
{'loss': 1.1966, 'learning_rate': 0.0002774619289340101, 'epoch': 1.08}                                                                                                       
{'loss': 1.1915, 'learning_rate': 0.0002772443799854967, 'epoch': 1.08}                                                                                                       
{'loss': 1.1324, 'learning_rate': 0.0002770268310369833, 'epoch': 1.09}                                                                                                       
{'loss': 1.1865, 'learning_rate': 0.00027680928208846986, 'epoch': 1.1}                                                                                                       
{'loss': 1.1726, 'learning_rate': 0.0002765917331399565, 'epoch': 1.11}                                                                                                       
{'loss': 1.1249, 'learning_rate': 0.00027637418419144304, 'epoch': 1.11}                                                                                                      
{'loss': 1.1259, 'learning_rate': 0.00027615663524292966, 'epoch': 1.12}                                                                                                      
 11%|██████████████▎                                                                                                                 | 1600/14290 [2:05:46<4:03:36,  1.15s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.8923030495643616, 'eval_wer': 0.9398904501071683, 'eval_cer': 0.30547504678516657, 'eval_runtime': 390.6344, 'eval_samples_per_second': 24.65, 'eval_steps_per_second': 3.082, 'epoch': 1.12}                                                                                                                                               
{'loss': 1.0687, 'learning_rate': 0.0002759390862944162, 'epoch': 1.13}                                                                                                       
{'loss': 1.1584, 'learning_rate': 0.0002757215373459028, 'epoch': 1.13}                                                                                                       
{'loss': 1.2261, 'learning_rate': 0.0002755039883973894, 'epoch': 1.14}                                                                                                       
{'loss': 1.099, 'learning_rate': 0.00027528643944887596, 'epoch': 1.15}                                                                                                       
{'loss': 1.0368, 'learning_rate': 0.0002750688905003626, 'epoch': 1.15}                                                                                                       
{'loss': 1.0369, 'learning_rate': 0.00027485134155184914, 'epoch': 1.16}                                                                                                      
{'loss': 1.0237, 'learning_rate': 0.0002746337926033357, 'epoch': 1.17}                                                                                                       
{'loss': 1.1618, 'learning_rate': 0.0002744162436548223, 'epoch': 1.18}                                                                                                       
{'loss': 1.0191, 'learning_rate': 0.0002741986947063089, 'epoch': 1.18}                                                                                                       
{'loss': 1.0294, 'learning_rate': 0.0002739811457577955, 'epoch': 1.19}                                                                                                       
 12%|███████████████▏                                                                                                                | 1700/14290 [2:13:59<3:52:34,  1.11s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.7913210391998291, 'eval_wer': 0.8982733984281972, 'eval_cer': 0.2791621908294318, 'eval_runtime': 390.1082, 'eval_samples_per_second': 24.683, 'eval_steps_per_second': 3.086, 'epoch': 1.19}                                                                                                                                               
{'loss': 1.0074, 'learning_rate': 0.00027376359680928206, 'epoch': 1.2}                                                                                                       
{'loss': 0.9879, 'learning_rate': 0.0002735460478607686, 'epoch': 1.2}                                                                                                        
{'loss': 1.0964, 'learning_rate': 0.00027332849891225524, 'epoch': 1.21}                                                                                                      
{'loss': 0.9652, 'learning_rate': 0.0002731109499637418, 'epoch': 1.22}                                                                                                       
{'loss': 0.9653, 'learning_rate': 0.0002728934010152284, 'epoch': 1.22}                                                                                                       
{'loss': 0.9869, 'learning_rate': 0.000272675852066715, 'epoch': 1.23}                                                                                                        
{'loss': 0.9936, 'learning_rate': 0.00027245830311820155, 'epoch': 1.24}                                                                                                      
{'loss': 1.0163, 'learning_rate': 0.00027224075416968816, 'epoch': 1.25}                                                                                                      
{'loss': 0.9016, 'learning_rate': 0.0002720232052211747, 'epoch': 1.25}                                                                                                       
{'loss': 0.9304, 'learning_rate': 0.00027180565627266134, 'epoch': 1.26}                                                                                                      
 13%|████████████████                                                                                                                | 1800/14290 [2:22:12<3:59:00,  1.15s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.7301341891288757, 'eval_wer': 0.8689211717075495, 'eval_cer': 0.25350804299506136, 'eval_runtime': 395.1795, 'eval_samples_per_second': 24.366, 'eval_steps_per_second': 3.047, 'epoch': 1.26}                                                                                                                                              
{'loss': 0.9199, 'learning_rate': 0.0002715881073241479, 'epoch': 1.27}                                                                                                       
{'loss': 0.948, 'learning_rate': 0.0002713705583756345, 'epoch': 1.27}                                                                                                        
{'loss': 1.0055, 'learning_rate': 0.0002711530094271211, 'epoch': 1.28}                                                                                                       
{'loss': 0.8863, 'learning_rate': 0.00027093546047860764, 'epoch': 1.29}                                                                                                      
{'loss': 0.8693, 'learning_rate': 0.00027071791153009426, 'epoch': 1.29}                                                                                                      
{'loss': 0.9394, 'learning_rate': 0.0002705003625815808, 'epoch': 1.3}                                                                                                        
{'loss': 1.0003, 'learning_rate': 0.00027028281363306744, 'epoch': 1.31}                                                                                                      
{'loss': 0.9109, 'learning_rate': 0.000270065264684554, 'epoch': 1.32}                                                                                                        
{'loss': 0.8669, 'learning_rate': 0.00026984771573604056, 'epoch': 1.32}                                                                                                      
{'loss': 0.8688, 'learning_rate': 0.0002696301667875272, 'epoch': 1.33}                                                                                                       
 13%|█████████████████                                                                                                               | 1900/14290 [2:30:30<3:48:39,  1.11s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.6591372489929199, 'eval_wer': 0.8419147416051441, 'eval_cer': 0.23296817257477181, 'eval_runtime': 391.669, 'eval_samples_per_second': 24.585, 'eval_steps_per_second': 3.074, 'epoch': 1.33}                                                                                                                                               
{'loss': 0.8823, 'learning_rate': 0.00026941261783901374, 'epoch': 1.34}                                                                                                      
{'loss': 0.9744, 'learning_rate': 0.00026919506889050036, 'epoch': 1.34}                                                                                                      
{'loss': 0.9677, 'learning_rate': 0.0002689775199419869, 'epoch': 1.35}                                                                                                       
{'loss': 0.8167, 'learning_rate': 0.0002687599709934735, 'epoch': 1.36}                                                                                                       
{'loss': 0.8224, 'learning_rate': 0.0002685424220449601, 'epoch': 1.36}                                                                                                       
{'loss': 0.857, 'learning_rate': 0.00026832487309644666, 'epoch': 1.37}                                                                                                       
{'loss': 0.9132, 'learning_rate': 0.0002681073241479333, 'epoch': 1.38}                                                                                                       
{'loss': 0.9221, 'learning_rate': 0.00026788977519941984, 'epoch': 1.39}                                                                                                      
{'loss': 0.7778, 'learning_rate': 0.0002676722262509064, 'epoch': 1.39}                                                                                                       
{'loss': 0.8146, 'learning_rate': 0.000267454677302393, 'epoch': 1.4}                                                                                                         
 14%|█████████████████▉                                                                                                              | 2000/14290 [2:38:43<3:48:48,  1.12s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.6396724581718445, 'eval_wer': 0.8237556561085972, 'eval_cer': 0.22388982346622346, 'eval_runtime': 392.7205, 'eval_samples_per_second': 24.519, 'eval_steps_per_second': 3.066, 'epoch': 1.4}                                                                                                                                               
{'loss': 0.8722, 'learning_rate': 0.0002672371283538796, 'epoch': 1.41}                                                                                                       
{'loss': 0.8565, 'learning_rate': 0.0002670195794053662, 'epoch': 1.41}                                                                                                       
{'loss': 0.9125, 'learning_rate': 0.00026680203045685276, 'epoch': 1.42}                                                                                                      
{'loss': 0.7552, 'learning_rate': 0.0002665844815083394, 'epoch': 1.43}                                                                                                       
{'loss': 0.8171, 'learning_rate': 0.00026636693255982594, 'epoch': 1.43}                                                                                                      
{'loss': 0.8552, 'learning_rate': 0.0002661493836113125, 'epoch': 1.44}                                                                                                       
{'loss': 0.8684, 'learning_rate': 0.0002659318346627991, 'epoch': 1.45}                                                                                                       
{'loss': 0.9103, 'learning_rate': 0.0002657142857142857, 'epoch': 1.46}                                                                                                       
{'loss': 0.7437, 'learning_rate': 0.0002654967367657723, 'epoch': 1.46}                                                                                                       
{'loss': 0.7545, 'learning_rate': 0.00026527918781725886, 'epoch': 1.47}                                                                                                      
 15%|██████████████████▊                                                                                                             | 2100/14290 [2:46:59<3:43:13,  1.10s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5893750786781311, 'eval_wer': 0.7844486782567278, 'eval_cer': 0.2060979482086517, 'eval_runtime': 395.5822, 'eval_samples_per_second': 24.341, 'eval_steps_per_second': 3.044, 'epoch': 1.47}                                                                                                                                               
{'loss': 0.7649, 'learning_rate': 0.0002650616388687454, 'epoch': 1.48}                                                                                                       
{'loss': 0.843, 'learning_rate': 0.00026484408992023204, 'epoch': 1.48}                                                                                                       
{'loss': 0.8264, 'learning_rate': 0.0002646265409717186, 'epoch': 1.49}                                                                                                       
{'loss': 0.7247, 'learning_rate': 0.0002644089920232052, 'epoch': 1.5}                                                                                                        
{'loss': 0.742, 'learning_rate': 0.0002641914430746918, 'epoch': 1.5}                                                                                                         
{'loss': 0.7856, 'learning_rate': 0.00026397389412617834, 'epoch': 1.51}                                                                                                      
{'loss': 0.8223, 'learning_rate': 0.00026375634517766496, 'epoch': 1.52}                                                                                                      
{'loss': 0.7803, 'learning_rate': 0.0002635387962291515, 'epoch': 1.53}                                                                                                       
{'loss': 0.7, 'learning_rate': 0.00026332124728063814, 'epoch': 1.53}                                                                                                         
{'loss': 0.7736, 'learning_rate': 0.0002631036983321247, 'epoch': 1.54}                                                                                                       
 15%|███████████████████▋                                                                                                            | 2200/14290 [2:55:17<3:44:33,  1.11s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5575834512710571, 'eval_wer': 0.76162181471779, 'eval_cer': 0.19472087665605978, 'eval_runtime': 396.1291, 'eval_samples_per_second': 24.308, 'eval_steps_per_second': 3.039, 'epoch': 1.54}                                                                                                                                                
{'loss': 0.7921, 'learning_rate': 0.00026288614938361127, 'epoch': 1.55}                                                                                                      
{'loss': 0.8051, 'learning_rate': 0.0002626686004350979, 'epoch': 1.55}                                                                                                       
{'loss': 0.8425, 'learning_rate': 0.00026245105148658444, 'epoch': 1.56}                                                                                                      
{'loss': 0.676, 'learning_rate': 0.00026223350253807106, 'epoch': 1.57}                                                                                                       
{'loss': 0.7147, 'learning_rate': 0.0002620159535895576, 'epoch': 1.57}                                                                                                       
{'loss': 0.7645, 'learning_rate': 0.00026179840464104424, 'epoch': 1.58}                                                                                                      
{'loss': 0.8, 'learning_rate': 0.0002615808556925308, 'epoch': 1.59}                                                                                                          
{'loss': 0.8248, 'learning_rate': 0.00026136330674401736, 'epoch': 1.6}                                                                                                       
{'loss': 0.703, 'learning_rate': 0.000261145757795504, 'epoch': 1.6}                                                                                                          
{'loss': 0.676, 'learning_rate': 0.00026092820884699054, 'epoch': 1.61}                                                                                                       
 16%|████████████████████▌                                                                                                           | 2300/14290 [3:03:37<3:45:24,  1.13s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5318080186843872, 'eval_wer': 0.7409502262443439, 'eval_cer': 0.18945796766587622, 'eval_runtime': 395.3626, 'eval_samples_per_second': 24.355, 'eval_steps_per_second': 3.045, 'epoch': 1.61}                                                                                                                                              
{'loss': 0.7162, 'learning_rate': 0.00026071065989847716, 'epoch': 1.62}                                                                                                      
{'loss': 0.7392, 'learning_rate': 0.0002604931109499637, 'epoch': 1.62}                                                                                                       
{'loss': 0.7933, 'learning_rate': 0.0002602755620014503, 'epoch': 1.63}                                                                                                       
{'loss': 0.6522, 'learning_rate': 0.0002600580130529369, 'epoch': 1.64}                                                                                                       
{'loss': 0.6606, 'learning_rate': 0.00025984046410442346, 'epoch': 1.64}                                                                                                      
{'loss': 0.695, 'learning_rate': 0.0002596229151559101, 'epoch': 1.65}                                                                                                        
{'loss': 0.7622, 'learning_rate': 0.00025940536620739664, 'epoch': 1.66}                                                                                                      
{'loss': 0.7525, 'learning_rate': 0.0002591878172588832, 'epoch': 1.67}                                                                                                       
{'loss': 0.6855, 'learning_rate': 0.0002589702683103698, 'epoch': 1.67}                                                                                                       
{'loss': 0.6376, 'learning_rate': 0.0002587527193618564, 'epoch': 1.68}                                                                                                       
 17%|█████████████████████▍                                                                                                          | 2400/14290 [3:11:55<3:43:36,  1.13s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5054419040679932, 'eval_wer': 0.7233507978090021, 'eval_cer': 0.18174770465554632, 'eval_runtime': 395.2155, 'eval_samples_per_second': 24.364, 'eval_steps_per_second': 3.046, 'epoch': 1.68}                                                                                                                                              
{'loss': 0.7313, 'learning_rate': 0.000258535170413343, 'epoch': 1.69}                                                                                                        
{'loss': 0.7726, 'learning_rate': 0.00025831762146482956, 'epoch': 1.69}                                                                                                      
{'loss': 0.7716, 'learning_rate': 0.0002581000725163161, 'epoch': 1.7}                                                                                                        
{'loss': 0.6082, 'learning_rate': 0.00025788252356780274, 'epoch': 1.71}                                                                                                      
{'loss': 0.6734, 'learning_rate': 0.0002576649746192893, 'epoch': 1.71}                                                                                                       
{'loss': 0.722, 'learning_rate': 0.0002574474256707759, 'epoch': 1.72}                                                                                                        
{'loss': 0.7125, 'learning_rate': 0.0002572298767222625, 'epoch': 1.73}                                                                                                       
{'loss': 0.8221, 'learning_rate': 0.00025701232777374905, 'epoch': 1.74}                                                                                                      
{'loss': 0.6552, 'learning_rate': 0.00025679477882523566, 'epoch': 1.74}                                                                                                      
{'loss': 0.6098, 'learning_rate': 0.0002565772298767222, 'epoch': 1.75}                                                                                                       
 17%|██████████████████████▍                                                                                                         | 2500/14290 [3:20:14<3:40:19,  1.12s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.481427401304245, 'eval_wer': 0.6966896880209573, 'eval_cer': 0.17468601579548296, 'eval_runtime': 396.2656, 'eval_samples_per_second': 24.299, 'eval_steps_per_second': 3.038, 'epoch': 1.75}                                                                                                                                               
{'loss': 0.6411, 'learning_rate': 0.00025635968092820884, 'epoch': 1.76}                                                                                                      
{'loss': 0.7383, 'learning_rate': 0.0002561421319796954, 'epoch': 1.76}                                                                                                       
{'loss': 0.8407, 'learning_rate': 0.000255924583031182, 'epoch': 1.77}                                                                                                        
{'loss': 0.6205, 'learning_rate': 0.0002557070340826686, 'epoch': 1.78}                                                                                                       
{'loss': 0.6342, 'learning_rate': 0.00025548948513415514, 'epoch': 1.78}                                                                                                      
{'loss': 0.7052, 'learning_rate': 0.00025527193618564176, 'epoch': 1.79}                                                                                                      
{'loss': 0.7294, 'learning_rate': 0.0002550543872371283, 'epoch': 1.8}                                                                                                        
{'loss': 0.7759, 'learning_rate': 0.00025483683828861494, 'epoch': 1.81}                                                                                                      
{'loss': 0.6343, 'learning_rate': 0.0002546192893401015, 'epoch': 1.81}                                                                                                       
{'loss': 0.6729, 'learning_rate': 0.00025440174039158806, 'epoch': 1.82}                                                                                                      
 18%|███████████████████████▎                                                                                                        | 2600/14290 [3:28:34<3:33:52,  1.10s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.46193966269493103, 'eval_wer': 0.6845082162419623, 'eval_cer': 0.17053277664052102, 'eval_runtime': 396.606, 'eval_samples_per_second': 24.279, 'eval_steps_per_second': 3.036, 'epoch': 1.82}                                                                                                                                              
{'loss': 0.6664, 'learning_rate': 0.0002541841914430747, 'epoch': 1.83}                                                                                                       
{'loss': 0.7035, 'learning_rate': 0.00025396664249456124, 'epoch': 1.83}                                                                                                      
{'loss': 0.6962, 'learning_rate': 0.00025374909354604786, 'epoch': 1.84}                                                                                                      
{'loss': 0.5792, 'learning_rate': 0.0002535315445975344, 'epoch': 1.85}                                                                                                       
{'loss': 0.6515, 'learning_rate': 0.000253313995649021, 'epoch': 1.85}                                                                                                        
{'loss': 0.6699, 'learning_rate': 0.0002530964467005076, 'epoch': 1.86}                                                                                                       
{'loss': 0.668, 'learning_rate': 0.00025287889775199416, 'epoch': 1.87}                                                                                                       
{'loss': 0.7311, 'learning_rate': 0.0002526613488034808, 'epoch': 1.88}                                                                                                       
{'loss': 0.5678, 'learning_rate': 0.00025244379985496734, 'epoch': 1.88}                                                                                                      
{'loss': 0.5962, 'learning_rate': 0.0002522262509064539, 'epoch': 1.89}                                                                                                       
 19%|████████████████████████▏                                                                                                       | 2700/14290 [3:36:55<3:38:15,  1.13s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.4444841146469116, 'eval_wer': 0.6676113360323886, 'eval_cer': 0.1643189633623165, 'eval_runtime': 397.1438, 'eval_samples_per_second': 24.246, 'eval_steps_per_second': 3.032, 'epoch': 1.89}                                                                                                                                               
{'loss': 0.7062, 'learning_rate': 0.0002520087019579405, 'epoch': 1.9}                                                                                                        
{'loss': 0.6983, 'learning_rate': 0.0002517911530094271, 'epoch': 1.9}                                                                                                        
{'loss': 0.8355, 'learning_rate': 0.0002515736040609137, 'epoch': 1.91}                                                                                                       
{'loss': 0.6109, 'learning_rate': 0.00025135605511240026, 'epoch': 1.92}                                                                                                      
{'loss': 0.6129, 'learning_rate': 0.0002511385061638869, 'epoch': 1.92}                                                                                                       
{'loss': 0.6708, 'learning_rate': 0.00025092095721537344, 'epoch': 1.93}                                                                                                      
{'loss': 0.6727, 'learning_rate': 0.00025070340826686, 'epoch': 1.94}                                                                                                         
{'loss': 0.7288, 'learning_rate': 0.0002504858593183466, 'epoch': 1.95}                                                                                                       
{'loss': 0.5647, 'learning_rate': 0.0002502683103698332, 'epoch': 1.95}                                                                                                       
{'loss': 0.6285, 'learning_rate': 0.0002500507614213198, 'epoch': 1.96}                                                                                                       
 20%|█████████████████████████                                                                                                       | 2800/14290 [3:45:14<3:30:27,  1.10s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.42640209197998047, 'eval_wer': 0.6524291497975708, 'eval_cer': 0.15972489646459528, 'eval_runtime': 395.1611, 'eval_samples_per_second': 24.367, 'eval_steps_per_second': 3.047, 'epoch': 1.96}                                                                                                                                             
{'loss': 0.636, 'learning_rate': 0.00024983321247280636, 'epoch': 1.97}                                                                                                       
{'loss': 0.6723, 'learning_rate': 0.0002496156635242929, 'epoch': 1.97}                                                                                                       
{'loss': 0.7047, 'learning_rate': 0.00024939811457577954, 'epoch': 1.98}                                                                                                      
{'loss': 0.607, 'learning_rate': 0.0002491805656272661, 'epoch': 1.99}                                                                                                        
{'loss': 0.5912, 'learning_rate': 0.0002489630166787527, 'epoch': 1.99}                                                                                                       
 20%|█████████████████████████▌                                                                                                      | 2856/14290 [3:52:40<2:08:06,  1.49it/s]Saving model checkpoint to ./russian_augmented/checkpoint-2856
Configuration saved in ./russian_augmented/checkpoint-2856/config.json
Model weights saved in ./russian_augmented/checkpoint-2856/pytorch_model.bin
Feature extractor saved in ./russian_augmented/checkpoint-2856/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.6871, 'learning_rate': 0.0002487454677302393, 'epoch': 2.0}                                                                                                        
{'loss': 0.5248, 'learning_rate': 0.00024852791878172585, 'epoch': 2.01}                                                                                                      
{'loss': 0.5195, 'learning_rate': 0.00024831036983321246, 'epoch': 2.02}                                                                                                      
{'loss': 0.5992, 'learning_rate': 0.000248092820884699, 'epoch': 2.02}                                                                                                        
{'loss': 0.5963, 'learning_rate': 0.00024787527193618564, 'epoch': 2.03}                                                                                                      
 20%|█████████████████████████▉                                                                                                      | 2900/14290 [3:53:30<2:11:08,  1.45it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.43782615661621094, 'eval_wer': 0.6550726363419862, 'eval_cer': 0.1606960686948121, 'eval_runtime': 393.936, 'eval_samples_per_second': 24.443, 'eval_steps_per_second': 3.056, 'epoch': 2.03}                                                                                                                                               
{'loss': 0.6287, 'learning_rate': 0.0002476577229876722, 'epoch': 2.04}                                                                                                       
{'loss': 0.4734, 'learning_rate': 0.00024744017403915877, 'epoch': 2.04}                                                                                                      
{'loss': 0.5377, 'learning_rate': 0.0002472226250906454, 'epoch': 2.05}                                                                                                       
{'loss': 0.5645, 'learning_rate': 0.00024700507614213194, 'epoch': 2.06}                                                                                                      
{'loss': 0.6098, 'learning_rate': 0.00024678752719361856, 'epoch': 2.06}                                                                                                      
{'loss': 0.6071, 'learning_rate': 0.0002465699782451051, 'epoch': 2.07}                                                                                                       
{'loss': 0.483, 'learning_rate': 0.00024635242929659174, 'epoch': 2.08}                                                                                                       
{'loss': 0.5321, 'learning_rate': 0.0002461348803480783, 'epoch': 2.09}                                                                                                       
{'loss': 0.5551, 'learning_rate': 0.00024591733139956486, 'epoch': 2.09}                                                                                                      
{'loss': 0.6066, 'learning_rate': 0.0002456997824510515, 'epoch': 2.1}                                                                                                        
 21%|██████████████████████████▊                                                                                                     | 3000/14290 [4:01:48<2:13:00,  1.41it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.41796088218688965, 'eval_wer': 0.6372588711598, 'eval_cer': 0.1549399731111967, 'eval_runtime': 394.5224, 'eval_samples_per_second': 24.407, 'eval_steps_per_second': 3.052, 'epoch': 2.1}                                                                                                                                                  
{'loss': 0.6502, 'learning_rate': 0.00024548223350253804, 'epoch': 2.11}                                                                                                      
{'loss': 0.5328, 'learning_rate': 0.00024526468455402466, 'epoch': 2.11}                                                                                                      
{'loss': 0.5526, 'learning_rate': 0.0002450471356055112, 'epoch': 2.12}                                                                                                       
{'loss': 0.5292, 'learning_rate': 0.0002448295866569978, 'epoch': 2.13}                                                                                                       
{'loss': 0.5575, 'learning_rate': 0.0002446120377084844, 'epoch': 2.13}                                                                                                       
{'loss': 0.6388, 'learning_rate': 0.00024439448875997096, 'epoch': 2.14}                                                                                                      
{'loss': 0.4638, 'learning_rate': 0.0002441769398114576, 'epoch': 2.15}                                                                                                       
{'loss': 0.4955, 'learning_rate': 0.00024395939086294412, 'epoch': 2.16}                                                                                                      
{'loss': 0.5693, 'learning_rate': 0.00024374184191443073, 'epoch': 2.16}                                                                                                      
{'loss': 0.6379, 'learning_rate': 0.00024352429296591732, 'epoch': 2.17}                                                                                                      
 22%|███████████████████████████▊                                                                                                    | 3100/14290 [4:10:06<2:11:15,  1.42it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.4112088084220886, 'eval_wer': 0.6257918552036199, 'eval_cer': 0.15254328894653993, 'eval_runtime': 394.0549, 'eval_samples_per_second': 24.436, 'eval_steps_per_second': 3.055, 'epoch': 2.17}                                                                                                                                              
{'loss': 0.5805, 'learning_rate': 0.00024330674401740388, 'epoch': 2.18}                                                                                                      
{'loss': 0.5115, 'learning_rate': 0.00024308919506889047, 'epoch': 2.18}                                                                                                      
{'loss': 0.5252, 'learning_rate': 0.00024287164612037706, 'epoch': 2.19}                                                                                                      
{'loss': 0.5475, 'learning_rate': 0.00024265409717186365, 'epoch': 2.2}                                                                                                       
{'loss': 0.5504, 'learning_rate': 0.00024243654822335024, 'epoch': 2.2}                                                                                                       
{'loss': 0.6035, 'learning_rate': 0.0002422189992748368, 'epoch': 2.21}                                                                                                       
{'loss': 0.4964, 'learning_rate': 0.00024200145032632342, 'epoch': 2.22}                                                                                                      
{'loss': 0.5231, 'learning_rate': 0.00024178390137780998, 'epoch': 2.23}                                                                                                      
{'loss': 0.5541, 'learning_rate': 0.00024156635242929657, 'epoch': 2.23}                                                                                                      
{'loss': 0.6035, 'learning_rate': 0.00024134880348078316, 'epoch': 2.24}                                                                                                      
 22%|████████████████████████████▋                                                                                                   | 3200/14290 [4:18:24<2:12:43,  1.39it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.4021724760532379, 'eval_wer': 0.6164443915217909, 'eval_cer': 0.15101474830593783, 'eval_runtime': 399.1124, 'eval_samples_per_second': 24.126, 'eval_steps_per_second': 3.017, 'epoch': 2.24}                                                                                                                                              
{'loss': 0.557, 'learning_rate': 0.00024113125453226972, 'epoch': 2.25}                                                                                                       
{'loss': 0.5, 'learning_rate': 0.00024091370558375634, 'epoch': 2.25}                                                                                                         
{'loss': 0.4431, 'learning_rate': 0.0002406961566352429, 'epoch': 2.26}                                                                                                       
{'loss': 0.5147, 'learning_rate': 0.0002404786076867295, 'epoch': 2.27}                                                                                                       
{'loss': 0.5773, 'learning_rate': 0.00024026105873821606, 'epoch': 2.27}                                                                                                      
{'loss': 0.5612, 'learning_rate': 0.00024004350978970267, 'epoch': 2.28}                                                                                                      
{'loss': 0.5119, 'learning_rate': 0.00023982596084118926, 'epoch': 2.29}                                                                                                      
{'loss': 0.4966, 'learning_rate': 0.00023960841189267582, 'epoch': 2.3}                                                                                                       
{'loss': 0.52, 'learning_rate': 0.0002393908629441624, 'epoch': 2.3}                                                                                                          
{'loss': 0.5444, 'learning_rate': 0.00023917331399564898, 'epoch': 2.31}                                                                                                      
 23%|█████████████████████████████▌                                                                                                  | 3300/14290 [4:26:47<2:25:44,  1.26it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.39946863055229187, 'eval_wer': 0.6122648249583235, 'eval_cer': 0.14960612632332773, 'eval_runtime': 396.3478, 'eval_samples_per_second': 24.294, 'eval_steps_per_second': 3.038, 'epoch': 2.31}                                                                                                                                             
{'loss': 0.5331, 'learning_rate': 0.0002389557650471356, 'epoch': 2.32}                                                                                                       
{'loss': 0.5009, 'learning_rate': 0.00023873821609862218, 'epoch': 2.32}                                                                                                      
{'loss': 0.5121, 'learning_rate': 0.00023852066715010874, 'epoch': 2.33}                                                                                                      
{'loss': 0.5305, 'learning_rate': 0.00023830311820159533, 'epoch': 2.34}                                                                                                      
{'loss': 0.5933, 'learning_rate': 0.0002380855692530819, 'epoch': 2.34}                                                                                                       
{'loss': 0.5991, 'learning_rate': 0.0002378680203045685, 'epoch': 2.35}                                                                                                       
{'loss': 0.4121, 'learning_rate': 0.0002376504713560551, 'epoch': 2.36}                                                                                                       
{'loss': 0.4984, 'learning_rate': 0.00023743292240754166, 'epoch': 2.37}                                                                                                      
{'loss': 0.555, 'learning_rate': 0.00023721537345902828, 'epoch': 2.37}                                                                                                       
{'loss': 0.5758, 'learning_rate': 0.00023699782451051484, 'epoch': 2.38}                                                                                                      
 24%|██████████████████████████████▍                                                                                                 | 3400/14290 [4:35:08<2:17:13,  1.32it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.37796124815940857, 'eval_wer': 0.5996308644915456, 'eval_cer': 0.1425140355499706, 'eval_runtime': 395.2268, 'eval_samples_per_second': 24.363, 'eval_steps_per_second': 3.046, 'epoch': 2.38}                                                                                                                                              
{'loss': 0.628, 'learning_rate': 0.00023678027556200143, 'epoch': 2.39}                                                                                                       
{'loss': 0.4205, 'learning_rate': 0.00023656272661348802, 'epoch': 2.39}                                                                                                      
{'loss': 0.4628, 'learning_rate': 0.00023634517766497458, 'epoch': 2.4}                                                                                                       
{'loss': 0.5217, 'learning_rate': 0.0002361276287164612, 'epoch': 2.41}                                                                                                       
{'loss': 0.5611, 'learning_rate': 0.00023591007976794776, 'epoch': 2.41}                                                                                                      
{'loss': 0.5359, 'learning_rate': 0.00023569253081943435, 'epoch': 2.42}                                                                                                      
{'loss': 0.4458, 'learning_rate': 0.00023547498187092092, 'epoch': 2.43}                                                                                                      
{'loss': 0.4921, 'learning_rate': 0.0002352574329224075, 'epoch': 2.44}                                                                                                       
{'loss': 0.5793, 'learning_rate': 0.00023503988397389412, 'epoch': 2.44}                                                                                                      
{'loss': 0.5289, 'learning_rate': 0.00023482233502538068, 'epoch': 2.45}                                                                                                      
 24%|███████████████████████████████▎                                                                                                | 3500/14290 [4:43:26<2:11:38,  1.37it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3921608626842499, 'eval_wer': 0.5919028340080972, 'eval_cer': 0.14452225082254067, 'eval_runtime': 394.312, 'eval_samples_per_second': 24.42, 'eval_steps_per_second': 3.053, 'epoch': 2.45}                                                                                                                                                
{'loss': 0.5951, 'learning_rate': 0.00023460478607686727, 'epoch': 2.46}                                                                                                      
{'loss': 0.4558, 'learning_rate': 0.00023438723712835384, 'epoch': 2.46}                                                                                                      
{'loss': 0.4676, 'learning_rate': 0.00023416968817984045, 'epoch': 2.47}                                                                                                      
{'loss': 0.4849, 'learning_rate': 0.00023395213923132704, 'epoch': 2.48}                                                                                                      
{'loss': 0.5706, 'learning_rate': 0.0002337345902828136, 'epoch': 2.48}                                                                                                       
{'loss': 0.5441, 'learning_rate': 0.0002335170413343002, 'epoch': 2.49}                                                                                                       
{'loss': 0.4339, 'learning_rate': 0.00023329949238578676, 'epoch': 2.5}                                                                                                       
{'loss': 0.4638, 'learning_rate': 0.00023308194343727337, 'epoch': 2.51}                                                                                                      
{'loss': 0.4679, 'learning_rate': 0.00023286439448875996, 'epoch': 2.51}                                                                                                      
{'loss': 0.5324, 'learning_rate': 0.00023264684554024652, 'epoch': 2.52}                                                                                                      
 25%|████████████████████████████████▏                                                                                               | 3600/14290 [4:51:42<2:07:44,  1.39it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.368081659078598, 'eval_wer': 0.5837818528221005, 'eval_cer': 0.1392475188660762, 'eval_runtime': 397.1313, 'eval_samples_per_second': 24.246, 'eval_steps_per_second': 3.032, 'epoch': 2.52}                                                                                                                                                
{'loss': 0.4963, 'learning_rate': 0.00023242929659173314, 'epoch': 2.53}                                                                                                      
{'loss': 0.4712, 'learning_rate': 0.0002322117476432197, 'epoch': 2.53}                                                                                                       
{'loss': 0.4777, 'learning_rate': 0.0002319941986947063, 'epoch': 2.54}                                                                                                       
{'loss': 0.5275, 'learning_rate': 0.00023177664974619288, 'epoch': 2.55}                                                                                                      
{'loss': 0.4977, 'learning_rate': 0.00023155910079767944, 'epoch': 2.55}                                                                                                      
{'loss': 0.5576, 'learning_rate': 0.00023134155184916606, 'epoch': 2.56}                                                                                                      
{'loss': 0.4288, 'learning_rate': 0.00023112400290065262, 'epoch': 2.57}                                                                                                      
{'loss': 0.4874, 'learning_rate': 0.0002309064539521392, 'epoch': 2.58}                                                                                                       
{'loss': 0.5021, 'learning_rate': 0.00023068890500362578, 'epoch': 2.58}                                                                                                      
{'loss': 0.5757, 'learning_rate': 0.00023047135605511236, 'epoch': 2.59}                                                                                                      
 26%|█████████████████████████████████▏                                                                                              | 3700/14290 [5:00:02<2:06:58,  1.39it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.35869213938713074, 'eval_wer': 0.5770064301024054, 'eval_cer': 0.14011735138531384, 'eval_runtime': 394.6396, 'eval_samples_per_second': 24.399, 'eval_steps_per_second': 3.051, 'epoch': 2.59}                                                                                                                                             
{'loss': 0.5993, 'learning_rate': 0.00023025380710659898, 'epoch': 2.6}                                                                                                       
{'loss': 0.4483, 'learning_rate': 0.00023003625815808554, 'epoch': 2.6}                                                                                                       
{'loss': 0.4628, 'learning_rate': 0.00022981870920957213, 'epoch': 2.61}                                                                                                      
{'loss': 0.5232, 'learning_rate': 0.0002296011602610587, 'epoch': 2.62}                                                                                                       
{'loss': 0.5352, 'learning_rate': 0.0002293836113125453, 'epoch': 2.62}                                                                                                       
{'loss': 0.517, 'learning_rate': 0.0002291660623640319, 'epoch': 2.63}                                                                                                        
{'loss': 0.487, 'learning_rate': 0.00022894851341551846, 'epoch': 2.64}                                                                                                       
{'loss': 0.4483, 'learning_rate': 0.00022873096446700505, 'epoch': 2.65}                                                                                                      
{'loss': 0.4826, 'learning_rate': 0.00022851341551849162, 'epoch': 2.65}                                                                                                      
{'loss': 0.6282, 'learning_rate': 0.00022829586656997823, 'epoch': 2.66}                                                                                                      
 27%|██████████████████████████████████                                                                                              | 3800/14290 [5:08:21<2:08:38,  1.36it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.35551780462265015, 'eval_wer': 0.5709454632055251, 'eval_cer': 0.1378743657823088, 'eval_runtime': 396.174, 'eval_samples_per_second': 24.305, 'eval_steps_per_second': 3.039, 'epoch': 2.66}                                                                                                                                               
{'loss': 0.551, 'learning_rate': 0.00022807831762146482, 'epoch': 2.67}                                                                                                       
{'loss': 0.4455, 'learning_rate': 0.00022786076867295138, 'epoch': 2.67}                                                                                                      
{'loss': 0.441, 'learning_rate': 0.00022764321972443797, 'epoch': 2.68}                                                                                                       
{'loss': 0.4653, 'learning_rate': 0.00022742567077592456, 'epoch': 2.69}                                                                                                      
{'loss': 0.4771, 'learning_rate': 0.00022720812182741115, 'epoch': 2.69}                                                                                                      
{'loss': 0.5341, 'learning_rate': 0.00022699057287889774, 'epoch': 2.7}                                                                                                       
{'loss': 0.4043, 'learning_rate': 0.0002267730239303843, 'epoch': 2.71}                                                                                                       
{'loss': 0.4523, 'learning_rate': 0.00022655547498187092, 'epoch': 2.72}                                                                                                      
{'loss': 0.486, 'learning_rate': 0.00022633792603335748, 'epoch': 2.72}                                                                                                       
{'loss': 0.4849, 'learning_rate': 0.00022612037708484407, 'epoch': 2.73}                                                                                                      
 27%|██████████████████████████████████▉                                                                                             | 3900/14290 [5:16:41<2:07:45,  1.36it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.35488948225975037, 'eval_wer': 0.5657418432960228, 'eval_cer': 0.1355063945357628, 'eval_runtime': 396.6649, 'eval_samples_per_second': 24.275, 'eval_steps_per_second': 3.035, 'epoch': 2.73}                                                                                                                                              
{'loss': 0.5402, 'learning_rate': 0.00022590282813633064, 'epoch': 2.74}                                                                                                      
{'loss': 0.4353, 'learning_rate': 0.00022568527918781722, 'epoch': 2.74}                                                                                                      
{'loss': 0.4566, 'learning_rate': 0.00022546773023930384, 'epoch': 2.75}                                                                                                      
{'loss': 0.504, 'learning_rate': 0.0002252501812907904, 'epoch': 2.76}                                                                                                        
{'loss': 0.5774, 'learning_rate': 0.000225032632342277, 'epoch': 2.76}                                                                                                        
{'loss': 0.5388, 'learning_rate': 0.00022481508339376356, 'epoch': 2.77}                                                                                                      
{'loss': 0.4077, 'learning_rate': 0.00022459753444525017, 'epoch': 2.78}                                                                                                      
{'loss': 0.4063, 'learning_rate': 0.00022437998549673676, 'epoch': 2.79}                                                                                                      
{'loss': 0.4912, 'learning_rate': 0.00022416243654822332, 'epoch': 2.79}                                                                                                      
{'loss': 0.4972, 'learning_rate': 0.0002239448875997099, 'epoch': 2.8}                                                                                                        
 28%|███████████████████████████████████▊                                                                                            | 4000/14290 [5:25:02<2:06:28,  1.36it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.34809964895248413, 'eval_wer': 0.560764467730412, 'eval_cer': 0.1331840261591574, 'eval_runtime': 396.4373, 'eval_samples_per_second': 24.289, 'eval_steps_per_second': 3.037, 'epoch': 2.8}                                                                                                                                                
{'loss': 0.5965, 'learning_rate': 0.00022372733865119648, 'epoch': 2.81}                                                                                                      
{'loss': 0.4518, 'learning_rate': 0.0002235097897026831, 'epoch': 2.81}                                                                                                       
{'loss': 0.4429, 'learning_rate': 0.00022329224075416968, 'epoch': 2.82}                                                                                                      
{'loss': 0.4846, 'learning_rate': 0.00022307469180565624, 'epoch': 2.83}                                                                                                      
{'loss': 0.5161, 'learning_rate': 0.00022285714285714283, 'epoch': 2.83}                                                                                                      
{'loss': 0.5224, 'learning_rate': 0.00022263959390862942, 'epoch': 2.84}                                                                                                      
{'loss': 0.4205, 'learning_rate': 0.000222422044960116, 'epoch': 2.85}                                                                                                        
{'loss': 0.4444, 'learning_rate': 0.0002222044960116026, 'epoch': 2.86}                                                                                                       
{'loss': 0.4884, 'learning_rate': 0.00022198694706308916, 'epoch': 2.86}                                                                                                      
{'loss': 0.5401, 'learning_rate': 0.00022176939811457578, 'epoch': 2.87}                                                                                                      
 29%|████████████████████████████████████▋                                                                                           | 4100/14290 [5:33:24<2:03:45,  1.37it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3405711352825165, 'eval_wer': 0.5587520838294832, 'eval_cer': 0.13342555247032437, 'eval_runtime': 398.9955, 'eval_samples_per_second': 24.133, 'eval_steps_per_second': 3.018, 'epoch': 2.87}                                                                                                                                              
{'loss': 0.5855, 'learning_rate': 0.00022155184916606234, 'epoch': 2.88}                                                                                                      
{'loss': 0.4119, 'learning_rate': 0.00022133430021754893, 'epoch': 2.88}                                                                                                      
{'loss': 0.4517, 'learning_rate': 0.0002211167512690355, 'epoch': 2.89}                                                                                                       
{'loss': 0.4596, 'learning_rate': 0.00022089920232052208, 'epoch': 2.9}                                                                                                       
{'loss': 0.5405, 'learning_rate': 0.0002206816533720087, 'epoch': 2.9}                                                                                                        
{'loss': 0.5064, 'learning_rate': 0.00022046410442349526, 'epoch': 2.91}                                                                                                      
{'loss': 0.4189, 'learning_rate': 0.00022024655547498185, 'epoch': 2.92}                                                                                                      
{'loss': 0.4249, 'learning_rate': 0.00022002900652646842, 'epoch': 2.93}                                                                                                      
{'loss': 0.4984, 'learning_rate': 0.00021981145757795503, 'epoch': 2.93}                                                                                                      
{'loss': 0.4865, 'learning_rate': 0.00021959390862944162, 'epoch': 2.94}                                                                                                      
 29%|█████████████████████████████████████▌                                                                                          | 4200/14290 [5:41:47<2:07:23,  1.32it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.339950829744339, 'eval_wer': 0.5529411764705883, 'eval_cer': 0.13229054770735793, 'eval_runtime': 396.5195, 'eval_samples_per_second': 24.284, 'eval_steps_per_second': 3.036, 'epoch': 2.94}                                                                                                                                               
{'loss': 0.4965, 'learning_rate': 0.00021937635968092818, 'epoch': 2.95}                                                                                                      
{'loss': 0.4175, 'learning_rate': 0.00021915881073241477, 'epoch': 2.95}                                                                                                      
{'loss': 0.4413, 'learning_rate': 0.00021894126178390134, 'epoch': 2.96}                                                                                                      
{'loss': 0.4913, 'learning_rate': 0.00021872371283538795, 'epoch': 2.97}                                                                                                      
{'loss': 0.4974, 'learning_rate': 0.00021850616388687454, 'epoch': 2.97}                                                                                                      
{'loss': 0.5473, 'learning_rate': 0.0002182886149383611, 'epoch': 2.98}                                                                                                       
{'loss': 0.4442, 'learning_rate': 0.0002180710659898477, 'epoch': 2.99}                                                                                                       
{'loss': 0.4773, 'learning_rate': 0.00021785351704133426, 'epoch': 3.0}                                                                                                       
 30%|██████████████████████████████████████▎                                                                                         | 4284/14290 [5:49:47<1:59:45,  1.39it/s]Saving model checkpoint to ./russian_augmented/checkpoint-4284
Configuration saved in ./russian_augmented/checkpoint-4284/config.json
Model weights saved in ./russian_augmented/checkpoint-4284/pytorch_model.bin
Feature extractor saved in ./russian_augmented/checkpoint-4284/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.5475, 'learning_rate': 0.00021763596809282087, 'epoch': 3.0}                                                                                                       
{'loss': 0.3847, 'learning_rate': 0.00021741841914430746, 'epoch': 3.01}                                                                                                      
 30%|██████████████████████████████████████▌                                                                                         | 4300/14290 [5:50:10<3:42:24,  1.34s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.33966049551963806, 'eval_wer': 0.5375446534889259, 'eval_cer': 0.12734854780194166, 'eval_runtime': 396.5979, 'eval_samples_per_second': 24.279, 'eval_steps_per_second': 3.036, 'epoch': 3.01}                                                                                                                                             
{'loss': 0.3852, 'learning_rate': 0.00021720087019579402, 'epoch': 3.02}                                                                                                      
{'loss': 0.4115, 'learning_rate': 0.00021698332124728064, 'epoch': 3.02}                                                                                                      
{'loss': 0.4356, 'learning_rate': 0.0002167657722987672, 'epoch': 3.03}                                                                                                       
{'loss': 0.4453, 'learning_rate': 0.0002165482233502538, 'epoch': 3.04}                                                                                                       
{'loss': 0.4258, 'learning_rate': 0.00021633067440174038, 'epoch': 3.04}                                                                                                      
{'loss': 0.3631, 'learning_rate': 0.00021611312545322694, 'epoch': 3.05}                                                                                                      
{'loss': 0.4117, 'learning_rate': 0.00021589557650471356, 'epoch': 3.06}                                                                                                      
{'loss': 0.4528, 'learning_rate': 0.00021567802755620012, 'epoch': 3.07}                                                                                                      
{'loss': 0.4673, 'learning_rate': 0.0002154604786076867, 'epoch': 3.07}                                                                                                       
{'loss': 0.3683, 'learning_rate': 0.00021524292965917328, 'epoch': 3.08}                                                                                                      
 31%|███████████████████████████████████████▍                                                                                        | 4400/14290 [5:58:31<3:33:17,  1.29s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3341304063796997, 'eval_wer': 0.5303881876637294, 'eval_cer': 0.1256038157779174, 'eval_runtime': 398.8912, 'eval_samples_per_second': 24.139, 'eval_steps_per_second': 3.018, 'epoch': 3.08}                                                                                                                                               
{'loss': 0.4036, 'learning_rate': 0.00021502538071065987, 'epoch': 3.09}                                                                                                      
{'loss': 0.3937, 'learning_rate': 0.00021480783176214648, 'epoch': 3.09}                                                                                                      
{'loss': 0.4869, 'learning_rate': 0.00021459028281363304, 'epoch': 3.1}                                                                                                       
{'loss': 0.4923, 'learning_rate': 0.00021437273386511963, 'epoch': 3.11}                                                                                                      
{'loss': 0.3529, 'learning_rate': 0.0002141551849166062, 'epoch': 3.11}                                                                                                       
{'loss': 0.3765, 'learning_rate': 0.0002139376359680928, 'epoch': 3.12}                                                                                                       
{'loss': 0.445, 'learning_rate': 0.0002137200870195794, 'epoch': 3.13}                                                                                                        
{'loss': 0.4571, 'learning_rate': 0.00021350253807106596, 'epoch': 3.14}                                                                                                      
{'loss': 0.3875, 'learning_rate': 0.00021328498912255255, 'epoch': 3.14}                                                                                                      
{'loss': 0.3875, 'learning_rate': 0.00021306744017403912, 'epoch': 3.15}                                                                                                      
 31%|████████████████████████████████████████▎                                                                                       | 4500/14290 [6:06:53<3:35:13,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.32749706506729126, 'eval_wer': 0.5320076208621101, 'eval_cer': 0.12660707891661094, 'eval_runtime': 399.6645, 'eval_samples_per_second': 24.093, 'eval_steps_per_second': 3.013, 'epoch': 3.15}                                                                                                                                             
{'loss': 0.3756, 'learning_rate': 0.00021284989122552573, 'epoch': 3.16}                                                                                                      
{'loss': 0.392, 'learning_rate': 0.00021263234227701232, 'epoch': 3.16}                                                                                                       
{'loss': 0.3994, 'learning_rate': 0.00021241479332849888, 'epoch': 3.17}                                                                                                      
{'loss': 0.4184, 'learning_rate': 0.00021219724437998547, 'epoch': 3.18}                                                                                                      
{'loss': 0.3254, 'learning_rate': 0.00021197969543147206, 'epoch': 3.18}                                                                                                      
{'loss': 0.3701, 'learning_rate': 0.00021176214648295865, 'epoch': 3.19}                                                                                                      
{'loss': 0.4091, 'learning_rate': 0.00021154459753444524, 'epoch': 3.2}                                                                                                       
{'loss': 0.509, 'learning_rate': 0.0002113270485859318, 'epoch': 3.21}                                                                                                        
{'loss': 0.4214, 'learning_rate': 0.00021110949963741842, 'epoch': 3.21}                                                                                                      
{'loss': 0.3661, 'learning_rate': 0.00021089195068890498, 'epoch': 3.22}                                                                                                      
 32%|█████████████████████████████████████████▏                                                                                      | 4600/14290 [6:15:19<3:33:47,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.31698235869407654, 'eval_wer': 0.5150512026673018, 'eval_cer': 0.12172588283778214, 'eval_runtime': 396.1122, 'eval_samples_per_second': 24.309, 'eval_steps_per_second': 3.04, 'epoch': 3.22}                                                                                                                                              
{'loss': 0.3812, 'learning_rate': 0.00021067440174039157, 'epoch': 3.23}                                                                                                      
{'loss': 0.3973, 'learning_rate': 0.00021045685279187814, 'epoch': 3.23}                                                                                                      
{'loss': 0.4079, 'learning_rate': 0.00021023930384336473, 'epoch': 3.24}                                                                                                      
{'loss': 0.4278, 'learning_rate': 0.00021002175489485134, 'epoch': 3.25}                                                                                                      
{'loss': 0.3653, 'learning_rate': 0.0002098042059463379, 'epoch': 3.25}                                                                                                       
{'loss': 0.3616, 'learning_rate': 0.0002095866569978245, 'epoch': 3.26}                                                                                                       
{'loss': 0.4288, 'learning_rate': 0.00020936910804931106, 'epoch': 3.27}                                                                                                      
{'loss': 0.4277, 'learning_rate': 0.00020915155910079767, 'epoch': 3.28}                                                                                                      
{'loss': 0.4423, 'learning_rate': 0.00020893401015228426, 'epoch': 3.28}                                                                                                      
{'loss': 0.3537, 'learning_rate': 0.00020871646120377082, 'epoch': 3.29}                                                                                                      
 33%|██████████████████████████████████████████                                                                                      | 4700/14290 [6:23:39<3:21:45,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.32368138432502747, 'eval_wer': 0.5190521552750655, 'eval_cer': 0.12556496888870872, 'eval_runtime': 396.7378, 'eval_samples_per_second': 24.27, 'eval_steps_per_second': 3.035, 'epoch': 3.29}                                                                                                                                              
{'loss': 0.3697, 'learning_rate': 0.00020849891225525741, 'epoch': 3.3}                                                                                                       
{'loss': 0.3626, 'learning_rate': 0.00020828136330674398, 'epoch': 3.3}                                                                                                       
{'loss': 0.4517, 'learning_rate': 0.0002080638143582306, 'epoch': 3.31}                                                                                                       
{'loss': 0.4673, 'learning_rate': 0.00020784626540971718, 'epoch': 3.32}                                                                                                      
{'loss': 0.371, 'learning_rate': 0.00020762871646120374, 'epoch': 3.32}                                                                                                       
{'loss': 0.3924, 'learning_rate': 0.00020741116751269033, 'epoch': 3.33}                                                                                                      
{'loss': 0.4141, 'learning_rate': 0.00020719361856417692, 'epoch': 3.34}                                                                                                      
{'loss': 0.4487, 'learning_rate': 0.0002069760696156635, 'epoch': 3.34}                                                                                                       
{'loss': 0.4245, 'learning_rate': 0.0002067585206671501, 'epoch': 3.35}                                                                                                       
{'loss': 0.3611, 'learning_rate': 0.00020654097171863666, 'epoch': 3.36}                                                                                                      
 34%|██████████████████████████████████████████▉                                                                                     | 4800/14290 [6:31:58<3:28:08,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3151925802230835, 'eval_wer': 0.5159561800428674, 'eval_cer': 0.1268232703000331, 'eval_runtime': 399.1366, 'eval_samples_per_second': 24.125, 'eval_steps_per_second': 3.017, 'epoch': 3.36}                                                                                                                                               
{'loss': 0.4121, 'learning_rate': 0.00020632342277012328, 'epoch': 3.37}                                                                                                      
{'loss': 0.4192, 'learning_rate': 0.00020610587382160984, 'epoch': 3.37}                                                                                                      
{'loss': 0.4337, 'learning_rate': 0.00020588832487309643, 'epoch': 3.38}                                                                                                      
{'loss': 0.4584, 'learning_rate': 0.000205670775924583, 'epoch': 3.39}                                                                                                        
{'loss': 0.3621, 'learning_rate': 0.00020545322697606959, 'epoch': 3.39}                                                                                                      
{'loss': 0.3959, 'learning_rate': 0.0002052356780275562, 'epoch': 3.4}                                                                                                        
{'loss': 0.4312, 'learning_rate': 0.00020501812907904276, 'epoch': 3.41}                                                                                                      
{'loss': 0.437, 'learning_rate': 0.00020480058013052935, 'epoch': 3.41}                                                                                                       
{'loss': 0.4597, 'learning_rate': 0.00020458303118201592, 'epoch': 3.42}                                                                                                      
{'loss': 0.3815, 'learning_rate': 0.00020436548223350253, 'epoch': 3.43}                                                                                                      
 34%|███████████████████████████████████████████▉                                                                                    | 4900/14290 [6:40:20<3:28:26,  1.33s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3189263641834259, 'eval_wer': 0.5187782805429865, 'eval_cer': 0.12425093063634582, 'eval_runtime': 398.7583, 'eval_samples_per_second': 24.147, 'eval_steps_per_second': 3.019, 'epoch': 3.43}                                                                                                                                              
{'loss': 0.3622, 'learning_rate': 0.00020414793328498912, 'epoch': 3.44}                                                                                                      
{'loss': 0.4069, 'learning_rate': 0.00020393038433647568, 'epoch': 3.44}                                                                                                      
{'loss': 0.4489, 'learning_rate': 0.00020371283538796227, 'epoch': 3.45}                                                                                                      
{'loss': 0.4058, 'learning_rate': 0.00020349528643944884, 'epoch': 3.46}                                                                                                      
{'loss': 0.3432, 'learning_rate': 0.00020327773749093545, 'epoch': 3.46}                                                                                                      
{'loss': 0.4039, 'learning_rate': 0.00020306018854242204, 'epoch': 3.47}                                                                                                      
{'loss': 0.3959, 'learning_rate': 0.0002028426395939086, 'epoch': 3.48}                                                                                                       
{'loss': 0.4888, 'learning_rate': 0.0002026250906453952, 'epoch': 3.48}                                                                                                       
{'loss': 0.4673, 'learning_rate': 0.00020240754169688176, 'epoch': 3.49}                                                                                                      
{'loss': 0.3335, 'learning_rate': 0.00020218999274836837, 'epoch': 3.5}                                                                                                       
 35%|████████████████████████████████████████████▊                                                                                   | 5000/14290 [6:48:42<3:23:31,  1.31s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.31477293372154236, 'eval_wer': 0.5159680876399143, 'eval_cer': 0.12119216035995865, 'eval_runtime': 398.7769, 'eval_samples_per_second': 24.146, 'eval_steps_per_second': 3.019, 'epoch': 3.5}                                                                                                                                              
{'loss': 0.381, 'learning_rate': 0.00020197244379985496, 'epoch': 3.51}                                                                                                       
{'loss': 0.4081, 'learning_rate': 0.00020175489485134152, 'epoch': 3.51}                                                                                                      
{'loss': 0.4163, 'learning_rate': 0.00020153734590282814, 'epoch': 3.52}                                                                                                      
{'loss': 0.4565, 'learning_rate': 0.0002013197969543147, 'epoch': 3.53}                                                                                                       
{'loss': 0.3764, 'learning_rate': 0.0002011022480058013, 'epoch': 3.53}                                                                                                       
{'loss': 0.3971, 'learning_rate': 0.00020088469905728786, 'epoch': 3.54}                                                                                                      
{'loss': 0.4263, 'learning_rate': 0.00020066715010877445, 'epoch': 3.55}                                                                                                      
{'loss': 0.4639, 'learning_rate': 0.00020044960116026106, 'epoch': 3.55}                                                                                                      
{'loss': 0.4247, 'learning_rate': 0.00020023205221174762, 'epoch': 3.56}                                                                                                      
{'loss': 0.3615, 'learning_rate': 0.0002000145032632342, 'epoch': 3.57}                                                                                                       
 36%|█████████████████████████████████████████████▋                                                                                  | 5100/14290 [6:57:05<3:25:20,  1.34s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3039921224117279, 'eval_wer': 0.49930935937127885, 'eval_cer': 0.1192329259476952, 'eval_runtime': 397.1414, 'eval_samples_per_second': 24.246, 'eval_steps_per_second': 3.032, 'epoch': 3.57}                                                                                                                                              
{'loss': 0.394, 'learning_rate': 0.00019979695431472078, 'epoch': 3.58}                                                                                                       
{'loss': 0.3884, 'learning_rate': 0.0001995794053662074, 'epoch': 3.58}                                                                                                       
{'loss': 0.3967, 'learning_rate': 0.00019936185641769398, 'epoch': 3.59}                                                                                                      
{'loss': 0.4034, 'learning_rate': 0.00019914430746918054, 'epoch': 3.6}                                                                                                       
{'loss': 0.3471, 'learning_rate': 0.00019892675852066713, 'epoch': 3.6}                                                                                                       
{'loss': 0.3967, 'learning_rate': 0.0001987092095721537, 'epoch': 3.61}                                                                                                       
{'loss': 0.4357, 'learning_rate': 0.0001984916606236403, 'epoch': 3.62}                                                                                                       
{'loss': 0.3781, 'learning_rate': 0.0001982741116751269, 'epoch': 3.62}                                                                                                       
{'loss': 0.4152, 'learning_rate': 0.00019805656272661346, 'epoch': 3.63}                                                                                                      
{'loss': 0.3502, 'learning_rate': 0.00019783901377810005, 'epoch': 3.64}                                                                                                      
 36%|██████████████████████████████████████████████▌                                                                                 | 5200/14290 [7:05:26<3:22:25,  1.34s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3029046952724457, 'eval_wer': 0.5017623243629435, 'eval_cer': 0.1189829546606133, 'eval_runtime': 399.8416, 'eval_samples_per_second': 24.082, 'eval_steps_per_second': 3.011, 'epoch': 3.64}                                                                                                                                               
{'loss': 0.3654, 'learning_rate': 0.00019762146482958662, 'epoch': 3.65}                                                                                                      
{'loss': 0.4211, 'learning_rate': 0.00019740391588107323, 'epoch': 3.65}                                                                                                      
{'loss': 0.4227, 'learning_rate': 0.00019718636693255982, 'epoch': 3.66}                                                                                                      
{'loss': 0.4227, 'learning_rate': 0.00019696881798404638, 'epoch': 3.67}                                                                                                      
{'loss': 0.3855, 'learning_rate': 0.000196751269035533, 'epoch': 3.67}                                                                                                        
{'loss': 0.3456, 'learning_rate': 0.00019653372008701956, 'epoch': 3.68}                                                                                                      
{'loss': 0.3865, 'learning_rate': 0.00019631617113850615, 'epoch': 3.69}                                                                                                      
{'loss': 0.3918, 'learning_rate': 0.00019609862218999272, 'epoch': 3.69}                                                                                                      
{'loss': 0.4574, 'learning_rate': 0.0001958810732414793, 'epoch': 3.7}                                                                                                        
{'loss': 0.338, 'learning_rate': 0.00019566352429296592, 'epoch': 3.71}                                                                                                       
 37%|███████████████████████████████████████████████▍                                                                                | 5300/14290 [7:13:50<3:16:05,  1.31s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29886311292648315, 'eval_wer': 0.4945463205525125, 'eval_cer': 0.1204642034360918, 'eval_runtime': 400.1973, 'eval_samples_per_second': 24.061, 'eval_steps_per_second': 3.009, 'epoch': 3.71}                                                                                                                                              
{'loss': 0.3412, 'learning_rate': 0.00019544597534445248, 'epoch': 3.72}                                                                                                      
{'loss': 0.3821, 'learning_rate': 0.00019522842639593907, 'epoch': 3.72}                                                                                                      
{'loss': 0.4579, 'learning_rate': 0.00019501087744742564, 'epoch': 3.73}                                                                                                      
{'loss': 0.5218, 'learning_rate': 0.00019479332849891223, 'epoch': 3.74}                                                                                                      
{'loss': 0.2972, 'learning_rate': 0.00019457577955039884, 'epoch': 3.74}                                                                                                      
{'loss': 0.3621, 'learning_rate': 0.0001943582306018854, 'epoch': 3.75}                                                                                                       
{'loss': 0.39, 'learning_rate': 0.000194140681653372, 'epoch': 3.76}                                                                                                          
{'loss': 0.4402, 'learning_rate': 0.00019392313270485856, 'epoch': 3.76}                                                                                                      
{'loss': 0.3992, 'learning_rate': 0.00019370558375634517, 'epoch': 3.77}                                                                                                      
{'loss': 0.3359, 'learning_rate': 0.00019348803480783176, 'epoch': 3.78}                                                                                                      
 38%|████████████████████████████████████████████████▎                                                                               | 5400/14290 [7:22:15<3:17:15,  1.33s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29843828082084656, 'eval_wer': 0.49158132888783046, 'eval_cer': 0.12056723214225393, 'eval_runtime': 399.7433, 'eval_samples_per_second': 24.088, 'eval_steps_per_second': 3.012, 'epoch': 3.78}                                                                                                                                            
{'loss': 0.3398, 'learning_rate': 0.00019327048585931832, 'epoch': 3.79}                                                                                                      
{'loss': 0.3587, 'learning_rate': 0.00019305293691080491, 'epoch': 3.79}                                                                                                      
{'loss': 0.383, 'learning_rate': 0.00019283538796229148, 'epoch': 3.8}                                                                                                        
{'loss': 0.505, 'learning_rate': 0.0001926178390137781, 'epoch': 3.81}                                                                                                        
{'loss': 0.3177, 'learning_rate': 0.00019240029006526468, 'epoch': 3.81}                                                                                                      
{'loss': 0.3558, 'learning_rate': 0.00019218274111675124, 'epoch': 3.82}                                                                                                      
{'loss': 0.4106, 'learning_rate': 0.00019196519216823783, 'epoch': 3.83}                                                                                                      
{'loss': 0.398, 'learning_rate': 0.00019174764321972442, 'epoch': 3.83}                                                                                                       
{'loss': 0.4702, 'learning_rate': 0.000191530094271211, 'epoch': 3.84}                                                                                                        
{'loss': 0.3563, 'learning_rate': 0.00019131254532269758, 'epoch': 3.85}                                                                                                      
 38%|█████████████████████████████████████████████████▎                                                                              | 5500/14290 [7:30:39<3:13:21,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29739269614219666, 'eval_wer': 0.4979161705167897, 'eval_cer': 0.11742232311153449, 'eval_runtime': 400.138, 'eval_samples_per_second': 24.064, 'eval_steps_per_second': 3.009, 'epoch': 3.85}                                                                                                                                              
{'loss': 0.3533, 'learning_rate': 0.00019109499637418417, 'epoch': 3.86}                                                                                                      
{'loss': 0.3921, 'learning_rate': 0.00019087744742567078, 'epoch': 3.86}                                                                                                      
{'loss': 0.4277, 'learning_rate': 0.00019065989847715734, 'epoch': 3.87}                                                                                                      
{'loss': 0.4726, 'learning_rate': 0.00019044234952864393, 'epoch': 3.88}                                                                                                      
{'loss': 0.3333, 'learning_rate': 0.0001902248005801305, 'epoch': 3.88}                                                                                                       
{'loss': 0.3645, 'learning_rate': 0.00019000725163161709, 'epoch': 3.89}                                                                                                      
{'loss': 0.4122, 'learning_rate': 0.0001897897026831037, 'epoch': 3.9}                                                                                                        
{'loss': 0.4129, 'learning_rate': 0.00018957215373459026, 'epoch': 3.9}                                                                                                       
{'loss': 0.3935, 'learning_rate': 0.00018935460478607685, 'epoch': 3.91}                                                                                                      
{'loss': 0.3652, 'learning_rate': 0.00018913705583756342, 'epoch': 3.92}                                                                                                      
 39%|██████████████████████████████████████████████████▏                                                                             | 5600/14290 [7:39:02<3:11:18,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29310864210128784, 'eval_wer': 0.493343653250774, 'eval_cer': 0.11885121303634041, 'eval_runtime': 400.0851, 'eval_samples_per_second': 24.067, 'eval_steps_per_second': 3.009, 'epoch': 3.92}                                                                                                                                              
{'loss': 0.3406, 'learning_rate': 0.00018891950688905003, 'epoch': 3.93}                                                                                                      
{'loss': 0.4018, 'learning_rate': 0.00018870195794053662, 'epoch': 3.93}                                                                                                      
{'loss': 0.3857, 'learning_rate': 0.00018848440899202318, 'epoch': 3.94}                                                                                                      
{'loss': 0.427, 'learning_rate': 0.00018826686004350977, 'epoch': 3.95}                                                                                                       
{'loss': 0.3242, 'learning_rate': 0.00018804931109499634, 'epoch': 3.95}                                                                                                      
{'loss': 0.332, 'learning_rate': 0.00018783176214648295, 'epoch': 3.96}                                                                                                       
{'loss': 0.403, 'learning_rate': 0.00018761421319796954, 'epoch': 3.97}                                                                                                       
{'loss': 0.45, 'learning_rate': 0.0001873966642494561, 'epoch': 3.97}                                                                                                         
{'loss': 0.4045, 'learning_rate': 0.0001871791153009427, 'epoch': 3.98}                                                                                                       
{'loss': 0.3281, 'learning_rate': 0.00018696156635242928, 'epoch': 3.99}                                                                                                      
 40%|███████████████████████████████████████████████████                                                                             | 5700/14290 [7:47:25<2:41:33,  1.13s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29166722297668457, 'eval_wer': 0.48335317932841154, 'eval_cer': 0.11633461021369167, 'eval_runtime': 400.7292, 'eval_samples_per_second': 24.029, 'eval_steps_per_second': 3.005, 'epoch': 3.99}                                                                                                                                            
{'loss': 0.3929, 'learning_rate': 0.00018674401740391587, 'epoch': 4.0}                                                                                                       
 40%|███████████████████████████████████████████████████▏                                                                            | 5712/14290 [7:54:16<7:22:26,  3.09s/it]Saving model checkpoint to ./russian_augmented/checkpoint-5712
Configuration saved in ./russian_augmented/checkpoint-5712/config.json
Model weights saved in ./russian_augmented/checkpoint-5712/pytorch_model.bin
Feature extractor saved in ./russian_augmented/checkpoint-5712/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4033, 'learning_rate': 0.00018652646845540244, 'epoch': 4.0}                                                                                                       
{'loss': 0.2959, 'learning_rate': 0.00018630891950688903, 'epoch': 4.01}                                                                                                      
{'loss': 0.284, 'learning_rate': 0.00018609137055837564, 'epoch': 4.02}                                                                                                       
{'loss': 0.3192, 'learning_rate': 0.0001858738216098622, 'epoch': 4.02}                                                                                                       
{'loss': 0.3903, 'learning_rate': 0.0001856562726613488, 'epoch': 4.03}                                                                                                       
{'loss': 0.3185, 'learning_rate': 0.00018543872371283536, 'epoch': 4.04}                                                                                                      
{'loss': 0.2878, 'learning_rate': 0.00018522117476432195, 'epoch': 4.04}                                                                                                      
{'loss': 0.3006, 'learning_rate': 0.00018500362581580856, 'epoch': 4.05}                                                                                                      
{'loss': 0.3622, 'learning_rate': 0.00018478607686729512, 'epoch': 4.06}                                                                                                      
 41%|███████████████████████████████████████████████████▉                                                                            | 5800/14290 [7:55:54<2:05:35,  1.13it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2906414270401001, 'eval_wer': 0.47949511788521076, 'eval_cer': 0.11353932318585028, 'eval_runtime': 400.0606, 'eval_samples_per_second': 24.069, 'eval_steps_per_second': 3.01, 'epoch': 4.06}                                                                                                                                              
{'loss': 0.3523, 'learning_rate': 0.00018456852791878171, 'epoch': 4.07}                                                                                                      
{'loss': 0.4122, 'learning_rate': 0.00018435097897026828, 'epoch': 4.07}                                                                                                      
{'loss': 0.3026, 'learning_rate': 0.0001841334300217549, 'epoch': 4.08}                                                                                                       
{'loss': 0.3077, 'learning_rate': 0.00018391588107324148, 'epoch': 4.09}                                                                                                      
{'loss': 0.3513, 'learning_rate': 0.00018369833212472804, 'epoch': 4.09}                                                                                                      
{'loss': 0.3718, 'learning_rate': 0.00018348078317621463, 'epoch': 4.1}                                                                                                       
{'loss': 0.3563, 'learning_rate': 0.0001832632342277012, 'epoch': 4.11}                                                                                                       
{'loss': 0.3086, 'learning_rate': 0.0001830456852791878, 'epoch': 4.11}                                                                                                       
{'loss': 0.2986, 'learning_rate': 0.0001828281363306744, 'epoch': 4.12}                                                                                                       
{'loss': 0.3731, 'learning_rate': 0.00018261058738216096, 'epoch': 4.13}                                                                                                      
 41%|████████████████████████████████████████████████████▊                                                                           | 5900/14290 [8:04:18<2:05:03,  1.12it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3005143404006958, 'eval_wer': 0.47635151226482497, 'eval_cer': 0.11435172986886641, 'eval_runtime': 408.2733, 'eval_samples_per_second': 23.585, 'eval_steps_per_second': 2.949, 'epoch': 4.13}                                                                                                                                             
{'loss': 0.3734, 'learning_rate': 0.00018239303843364755, 'epoch': 4.14}                                                                                                      
{'loss': 0.3671, 'learning_rate': 0.00018217548948513412, 'epoch': 4.14}                                                                                                      
{'loss': 0.3012, 'learning_rate': 0.00018195794053662073, 'epoch': 4.15}                                                                                                      
{'loss': 0.3382, 'learning_rate': 0.0001817403915881073, 'epoch': 4.16}                                                                                                       
{'loss': 0.3703, 'learning_rate': 0.00018152284263959389, 'epoch': 4.16}                                                                                                      
{'loss': 0.3758, 'learning_rate': 0.0001813052936910805, 'epoch': 4.17}                                                                                                       
{'loss': 0.3396, 'learning_rate': 0.00018108774474256706, 'epoch': 4.18}                                                                                                      
{'loss': 0.3011, 'learning_rate': 0.00018087019579405365, 'epoch': 4.18}                                                                                                      
{'loss': 0.3143, 'learning_rate': 0.00018065264684554022, 'epoch': 4.19}                                                                                                      
{'loss': 0.3501, 'learning_rate': 0.0001804350978970268, 'epoch': 4.2}                                                                                                        
 42%|█████████████████████████████████████████████████████▋                                                                          | 6000/14290 [8:12:53<2:05:19,  1.10it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.286941260099411, 'eval_wer': 0.47213622291021673, 'eval_cer': 0.11239756244215192, 'eval_runtime': 409.0152, 'eval_samples_per_second': 23.542, 'eval_steps_per_second': 2.944, 'epoch': 4.2}                                                                                                                                               
{'loss': 0.4152, 'learning_rate': 0.00018021754894851342, 'epoch': 4.21}                                                                                                      
{'loss': 0.3751, 'learning_rate': 0.00017999999999999998, 'epoch': 4.21}                                                                                                      
{'loss': 0.3239, 'learning_rate': 0.00017978245105148657, 'epoch': 4.22}                                                                                                      
{'loss': 0.3503, 'learning_rate': 0.00017956490210297314, 'epoch': 4.23}                                                                                                      
{'loss': 0.3324, 'learning_rate': 0.00017934735315445973, 'epoch': 4.23}                                                                                                      
{'loss': 0.3961, 'learning_rate': 0.00017912980420594634, 'epoch': 4.24}                                                                                                      
{'loss': 0.3257, 'learning_rate': 0.0001789122552574329, 'epoch': 4.25}                                                                                                       
{'loss': 0.2854, 'learning_rate': 0.0001786947063089195, 'epoch': 4.25}                                                                                                       
{'loss': 0.3531, 'learning_rate': 0.00017847715736040606, 'epoch': 4.26}                                                                                                      
{'loss': 0.3198, 'learning_rate': 0.00017825960841189267, 'epoch': 4.27}                                                                                                      
 43%|██████████████████████████████████████████████████████▋                                                                         | 6100/14290 [8:21:27<2:02:55,  1.11it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2991798222064972, 'eval_wer': 0.47432722076684924, 'eval_cer': 0.11147030408669274, 'eval_runtime': 410.2454, 'eval_samples_per_second': 23.471, 'eval_steps_per_second': 2.935, 'epoch': 4.27}                                                                                                                                             
{'loss': 0.3656, 'learning_rate': 0.00017804205946337926, 'epoch': 4.28}                                                                                                      
{'loss': 0.3478, 'learning_rate': 0.00017782451051486582, 'epoch': 4.28}                                                                                                      
{'loss': 0.2957, 'learning_rate': 0.00017760696156635241, 'epoch': 4.29}                                                                                                      
{'loss': 0.3146, 'learning_rate': 0.00017738941261783898, 'epoch': 4.3}                                                                                                       
{'loss': 0.3115, 'learning_rate': 0.0001771718636693256, 'epoch': 4.3}                                                                                                        
{'loss': 0.3719, 'learning_rate': 0.00017695431472081216, 'epoch': 4.31}                                                                                                      
{'loss': 0.3314, 'learning_rate': 0.00017673676577229875, 'epoch': 4.32}                                                                                                      
{'loss': 0.2907, 'learning_rate': 0.00017651921682378533, 'epoch': 4.32}                                                                                                      
{'loss': 0.296, 'learning_rate': 0.00017630166787527192, 'epoch': 4.33}                                                                                                       
{'loss': 0.3625, 'learning_rate': 0.0001760841189267585, 'epoch': 4.34}                                                                                                       
 43%|███████████████████████████████████████████████████████▌                                                                        | 6200/14290 [8:30:05<2:06:36,  1.06it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.28357309103012085, 'eval_wer': 0.4651940938318647, 'eval_cer': 0.11057851463007627, 'eval_runtime': 412.3063, 'eval_samples_per_second': 23.354, 'eval_steps_per_second': 2.92, 'epoch': 4.34}                                                                                                                                              
{'loss': 0.3464, 'learning_rate': 0.00017586656997824508, 'epoch': 4.35}                                                                                                      
{'loss': 0.4507, 'learning_rate': 0.00017564902102973167, 'epoch': 4.35}                                                                                                      
{'loss': 0.3045, 'learning_rate': 0.00017543147208121828, 'epoch': 4.36}                                                                                                      
{'loss': 0.343, 'learning_rate': 0.00017521392313270484, 'epoch': 4.37}                                                                                                       
{'loss': 0.3737, 'learning_rate': 0.00017499637418419143, 'epoch': 4.37}                                                                                                      
{'loss': 0.3485, 'learning_rate': 0.000174778825235678, 'epoch': 4.38}                                                                                                        
{'loss': 0.4254, 'learning_rate': 0.00017456127628716459, 'epoch': 4.39}                                                                                                      
{'loss': 0.306, 'learning_rate': 0.0001743437273386512, 'epoch': 4.39}                                                                                                        
{'loss': 0.3352, 'learning_rate': 0.00017412617839013776, 'epoch': 4.4}                                                                                                       
{'loss': 0.337, 'learning_rate': 0.00017390862944162435, 'epoch': 4.41}                                                                                                       
 44%|████████████████████████████████████████████████████████▍                                                                       | 6300/14290 [8:38:42<2:02:41,  1.09it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2898269593715668, 'eval_wer': 0.47281495594189094, 'eval_cer': 0.1105160218083058, 'eval_runtime': 412.1161, 'eval_samples_per_second': 23.365, 'eval_steps_per_second': 2.922, 'epoch': 4.41}                                                                                                                                              
{'loss': 0.3429, 'learning_rate': 0.00017369108049311092, 'epoch': 4.42}                                                                                                      
{'loss': 0.4206, 'learning_rate': 0.00017347353154459753, 'epoch': 4.42}                                                                                                      
{'loss': 0.2995, 'learning_rate': 0.00017325598259608412, 'epoch': 4.43}                                                                                                      
{'loss': 0.301, 'learning_rate': 0.00017303843364757068, 'epoch': 4.44}                                                                                                       
{'loss': 0.3387, 'learning_rate': 0.00017282088469905727, 'epoch': 4.44}                                                                                                      
{'loss': 0.3223, 'learning_rate': 0.00017260333575054384, 'epoch': 4.45}                                                                                                      
{'loss': 0.3786, 'learning_rate': 0.00017238578680203045, 'epoch': 4.46}                                                                                                      
{'loss': 0.271, 'learning_rate': 0.00017216823785351702, 'epoch': 4.46}                                                                                                       
{'loss': 0.2837, 'learning_rate': 0.0001719506889050036, 'epoch': 4.47}                                                                                                       
{'loss': 0.3302, 'learning_rate': 0.0001717331399564902, 'epoch': 4.48}                                                                                                       
 45%|█████████████████████████████████████████████████████████▎                                                                      | 6400/14290 [8:47:21<2:00:35,  1.09it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2894989848136902, 'eval_wer': 0.46624196237199333, 'eval_cer': 0.11032516535262842, 'eval_runtime': 408.4728, 'eval_samples_per_second': 23.573, 'eval_steps_per_second': 2.948, 'epoch': 4.48}                                                                                                                                             
{'loss': 0.3348, 'learning_rate': 0.00017151559100797678, 'epoch': 4.49}                                                                                                      
{'loss': 0.3904, 'learning_rate': 0.00017129804205946337, 'epoch': 4.49}                                                                                                      
{'loss': 0.3035, 'learning_rate': 0.00017108049311094994, 'epoch': 4.5}                                                                                                       
{'loss': 0.3183, 'learning_rate': 0.00017086294416243653, 'epoch': 4.51}                                                                                                      
{'loss': 0.3194, 'learning_rate': 0.00017064539521392314, 'epoch': 4.51}                                                                                                      
{'loss': 0.3742, 'learning_rate': 0.0001704278462654097, 'epoch': 4.52}                                                                                                       
{'loss': 0.3437, 'learning_rate': 0.0001702102973168963, 'epoch': 4.53}                                                                                                       
{'loss': 0.2803, 'learning_rate': 0.00016999274836838286, 'epoch': 4.53}                                                                                                      
{'loss': 0.3079, 'learning_rate': 0.00016977519941986945, 'epoch': 4.54}                                                                                                      
{'loss': 0.3581, 'learning_rate': 0.00016955765047135606, 'epoch': 4.55}                                                                                                      
 45%|██████████████████████████████████████████████████████████▏                                                                     | 6500/14290 [8:55:55<1:59:23,  1.09it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.28143301606178284, 'eval_wer': 0.46234817813765183, 'eval_cer': 0.11046366295763324, 'eval_runtime': 412.5161, 'eval_samples_per_second': 23.342, 'eval_steps_per_second': 2.919, 'epoch': 4.55}                                                                                                                                            
{'loss': 0.3797, 'learning_rate': 0.00016934010152284262, 'epoch': 4.56}                                                                                                      
{'loss': 0.3613, 'learning_rate': 0.00016912255257432921, 'epoch': 4.56}                                                                                                      
{'loss': 0.3006, 'learning_rate': 0.00016890500362581578, 'epoch': 4.57}                                                                                                      
{'loss': 0.3395, 'learning_rate': 0.0001686874546773024, 'epoch': 4.58}                                                                                                       
{'loss': 0.3156, 'learning_rate': 0.00016846990572878898, 'epoch': 4.58}                                                                                                      
{'loss': 0.4216, 'learning_rate': 0.00016825235678027554, 'epoch': 4.59}                                                                                                      
{'loss': 0.323, 'learning_rate': 0.00016803480783176213, 'epoch': 4.6}                                                                                                        
{'loss': 0.2799, 'learning_rate': 0.0001678172588832487, 'epoch': 4.6}                                                                                                        
{'loss': 0.3188, 'learning_rate': 0.0001675997099347353, 'epoch': 4.61}                                                                                                       
{'loss': 0.3293, 'learning_rate': 0.00016738216098622188, 'epoch': 4.62}                                                                                                      
 46%|███████████████████████████████████████████████████████████                                                                     | 6600/14290 [9:04:34<1:56:30,  1.10it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2824387848377228, 'eval_wer': 0.46245534651107406, 'eval_cer': 0.11066634237959154, 'eval_runtime': 410.3707, 'eval_samples_per_second': 23.464, 'eval_steps_per_second': 2.934, 'epoch': 4.62}                                                                                                                                             
{'loss': 0.3537, 'learning_rate': 0.00016716461203770847, 'epoch': 4.63}                                                                                                      
{'loss': 0.3794, 'learning_rate': 0.00016694706308919505, 'epoch': 4.63}                                                                                                      
{'loss': 0.297, 'learning_rate': 0.00016672951414068162, 'epoch': 4.64}                                                                                                       
{'loss': 0.3202, 'learning_rate': 0.00016651196519216823, 'epoch': 4.65}                                                                                                      
{'loss': 0.3494, 'learning_rate': 0.0001662944162436548, 'epoch': 4.65}                                                                                                       
{'loss': 0.35, 'learning_rate': 0.00016607686729514139, 'epoch': 4.66}                                                                                                        
{'loss': 0.3295, 'learning_rate': 0.000165859318346628, 'epoch': 4.67}                                                                                                        
{'loss': 0.3051, 'learning_rate': 0.00016564176939811456, 'epoch': 4.67}                                                                                                      
{'loss': 0.3302, 'learning_rate': 0.00016542422044960115, 'epoch': 4.68}                                                                                                      
{'loss': 0.3324, 'learning_rate': 0.00016520667150108772, 'epoch': 4.69}                                                                                                      
 47%|████████████████████████████████████████████████████████████                                                                    | 6700/14290 [9:13:10<1:55:55,  1.09it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2778180241584778, 'eval_wer': 0.4587639914265301, 'eval_cer': 0.11117641892485322, 'eval_runtime': 415.2591, 'eval_samples_per_second': 23.188, 'eval_steps_per_second': 2.899, 'epoch': 4.69}                                                                                                                                              
{'loss': 0.3471, 'learning_rate': 0.0001649891225525743, 'epoch': 4.7}                                                                                                        
{'loss': 0.3324, 'learning_rate': 0.00016477157360406092, 'epoch': 4.7}                                                                                                       
{'loss': 0.3063, 'learning_rate': 0.00016455402465554748, 'epoch': 4.71}                                                                                                      
{'loss': 0.3204, 'learning_rate': 0.00016433647570703407, 'epoch': 4.72}                                                                                                      
{'loss': 0.3037, 'learning_rate': 0.00016411892675852064, 'epoch': 4.72}                                                                                                      
{'loss': 0.3959, 'learning_rate': 0.00016390137781000725, 'epoch': 4.73}                                                                                                      
{'loss': 0.3485, 'learning_rate': 0.00016368382886149384, 'epoch': 4.74}                                                                                                      
{'loss': 0.2905, 'learning_rate': 0.0001634662799129804, 'epoch': 4.74}                                                                                                       
{'loss': 0.3232, 'learning_rate': 0.000163248730964467, 'epoch': 4.75}                                                                                                        
{'loss': 0.3092, 'learning_rate': 0.00016303118201595356, 'epoch': 4.76}                                                                                                      
 48%|████████████████████████████████████████████████████████████▉                                                                   | 6800/14290 [9:21:52<1:56:35,  1.07it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8

Killed███████████████████████████████████████████████████████████████████████████████████▌                                                 | 760/1204 [04:32<02:46,  2.66it/s]
(base) or@anidjar:~/Desktop/wav2vec2$ cd augmentations/
(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
Traceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/augmentations/augmentation_script.py", line 14, in <module>
    os.makedirs(new_path)  # only once creates directory
  File "/home/or/anaconda3/lib/python3.9/os.py", line 225, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: '/home/or/Desktop/russian_dataset/augmentations/augmented_GaussianNoise_audio'
(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ python3 augmentation_script.py 
----------- Augmenting... ----------------
----------- Augmenting complete. ----------


----------- exporting to mp3... ----------------
----------- exporting to mp3 complete. ----------


(base) or@anidjar:~/Desktop/wav2vec2/augmentations$ cd ..
(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-3f5dd2435db3f810
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12052.60it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2424.45it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1102.02it/s]
Using custom data configuration default-a5f54108dd45233d
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15650.39it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2525.17it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1025.75it/s]
Casting the dataset:  75%|████████████████████████████████████████████████████████████████████████████████████████▌                             | 3/4 [00:00<00:00, 19.52ba/s]
Casting the dataset:   0%|                                                                                                                              | 0/1 [00:00<?, ?ba/s]
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7fc05998d280> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36581/36581 [00:01<00:00, 34271.34ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9629/9629 [00:00<00:00, 37258.57ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'и': 0, 'b': 1, 'ъ': 2, 'я': 3, '—': 4, 'ж': 5, 'f': 6, 'з': 7, 'ь': 8, '…': 9, 'й': 10, 'е': 11, 'б': 12, 'м': 13, 'в': 14, 'ё': 15, 'р': 16, 'т': 17, '–': 18, '‑': 19, 'a': 20, 'i': 21, 'z': 22, 'н': 23, ')': 24, '−': 25, 'h': 26, 'к': 27, 'c': 28, 'п': 29, 'l': 30, 'x': 31, '(': 32, 'o': 33, 'д': 34, '«': 35, 't': 36, 'ц': 37, '»': 38, 'ф': 39, 'ю': 40, 'а': 41, 'у': 42, 'э': 43, 'х': 44, 'ш': 45, '„': 46, 'ч': 47, 'о': 48, 'щ': 49, 'r': 50, "'": 51, 'г': 52, 'k': 53, 'ы': 54, 'p': 55, ' ': 56, 'e': 57, 'с': 58, 'm': 59, 'n': 60, 'л': 61}
Vocab_len: 64
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_ru_25214310.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-1.8901949e-15, -4.6953148e-13, -7.2621851e-13, ...,
       -5.1819221e-10, -3.6428285e-10, -1.2440289e-10], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-2.9991360e-13, -8.7667646e-14,  1.2071884e-13, ...,
        2.1660353e-10, -2.9635747e-10, -4.2491713e-10], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                           | 0/18291 [00:00<?, ?ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0:   5%|███████                                                                                                                          | 998/18291 [00:52<17:41, 16.30ex/s]
#1:  22%|███████████████████████████▉                                                                                                    | 3997/18290 [01:33<03:55, 60.63ex/s]
^CProcess ForkPoolWorker-4:
Process ForkPoolWorker-3:
Traceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 165, in <module>
    train = train.map(prepare_dataset, remove_columns=train.column_names, num_proc=2)  # maybe we'll have to reduce to 1
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2685, in map
    transformed_shards[index] = async_result.get()
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 765, in get
    self.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 762, in wait
    self._event.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 581, in wait
    signaled = self._cond.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-3f5dd2435db3f810
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 297.34it/s]
Using custom data configuration default-a5f54108dd45233d
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 849.74it/s]
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ecad5a67b0423ba1.arrow
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0b8f5845c4d29140.arrow
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7f03ec9fcee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36581/36581 [00:01<00:00, 30646.19ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9629/9629 [00:00<00:00, 36480.71ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'й': 0, 'э': 1, 'я': 2, 'k': 3, 'о': 4, '‑': 5, 'ц': 6, 'c': 7, 'г': 8, 'm': 9, 't': 10, 'l': 11, 'x': 12, '«': 13, 'b': 14, "'": 15, 'ё': 16, '…': 17, 'i': 18, 'п': 19, 'n': 20, 'h': 21, 'р': 22, 'м': 23, 'ж': 24, 'б': 25, '–': 26, 'ь': 27, 'у': 28, '»': 29, 'e': 30, '„': 31, 'х': 32, 'с': 33, ')': 34, 'щ': 35, 'а': 36, 'ч': 37, 'f': 38, 'z': 39, ' ': 40, 'ю': 41, 'и': 42, 'r': 43, 'л': 44, 'ъ': 45, 'т': 46, 'з': 47, '(': 48, 'н': 49, 'a': 50, 'к': 51, 'д': 52, 'ш': 53, 'ы': 54, '−': 55, 'в': 56, 'p': 57, 'o': 58, '—': 59, 'е': 60, 'ф': 61}
Vocab_len: 64
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_ru_25214310.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-1.8901949e-15, -4.6953148e-13, -7.2621851e-13, ...,
       -5.1819221e-10, -3.6428285e-10, -1.2440289e-10], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-2.9991360e-13, -8.7667646e-14,  1.2071884e-13, ...,
        2.1660353e-10, -2.9635747e-10, -4.2491713e-10], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                           | 0/18291 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0:   5%|███████                                                                                                                          | 999/18291 [00:58<22:35, 12.76ex/s]
^Z:  22%|███████████████████████████▉                                                                                                    | 3992/18290 [01:34<02:43, 87.45ex/s]
[1]+  Stopped                 python3 main_russian.py
(base) or@anidjar:~/Desktop/wav2vec2$ fg
python3 main_russian.py

^CProcess ForkPoolWorker-4:
Process ForkPoolWorker-3:
Traceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 165, in <module>
    train = train.map(prepare_dataset, remove_columns=train.column_names, num_proc=4)  # maybe we'll have to reduce to 1
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2685, in map
    transformed_shards[index] = async_result.get()
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 765, in get
    self.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 762, in wait
    self._event.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 581, in wait
    signaled = self._cond.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ ps
    PID TTY          TIME CMD
1019724 pts/0    00:00:00 bash
3456563 pts/0    00:00:00 ps
(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-3f5dd2435db3f810
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 294.54it/s]
Using custom data configuration default-a5f54108dd45233d
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 954.77it/s]
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ecad5a67b0423ba1.arrow
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0b8f5845c4d29140.arrow
^CTraceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 65, in <module>
    train['audio']
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2343, in __getitem__
    return self._getitem(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2328, in _getitem
    formatted_output = format_table(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 512, in format_table
    return formatter(pa_table, query_type)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 284, in __call__
    return self.format_column(pa_table)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 319, in format_column
    column = self.python_features_decoder.decode_column(column, pa_table.column_names[0])
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 225, in decode_column
    return self.features.decode_column(column, column_name) if self.features else column
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1811, in decode_column
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1811, in <listcomp>
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1262, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 145, in decode_example
    array, sampling_rate = self._decode_mp3(file if file else path)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 296, in _decode_mp3
    array, sampling_rate = self._decode_mp3_torchaudio(path_or_file)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 325, in _decode_mp3_torchaudio
    array, sampling_rate = torchaudio.load(path_or_file, format="mp3")
  File "/home/or/anaconda3/lib/python3.9/site-packages/torchaudio/backend/sox_io_backend.py", line 227, in load
    return _fallback_load(filepath, frame_offset, num_frames, normalize, channels_first, format)
  File "/home/or/anaconda3/lib/python3.9/site-packages/torchaudio/io/_compat.py", line 103, in load_audio
    return _load_audio(s, frame_offset, num_frames, convert, channels_first)
  File "/home/or/anaconda3/lib/python3.9/site-packages/torchaudio/io/_compat.py", line 84, in _load_audio
    s.process_all_packets()
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-3f5dd2435db3f810
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12228.29it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1810.23it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1047.27it/s]
Using custom data configuration default-a5f54108dd45233d
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11008.67it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3175.10it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1244.60it/s]
Casting the dataset:  75%|████████████████████████████████████████████████████████████████████████████████████████▌                             | 3/4 [00:00<00:00, 18.94ba/s]
Casting the dataset:   0%|                                                                                                                              | 0/1 [00:00<?, ?ba/s]
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7fa8e8f85280> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36581/36581 [00:01<00:00, 33614.18ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9629/9629 [00:00<00:00, 35044.46ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'у': 0, 'ы': 1, 'е': 2, 'э': 3, 'о': 4, 'r': 5, 'щ': 6, '—': 7, ')': 8, 'ё': 9, 'i': 10, 'p': 11, 't': 12, 'ц': 13, 'b': 14, 'р': 15, 'h': 16, 'г': 17, 'ъ': 18, 'e': 19, '(': 20, 'f': 21, 'х': 22, 'ь': 23, 'н': 24, '«': 25, 'a': 26, ' ': 27, 'б': 28, '–': 29, '‑': 30, 'я': 31, 'к': 32, 'з': 33, 'z': 34, '…': 35, 'c': 36, 'а': 37, 'в': 38, 'м': 39, 'n': 40, 'п': 41, 'ш': 42, 'o': 43, 'k': 44, 'й': 45, 'x': 46, 'ж': 47, 'ю': 48, 'ч': 49, '−': 50, 'l': 51, 'm': 52, "'": 53, '»': 54, 'т': 55, 'л': 56, 'и': 57, '„': 58, 'ф': 59, 'д': 60, 'с': 61}
Vocab_len: 64
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_ru_25214310.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-1.8901949e-15, -4.6953148e-13, -7.2621851e-13, ...,
       -5.1819221e-10, -3.6428285e-10, -1.2440289e-10], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-2.9991360e-13, -8.7667646e-14,  1.2071884e-13, ...,
        2.1660353e-10, -2.9635747e-10, -4.2491713e-10], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                            | 0/9146 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                            | 0/9145 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0:   0%|                                                                                                                                    | 1/9146 [00:00<18:20,  8.31ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                    | 1/9145 [00:00<16:42,  9.12ex/s]
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
#0:  38%|████████████████████████████████████████████████▌                                                                              | 3498/9146 [02:17<1:37:17,  1.03s/ex]^CProcess ForkPoolWorker-8:                                                                                                                | 333/9145 [00:25<14:05, 10.42ex/s]
Process ForkPoolWorker-5:                                                                                                                  | 910/9145 [01:07<15:33,  8.82ex/s]
Process ForkPoolWorker-6:                                                                                                                | 533/9145 [00:45<1:42:51,  1.40ex/s]
Process ForkPoolWorker-7:
Traceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 165, in <module>
    train = train.map(prepare_dataset, remove_columns=train.column_names, num_proc=1)  # maybe we'll have to reduce to 1
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2685, in map
    transformed_shards[index] = async_result.get()
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 765, in get
    self.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 762, in wait
    self._event.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 581, in wait
    signaled = self._cond.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-3f5dd2435db3f810
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 294.52it/s]
Using custom data configuration default-a5f54108dd45233d
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 893.17it/s]
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ecad5a67b0423ba1.arrow
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0b8f5845c4d29140.arrow
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7f6ef4116ee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36581/36581 [00:01<00:00, 30139.46ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9629/9629 [00:00<00:00, 35308.10ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'и': 0, '»': 1, '−': 2, 'k': 3, 'е': 4, 'о': 5, 'н': 6, 'л': 7, 'b': 8, 'ё': 9, 'д': 10, ')': 11, 'ъ': 12, 'c': 13, '–': 14, 'h': 15, 'e': 16, 'i': 17, 'n': 18, '„': 19, 'r': 20, 'щ': 21, 'l': 22, 'в': 23, 'ю': 24, 'б': 25, 'г': 26, 'a': 27, "'": 28, 'м': 29, 'т': 30, 'ш': 31, 'з': 32, 'я': 33, 'z': 34, 'm': 35, 'ф': 36, 'o': 37, 'p': 38, 'а': 39, 'у': 40, 'ы': 41, ' ': 42, 'х': 43, 'с': 44, '…': 45, 'x': 46, 'п': 47, 'f': 48, 'р': 49, 'ц': 50, 't': 51, 'ч': 52, '«': 53, 'ь': 54, '(': 55, 'ж': 56, '‑': 57, 'й': 58, 'к': 59, 'э': 60, '—': 61}
Vocab_len: 64
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_ru_25214310.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-1.8901949e-15, -4.6953148e-13, -7.2621851e-13, ...,
       -5.1819221e-10, -3.6428285e-10, -1.2440289e-10], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-2.9991360e-13, -8.7667646e-14,  1.2071884e-13, ...,
        2.1660353e-10, -2.9635747e-10, -4.2491713e-10], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
  0%|                                                                                                                                               | 0/36581 [00:00<?, ?ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36581/36581 [04:20<00:00, 140.36ex/s]
#1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4814/4814 [01:55<00:00, 41.63ex/s]
#1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 4813/4814 [01:55<00:00, 104.35ex/s]
^CProcess ForkPoolWorker-2:
Process ForkPoolWorker-3:
Traceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 166, in <module>
    validation = validation.map(prepare_dataset, remove_columns=validation.column_names, num_proc=2)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2685, in map
    transformed_shards[index] = async_result.get()
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 765, in get
    self.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 762, in wait
    self._event.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 581, in wait
    signaled = self._cond.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-3f5dd2435db3f810
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 453.24it/s]
Using custom data configuration default-a5f54108dd45233d
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 610.35it/s]
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-3f5dd2435db3f810/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ecad5a67b0423ba1.arrow
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0b8f5845c4d29140.arrow
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7faae1c15ee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36581/36581 [00:01<00:00, 29377.39ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9629/9629 [00:00<00:00, 35107.64ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'в': 0, 'т': 1, 'л': 2, 'o': 3, 'п': 4, 'ю': 5, 'и': 6, 'к': 7, 'x': 8, 'г': 9, '—': 10, ')': 11, 'э': 12, 'н': 13, '–': 14, 'а': 15, 'о': 16, 'я': 17, 'р': 18, 'ц': 19, 'ъ': 20, 'k': 21, 'r': 22, 'ё': 23, 'c': 24, 'щ': 25, "'": 26, ' ': 27, 'ы': 28, '„': 29, 'д': 30, 'a': 31, 'n': 32, 'ш': 33, 'p': 34, 'ч': 35, 'ф': 36, 'ь': 37, 'f': 38, 't': 39, 'h': 40, 'z': 41, 'х': 42, 'm': 43, 'ж': 44, '‑': 45, 'б': 46, '…': 47, 'е': 48, 'з': 49, 'й': 50, 'м': 51, 'e': 52, '(': 53, 'l': 54, '«': 55, 'с': 56, '»': 57, 'у': 58, '−': 59, 'b': 60, 'i': 61}
Vocab_len: 64
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_ru_25214310.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-1.8901949e-15, -4.6953148e-13, -7.2621851e-13, ...,
       -5.1819221e-10, -3.6428285e-10, -1.2440289e-10], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_25214310.mp3', 'array': array([-2.9991360e-13, -8.7667646e-14,  1.2071884e-13, ...,
        2.1660353e-10, -2.9635747e-10, -4.2491713e-10], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
  0%|                                                                                                                                               | 0/36581 [00:00<?, ?ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36581/36581 [04:21<00:00, 139.66ex/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9629/9629 [01:11<00:00, 135.36ex/s]


----------------- Preparing datasets complete. -----------------


----------------- saving datasets... -----------------
----------------- saving datasets complete. -----------


----------------- Loading Metrics... -----------------
/home/or/Desktop/wav2vec2/main_russian.py:246: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['project_hid.bias', 'project_q.weight', 'project_hid.weight', 'project_q.bias', 'quantizer.codevectors', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 36581
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 16
  Gradient Accumulation steps = 2
  Total optimization steps = 22860
  Number of trainable parameters = 311294144
  0%|                                                                                                                                               | 0/22860 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 13.5122, 'learning_rate': 5.399999999999999e-06, 'epoch': 0.0}                                                                                                       
{'loss': 13.8441, 'learning_rate': 1.0799999999999998e-05, 'epoch': 0.01}                                                                                                     
{'loss': 13.7473, 'learning_rate': 1.68e-05, 'epoch': 0.01}                                                                                                                   
{'loss': 15.7799, 'learning_rate': 2.2199999999999998e-05, 'epoch': 0.02}                                                                                                     
{'loss': 20.1898, 'learning_rate': 2.7599999999999997e-05, 'epoch': 0.02}                                                                                                     
{'loss': 11.6701, 'learning_rate': 3.36e-05, 'epoch': 0.03}                                                                                                                   
{'loss': 9.7044, 'learning_rate': 3.96e-05, 'epoch': 0.03}                                                                                                                    
{'loss': 7.2405, 'learning_rate': 4.56e-05, 'epoch': 0.03}                                                                                                                    
{'loss': 6.2356, 'learning_rate': 5.1599999999999994e-05, 'epoch': 0.04}                                                                                                      
{'loss': 6.4733, 'learning_rate': 5.76e-05, 'epoch': 0.04}                                                                                                                    
  0%|▌                                                                                                                                  | 100/22860 [01:41<3:26:04,  1.84it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 4.340520858764648, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 393.2781, 'eval_samples_per_second': 24.484, 'eval_steps_per_second': 3.061, 'epoch': 0.04}                                                                                                                                                
{'loss': 4.1237, 'learning_rate': 6.359999999999999e-05, 'epoch': 0.05}                                                                                                       
{'loss': 3.789, 'learning_rate': 6.96e-05, 'epoch': 0.05}                                                                                                                     
{'loss': 3.6332, 'learning_rate': 7.56e-05, 'epoch': 0.06}                                                                                                                    
{'loss': 3.5036, 'learning_rate': 8.16e-05, 'epoch': 0.06}                                                                                                                    
{'loss': 3.6745, 'learning_rate': 8.759999999999999e-05, 'epoch': 0.07}                                                                                                       
{'loss': 3.3296, 'learning_rate': 9.36e-05, 'epoch': 0.07}                                                                                                                    
{'loss': 3.2375, 'learning_rate': 9.96e-05, 'epoch': 0.07}                                                                                                                    
{'loss': 3.2353, 'learning_rate': 0.00010559999999999998, 'epoch': 0.08}                                                                                                      
{'loss': 3.2565, 'learning_rate': 0.00011159999999999999, 'epoch': 0.08}                                                                                                      
{'loss': 3.409, 'learning_rate': 0.0001176, 'epoch': 0.09}                                                                                                                    
  1%|█▏                                                                                                                                 | 200/22860 [09:55<3:16:31,  1.92it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.292044162750244, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 389.9815, 'eval_samples_per_second': 24.691, 'eval_steps_per_second': 3.087, 'epoch': 0.09}                                                                                                                                                
{'loss': 3.2819, 'learning_rate': 0.0001236, 'epoch': 0.09}                                                                                                                   
{'loss': 3.1957, 'learning_rate': 0.00012959999999999998, 'epoch': 0.1}                                                                                                       
{'loss': 3.2292, 'learning_rate': 0.0001356, 'epoch': 0.1}                                                                                                                    
{'loss': 3.2381, 'learning_rate': 0.00014159999999999997, 'epoch': 0.1}                                                                                                       
{'loss': 3.3054, 'learning_rate': 0.00014759999999999998, 'epoch': 0.11}                                                                                                      
{'loss': 3.2136, 'learning_rate': 0.0001536, 'epoch': 0.11}                                                                                                                   
{'loss': 3.2032, 'learning_rate': 0.0001596, 'epoch': 0.12}                                                                                                                   
{'loss': 3.2557, 'learning_rate': 0.0001656, 'epoch': 0.12}                                                                                                                   
{'loss': 3.2309, 'learning_rate': 0.00017159999999999997, 'epoch': 0.13}                                                                                                      
{'loss': 3.2876, 'learning_rate': 0.00017759999999999998, 'epoch': 0.13}                                                                                                      
  1%|█▋                                                                                                                                 | 300/22860 [18:03<3:06:35,  2.02it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.2404184341430664, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 394.1282, 'eval_samples_per_second': 24.431, 'eval_steps_per_second': 3.055, 'epoch': 0.13}                                                                                                                                               
{'loss': 3.2025, 'learning_rate': 0.0001836, 'epoch': 0.14}                                                                                                                   
{'loss': 3.1773, 'learning_rate': 0.00018959999999999997, 'epoch': 0.14}                                                                                                      
{'loss': 3.1729, 'learning_rate': 0.00019559999999999998, 'epoch': 0.14}                                                                                                      
{'loss': 3.2409, 'learning_rate': 0.0002016, 'epoch': 0.15}                                                                                                                   
{'loss': 3.2723, 'learning_rate': 0.00020759999999999998, 'epoch': 0.15}                                                                                                      
{'loss': 3.2404, 'learning_rate': 0.00021359999999999996, 'epoch': 0.16}                                                                                                      
{'loss': 3.1538, 'learning_rate': 0.00021959999999999997, 'epoch': 0.16}                                                                                                      
{'loss': 3.1739, 'learning_rate': 0.00022559999999999998, 'epoch': 0.17}                                                                                                      
{'loss': 3.1823, 'learning_rate': 0.0002316, 'epoch': 0.17}                                                                                                                   
{'loss': 3.2888, 'learning_rate': 0.0002376, 'epoch': 0.17}                                                                                                                   
  2%|██▎                                                                                                                                | 400/22860 [26:17<3:13:23,  1.94it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.3245129585266113, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 393.7201, 'eval_samples_per_second': 24.456, 'eval_steps_per_second': 3.058, 'epoch': 0.17}                                                                                                                                               
{'loss': 3.3219, 'learning_rate': 0.00024359999999999999, 'epoch': 0.18}                                                                                                      
{'loss': 3.1635, 'learning_rate': 0.00024959999999999994, 'epoch': 0.18}                                                                                                      
{'loss': 3.1621, 'learning_rate': 0.0002556, 'epoch': 0.19}                                                                                                                   
{'loss': 3.2109, 'learning_rate': 0.00026159999999999996, 'epoch': 0.19}                                                                                                      
{'loss': 3.2465, 'learning_rate': 0.0002676, 'epoch': 0.2}                                                                                                                    
{'loss': 3.1764, 'learning_rate': 0.0002736, 'epoch': 0.2}                                                                                                                    
{'loss': 3.1592, 'learning_rate': 0.00027959999999999997, 'epoch': 0.21}                                                                                                      
{'loss': 3.1683, 'learning_rate': 0.00028559999999999995, 'epoch': 0.21}                                                                                                      
{'loss': 3.1716, 'learning_rate': 0.0002916, 'epoch': 0.21}                                                                                                                   
{'loss': 3.2108, 'learning_rate': 0.00029759999999999997, 'epoch': 0.22}                                                                                                      
  2%|██▊                                                                                                                                | 500/22860 [34:30<3:11:12,  1.95it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.1623644828796387, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 392.8584, 'eval_samples_per_second': 24.51, 'eval_steps_per_second': 3.065, 'epoch': 0.22}                                                                                                                                                
{'loss': 3.1555, 'learning_rate': 0.00029991949910554563, 'epoch': 0.22}                                                                                                      
{'loss': 3.1395, 'learning_rate': 0.0002997853309481216, 'epoch': 0.23}                                                                                                       
{'loss': 3.1556, 'learning_rate': 0.00029965116279069765, 'epoch': 0.23}                                                                                                      
{'loss': 3.1728, 'learning_rate': 0.0002995169946332737, 'epoch': 0.24}                                                                                                       
{'loss': 3.2055, 'learning_rate': 0.00029938282647584973, 'epoch': 0.24}                                                                                                      
{'loss': 3.1436, 'learning_rate': 0.00029924865831842577, 'epoch': 0.24}                                                                                                      
{'loss': 3.1185, 'learning_rate': 0.00029911449016100175, 'epoch': 0.25}                                                                                                      
{'loss': 3.1355, 'learning_rate': 0.0002989803220035778, 'epoch': 0.25}                                                                                                       
{'loss': 3.1458, 'learning_rate': 0.0002988461538461538, 'epoch': 0.26}                                                                                                       
{'loss': 3.2125, 'learning_rate': 0.00029871198568872986, 'epoch': 0.26}                                                                                                      
  3%|███▍                                                                                                                               | 600/22860 [42:44<3:10:31,  1.95it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.1525826454162598, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 392.2711, 'eval_samples_per_second': 24.547, 'eval_steps_per_second': 3.069, 'epoch': 0.26}                                                                                                                                               
{'loss': 3.1472, 'learning_rate': 0.00029857781753130585, 'epoch': 0.27}                                                                                                      
{'loss': 3.1211, 'learning_rate': 0.0002984436493738819, 'epoch': 0.27}                                                                                                       
{'loss': 3.1301, 'learning_rate': 0.0002983094812164579, 'epoch': 0.28}                                                                                                       
{'loss': 3.1262, 'learning_rate': 0.00029817531305903396, 'epoch': 0.28}                                                                                                      
{'loss': 3.1577, 'learning_rate': 0.00029804114490161, 'epoch': 0.28}                                                                                                         
{'loss': 3.1719, 'learning_rate': 0.000297906976744186, 'epoch': 0.29}                                                                                                        
{'loss': 3.1148, 'learning_rate': 0.000297772808586762, 'epoch': 0.29}                                                                                                        
{'loss': 3.089, 'learning_rate': 0.00029763864042933806, 'epoch': 0.3}                                                                                                        
{'loss': 3.0897, 'learning_rate': 0.0002975044722719141, 'epoch': 0.3}                                                                                                        
{'loss': 3.0601, 'learning_rate': 0.00029737030411449014, 'epoch': 0.31}                                                                                                      
  3%|████                                                                                                                               | 700/22860 [50:56<3:04:07,  2.01it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.0914883613586426, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 394.4581, 'eval_samples_per_second': 24.411, 'eval_steps_per_second': 3.052, 'epoch': 0.31}                                                                                                                                               
{'loss': 3.1317, 'learning_rate': 0.0002972361359570662, 'epoch': 0.31}                                                                                                       
{'loss': 3.1183, 'learning_rate': 0.0002971019677996422, 'epoch': 0.31}                                                                                                       
{'loss': 3.1022, 'learning_rate': 0.00029696779964221825, 'epoch': 0.32}                                                                                                      
{'loss': 3.1188, 'learning_rate': 0.0002968336314847943, 'epoch': 0.32}                                                                                                       
{'loss': 3.0961, 'learning_rate': 0.00029669946332737027, 'epoch': 0.33}                                                                                                      
{'loss': 3.1273, 'learning_rate': 0.0002965652951699463, 'epoch': 0.33}                                                                                                       
{'loss': 3.0941, 'learning_rate': 0.00029643112701252235, 'epoch': 0.34}                                                                                                      
{'loss': 3.0954, 'learning_rate': 0.0002962969588550984, 'epoch': 0.34}                                                                                                       
{'loss': 3.124, 'learning_rate': 0.00029616279069767437, 'epoch': 0.35}                                                                                                       
{'loss': 3.0663, 'learning_rate': 0.0002960286225402504, 'epoch': 0.35}                                                                                                       
  3%|████▌                                                                                                                              | 800/22860 [59:10<3:01:16,  2.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.0778048038482666, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 394.8596, 'eval_samples_per_second': 24.386, 'eval_steps_per_second': 3.049, 'epoch': 0.35}                                                                                                                                               
{'loss': 3.1034, 'learning_rate': 0.00029589445438282645, 'epoch': 0.35}                                                                                                      
{'loss': 3.0783, 'learning_rate': 0.0002957602862254025, 'epoch': 0.36}                                                                                                       
{'loss': 3.0572, 'learning_rate': 0.0002956261180679785, 'epoch': 0.36}                                                                                                       
{'loss': 3.0338, 'learning_rate': 0.0002954919499105545, 'epoch': 0.37}                                                                                                       
{'loss': 3.0268, 'learning_rate': 0.00029535778175313054, 'epoch': 0.37}                                                                                                      
{'loss': 3.0336, 'learning_rate': 0.0002952236135957066, 'epoch': 0.38}                                                                                                       
{'loss': 2.9272, 'learning_rate': 0.0002950894454382826, 'epoch': 0.38}                                                                                                       
{'loss': 2.8384, 'learning_rate': 0.00029495527728085866, 'epoch': 0.38}                                                                                                      
{'loss': 2.7963, 'learning_rate': 0.0002948211091234347, 'epoch': 0.39}                                                                                                       
{'loss': 2.7382, 'learning_rate': 0.00029468694096601073, 'epoch': 0.39}                                                                                                      
  4%|█████                                                                                                                            | 900/22860 [1:07:24<3:08:23,  1.94it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 2.5168263912200928, 'eval_wer': 0.9778399618956894, 'eval_cer': 0.9371997811062243, 'eval_runtime': 395.7315, 'eval_samples_per_second': 24.332, 'eval_steps_per_second': 3.042, 'epoch': 0.39}                                                                                                                                               
{'loss': 2.5321, 'learning_rate': 0.00029455277280858677, 'epoch': 0.4}                                                                                                       
{'loss': 2.2952, 'learning_rate': 0.00029441860465116276, 'epoch': 0.4}                                                                                                       
{'loss': 2.2126, 'learning_rate': 0.0002942844364937388, 'epoch': 0.41}                                                                                                       
{'loss': 2.0818, 'learning_rate': 0.00029415026833631483, 'epoch': 0.41}                                                                                                      
{'loss': 2.1585, 'learning_rate': 0.00029401610017889087, 'epoch': 0.42}                                                                                                      
{'loss': 1.7822, 'learning_rate': 0.0002938819320214669, 'epoch': 0.42}                                                                                                       
{'loss': 1.6454, 'learning_rate': 0.0002937477638640429, 'epoch': 0.42}                                                                                                       
{'loss': 1.6365, 'learning_rate': 0.00029361359570661893, 'epoch': 0.43}                                                                                                      
{'loss': 1.6788, 'learning_rate': 0.00029347942754919497, 'epoch': 0.43}                                                                                                      
{'loss': 1.7819, 'learning_rate': 0.000293345259391771, 'epoch': 0.44}                                                                                                        
  4%|█████▌                                                                                                                          | 1000/22860 [1:15:41<3:06:46,  1.95it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 1.2877143621444702, 'eval_wer': 0.9721838532984044, 'eval_cer': 0.40924691082781034, 'eval_runtime': 398.2426, 'eval_samples_per_second': 24.179, 'eval_steps_per_second': 3.023, 'epoch': 0.44}                                                                                                                                              
{'loss': 1.4643, 'learning_rate': 0.000293211091234347, 'epoch': 0.44}                                                                                                        
{'loss': 1.462, 'learning_rate': 0.00029307692307692303, 'epoch': 0.45}                                                                                                       
{'loss': 1.4749, 'learning_rate': 0.00029294275491949907, 'epoch': 0.45}                                                                                                      
{'loss': 1.4827, 'learning_rate': 0.0002928085867620751, 'epoch': 0.45}                                                                                                       
{'loss': 1.7826, 'learning_rate': 0.00029267441860465114, 'epoch': 0.46}                                                                                                      
{'loss': 1.3992, 'learning_rate': 0.0002925402504472272, 'epoch': 0.46}                                                                                                       
{'loss': 1.2804, 'learning_rate': 0.00029240608228980316, 'epoch': 0.47}                                                                                                      
{'loss': 1.342, 'learning_rate': 0.0002922719141323792, 'epoch': 0.47}                                                                                                        
{'loss': 1.3922, 'learning_rate': 0.00029213774597495524, 'epoch': 0.48}                                                                                                      
{'loss': 1.5681, 'learning_rate': 0.0002920035778175313, 'epoch': 0.48}                                                                                                       
  5%|██████▏                                                                                                                         | 1100/22860 [1:23:58<3:05:17,  1.96it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 1.005147099494934, 'eval_wer': 0.9493927125506073, 'eval_cer': 0.3195933575197444, 'eval_runtime': 401.1313, 'eval_samples_per_second': 24.005, 'eval_steps_per_second': 3.002, 'epoch': 0.48}                                                                                                                                                
{'loss': 1.1855, 'learning_rate': 0.0002918694096601073, 'epoch': 0.49}                                                                                                       
{'loss': 1.1887, 'learning_rate': 0.00029173524150268335, 'epoch': 0.49}                                                                                                      
{'loss': 1.1694, 'learning_rate': 0.0002916010733452594, 'epoch': 0.49}                                                                                                       
{'loss': 1.3409, 'learning_rate': 0.00029146690518783543, 'epoch': 0.5}                                                                                                       
{'loss': 1.5329, 'learning_rate': 0.0002913327370304114, 'epoch': 0.5}                                                                                                        
{'loss': 1.1819, 'learning_rate': 0.00029119856887298745, 'epoch': 0.51}                                                                                                      
{'loss': 1.1048, 'learning_rate': 0.0002910644007155635, 'epoch': 0.51}                                                                                                       
{'loss': 1.1326, 'learning_rate': 0.00029093023255813953, 'epoch': 0.52}                                                                                                      
{'loss': 1.2213, 'learning_rate': 0.0002907960644007155, 'epoch': 0.52}                                                                                                       
{'loss': 1.3944, 'learning_rate': 0.00029066189624329155, 'epoch': 0.52}                                                                                                      
  5%|██████▋                                                                                                                         | 1200/22860 [1:32:19<3:06:43,  1.93it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.8423522710800171, 'eval_wer': 0.9011550369135508, 'eval_cer': 0.28445719072809206, 'eval_runtime': 396.2849, 'eval_samples_per_second': 24.298, 'eval_steps_per_second': 3.038, 'epoch': 0.52}                                                                                                                                              
{'loss': 1.0007, 'learning_rate': 0.0002905277280858676, 'epoch': 0.53}                                                                                                       
{'loss': 1.0191, 'learning_rate': 0.0002903935599284436, 'epoch': 0.53}                                                                                                       
{'loss': 1.1262, 'learning_rate': 0.00029025939177101967, 'epoch': 0.54}                                                                                                      
{'loss': 1.2171, 'learning_rate': 0.00029012522361359565, 'epoch': 0.54}                                                                                                      
{'loss': 1.4747, 'learning_rate': 0.0002899910554561717, 'epoch': 0.55}                                                                                                       
{'loss': 0.9591, 'learning_rate': 0.0002898568872987477, 'epoch': 0.55}                                                                                                       
{'loss': 0.987, 'learning_rate': 0.00028972271914132376, 'epoch': 0.56}                                                                                                       
{'loss': 1.0409, 'learning_rate': 0.0002895885509838998, 'epoch': 0.56}                                                                                                       
{'loss': 1.1722, 'learning_rate': 0.00028945438282647584, 'epoch': 0.56}                                                                                                      
{'loss': 1.3653, 'learning_rate': 0.0002893202146690519, 'epoch': 0.57}                                                                                                       
  6%|███████▎                                                                                                                        | 1300/22860 [1:40:36<3:07:46,  1.91it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.7757205367088318, 'eval_wer': 0.8804120028578233, 'eval_cer': 0.26472972699081865, 'eval_runtime': 397.9142, 'eval_samples_per_second': 24.199, 'eval_steps_per_second': 3.026, 'epoch': 0.57}                                                                                                                                              
{'loss': 0.9487, 'learning_rate': 0.0002891860465116279, 'epoch': 0.57}                                                                                                       
{'loss': 0.9094, 'learning_rate': 0.0002890518783542039, 'epoch': 0.58}                                                                                                       
{'loss': 1.0721, 'learning_rate': 0.00028891771019677994, 'epoch': 0.58}                                                                                                      
{'loss': 1.1092, 'learning_rate': 0.000288783542039356, 'epoch': 0.59}                                                                                                        
{'loss': 1.4086, 'learning_rate': 0.000288649373881932, 'epoch': 0.59}                                                                                                        
{'loss': 0.9987, 'learning_rate': 0.00028851520572450805, 'epoch': 0.59}                                                                                                      
{'loss': 0.8802, 'learning_rate': 0.00028838103756708404, 'epoch': 0.6}                                                                                                       
{'loss': 0.9827, 'learning_rate': 0.0002882468694096601, 'epoch': 0.6}                                                                                                        
{'loss': 1.0234, 'learning_rate': 0.0002881127012522361, 'epoch': 0.61}                                                                                                       
{'loss': 1.2913, 'learning_rate': 0.00028797853309481215, 'epoch': 0.61}                                                                                                      
  6%|███████▊                                                                                                                        | 1400/22860 [1:48:54<3:02:50,  1.96it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.7037601470947266, 'eval_wer': 0.8422719695165516, 'eval_cer': 0.2388104069127195, 'eval_runtime': 402.0379, 'eval_samples_per_second': 23.95, 'eval_steps_per_second': 2.995, 'epoch': 0.61}                                                                                                                                                
{'loss': 0.9182, 'learning_rate': 0.0002878443649373882, 'epoch': 0.62}                                                                                                       
{'loss': 0.901, 'learning_rate': 0.00028771019677996417, 'epoch': 0.62}                                                                                                       
{'loss': 0.973, 'learning_rate': 0.0002875760286225402, 'epoch': 0.63}                                                                                                        
{'loss': 1.0775, 'learning_rate': 0.00028744186046511625, 'epoch': 0.63}                                                                                                      
{'loss': 1.2926, 'learning_rate': 0.0002873076923076923, 'epoch': 0.63}                                                                                                       
{'loss': 0.8182, 'learning_rate': 0.0002871735241502683, 'epoch': 0.64}                                                                                                       
{'loss': 0.8706, 'learning_rate': 0.0002870393559928443, 'epoch': 0.64}                                                                                                       
{'loss': 1.022, 'learning_rate': 0.00028690518783542035, 'epoch': 0.65}                                                                                                       
{'loss': 0.9792, 'learning_rate': 0.0002867710196779964, 'epoch': 0.65}                                                                                                       
{'loss': 1.2347, 'learning_rate': 0.0002866368515205724, 'epoch': 0.66}                                                                                                       
  7%|████████▍                                                                                                                       | 1500/22860 [1:57:15<3:01:40,  1.96it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.6343336701393127, 'eval_wer': 0.8103238866396761, 'eval_cer': 0.21970280440760184, 'eval_runtime': 396.1848, 'eval_samples_per_second': 24.304, 'eval_steps_per_second': 3.039, 'epoch': 0.66}                                                                                                                                              
{'loss': 0.826, 'learning_rate': 0.00028650268336314846, 'epoch': 0.66}                                                                                                       
{'loss': 0.8925, 'learning_rate': 0.0002863685152057245, 'epoch': 0.66}                                                                                                       
{'loss': 0.9174, 'learning_rate': 0.00028623434704830054, 'epoch': 0.67}                                                                                                      
{'loss': 1.0164, 'learning_rate': 0.0002861001788908766, 'epoch': 0.67}                                                                                                       
{'loss': 1.1817, 'learning_rate': 0.00028596601073345256, 'epoch': 0.68}                                                                                                      
{'loss': 0.7604, 'learning_rate': 0.0002858318425760286, 'epoch': 0.68}                                                                                                       
{'loss': 0.8613, 'learning_rate': 0.00028569767441860463, 'epoch': 0.69}                                                                                                      
{'loss': 0.8759, 'learning_rate': 0.00028556350626118067, 'epoch': 0.69}                                                                                                      
{'loss': 1.0227, 'learning_rate': 0.0002854293381037567, 'epoch': 0.7}                                                                                                        
{'loss': 1.2049, 'learning_rate': 0.0002852951699463327, 'epoch': 0.7}                                                                                                        
  7%|████████▉                                                                                                                       | 1600/22860 [2:05:31<3:00:49,  1.96it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5805131793022156, 'eval_wer': 0.7702786377708978, 'eval_cer': 0.20232811096022754, 'eval_runtime': 397.424, 'eval_samples_per_second': 24.229, 'eval_steps_per_second': 3.03, 'epoch': 0.7}                                                                                                                                                 
{'loss': 0.7501, 'learning_rate': 0.00028516100178890873, 'epoch': 0.7}                                                                                                       
{'loss': 0.7884, 'learning_rate': 0.00028502683363148477, 'epoch': 0.71}                                                                                                      
{'loss': 0.8939, 'learning_rate': 0.0002848926654740608, 'epoch': 0.71}                                                                                                       
{'loss': 0.9092, 'learning_rate': 0.0002847584973166368, 'epoch': 0.72}                                                                                                       
{'loss': 1.1424, 'learning_rate': 0.00028462432915921283, 'epoch': 0.72}                                                                                                      
{'loss': 0.7986, 'learning_rate': 0.00028449016100178887, 'epoch': 0.73}                                                                                                      
{'loss': 0.7981, 'learning_rate': 0.0002843559928443649, 'epoch': 0.73}                                                                                                       
{'loss': 0.8751, 'learning_rate': 0.00028422182468694094, 'epoch': 0.73}                                                                                                      
{'loss': 0.9126, 'learning_rate': 0.000284087656529517, 'epoch': 0.74}                                                                                                        
{'loss': 1.2431, 'learning_rate': 0.000283953488372093, 'epoch': 0.74}                                                                                                        
  7%|█████████▌                                                                                                                      | 1700/22860 [2:13:48<3:00:16,  1.96it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5455296635627747, 'eval_wer': 0.7502619671350321, 'eval_cer': 0.1962207043785511, 'eval_runtime': 394.8172, 'eval_samples_per_second': 24.389, 'eval_steps_per_second': 3.05, 'epoch': 0.74}                                                                                                                                                
{'loss': 0.6986, 'learning_rate': 0.00028381932021466906, 'epoch': 0.75}                                                                                                      
{'loss': 0.7926, 'learning_rate': 0.00028368515205724504, 'epoch': 0.75}                                                                                                      
{'loss': 0.8537, 'learning_rate': 0.0002835509838998211, 'epoch': 0.76}                                                                                                       
{'loss': 0.9114, 'learning_rate': 0.0002834168157423971, 'epoch': 0.76}                                                                                                       
{'loss': 1.1173, 'learning_rate': 0.00028328264758497316, 'epoch': 0.77}                                                                                                      
{'loss': 0.6732, 'learning_rate': 0.0002831484794275492, 'epoch': 0.77}                                                                                                       
{'loss': 0.7718, 'learning_rate': 0.0002830143112701252, 'epoch': 0.77}                                                                                                       
{'loss': 0.9323, 'learning_rate': 0.0002828801431127012, 'epoch': 0.78}                                                                                                       
{'loss': 0.9411, 'learning_rate': 0.00028274597495527725, 'epoch': 0.78}                                                                                                      
{'loss': 1.2243, 'learning_rate': 0.0002826118067978533, 'epoch': 0.79}                                                                                                       
  8%|██████████                                                                                                                      | 1800/22860 [2:22:04<3:03:18,  1.91it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5468420386314392, 'eval_wer': 0.7457370802572041, 'eval_cer': 0.19303188147307404, 'eval_runtime': 398.5784, 'eval_samples_per_second': 24.158, 'eval_steps_per_second': 3.021, 'epoch': 0.79}                                                                                                                                              
{'loss': 0.6862, 'learning_rate': 0.00028247763864042933, 'epoch': 0.79}                                                                                                      
{'loss': 0.668, 'learning_rate': 0.0002823434704830053, 'epoch': 0.8}                                                                                                         
{'loss': 0.8576, 'learning_rate': 0.00028220930232558135, 'epoch': 0.8}                                                                                                       
{'loss': 0.8988, 'learning_rate': 0.0002820751341681574, 'epoch': 0.8}                                                                                                        
{'loss': 1.0726, 'learning_rate': 0.00028194096601073343, 'epoch': 0.81}                                                                                                      
{'loss': 0.7053, 'learning_rate': 0.00028180679785330947, 'epoch': 0.81}                                                                                                      
{'loss': 0.6733, 'learning_rate': 0.00028167262969588545, 'epoch': 0.82}                                                                                                      
{'loss': 0.7685, 'learning_rate': 0.0002815384615384615, 'epoch': 0.82}                                                                                                       
{'loss': 0.8537, 'learning_rate': 0.0002814042933810375, 'epoch': 0.83}                                                                                                       
{'loss': 1.075, 'learning_rate': 0.00028127012522361356, 'epoch': 0.83}                                                                                                       
  8%|██████████▋                                                                                                                     | 1900/22860 [2:30:23<2:57:38,  1.97it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.4984510838985443, 'eval_wer': 0.7080138128125745, 'eval_cer': 0.1803036137740935, 'eval_runtime': 398.6312, 'eval_samples_per_second': 24.155, 'eval_steps_per_second': 3.02, 'epoch': 0.83}                                                                                                                                                
{'loss': 0.6768, 'learning_rate': 0.0002811359570661896, 'epoch': 0.84}                                                                                                       
{'loss': 0.6883, 'learning_rate': 0.00028100178890876564, 'epoch': 0.84}                                                                                                      
{'loss': 0.738, 'learning_rate': 0.0002808676207513417, 'epoch': 0.84}                                                                                                        
{'loss': 0.8688, 'learning_rate': 0.0002807334525939177, 'epoch': 0.85}                                                                                                       
{'loss': 1.0365, 'learning_rate': 0.0002805992844364937, 'epoch': 0.85}                                                                                                       
{'loss': 0.6602, 'learning_rate': 0.00028046511627906974, 'epoch': 0.86}                                                                                                      
{'loss': 0.7091, 'learning_rate': 0.0002803309481216458, 'epoch': 0.86}                                                                                                       
{'loss': 0.7732, 'learning_rate': 0.0002801967799642218, 'epoch': 0.87}                                                                                                       
{'loss': 0.9761, 'learning_rate': 0.00028006261180679785, 'epoch': 0.87}                                                                                                      
{'loss': 1.0799, 'learning_rate': 0.00027992844364937384, 'epoch': 0.87}                                                                                                      
  9%|███████████▏                                                                                                                    | 2000/22860 [2:38:43<3:02:19,  1.91it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.47117990255355835, 'eval_wer': 0.6857704215289354, 'eval_cer': 0.1720292263726464, 'eval_runtime': 397.9917, 'eval_samples_per_second': 24.194, 'eval_steps_per_second': 3.025, 'epoch': 0.87}                                                                                                                                              
{'loss': 0.626, 'learning_rate': 0.0002797942754919499, 'epoch': 0.88}                                                                                                        
{'loss': 0.6812, 'learning_rate': 0.0002796601073345259, 'epoch': 0.88}                                                                                                       
{'loss': 0.8264, 'learning_rate': 0.00027952593917710195, 'epoch': 0.89}                                                                                                      
{'loss': 0.8597, 'learning_rate': 0.00027939177101967794, 'epoch': 0.89}                                                                                                      
{'loss': 1.1014, 'learning_rate': 0.000279257602862254, 'epoch': 0.9}                                                                                                         
{'loss': 0.5561, 'learning_rate': 0.00027912343470483, 'epoch': 0.9}                                                                                                          
{'loss': 0.6947, 'learning_rate': 0.00027898926654740605, 'epoch': 0.91}                                                                                                      
{'loss': 0.6775, 'learning_rate': 0.0002788550983899821, 'epoch': 0.91}                                                                                                       
{'loss': 0.8664, 'learning_rate': 0.0002787209302325581, 'epoch': 0.91}                                                                                                       
{'loss': 1.0762, 'learning_rate': 0.00027858676207513416, 'epoch': 0.92}                                                                                                      
  9%|███████████▊                                                                                                                    | 2100/22860 [2:47:01<2:57:42,  1.95it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.47522011399269104, 'eval_wer': 0.697880447725649, 'eval_cer': 0.1764206138484093, 'eval_runtime': 398.0637, 'eval_samples_per_second': 24.19, 'eval_steps_per_second': 3.025, 'epoch': 0.92}                                                                                                                                                
{'loss': 0.6086, 'learning_rate': 0.0002784525939177102, 'epoch': 0.92}                                                                                                       
{'loss': 0.6538, 'learning_rate': 0.0002783184257602862, 'epoch': 0.93}                                                                                                       
{'loss': 0.7129, 'learning_rate': 0.0002781842576028622, 'epoch': 0.93}                                                                                                       
{'loss': 0.8206, 'learning_rate': 0.00027805008944543826, 'epoch': 0.94}                                                                                                      
{'loss': 0.9982, 'learning_rate': 0.0002779159212880143, 'epoch': 0.94}                                                                                                       
{'loss': 0.608, 'learning_rate': 0.00027778175313059034, 'epoch': 0.94}                                                                                                       
{'loss': 0.6458, 'learning_rate': 0.0002776475849731664, 'epoch': 0.95}                                                                                                       
{'loss': 0.7458, 'learning_rate': 0.00027751341681574236, 'epoch': 0.95}                                                                                                      
{'loss': 0.822, 'learning_rate': 0.0002773792486583184, 'epoch': 0.96}                                                                                                        
{'loss': 1.0009, 'learning_rate': 0.00027724508050089444, 'epoch': 0.96}                                                                                                      
 10%|████████████▎                                                                                                                   | 2200/22860 [2:55:22<3:05:43,  1.85it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.43950068950653076, 'eval_wer': 0.6585734698737795, 'eval_cer': 0.16679334130539059, 'eval_runtime': 400.6281, 'eval_samples_per_second': 24.035, 'eval_steps_per_second': 3.005, 'epoch': 0.96}                                                                                                                                             
{'loss': 0.6181, 'learning_rate': 0.0002771109123434705, 'epoch': 0.97}                                                                                                       
{'loss': 0.6414, 'learning_rate': 0.00027697674418604646, 'epoch': 0.97}                                                                                                      
{'loss': 0.6741, 'learning_rate': 0.0002768425760286225, 'epoch': 0.98}                                                                                                       
{'loss': 0.8074, 'learning_rate': 0.00027670840787119853, 'epoch': 0.98}                                                                                                      
{'loss': 1.0163, 'learning_rate': 0.00027657423971377457, 'epoch': 0.98}                                                                                                      
{'loss': 0.6524, 'learning_rate': 0.0002764400715563506, 'epoch': 0.99}                                                                                                       
{'loss': 0.6694, 'learning_rate': 0.0002763059033989266, 'epoch': 0.99}                                                                                                       
{'loss': 0.7346, 'learning_rate': 0.00027617173524150263, 'epoch': 1.0}                                                                                                       
 10%|████████████▊                                                                                                                   | 2286/22860 [3:03:30<3:14:02,  1.77it/s]Saving model checkpoint to russian_augmented/checkpoint-2286
Configuration saved in russian_augmented/checkpoint-2286/config.json
Model weights saved in russian_augmented/checkpoint-2286/pytorch_model.bin
Feature extractor saved in russian_augmented/checkpoint-2286/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.887, 'learning_rate': 0.00027603756708407867, 'epoch': 1.0}                                                                                                        
{'loss': 0.5517, 'learning_rate': 0.0002759033989266547, 'epoch': 1.01}                                                                                                       
 10%|████████████▉                                                                                                                   | 2300/22860 [3:03:53<7:13:31,  1.27s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.41114720702171326, 'eval_wer': 0.6233746130030959, 'eval_cer': 0.15248248511995244, 'eval_runtime': 403.0427, 'eval_samples_per_second': 23.891, 'eval_steps_per_second': 2.987, 'epoch': 1.01}                                                                                                                                             
{'loss': 0.6362, 'learning_rate': 0.00027576923076923075, 'epoch': 1.01}                                                                                                      
{'loss': 0.6699, 'learning_rate': 0.0002756350626118068, 'epoch': 1.01}                                                                                                       
{'loss': 0.8369, 'learning_rate': 0.0002755008944543828, 'epoch': 1.02}                                                                                                       
{'loss': 0.8679, 'learning_rate': 0.00027536672629695886, 'epoch': 1.02}                                                                                                      
{'loss': 0.5585, 'learning_rate': 0.0002752325581395349, 'epoch': 1.03}                                                                                                       
{'loss': 0.6721, 'learning_rate': 0.0002750983899821109, 'epoch': 1.03}                                                                                                       
{'loss': 0.7118, 'learning_rate': 0.0002749642218246869, 'epoch': 1.04}                                                                                                       
{'loss': 0.8297, 'learning_rate': 0.00027483005366726296, 'epoch': 1.04}                                                                                                      
{'loss': 0.8506, 'learning_rate': 0.000274695885509839, 'epoch': 1.05}                                                                                                        
{'loss': 0.566, 'learning_rate': 0.000274561717352415, 'epoch': 1.05}                                                                                                         
 10%|█████████████▍                                                                                                                  | 2400/22860 [3:12:16<7:14:14,  1.27s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8

{'eval_loss': 0.4123610854148865, 'eval_wer': 0.6204691593236484, 'eval_cer': 0.15145388705351412, 'eval_runtime': 402.5255, 'eval_samples_per_second': 23.921, 'eval_steps_per_second': 2.991, 'epoch': 1.05}                                                                                                                                              
{'loss': 0.5985, 'learning_rate': 0.000274427549194991, 'epoch': 1.05}                                                                                                        
{'loss': 0.7089, 'learning_rate': 0.00027429338103756706, 'epoch': 1.06}                                                                                                      
{'loss': 0.7681, 'learning_rate': 0.0002741592128801431, 'epoch': 1.06}                                                                                                       
{'loss': 0.7997, 'learning_rate': 0.00027402504472271913, 'epoch': 1.07}                                                                                                      
{'loss': 0.5659, 'learning_rate': 0.0002738908765652951, 'epoch': 1.07}                                                                                                       
{'loss': 0.6245, 'learning_rate': 0.00027375670840787115, 'epoch': 1.08}                                                                                                      
{'loss': 0.6382, 'learning_rate': 0.0002736225402504472, 'epoch': 1.08}                                                                                                       
{'loss': 0.7934, 'learning_rate': 0.00027348837209302323, 'epoch': 1.08}                                                                                                      
{'loss': 0.8081, 'learning_rate': 0.00027335420393559927, 'epoch': 1.09}                                                                                                      
{'loss': 0.5304, 'learning_rate': 0.0002732200357781753, 'epoch': 1.09}                                                                                                       
 11%|█████████████▉                                                                                                                  | 2500/22860 [3:20:41<7:06:27,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3951786458492279, 'eval_wer': 0.6155632293403192, 'eval_cer': 0.14697298283305296, 'eval_runtime': 402.4971, 'eval_samples_per_second': 23.923, 'eval_steps_per_second': 2.991, 'epoch': 1.09}                                                                                                                                              
{'loss': 0.594, 'learning_rate': 0.00027308586762075134, 'epoch': 1.1}                                                                                                        
{'loss': 0.7062, 'learning_rate': 0.00027295169946332733, 'epoch': 1.1}                                                                                                       
{'loss': 0.7688, 'learning_rate': 0.00027281753130590337, 'epoch': 1.11}                                                                                                      
{'loss': 0.8626, 'learning_rate': 0.0002726833631484794, 'epoch': 1.11}                                                                                                       
{'loss': 0.5556, 'learning_rate': 0.00027254919499105544, 'epoch': 1.12}                                                                                                      
{'loss': 0.5487, 'learning_rate': 0.0002724150268336315, 'epoch': 1.12}                                                                                                       
{'loss': 0.6966, 'learning_rate': 0.0002722808586762075, 'epoch': 1.12}                                                                                                       
{'loss': 0.7792, 'learning_rate': 0.0002721466905187835, 'epoch': 1.13}                                                                                                       
{'loss': 0.8747, 'learning_rate': 0.00027201252236135954, 'epoch': 1.13}                                                                                                      
{'loss': 0.5551, 'learning_rate': 0.0002718783542039356, 'epoch': 1.14}                                                                                                       
 11%|██████████████▌                                                                                                                 | 2600/22860 [3:29:03<7:04:34,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.38329368829727173, 'eval_wer': 0.5889973803286497, 'eval_cer': 0.1433923130451232, 'eval_runtime': 398.4423, 'eval_samples_per_second': 24.167, 'eval_steps_per_second': 3.022, 'epoch': 1.14}                                                                                                                                              
{'loss': 0.5773, 'learning_rate': 0.0002717441860465116, 'epoch': 1.14}                                                                                                       
{'loss': 0.7491, 'learning_rate': 0.0002716100178890876, 'epoch': 1.15}                                                                                                       
{'loss': 0.762, 'learning_rate': 0.00027147584973166364, 'epoch': 1.15}                                                                                                       
{'loss': 0.8584, 'learning_rate': 0.0002713416815742397, 'epoch': 1.15}                                                                                                       
{'loss': 0.5402, 'learning_rate': 0.0002712075134168157, 'epoch': 1.16}                                                                                                       
{'loss': 0.5979, 'learning_rate': 0.00027107334525939175, 'epoch': 1.16}                                                                                                      
{'loss': 0.685, 'learning_rate': 0.00027093917710196774, 'epoch': 1.17}                                                                                                       
{'loss': 0.7904, 'learning_rate': 0.0002708050089445438, 'epoch': 1.17}                                                                                                       
{'loss': 0.8745, 'learning_rate': 0.0002706708407871198, 'epoch': 1.18}                                                                                                       
{'loss': 0.5271, 'learning_rate': 0.00027053667262969585, 'epoch': 1.18}                                                                                                      
 12%|███████████████                                                                                                                 | 2700/22860 [3:37:21<7:09:13,  1.28s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.38082680106163025, 'eval_wer': 0.5905334603477018, 'eval_cer': 0.14263902119351154, 'eval_runtime': 401.0105, 'eval_samples_per_second': 24.012, 'eval_steps_per_second': 3.002, 'epoch': 1.18}                                                                                                                                             
{'loss': 0.6206, 'learning_rate': 0.0002704025044722719, 'epoch': 1.19}                                                                                                       
{'loss': 0.6601, 'learning_rate': 0.00027026833631484793, 'epoch': 1.19}                                                                                                      
{'loss': 0.7307, 'learning_rate': 0.00027013416815742397, 'epoch': 1.19}                                                                                                      
{'loss': 0.7765, 'learning_rate': 0.00027, 'epoch': 1.2}                                                                                                                      
{'loss': 0.5461, 'learning_rate': 0.00026986583184257604, 'epoch': 1.2}                                                                                                       
{'loss': 0.5724, 'learning_rate': 0.000269731663685152, 'epoch': 1.21}                                                                                                        
{'loss': 0.6069, 'learning_rate': 0.00026959749552772806, 'epoch': 1.21}                                                                                                      
{'loss': 0.6907, 'learning_rate': 0.0002694633273703041, 'epoch': 1.22}                                                                                                       
{'loss': 0.7691, 'learning_rate': 0.00026932915921288014, 'epoch': 1.22}                                                                                                      
{'loss': 0.4828, 'learning_rate': 0.0002691949910554561, 'epoch': 1.22}                                                                                                       
 12%|███████████████▋                                                                                                                | 2800/22860 [3:45:44<7:19:22,  1.31s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.37021952867507935, 'eval_wer': 0.5855918075732317, 'eval_cer': 0.14289237047095943, 'eval_runtime': 401.0899, 'eval_samples_per_second': 24.007, 'eval_steps_per_second': 3.002, 'epoch': 1.22}                                                                                                                                             
{'loss': 0.6456, 'learning_rate': 0.00026906082289803216, 'epoch': 1.23}                                                                                                      
{'loss': 0.7062, 'learning_rate': 0.0002689266547406082, 'epoch': 1.23}                                                                                                       
{'loss': 0.7307, 'learning_rate': 0.00026879248658318424, 'epoch': 1.24}                                                                                                      
{'loss': 0.797, 'learning_rate': 0.0002686583184257603, 'epoch': 1.24}                                                                                                        
{'loss': 0.5687, 'learning_rate': 0.00026852415026833626, 'epoch': 1.25}                                                                                                      
{'loss': 0.5602, 'learning_rate': 0.0002683899821109123, 'epoch': 1.25}                                                                                                       
{'loss': 0.6101, 'learning_rate': 0.00026825581395348834, 'epoch': 1.26}                                                                                                      
{'loss': 0.792, 'learning_rate': 0.0002681216457960644, 'epoch': 1.26}                                                                                                        
{'loss': 0.8184, 'learning_rate': 0.0002679874776386404, 'epoch': 1.26}                                                                                                       
{'loss': 0.516, 'learning_rate': 0.00026785330948121645, 'epoch': 1.27}                                                                                                       
 13%|████████████████▏                                                                                                               | 2900/22860 [3:54:06<7:04:44,  1.28s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3665190637111664, 'eval_wer': 0.5825315551321744, 'eval_cer': 0.1397204375173122, 'eval_runtime': 401.7174, 'eval_samples_per_second': 23.97, 'eval_steps_per_second': 2.997, 'epoch': 1.27}                                                                                                                                                
{'loss': 0.5313, 'learning_rate': 0.0002677191413237925, 'epoch': 1.27}                                                                                                       
{'loss': 0.618, 'learning_rate': 0.0002675849731663685, 'epoch': 1.28}                                                                                                        
{'loss': 0.7768, 'learning_rate': 0.0002674508050089445, 'epoch': 1.28}                                                                                                       
{'loss': 0.7686, 'learning_rate': 0.00026731663685152055, 'epoch': 1.29}                                                                                                      
{'loss': 0.5072, 'learning_rate': 0.0002671824686940966, 'epoch': 1.29}                                                                                                       
{'loss': 0.5085, 'learning_rate': 0.0002670483005366726, 'epoch': 1.29}                                                                                                       
{'loss': 0.6058, 'learning_rate': 0.00026691413237924866, 'epoch': 1.3}                                                                                                       
{'loss': 0.6978, 'learning_rate': 0.00026677996422182465, 'epoch': 1.3}                                                                                                       
{'loss': 0.8127, 'learning_rate': 0.0002666457960644007, 'epoch': 1.31}                                                                                                       
{'loss': 0.5176, 'learning_rate': 0.0002665116279069767, 'epoch': 1.31}                                                                                                       
 13%|████████████████▊                                                                                                               | 3000/22860 [4:02:28<7:00:53,  1.27s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3580318093299866, 'eval_wer': 0.5731126458680639, 'eval_cer': 0.1393775714951661, 'eval_runtime': 400.8419, 'eval_samples_per_second': 24.022, 'eval_steps_per_second': 3.004, 'epoch': 1.31}                                                                                                                                               
{'loss': 0.5851, 'learning_rate': 0.00026637745974955276, 'epoch': 1.32}                                                                                                      
{'loss': 0.5442, 'learning_rate': 0.0002662432915921288, 'epoch': 1.32}                                                                                                       
{'loss': 0.7586, 'learning_rate': 0.0002661091234347048, 'epoch': 1.33}                                                                                                       
{'loss': 0.7672, 'learning_rate': 0.0002659749552772808, 'epoch': 1.33}                                                                                                       
{'loss': 0.5171, 'learning_rate': 0.00026584078711985686, 'epoch': 1.33}                                                                                                      
{'loss': 0.5721, 'learning_rate': 0.0002657066189624329, 'epoch': 1.34}                                                                                                       
{'loss': 0.6515, 'learning_rate': 0.00026557245080500893, 'epoch': 1.34}                                                                                                      
{'loss': 0.7159, 'learning_rate': 0.0002654382826475849, 'epoch': 1.35}                                                                                                       
{'loss': 0.7659, 'learning_rate': 0.00026530411449016096, 'epoch': 1.35}                                                                                                      
{'loss': 0.4834, 'learning_rate': 0.000265169946332737, 'epoch': 1.36}                                                                                                        
 14%|█████████████████▎                                                                                                              | 3100/22860 [4:10:49<6:54:16,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.35808655619621277, 'eval_wer': 0.5625863300785902, 'eval_cer': 0.1362174615077998, 'eval_runtime': 398.0046, 'eval_samples_per_second': 24.193, 'eval_steps_per_second': 3.025, 'epoch': 1.36}                                                                                                                                              
{'loss': 0.5767, 'learning_rate': 0.00026503577817531303, 'epoch': 1.36}                                                                                                      
{'loss': 0.6207, 'learning_rate': 0.00026490161001788907, 'epoch': 1.36}                                                                                                      
{'loss': 0.745, 'learning_rate': 0.0002647674418604651, 'epoch': 1.37}                                                                                                        
{'loss': 0.8872, 'learning_rate': 0.00026463327370304115, 'epoch': 1.37}                                                                                                      
{'loss': 0.4678, 'learning_rate': 0.0002644991055456172, 'epoch': 1.38}                                                                                                       
{'loss': 0.5514, 'learning_rate': 0.00026436493738819317, 'epoch': 1.38}                                                                                                      
{'loss': 0.5895, 'learning_rate': 0.0002642307692307692, 'epoch': 1.39}                                                                                                       
{'loss': 0.7868, 'learning_rate': 0.00026409660107334524, 'epoch': 1.39}                                                                                                      
{'loss': 0.7046, 'learning_rate': 0.0002639624329159213, 'epoch': 1.4}                                                                                                        
{'loss': 0.4569, 'learning_rate': 0.0002638282647584973, 'epoch': 1.4}                                                                                                        
 14%|█████████████████▉                                                                                                              | 3200/22860 [4:19:09<6:54:53,  1.27s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.36588141322135925, 'eval_wer': 0.5622767325553704, 'eval_cer': 0.13458420316585257, 'eval_runtime': 395.5666, 'eval_samples_per_second': 24.342, 'eval_steps_per_second': 3.044, 'epoch': 1.4}                                                                                                                                              
{'loss': 0.4801, 'learning_rate': 0.0002636940966010733, 'epoch': 1.4}                                                                                                        
{'loss': 0.5932, 'learning_rate': 0.00026355992844364934, 'epoch': 1.41}                                                                                                      
{'loss': 0.823, 'learning_rate': 0.0002634257602862254, 'epoch': 1.41}                                                                                                        
{'loss': 0.8556, 'learning_rate': 0.0002632915921288014, 'epoch': 1.42}                                                                                                       
{'loss': 0.4872, 'learning_rate': 0.0002631574239713774, 'epoch': 1.42}                                                                                                       
{'loss': 0.5316, 'learning_rate': 0.00026302325581395344, 'epoch': 1.43}                                                                                                      
{'loss': 0.633, 'learning_rate': 0.0002628890876565295, 'epoch': 1.43}                                                                                                        
{'loss': 0.6927, 'learning_rate': 0.0002627549194991055, 'epoch': 1.43}                                                                                                       
{'loss': 0.7746, 'learning_rate': 0.00026262075134168155, 'epoch': 1.44}                                                                                                      
{'loss': 0.4941, 'learning_rate': 0.0002624865831842576, 'epoch': 1.44}                                                                                                       
 14%|██████████████████▍                                                                                                             | 3300/22860 [4:27:25<6:55:19,  1.27s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.35246261954307556, 'eval_wer': 0.5510478685401285, 'eval_cer': 0.1315152989183675, 'eval_runtime': 400.603, 'eval_samples_per_second': 24.036, 'eval_steps_per_second': 3.005, 'epoch': 1.44}                                                                                                                                               
{'loss': 0.5166, 'learning_rate': 0.00026235241502683363, 'epoch': 1.45}                                                                                                      
{'loss': 0.6709, 'learning_rate': 0.00026221824686940967, 'epoch': 1.45}                                                                                                      
{'loss': 0.7276, 'learning_rate': 0.00026208407871198565, 'epoch': 1.46}                                                                                                      
{'loss': 0.7343, 'learning_rate': 0.0002619499105545617, 'epoch': 1.46}                                                                                                       
{'loss': 0.4822, 'learning_rate': 0.00026181574239713773, 'epoch': 1.47}                                                                                                      
{'loss': 0.5318, 'learning_rate': 0.00026168157423971377, 'epoch': 1.47}                                                                                                      
{'loss': 0.6407, 'learning_rate': 0.0002615474060822898, 'epoch': 1.47}                                                                                                       
{'loss': 0.7424, 'learning_rate': 0.0002614132379248658, 'epoch': 1.48}                                                                                                       
{'loss': 0.8327, 'learning_rate': 0.00026127906976744183, 'epoch': 1.48}                                                                                                      
{'loss': 0.4491, 'learning_rate': 0.00026114490161001787, 'epoch': 1.49}                                                                                                      
 15%|███████████████████                                                                                                             | 3400/22860 [4:35:46<6:48:25,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.34325915575027466, 'eval_wer': 0.5466539652298166, 'eval_cer': 0.1299732463163015, 'eval_runtime': 400.0512, 'eval_samples_per_second': 24.069, 'eval_steps_per_second': 3.01, 'epoch': 1.49}                                                                                                                                               
{'loss': 0.5497, 'learning_rate': 0.0002610107334525939, 'epoch': 1.49}                                                                                                       
{'loss': 0.6116, 'learning_rate': 0.00026087656529516994, 'epoch': 1.5}                                                                                                       
{'loss': 0.7786, 'learning_rate': 0.0002607423971377459, 'epoch': 1.5}                                                                                                        
{'loss': 0.7268, 'learning_rate': 0.00026060822898032196, 'epoch': 1.5}                                                                                                       
{'loss': 0.4263, 'learning_rate': 0.000260474060822898, 'epoch': 1.51}                                                                                                        
{'loss': 0.5226, 'learning_rate': 0.00026033989266547404, 'epoch': 1.51}                                                                                                      
{'loss': 0.6075, 'learning_rate': 0.0002602057245080501, 'epoch': 1.52}                                                                                                       
{'loss': 0.6862, 'learning_rate': 0.00026007155635062606, 'epoch': 1.52}                                                                                                      
{'loss': 0.7718, 'learning_rate': 0.0002599373881932021, 'epoch': 1.53}                                                                                                       
{'loss': 0.4756, 'learning_rate': 0.00025980322003577814, 'epoch': 1.53}                                                                                                      
 15%|███████████████████▌                                                                                                            | 3500/22860 [4:44:07<6:36:10,  1.23s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.34414660930633545, 'eval_wer': 0.5427601809954751, 'eval_cer': 0.1300441841139869, 'eval_runtime': 398.3282, 'eval_samples_per_second': 24.174, 'eval_steps_per_second': 3.023, 'epoch': 1.53}                                                                                                                                              
{'loss': 0.5412, 'learning_rate': 0.0002596690518783542, 'epoch': 1.54}                                                                                                       
{'loss': 0.6472, 'learning_rate': 0.0002595348837209302, 'epoch': 1.54}                                                                                                       
{'loss': 0.8716, 'learning_rate': 0.00025940071556350625, 'epoch': 1.54}                                                                                                      
{'loss': 0.7668, 'learning_rate': 0.0002592665474060823, 'epoch': 1.55}                                                                                                       
{'loss': 0.4911, 'learning_rate': 0.00025913237924865833, 'epoch': 1.55}                                                                                                      
{'loss': 0.5048, 'learning_rate': 0.0002589982110912343, 'epoch': 1.56}                                                                                                       
{'loss': 0.5637, 'learning_rate': 0.00025886404293381035, 'epoch': 1.56}                                                                                                      
{'loss': 0.6786, 'learning_rate': 0.0002587298747763864, 'epoch': 1.57}                                                                                                       
{'loss': 0.7781, 'learning_rate': 0.0002585957066189624, 'epoch': 1.57}                                                                                                       
{'loss': 0.4533, 'learning_rate': 0.00025846153846153846, 'epoch': 1.57}                                                                                                      
 16%|████████████████████▏                                                                                                           | 3600/22860 [4:52:27<7:00:09,  1.31s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3266298174858093, 'eval_wer': 0.5342581567039771, 'eval_cer': 0.1265023612152658, 'eval_runtime': 401.3444, 'eval_samples_per_second': 23.992, 'eval_steps_per_second': 3.0, 'epoch': 1.57}                                                                                                                                                 
{'loss': 0.5335, 'learning_rate': 0.00025832737030411445, 'epoch': 1.58}                                                                                                      
{'loss': 0.612, 'learning_rate': 0.0002581932021466905, 'epoch': 1.58}                                                                                                        
{'loss': 0.7451, 'learning_rate': 0.0002580590339892665, 'epoch': 1.59}                                                                                                       
{'loss': 0.7431, 'learning_rate': 0.00025792486583184256, 'epoch': 1.59}                                                                                                      
{'loss': 0.4392, 'learning_rate': 0.00025779069767441855, 'epoch': 1.6}                                                                                                       
{'loss': 0.4429, 'learning_rate': 0.0002576565295169946, 'epoch': 1.6}                                                                                                        
{'loss': 0.5609, 'learning_rate': 0.0002575223613595706, 'epoch': 1.61}                                                                                                       
{'loss': 0.774, 'learning_rate': 0.00025738819320214666, 'epoch': 1.61}                                                                                                       
{'loss': 0.6877, 'learning_rate': 0.0002572540250447227, 'epoch': 1.61}                                                                                                       
{'loss': 0.4578, 'learning_rate': 0.00025711985688729874, 'epoch': 1.62}                                                                                                      
 16%|████████████████████▋                                                                                                           | 3700/22860 [5:00:49<6:55:54,  1.30s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3325108289718628, 'eval_wer': 0.5333531793284115, 'eval_cer': 0.12668477269502829, 'eval_runtime': 403.8157, 'eval_samples_per_second': 23.845, 'eval_steps_per_second': 2.982, 'epoch': 1.62}                                                                                                                                              
{'loss': 0.5085, 'learning_rate': 0.0002569856887298748, 'epoch': 1.62}                                                                                                       
{'loss': 0.6366, 'learning_rate': 0.0002568515205724508, 'epoch': 1.63}                                                                                                       
{'loss': 0.7365, 'learning_rate': 0.0002567173524150268, 'epoch': 1.63}                                                                                                       
{'loss': 0.7248, 'learning_rate': 0.00025658318425760283, 'epoch': 1.64}                                                                                                      
{'loss': 0.4842, 'learning_rate': 0.00025644901610017887, 'epoch': 1.64}                                                                                                      
{'loss': 0.4947, 'learning_rate': 0.0002563148479427549, 'epoch': 1.64}                                                                                                       
{'loss': 0.5659, 'learning_rate': 0.00025618067978533095, 'epoch': 1.65}                                                                                                      
{'loss': 0.7152, 'learning_rate': 0.000256046511627907, 'epoch': 1.65}                                                                                                        
{'loss': 0.7933, 'learning_rate': 0.00025591234347048297, 'epoch': 1.66}                                                                                                      
{'loss': 0.4569, 'learning_rate': 0.000255778175313059, 'epoch': 1.66}                                                                                                        
 17%|█████████████████████▎                                                                                                          | 3800/22860 [5:09:13<6:50:58,  1.29s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3284572958946228, 'eval_wer': 0.5315432245772803, 'eval_cer': 0.1261949640919624, 'eval_runtime': 401.6583, 'eval_samples_per_second': 23.973, 'eval_steps_per_second': 2.998, 'epoch': 1.66}                                                                                                                                               
{'loss': 0.5289, 'learning_rate': 0.00025564400715563505, 'epoch': 1.67}                                                                                                      
{'loss': 0.5992, 'learning_rate': 0.0002555098389982111, 'epoch': 1.67}                                                                                                       
{'loss': 0.6666, 'learning_rate': 0.00025537567084078707, 'epoch': 1.68}                                                                                                      
{'loss': 0.7186, 'learning_rate': 0.0002552415026833631, 'epoch': 1.68}                                                                                                       
{'loss': 0.4045, 'learning_rate': 0.00025510733452593914, 'epoch': 1.68}                                                                                                      
{'loss': 0.5105, 'learning_rate': 0.0002549731663685152, 'epoch': 1.69}                                                                                                       
{'loss': 0.5503, 'learning_rate': 0.0002548389982110912, 'epoch': 1.69}                                                                                                       
{'loss': 0.6938, 'learning_rate': 0.0002547048300536672, 'epoch': 1.7}                                                                                                        
{'loss': 0.783, 'learning_rate': 0.00025457066189624324, 'epoch': 1.7}                                                                                                        
{'loss': 0.4765, 'learning_rate': 0.0002544364937388193, 'epoch': 1.71}                                                                                                       
 17%|█████████████████████▊                                                                                                          | 3900/22860 [5:17:38<6:39:29,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3214775621891022, 'eval_wer': 0.5214336746844487, 'eval_cer': 0.12535046650046955, 'eval_runtime': 397.6143, 'eval_samples_per_second': 24.217, 'eval_steps_per_second': 3.028, 'epoch': 1.71}                                                                                                                                              
{'loss': 0.5064, 'learning_rate': 0.0002543023255813953, 'epoch': 1.71}                                                                                                       
{'loss': 0.6124, 'learning_rate': 0.00025416815742397136, 'epoch': 1.71}                                                                                                      
{'loss': 0.6719, 'learning_rate': 0.0002540339892665474, 'epoch': 1.72}                                                                                                       
{'loss': 0.8255, 'learning_rate': 0.00025389982110912343, 'epoch': 1.72}                                                                                                      
{'loss': 0.4175, 'learning_rate': 0.00025376565295169947, 'epoch': 1.73}                                                                                                      
{'loss': 0.5172, 'learning_rate': 0.0002536314847942755, 'epoch': 1.73}                                                                                                       
{'loss': 0.626, 'learning_rate': 0.0002534973166368515, 'epoch': 1.74}                                                                                                        
{'loss': 0.6888, 'learning_rate': 0.00025336314847942753, 'epoch': 1.74}                                                                                                      
{'loss': 0.7082, 'learning_rate': 0.00025322898032200357, 'epoch': 1.75}                                                                                                      
{'loss': 0.4558, 'learning_rate': 0.0002530948121645796, 'epoch': 1.75}                                                                                                       
 17%|██████████████████████▍                                                                                                         | 4000/22860 [5:25:56<6:36:16,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.317386656999588, 'eval_wer': 0.521397951893308, 'eval_cer': 0.122926758412885, 'eval_runtime': 404.1322, 'eval_samples_per_second': 23.826, 'eval_steps_per_second': 2.979, 'epoch': 1.75}                                                                                                                                                  
{'loss': 0.4863, 'learning_rate': 0.0002529606440071556, 'epoch': 1.75}                                                                                                       
{'loss': 0.5755, 'learning_rate': 0.00025282647584973163, 'epoch': 1.76}                                                                                                      
{'loss': 0.6842, 'learning_rate': 0.00025269230769230767, 'epoch': 1.76}                                                                                                      
{'loss': 0.715, 'learning_rate': 0.0002525581395348837, 'epoch': 1.77}                                                                                                        
{'loss': 0.4296, 'learning_rate': 0.00025242397137745974, 'epoch': 1.77}                                                                                                      
{'loss': 0.4885, 'learning_rate': 0.0002522898032200357, 'epoch': 1.78}                                                                                                       
{'loss': 0.627, 'learning_rate': 0.00025215563506261177, 'epoch': 1.78}                                                                                                       
{'loss': 0.6997, 'learning_rate': 0.0002520214669051878, 'epoch': 1.78}                                                                                                       
{'loss': 0.6926, 'learning_rate': 0.00025188729874776384, 'epoch': 1.79}                                                                                                      
{'loss': 0.4299, 'learning_rate': 0.0002517531305903399, 'epoch': 1.79}                                                                                                       
 18%|██████████████████████▉                                                                                                         | 4100/22860 [5:34:22<6:38:17,  1.27s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3132425844669342, 'eval_wer': 0.5165396522981662, 'eval_cer': 0.12233054311329104, 'eval_runtime': 403.6918, 'eval_samples_per_second': 23.852, 'eval_steps_per_second': 2.982, 'epoch': 1.79}                                                                                                                                              
{'loss': 0.4812, 'learning_rate': 0.0002516189624329159, 'epoch': 1.8}                                                                                                        
{'loss': 0.5349, 'learning_rate': 0.00025148479427549196, 'epoch': 1.8}                                                                                                       
{'loss': 0.7015, 'learning_rate': 0.00025135062611806794, 'epoch': 1.81}                                                                                                      
{'loss': 0.6722, 'learning_rate': 0.000251216457960644, 'epoch': 1.81}                                                                                                        
{'loss': 0.3932, 'learning_rate': 0.00025108228980322, 'epoch': 1.82}                                                                                                         
{'loss': 0.4453, 'learning_rate': 0.00025094812164579605, 'epoch': 1.82}                                                                                                      
{'loss': 0.5794, 'learning_rate': 0.0002508139534883721, 'epoch': 1.82}                                                                                                       
{'loss': 0.679, 'learning_rate': 0.00025067978533094813, 'epoch': 1.83}                                                                                                       
{'loss': 0.7297, 'learning_rate': 0.0002505456171735241, 'epoch': 1.83}                                                                                                       
{'loss': 0.4244, 'learning_rate': 0.00025041144901610015, 'epoch': 1.84}                                                                                                      
 18%|███████████████████████▌                                                                                                        | 4200/22860 [5:42:47<6:32:00,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.31582194566726685, 'eval_wer': 0.5138247201714694, 'eval_cer': 0.12235587804103583, 'eval_runtime': 405.5023, 'eval_samples_per_second': 23.746, 'eval_steps_per_second': 2.969, 'epoch': 1.84}                                                                                                                                             
{'loss': 0.4894, 'learning_rate': 0.0002502772808586762, 'epoch': 1.84}                                                                                                       
{'loss': 0.6045, 'learning_rate': 0.00025014311270125223, 'epoch': 1.85}                                                                                                      
{'loss': 0.7768, 'learning_rate': 0.0002500089445438282, 'epoch': 1.85}                                                                                                       
{'loss': 0.7293, 'learning_rate': 0.00024987477638640425, 'epoch': 1.85}                                                                                                      
{'loss': 0.3703, 'learning_rate': 0.0002497406082289803, 'epoch': 1.86}                                                                                                       
{'loss': 0.5054, 'learning_rate': 0.0002496064400715563, 'epoch': 1.86}                                                                                                       
{'loss': 0.5333, 'learning_rate': 0.00024947227191413236, 'epoch': 1.87}                                                                                                      
{'loss': 0.5577, 'learning_rate': 0.00024933810375670835, 'epoch': 1.87}                                                                                                      
{'loss': 0.7775, 'learning_rate': 0.0002492039355992844, 'epoch': 1.88}                                                                                                       
{'loss': 0.4122, 'learning_rate': 0.0002490697674418604, 'epoch': 1.88}                                                                                                       
 19%|████████████████████████                                                                                                        | 4300/22860 [5:51:13<6:29:58,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2988564074039459, 'eval_wer': 0.5102524410573946, 'eval_cer': 0.12094556706324273, 'eval_runtime': 400.0505, 'eval_samples_per_second': 24.069, 'eval_steps_per_second': 3.01, 'epoch': 1.88}                                                                                                                                               
{'loss': 0.5811, 'learning_rate': 0.00024893559928443646, 'epoch': 1.89}                                                                                                      
{'loss': 0.5645, 'learning_rate': 0.0002488014311270125, 'epoch': 1.89}                                                                                                       
{'loss': 0.653, 'learning_rate': 0.00024866726296958854, 'epoch': 1.89}                                                                                                       
{'loss': 0.7529, 'learning_rate': 0.0002485330948121646, 'epoch': 1.9}                                                                                                        
{'loss': 0.42, 'learning_rate': 0.0002483989266547406, 'epoch': 1.9}                                                                                                          
{'loss': 0.4895, 'learning_rate': 0.00024826475849731665, 'epoch': 1.91}                                                                                                      
{'loss': 0.5637, 'learning_rate': 0.00024813059033989264, 'epoch': 1.91}                                                                                                      
{'loss': 0.643, 'learning_rate': 0.0002479964221824687, 'epoch': 1.92}                                                                                                        
{'loss': 0.7306, 'learning_rate': 0.0002478622540250447, 'epoch': 1.92}                                                                                                       
{'loss': 0.404, 'learning_rate': 0.00024772808586762075, 'epoch': 1.92}                                                                                                       
 19%|████████████████████████▋                                                                                                       | 4400/22860 [5:59:33<6:37:20,  1.29s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3045303523540497, 'eval_wer': 0.5083472255298881, 'eval_cer': 0.12124283021544822, 'eval_runtime': 401.5387, 'eval_samples_per_second': 23.98, 'eval_steps_per_second': 2.998, 'epoch': 1.92}                                                                                                                                               
{'loss': 0.4924, 'learning_rate': 0.00024759391771019673, 'epoch': 1.93}                                                                                                      
{'loss': 0.5874, 'learning_rate': 0.00024745974955277277, 'epoch': 1.93}                                                                                                      
{'loss': 0.613, 'learning_rate': 0.0002473255813953488, 'epoch': 1.94}                                                                                                        
{'loss': 0.6576, 'learning_rate': 0.00024719141323792485, 'epoch': 1.94}                                                                                                      
{'loss': 0.3838, 'learning_rate': 0.0002470572450805009, 'epoch': 1.95}                                                                                                       
{'loss': 0.4745, 'learning_rate': 0.00024692307692307687, 'epoch': 1.95}                                                                                                      
{'loss': 0.531, 'learning_rate': 0.0002467889087656529, 'epoch': 1.96}                                                                                                        
{'loss': 0.617, 'learning_rate': 0.00024665474060822895, 'epoch': 1.96}                                                                                                       
{'loss': 0.7649, 'learning_rate': 0.000246520572450805, 'epoch': 1.96}                                                                                                        
{'loss': 0.421, 'learning_rate': 0.000246386404293381, 'epoch': 1.97}                                                                                                         
 20%|█████████████████████████▏                                                                                                      | 4500/22860 [6:07:55<6:33:25,  1.29s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3043109178543091, 'eval_wer': 0.5038937842343415, 'eval_cer': 0.11983758622320409, 'eval_runtime': 405.3921, 'eval_samples_per_second': 23.752, 'eval_steps_per_second': 2.97, 'epoch': 1.97}                                                                                                                                               
{'loss': 0.4731, 'learning_rate': 0.00024625223613595706, 'epoch': 1.97}                                                                                                      
{'loss': 0.5676, 'learning_rate': 0.0002461180679785331, 'epoch': 1.98}                                                                                                       
{'loss': 0.7861, 'learning_rate': 0.0002459838998211091, 'epoch': 1.98}                                                                                                       
{'loss': 0.7195, 'learning_rate': 0.0002458497316636851, 'epoch': 1.99}                                                                                                       
{'loss': 0.4602, 'learning_rate': 0.00024571556350626116, 'epoch': 1.99}                                                                                                      
{'loss': 0.4939, 'learning_rate': 0.0002455813953488372, 'epoch': 1.99}                                                                                                       
{'loss': 0.6893, 'learning_rate': 0.00024544722719141323, 'epoch': 2.0}                                                                                                       
 20%|█████████████████████████▌                                                                                                      | 4572/22860 [6:15:48<2:52:02,  1.77it/s]Saving model checkpoint to russian_augmented/checkpoint-4572
Configuration saved in russian_augmented/checkpoint-4572/config.json
Model weights saved in russian_augmented/checkpoint-4572/pytorch_model.bin
Feature extractor saved in russian_augmented/checkpoint-4572/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.6052, 'learning_rate': 0.00024531305903398927, 'epoch': 2.0}                                                                                                       
{'loss': 0.4071, 'learning_rate': 0.00024517889087656526, 'epoch': 2.01}                                                                                                      
{'loss': 0.4235, 'learning_rate': 0.0002450447227191413, 'epoch': 2.01}                                                                                                       
 20%|█████████████████████████▊                                                                                                      | 4600/22860 [6:16:27<4:54:04,  1.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3055994510650635, 'eval_wer': 0.5030483448440105, 'eval_cer': 0.11987812210759576, 'eval_runtime': 406.243, 'eval_samples_per_second': 23.703, 'eval_steps_per_second': 2.964, 'epoch': 2.01}                                                                                                                                               
{'loss': 0.5113, 'learning_rate': 0.00024491055456171733, 'epoch': 2.02}                                                                                                      
{'loss': 0.7048, 'learning_rate': 0.00024477638640429337, 'epoch': 2.02}                                                                                                      
{'loss': 0.5043, 'learning_rate': 0.0002446422182468694, 'epoch': 2.03}                                                                                                       
{'loss': 0.3929, 'learning_rate': 0.0002445080500894454, 'epoch': 2.03}                                                                                                       
{'loss': 0.4808, 'learning_rate': 0.00024437388193202143, 'epoch': 2.03}                                                                                                      
{'loss': 0.551, 'learning_rate': 0.00024423971377459747, 'epoch': 2.04}                                                                                                       
{'loss': 0.6828, 'learning_rate': 0.0002441055456171735, 'epoch': 2.04}                                                                                                       
{'loss': 0.535, 'learning_rate': 0.00024397137745974952, 'epoch': 2.05}                                                                                                       
{'loss': 0.4219, 'learning_rate': 0.00024383720930232556, 'epoch': 2.05}                                                                                                      
{'loss': 0.4616, 'learning_rate': 0.0002437030411449016, 'epoch': 2.06}                                                                                                       
 21%|██████████████████████████▎                                                                                                     | 4700/22860 [6:24:53<4:54:14,  1.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3059828579425812, 'eval_wer': 0.49502262443438916, 'eval_cer': 0.11728213651134667, 'eval_runtime': 403.0173, 'eval_samples_per_second': 23.892, 'eval_steps_per_second': 2.987, 'epoch': 2.06}                                                                                                                                             
{'loss': 0.4436, 'learning_rate': 0.00024356887298747763, 'epoch': 2.06}                                                                                                      
{'loss': 0.6226, 'learning_rate': 0.00024343470483005367, 'epoch': 2.06}                                                                                                      
{'loss': 0.5264, 'learning_rate': 0.00024330053667262965, 'epoch': 2.07}                                                                                                      
{'loss': 0.4013, 'learning_rate': 0.0002431663685152057, 'epoch': 2.07}                                                                                                       
{'loss': 0.493, 'learning_rate': 0.00024303220035778173, 'epoch': 2.08}                                                                                                       
{'loss': 0.5423, 'learning_rate': 0.00024289803220035777, 'epoch': 2.08}                                                                                                      
{'loss': 0.6227, 'learning_rate': 0.00024276386404293378, 'epoch': 2.09}                                                                                                      
{'loss': 0.518, 'learning_rate': 0.00024262969588550982, 'epoch': 2.09}                                                                                                       
{'loss': 0.3643, 'learning_rate': 0.00024249552772808586, 'epoch': 2.1}                                                                                                       
{'loss': 0.4184, 'learning_rate': 0.0002423613595706619, 'epoch': 2.1}                                                                                                        
 21%|██████████████████████████▉                                                                                                     | 4800/22860 [6:33:18<4:59:29,  1.01it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3006489872932434, 'eval_wer': 0.4917004048582996, 'eval_cer': 0.11778207908551044, 'eval_runtime': 401.4141, 'eval_samples_per_second': 23.988, 'eval_steps_per_second': 2.999, 'epoch': 2.1}                                                                                                                                               
{'loss': 0.4929, 'learning_rate': 0.00024222719141323793, 'epoch': 2.1}                                                                                                       
{'loss': 0.7049, 'learning_rate': 0.00024209302325581392, 'epoch': 2.11}                                                                                                      
{'loss': 0.4539, 'learning_rate': 0.00024195885509838995, 'epoch': 2.11}                                                                                                      
{'loss': 0.3614, 'learning_rate': 0.000241824686940966, 'epoch': 2.12}                                                                                                        
{'loss': 0.4676, 'learning_rate': 0.00024169051878354203, 'epoch': 2.12}                                                                                                      
{'loss': 0.5298, 'learning_rate': 0.00024155635062611804, 'epoch': 2.13}                                                                                                      
{'loss': 0.6537, 'learning_rate': 0.00024142218246869408, 'epoch': 2.13}                                                                                                      
{'loss': 0.46, 'learning_rate': 0.00024128801431127012, 'epoch': 2.13}                                                                                                        
{'loss': 0.4042, 'learning_rate': 0.00024115384615384615, 'epoch': 2.14}                                                                                                      
{'loss': 0.443, 'learning_rate': 0.00024101967799642214, 'epoch': 2.14}                                                                                                       
 21%|███████████████████████████▍                                                                                                    | 4900/22860 [6:41:41<4:53:10,  1.02it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.304774671792984, 'eval_wer': 0.49736842105263157, 'eval_cer': 0.1172314666558571, 'eval_runtime': 399.6174, 'eval_samples_per_second': 24.096, 'eval_steps_per_second': 3.013, 'epoch': 2.14}                                                                                                                                               
{'loss': 0.5954, 'learning_rate': 0.00024088550983899818, 'epoch': 2.15}                                                                                                      
{'loss': 0.6881, 'learning_rate': 0.00024075134168157421, 'epoch': 2.15}                                                                                                      
{'loss': 0.51, 'learning_rate': 0.00024061717352415025, 'epoch': 2.16}                                                                                                        
{'loss': 0.3722, 'learning_rate': 0.0002404830053667263, 'epoch': 2.16}                                                                                                       
{'loss': 0.4187, 'learning_rate': 0.0002403488372093023, 'epoch': 2.17}                                                                                                       
{'loss': 0.5398, 'learning_rate': 0.00024021466905187834, 'epoch': 2.17}                                                                                                      
{'loss': 0.6827, 'learning_rate': 0.00024008050089445435, 'epoch': 2.17}                                                                                                      
{'loss': 0.5678, 'learning_rate': 0.0002399463327370304, 'epoch': 2.18}                                                                                                       
{'loss': 0.3823, 'learning_rate': 0.0002398121645796064, 'epoch': 2.18}                                                                                                       
{'loss': 0.4369, 'learning_rate': 0.00023967799642218244, 'epoch': 2.19}                                                                                                      
 22%|███████████████████████████▉                                                                                                    | 5000/22860 [6:50:00<4:49:41,  1.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2897140085697174, 'eval_wer': 0.4885806144320076, 'eval_cer': 0.11610152887843964, 'eval_runtime': 402.9752, 'eval_samples_per_second': 23.895, 'eval_steps_per_second': 2.988, 'epoch': 2.19}                                                                                                                                              
{'loss': 0.5403, 'learning_rate': 0.00023954382826475848, 'epoch': 2.19}                                                                                                      
{'loss': 0.6596, 'learning_rate': 0.00023940966010733451, 'epoch': 2.2}                                                                                                       
{'loss': 0.4987, 'learning_rate': 0.00023927549194991055, 'epoch': 2.2}                                                                                                       
{'loss': 0.3719, 'learning_rate': 0.00023914132379248656, 'epoch': 2.2}                                                                                                       
{'loss': 0.412, 'learning_rate': 0.00023900715563506257, 'epoch': 2.21}                                                                                                       
{'loss': 0.5671, 'learning_rate': 0.0002388729874776386, 'epoch': 2.21}                                                                                                       
{'loss': 0.707, 'learning_rate': 0.00023873881932021465, 'epoch': 2.22}                                                                                                       
{'loss': 0.4406, 'learning_rate': 0.00023860465116279066, 'epoch': 2.22}                                                                                                      
{'loss': 0.3375, 'learning_rate': 0.0002384704830053667, 'epoch': 2.23}                                                                                                       
{'loss': 0.4437, 'learning_rate': 0.00023833631484794274, 'epoch': 2.23}                                                                                                      
 22%|████████████████████████████▌                                                                                                   | 5100/22860 [6:58:25<4:46:07,  1.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.30025550723075867, 'eval_wer': 0.48361514646344367, 'eval_cer': 0.11715883986298871, 'eval_runtime': 404.2356, 'eval_samples_per_second': 23.82, 'eval_steps_per_second': 2.978, 'epoch': 2.23}                                                                                                                                             
{'loss': 0.5512, 'learning_rate': 0.00023820214669051878, 'epoch': 2.24}                                                                                                      
{'loss': 0.6539, 'learning_rate': 0.0002380679785330948, 'epoch': 2.24}                                                                                                       
{'loss': 0.4679, 'learning_rate': 0.0002379338103756708, 'epoch': 2.24}                                                                                                       
{'loss': 0.3906, 'learning_rate': 0.00023779964221824684, 'epoch': 2.25}                                                                                                      
{'loss': 0.3964, 'learning_rate': 0.00023766547406082287, 'epoch': 2.25}                                                                                                      
{'loss': 0.5411, 'learning_rate': 0.0002375313059033989, 'epoch': 2.26}                                                                                                       
{'loss': 0.6958, 'learning_rate': 0.00023739713774597492, 'epoch': 2.26}                                                                                                      
{'loss': 0.4837, 'learning_rate': 0.00023726296958855096, 'epoch': 2.27}                                                                                                      
{'loss': 0.3927, 'learning_rate': 0.000237128801431127, 'epoch': 2.27}                                                                                                        
{'loss': 0.4163, 'learning_rate': 0.00023699463327370304, 'epoch': 2.27}                                                                                                      
 23%|█████████████████████████████                                                                                                   | 5200/22860 [7:06:51<4:41:46,  1.04it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2966362237930298, 'eval_wer': 0.48342462491069305, 'eval_cer': 0.11392441408757102, 'eval_runtime': 406.4694, 'eval_samples_per_second': 23.689, 'eval_steps_per_second': 2.962, 'epoch': 2.27}                                                                                                                                             
{'loss': 0.4485, 'learning_rate': 0.00023686046511627907, 'epoch': 2.28}                                                                                                      
{'loss': 0.6763, 'learning_rate': 0.00023672629695885506, 'epoch': 2.28}                                                                                                      
{'loss': 0.5451, 'learning_rate': 0.0002365921288014311, 'epoch': 2.29}                                                                                                       
{'loss': 0.468, 'learning_rate': 0.00023645796064400713, 'epoch': 2.29}                                                                                                       
{'loss': 0.4399, 'learning_rate': 0.00023632379248658317, 'epoch': 2.3}                                                                                                       
{'loss': 0.5353, 'learning_rate': 0.00023618962432915918, 'epoch': 2.3}                                                                                                       
{'loss': 0.615, 'learning_rate': 0.00023605545617173522, 'epoch': 2.31}                                                                                                       
{'loss': 0.5549, 'learning_rate': 0.00023592128801431126, 'epoch': 2.31}                                                                                                      
{'loss': 0.354, 'learning_rate': 0.0002357871198568873, 'epoch': 2.31}                                                                                                        
{'loss': 0.4288, 'learning_rate': 0.0002356529516994633, 'epoch': 2.32}                                                                                                       
 23%|█████████████████████████████▋                                                                                                  | 5300/22860 [7:15:18<4:39:17,  1.05it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2852542996406555, 'eval_wer': 0.47095737080257205, 'eval_cer': 0.11307653850571218, 'eval_runtime': 400.6943, 'eval_samples_per_second': 24.031, 'eval_steps_per_second': 3.005, 'epoch': 2.32}                                                                                                                                             
{'loss': 0.4764, 'learning_rate': 0.00023551878354203932, 'epoch': 2.32}                                                                                                      
{'loss': 0.6429, 'learning_rate': 0.00023538461538461536, 'epoch': 2.33}                                                                                                      
{'loss': 0.4909, 'learning_rate': 0.0002352504472271914, 'epoch': 2.33}                                                                                                       
{'loss': 0.3587, 'learning_rate': 0.00023511627906976743, 'epoch': 2.34}                                                                                                      
{'loss': 0.4041, 'learning_rate': 0.00023498211091234344, 'epoch': 2.34}                                                                                                      
{'loss': 0.5158, 'learning_rate': 0.00023484794275491948, 'epoch': 2.34}                                                                                                      
{'loss': 0.7161, 'learning_rate': 0.00023471377459749552, 'epoch': 2.35}                                                                                                      
{'loss': 0.4563, 'learning_rate': 0.00023457960644007153, 'epoch': 2.35}                                                                                                      
{'loss': 0.378, 'learning_rate': 0.00023444543828264757, 'epoch': 2.36}                                                                                                       
{'loss': 0.4901, 'learning_rate': 0.00023431127012522358, 'epoch': 2.36}                                                                                                      
 24%|██████████████████████████████▏                                                                                                 | 5400/22860 [7:23:41<4:47:04,  1.01it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2899315357208252, 'eval_wer': 0.4716837342224339, 'eval_cer': 0.11243303134099461, 'eval_runtime': 399.0262, 'eval_samples_per_second': 24.131, 'eval_steps_per_second': 3.017, 'epoch': 2.36}                                                                                                                                              
{'loss': 0.5011, 'learning_rate': 0.00023417710196779962, 'epoch': 2.37}                                                                                                      
{'loss': 0.6937, 'learning_rate': 0.00023404293381037566, 'epoch': 2.37}                                                                                                      
{'loss': 0.4917, 'learning_rate': 0.0002339087656529517, 'epoch': 2.38}                                                                                                       
{'loss': 0.3674, 'learning_rate': 0.0002337745974955277, 'epoch': 2.38}                                                                                                       
{'loss': 0.4411, 'learning_rate': 0.00023364042933810372, 'epoch': 2.38}                                                                                                      
{'loss': 0.5649, 'learning_rate': 0.00023350626118067976, 'epoch': 2.39}                                                                                                      
{'loss': 0.6209, 'learning_rate': 0.0002333720930232558, 'epoch': 2.39}                                                                                                       
{'loss': 0.4319, 'learning_rate': 0.00023323792486583183, 'epoch': 2.4}                                                                                                       
{'loss': 0.3804, 'learning_rate': 0.00023310375670840784, 'epoch': 2.4}                                                                                                       
{'loss': 0.4543, 'learning_rate': 0.00023296958855098388, 'epoch': 2.41}                                                                                                      
 24%|██████████████████████████████▊                                                                                                 | 5500/22860 [7:32:00<4:39:44,  1.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.28511685132980347, 'eval_wer': 0.47731602762562514, 'eval_cer': 0.11248876818203314, 'eval_runtime': 400.076, 'eval_samples_per_second': 24.068, 'eval_steps_per_second': 3.009, 'epoch': 2.41}                                                                                                                                             
{'loss': 0.5667, 'learning_rate': 0.00023283542039355992, 'epoch': 2.41}                                                                                                      
{'loss': 0.6265, 'learning_rate': 0.00023270125223613596, 'epoch': 2.41}                                                                                                      
{'loss': 0.4862, 'learning_rate': 0.00023256708407871194, 'epoch': 2.42}                                                                                                      
{'loss': 0.3908, 'learning_rate': 0.00023243291592128798, 'epoch': 2.42}                                                                                                      
{'loss': 0.4086, 'learning_rate': 0.00023229874776386402, 'epoch': 2.43}                                                                                                      
{'loss': 0.5451, 'learning_rate': 0.00023216457960644005, 'epoch': 2.43}                                                                                                      
{'loss': 0.6049, 'learning_rate': 0.0002320304114490161, 'epoch': 2.44}                                                                                                       
{'loss': 0.5391, 'learning_rate': 0.0002318962432915921, 'epoch': 2.44}                                                                                                       
{'loss': 0.3723, 'learning_rate': 0.00023176207513416814, 'epoch': 2.45}                                                                                                      
{'loss': 0.4427, 'learning_rate': 0.00023162790697674418, 'epoch': 2.45}                                                                                                      
 24%|███████████████████████████████▎                                                                                                | 5600/22860 [7:40:22<4:34:24,  1.05it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2783251404762268, 'eval_wer': 0.4709811859966659, 'eval_cer': 0.11229791172635575, 'eval_runtime': 398.9879, 'eval_samples_per_second': 24.134, 'eval_steps_per_second': 3.018, 'epoch': 2.45}                                                                                                                                              
{'loss': 0.501, 'learning_rate': 0.00023149373881932022, 'epoch': 2.45}                                                                                                       
{'loss': 0.6517, 'learning_rate': 0.0002313595706618962, 'epoch': 2.46}                                                                                                       
{'loss': 0.4287, 'learning_rate': 0.00023122540250447224, 'epoch': 2.46}                                                                                                      
{'loss': 0.4167, 'learning_rate': 0.00023109123434704828, 'epoch': 2.47}                                                                                                      
{'loss': 0.4701, 'learning_rate': 0.00023095706618962432, 'epoch': 2.47}                                                                                                      
{'loss': 0.56, 'learning_rate': 0.00023082289803220035, 'epoch': 2.48}                                                                                                        
{'loss': 0.5915, 'learning_rate': 0.00023068872987477636, 'epoch': 2.48}                                                                                                      
{'loss': 0.4622, 'learning_rate': 0.0002305545617173524, 'epoch': 2.48}                                                                                                       
{'loss': 0.3626, 'learning_rate': 0.00023042039355992844, 'epoch': 2.49}                                                                                                      
{'loss': 0.4052, 'learning_rate': 0.00023028622540250445, 'epoch': 2.49}                                                                                                      
 25%|███████████████████████████████▉                                                                                                | 5700/22860 [7:48:39<4:21:14,  1.09it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2797320783138275, 'eval_wer': 0.4676589664205763, 'eval_cer': 0.11166622752791909, 'eval_runtime': 400.3671, 'eval_samples_per_second': 24.05, 'eval_steps_per_second': 3.007, 'epoch': 2.49}                                                                                                                                               
{'loss': 0.4821, 'learning_rate': 0.00023015205724508046, 'epoch': 2.5}                                                                                                       
{'loss': 0.6286, 'learning_rate': 0.0002300178890876565, 'epoch': 2.5}                                                                                                        
{'loss': 0.5456, 'learning_rate': 0.00022988372093023254, 'epoch': 2.51}                                                                                                      
{'loss': 0.3312, 'learning_rate': 0.00022974955277280858, 'epoch': 2.51}                                                                                                      
{'loss': 0.4749, 'learning_rate': 0.0002296153846153846, 'epoch': 2.52}                                                                                                       
{'loss': 0.5788, 'learning_rate': 0.00022948121645796063, 'epoch': 2.52}                                                                                                      
{'loss': 0.7282, 'learning_rate': 0.00022934704830053666, 'epoch': 2.52}                                                                                                      
{'loss': 0.4936, 'learning_rate': 0.00022921288014311268, 'epoch': 2.53}                                                                                                      
{'loss': 0.4102, 'learning_rate': 0.0002290787119856887, 'epoch': 2.53}                                                                                                       
{'loss': 0.4467, 'learning_rate': 0.00022894454382826472, 'epoch': 2.54}                                                                                                      
 25%|████████████████████████████████▍                                                                                               | 5800/22860 [7:57:00<4:35:07,  1.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2840636968612671, 'eval_wer': 0.4718385329840438, 'eval_cer': 0.11093995959923522, 'eval_runtime': 400.043, 'eval_samples_per_second': 24.07, 'eval_steps_per_second': 3.01, 'epoch': 2.54}                                                                                                                                                 
{'loss': 0.5096, 'learning_rate': 0.00022881037567084076, 'epoch': 2.54}                                                                                                      
{'loss': 0.5926, 'learning_rate': 0.0002286762075134168, 'epoch': 2.55}                                                                                                       
{'loss': 0.3906, 'learning_rate': 0.00022854203935599284, 'epoch': 2.55}                                                                                                      
{'loss': 0.4084, 'learning_rate': 0.00022840787119856885, 'epoch': 2.55}                                                                                                      
{'loss': 0.4517, 'learning_rate': 0.00022827370304114486, 'epoch': 2.56}                                                                                                      
{'loss': 0.5282, 'learning_rate': 0.0002281395348837209, 'epoch': 2.56}                                                                                                       
{'loss': 0.7045, 'learning_rate': 0.00022800536672629694, 'epoch': 2.57}                                                                                                      
{'loss': 0.5465, 'learning_rate': 0.00022787119856887297, 'epoch': 2.57}                                                                                                      
{'loss': 0.3747, 'learning_rate': 0.00022773703041144899, 'epoch': 2.58}                                                                                                      
{'loss': 0.441, 'learning_rate': 0.00022760286225402502, 'epoch': 2.58}                                                                                                       
 26%|█████████████████████████████████                                                                                               | 5900/22860 [8:05:21<4:41:13,  1.01it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.27504727244377136, 'eval_wer': 0.4647416051440819, 'eval_cer': 0.10929150030064114, 'eval_runtime': 403.0582, 'eval_samples_per_second': 23.89, 'eval_steps_per_second': 2.987, 'epoch': 2.58}                                                                                                                                              
{'loss': 0.5067, 'learning_rate': 0.00022746869409660106, 'epoch': 2.59}                                                                                                      
{'loss': 0.6385, 'learning_rate': 0.0002273345259391771, 'epoch': 2.59}                                                                                                       
{'loss': 0.5105, 'learning_rate': 0.00022720035778175308, 'epoch': 2.59}                                                                                                      
{'loss': 0.3269, 'learning_rate': 0.00022706618962432912, 'epoch': 2.6}                                                                                                       
{'loss': 0.3975, 'learning_rate': 0.00022693202146690516, 'epoch': 2.6}                                                                                                       
{'loss': 0.4914, 'learning_rate': 0.0002267978533094812, 'epoch': 2.61}                                                                                                       
{'loss': 0.6609, 'learning_rate': 0.00022666368515205724, 'epoch': 2.61}                                                                                                      
{'loss': 0.5077, 'learning_rate': 0.00022652951699463325, 'epoch': 2.62}                                                                                                      
{'loss': 0.3637, 'learning_rate': 0.00022639534883720928, 'epoch': 2.62}                                                                                                      
{'loss': 0.4176, 'learning_rate': 0.00022626118067978532, 'epoch': 2.62}                                                                                                      
 26%|█████████████████████████████████▌                                                                                              | 6000/22860 [8:13:47<4:33:35,  1.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.27346715331077576, 'eval_wer': 0.46476542033817575, 'eval_cer': 0.10981339981218373, 'eval_runtime': 402.7636, 'eval_samples_per_second': 23.907, 'eval_steps_per_second': 2.989, 'epoch': 2.62}                                                                                                                                            
{'loss': 0.4936, 'learning_rate': 0.00022612701252236136, 'epoch': 2.63}                                                                                                      
{'loss': 0.5934, 'learning_rate': 0.00022599284436493734, 'epoch': 2.63}                                                                                                      
{'loss': 0.4684, 'learning_rate': 0.00022585867620751338, 'epoch': 2.64}                                                                                                      
{'loss': 0.338, 'learning_rate': 0.00022572450805008942, 'epoch': 2.64}                                                                                                       
{'loss': 0.3903, 'learning_rate': 0.00022559033989266546, 'epoch': 2.65}                                                                                                      
{'loss': 0.4994, 'learning_rate': 0.0002254561717352415, 'epoch': 2.65}                                                                                                       
{'loss': 0.6435, 'learning_rate': 0.0002253220035778175, 'epoch': 2.66}                                                                                                       
{'loss': 0.465, 'learning_rate': 0.00022518783542039355, 'epoch': 2.66}                                                                                                       
{'loss': 0.3831, 'learning_rate': 0.00022505366726296958, 'epoch': 2.66}                                                                                                      
{'loss': 0.4183, 'learning_rate': 0.00022491949910554562, 'epoch': 2.67}                                                                                                      
 27%|██████████████████████████████████▏                                                                                             | 6100/22860 [8:22:11<4:34:04,  1.02it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.26805493235588074, 'eval_wer': 0.45607287449392714, 'eval_cer': 0.1086564381118385, 'eval_runtime': 403.9287, 'eval_samples_per_second': 23.838, 'eval_steps_per_second': 2.981, 'epoch': 2.67}                                                                                                                                             
{'loss': 0.5261, 'learning_rate': 0.0002247853309481216, 'epoch': 2.67}                                                                                                       
{'loss': 0.5974, 'learning_rate': 0.00022465116279069764, 'epoch': 2.68}                                                                                                      
{'loss': 0.43, 'learning_rate': 0.00022451699463327368, 'epoch': 2.68}                                                                                                        
{'loss': 0.2944, 'learning_rate': 0.00022438282647584972, 'epoch': 2.69}                                                                                                      
{'loss': 0.4549, 'learning_rate': 0.00022424865831842576, 'epoch': 2.69}                                                                                                      
{'loss': 0.4577, 'learning_rate': 0.00022411449016100177, 'epoch': 2.69}                                                                                                      
{'loss': 0.6383, 'learning_rate': 0.0002239803220035778, 'epoch': 2.7}                                                                                                        
{'loss': 0.4354, 'learning_rate': 0.00022384615384615382, 'epoch': 2.7}                                                                                                       
{'loss': 0.3928, 'learning_rate': 0.00022371198568872986, 'epoch': 2.71}                                                                                                      
{'loss': 0.4037, 'learning_rate': 0.00022357781753130587, 'epoch': 2.71}                                                                                                      
 27%|██████████████████████████████████▋                                                                                             | 6200/22860 [8:30:37<4:33:39,  1.01it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.27833375334739685, 'eval_wer': 0.4593355560847821, 'eval_cer': 0.11159697872541667, 'eval_runtime': 401.6887, 'eval_samples_per_second': 23.971, 'eval_steps_per_second': 2.997, 'epoch': 2.71}                                                                                                                                             
{'loss': 0.4812, 'learning_rate': 0.0002234436493738819, 'epoch': 2.72}                                                                                                       
{'loss': 0.6593, 'learning_rate': 0.00022330948121645794, 'epoch': 2.72}                                                                                                      
{'loss': 0.525, 'learning_rate': 0.00022317531305903398, 'epoch': 2.73}                                                                                                       
{'loss': 0.3669, 'learning_rate': 0.00022304114490161002, 'epoch': 2.73}                                                                                                      
{'loss': 0.4609, 'learning_rate': 0.000222906976744186, 'epoch': 2.73}                                                                                                        
{'loss': 0.5183, 'learning_rate': 0.00022277280858676204, 'epoch': 2.74}                                                                                                      
{'loss': 0.6189, 'learning_rate': 0.00022263864042933808, 'epoch': 2.74}                                                                                                      
{'loss': 0.4438, 'learning_rate': 0.00022250447227191412, 'epoch': 2.75}                                                                                                      
{'loss': 0.3549, 'learning_rate': 0.00022237030411449013, 'epoch': 2.75}                                                                                                      
{'loss': 0.486, 'learning_rate': 0.00022223613595706617, 'epoch': 2.76}                                                                                                       
 28%|███████████████████████████████████▎                                                                                            | 6300/22860 [8:38:58<4:25:25,  1.04it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2767322063446045, 'eval_wer': 0.46268159085496546, 'eval_cer': 0.10953809359735706, 'eval_runtime': 401.8986, 'eval_samples_per_second': 23.959, 'eval_steps_per_second': 2.996, 'epoch': 2.76}                                                                                                                                             
{'loss': 0.487, 'learning_rate': 0.0002221019677996422, 'epoch': 2.76}                                                                                                        
{'loss': 0.594, 'learning_rate': 0.00022196779964221824, 'epoch': 2.76}                                                                                                       
{'loss': 0.5039, 'learning_rate': 0.00022183363148479428, 'epoch': 2.77}                                                                                                      
{'loss': 0.385, 'learning_rate': 0.00022169946332737026, 'epoch': 2.77}                                                                                                       
{'loss': 0.4141, 'learning_rate': 0.0002215652951699463, 'epoch': 2.78}                                                                                                       
{'loss': 0.4845, 'learning_rate': 0.00022143112701252234, 'epoch': 2.78}                                                                                                      
{'loss': 0.6656, 'learning_rate': 0.00022129695885509838, 'epoch': 2.79}                                                                                                      
{'loss': 0.4649, 'learning_rate': 0.0002211627906976744, 'epoch': 2.79}                                                                                                       
{'loss': 0.348, 'learning_rate': 0.00022102862254025043, 'epoch': 2.8}                                                                                                        
{'loss': 0.4345, 'learning_rate': 0.00022089445438282647, 'epoch': 2.8}                                                                                                       
 28%|███████████████████████████████████▊                                                                                            | 6400/22860 [8:47:21<4:15:29,  1.07it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.27586081624031067, 'eval_wer': 0.45376280066682545, 'eval_cer': 0.1090601079605721, 'eval_runtime': 404.5424, 'eval_samples_per_second': 23.802, 'eval_steps_per_second': 2.976, 'epoch': 2.8}                                                                                                                                              
{'loss': 0.5362, 'learning_rate': 0.0002207602862254025, 'epoch': 2.8}                                                                                                        
{'loss': 0.6947, 'learning_rate': 0.00022062611806797854, 'epoch': 2.81}                                                                                                      
{'loss': 0.4556, 'learning_rate': 0.00022049194991055453, 'epoch': 2.81}                                                                                                      
{'loss': 0.36, 'learning_rate': 0.00022035778175313056, 'epoch': 2.82}                                                                                                        
{'loss': 0.3966, 'learning_rate': 0.0002202236135957066, 'epoch': 2.82}                                                                                                       
{'loss': 0.4831, 'learning_rate': 0.00022008944543828264, 'epoch': 2.83}                                                                                                      
{'loss': 0.6207, 'learning_rate': 0.00021995527728085865, 'epoch': 2.83}                                                                                                      
{'loss': 0.4659, 'learning_rate': 0.0002198211091234347, 'epoch': 2.83}                                                                                                       
{'loss': 0.3303, 'learning_rate': 0.00021968694096601073, 'epoch': 2.84}                                                                                                      
{'loss': 0.4148, 'learning_rate': 0.00021955277280858677, 'epoch': 2.84}                                                                                                      
 28%|████████████████████████████████████▍                                                                                           | 6500/22860 [8:55:45<4:24:00,  1.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.27417609095573425, 'eval_wer': 0.4574184329602286, 'eval_cer': 0.10825952424383686, 'eval_runtime': 401.6845, 'eval_samples_per_second': 23.972, 'eval_steps_per_second': 2.997, 'epoch': 2.84}                                                                                                                                             
{'loss': 0.4924, 'learning_rate': 0.00021941860465116275, 'epoch': 2.85}                                                                                                      
{'loss': 0.6574, 'learning_rate': 0.0002192844364937388, 'epoch': 2.85}                                                                                                       
{'loss': 0.4555, 'learning_rate': 0.00021915026833631483, 'epoch': 2.86}                                                                                                      
{'loss': 0.3712, 'learning_rate': 0.00021901610017889086, 'epoch': 2.86}                                                                                                      
{'loss': 0.4298, 'learning_rate': 0.0002188819320214669, 'epoch': 2.87}                                                                                                       
{'loss': 0.4744, 'learning_rate': 0.0002187477638640429, 'epoch': 2.87}                                                                                                       
{'loss': 0.5607, 'learning_rate': 0.00021861359570661895, 'epoch': 2.87}                                                                                                      
{'loss': 0.471, 'learning_rate': 0.00021847942754919496, 'epoch': 2.88}                                                                                                       
{'loss': 0.3705, 'learning_rate': 0.000218345259391771, 'epoch': 2.88}                                                                                                        
{'loss': 0.3811, 'learning_rate': 0.000218211091234347, 'epoch': 2.89}                                                                                                        
 29%|████████████████████████████████████▉                                                                                           | 6600/22860 [9:04:08<4:25:45,  1.02it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.272602379322052, 'eval_wer': 0.45901405096451536, 'eval_cer': 0.10795719410608241, 'eval_runtime': 401.963, 'eval_samples_per_second': 23.955, 'eval_steps_per_second': 2.995, 'epoch': 2.89}                                                                                                                                               
{'loss': 0.5633, 'learning_rate': 0.00021807692307692305, 'epoch': 2.89}                                                                                                      
{'loss': 0.6719, 'learning_rate': 0.0002179427549194991, 'epoch': 2.9}                                                                                                        
{'loss': 0.4626, 'learning_rate': 0.00021780858676207512, 'epoch': 2.9}                                                                                                       
{'loss': 0.3111, 'learning_rate': 0.00021767441860465116, 'epoch': 2.9}                                                                                                       
{'loss': 0.4304, 'learning_rate': 0.00021754025044722717, 'epoch': 2.91}                                                                                                      
{'loss': 0.5048, 'learning_rate': 0.00021740608228980318, 'epoch': 2.91}                                                                                                      
{'loss': 0.6461, 'learning_rate': 0.00021727191413237922, 'epoch': 2.92}                                                                                                      
{'loss': 0.5236, 'learning_rate': 0.00021713774597495526, 'epoch': 2.92}                                                                                                      
{'loss': 0.3661, 'learning_rate': 0.00021700357781753127, 'epoch': 2.93}                                                                                                      
{'loss': 0.4215, 'learning_rate': 0.0002168694096601073, 'epoch': 2.93}                                                                                                       
 29%|█████████████████████████████████████▌                                                                                          | 6700/22860 [9:12:32<4:21:20,  1.03it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.27039483189582825, 'eval_wer': 0.4552988806858776, 'eval_cer': 0.10921211752704081, 'eval_runtime': 401.9179, 'eval_samples_per_second': 23.958, 'eval_steps_per_second': 2.996, 'epoch': 2.93}                                                                                                                                             
{'loss': 0.4909, 'learning_rate': 0.00021673524150268335, 'epoch': 2.94}                                                                                                      
{'loss': 0.6787, 'learning_rate': 0.00021660107334525939, 'epoch': 2.94}                                                                                                      
{'loss': 0.4779, 'learning_rate': 0.00021646690518783542, 'epoch': 2.94}                                                                                                      
{'loss': 0.377, 'learning_rate': 0.0002163327370304114, 'epoch': 2.95}                                                                                                        
{'loss': 0.4093, 'learning_rate': 0.00021619856887298745, 'epoch': 2.95}                                                                                                      
{'loss': 0.4702, 'learning_rate': 0.00021606440071556348, 'epoch': 2.96}                                                                                                      
{'loss': 0.5423, 'learning_rate': 0.00021593023255813952, 'epoch': 2.96}                                                                                                      
{'loss': 0.4703, 'learning_rate': 0.00021579606440071553, 'epoch': 2.97}                                                                                                      
{'loss': 0.3374, 'learning_rate': 0.00021566189624329157, 'epoch': 2.97}                                                                                                      
{'loss': 0.3683, 'learning_rate': 0.0002155277280858676, 'epoch': 2.97}                                                                                                       
 30%|██████████████████████████████████████                                                                                          | 6800/22860 [9:20:55<4:22:12,  1.02it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.26195716857910156, 'eval_wer': 0.44801143129316506, 'eval_cer': 0.10551659606666802, 'eval_runtime': 402.1847, 'eval_samples_per_second': 23.942, 'eval_steps_per_second': 2.994, 'epoch': 2.97}                                                                                                                                            
{'loss': 0.4569, 'learning_rate': 0.00021539355992844365, 'epoch': 2.98}                                                                                                      
{'loss': 0.5936, 'learning_rate': 0.00021525939177101969, 'epoch': 2.98}                                                                                                      
{'loss': 0.5526, 'learning_rate': 0.00021512522361359567, 'epoch': 2.99}                                                                                                      
{'loss': 0.3875, 'learning_rate': 0.0002149910554561717, 'epoch': 2.99}                                                                                                       
{'loss': 0.475, 'learning_rate': 0.00021485688729874775, 'epoch': 3.0}                                                                                                        
 30%|██████████████████████████████████████▍                                                                                         | 6858/22860 [9:28:29<2:26:50,  1.82it/s]Saving model checkpoint to russian_augmented/checkpoint-6858
Configuration saved in russian_augmented/checkpoint-6858/config.json
Model weights saved in russian_augmented/checkpoint-6858/pytorch_model.bin
Feature extractor saved in russian_augmented/checkpoint-6858/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.6986, 'learning_rate': 0.00021472271914132378, 'epoch': 3.0}                                                                                                       
{'loss': 0.2862, 'learning_rate': 0.0002145885509838998, 'epoch': 3.01}                                                                                                       
{'loss': 0.3216, 'learning_rate': 0.00021445438282647583, 'epoch': 3.01}                                                                                                      
{'loss': 0.4066, 'learning_rate': 0.00021432021466905187, 'epoch': 3.01}                                                                                                      
{'loss': 0.5521, 'learning_rate': 0.0002141860465116279, 'epoch': 3.02}                                                                                                       
 30%|██████████████████████████████████████▋                                                                                         | 6900/22860 [9:29:18<3:09:30,  1.40it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2662944495677948, 'eval_wer': 0.45152417242200527, 'eval_cer': 0.10603005060229569, 'eval_runtime': 405.2369, 'eval_samples_per_second': 23.761, 'eval_steps_per_second': 2.971, 'epoch': 3.02}                                                                                                                                             
{'loss': 0.6744, 'learning_rate': 0.00021405187835420392, 'epoch': 3.02}                                                                                                      
{'loss': 0.3014, 'learning_rate': 0.00021391771019677993, 'epoch': 3.03}                                                                                                      
{'loss': 0.341, 'learning_rate': 0.00021378354203935597, 'epoch': 3.03}                                                                                                       
{'loss': 0.3784, 'learning_rate': 0.000213649373881932, 'epoch': 3.04}                                                                                                        
{'loss': 0.4449, 'learning_rate': 0.00021351520572450804, 'epoch': 3.04}                                                                                                      
{'loss': 0.6363, 'learning_rate': 0.00021338103756708406, 'epoch': 3.04}                                                                                                      
{'loss': 0.2963, 'learning_rate': 0.0002132468694096601, 'epoch': 3.05}                                                                                                       
{'loss': 0.3707, 'learning_rate': 0.0002131127012522361, 'epoch': 3.05}                                                                                                       
{'loss': 0.3779, 'learning_rate': 0.00021297853309481214, 'epoch': 3.06}                                                                                                      
{'loss': 0.5002, 'learning_rate': 0.00021284436493738818, 'epoch': 3.06}                                                                                                      
 31%|███████████████████████████████████████▏                                                                                        | 7000/22860 [9:37:44<3:00:14,  1.47it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2811150550842285, 'eval_wer': 0.4588830673969993, 'eval_cer': 0.11034543329482424, 'eval_runtime': 400.5303, 'eval_samples_per_second': 24.041, 'eval_steps_per_second': 3.006, 'epoch': 3.06}                                                                                                                                              
{'loss': 0.6049, 'learning_rate': 0.0002127101967799642, 'epoch': 3.07}                                                                                                       
{'loss': 0.2998, 'learning_rate': 0.00021257602862254023, 'epoch': 3.07}                                                                                                      
{'loss': 0.402, 'learning_rate': 0.00021244186046511627, 'epoch': 3.08}                                                                                                       
{'loss': 0.4542, 'learning_rate': 0.0002123076923076923, 'epoch': 3.08}                                                                                                       
{'loss': 0.5178, 'learning_rate': 0.00021217352415026832, 'epoch': 3.08}                                                                                                      
{'loss': 0.646, 'learning_rate': 0.00021203935599284433, 'epoch': 3.09}                                                                                                       
{'loss': 0.2816, 'learning_rate': 0.00021190518783542037, 'epoch': 3.09}                                                                                                      
{'loss': 0.3059, 'learning_rate': 0.0002117710196779964, 'epoch': 3.1}                                                                                                        
{'loss': 0.4022, 'learning_rate': 0.00021163685152057244, 'epoch': 3.1}                                                                                                       
{'loss': 0.501, 'learning_rate': 0.00021150268336314845, 'epoch': 3.11}                                                                                                       
 31%|███████████████████████████████████████▊                                                                                        | 7100/22860 [9:46:05<3:04:23,  1.42it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.27358299493789673, 'eval_wer': 0.44979757085020244, 'eval_cer': 0.10926447637771337, 'eval_runtime': 407.2752, 'eval_samples_per_second': 23.642, 'eval_steps_per_second': 2.956, 'epoch': 3.11}                                                                                                                                            
{'loss': 0.6377, 'learning_rate': 0.0002113685152057245, 'epoch': 3.11}                                                                                                       
{'loss': 0.2899, 'learning_rate': 0.00021123434704830053, 'epoch': 3.11}                                                                                                      
{'loss': 0.3371, 'learning_rate': 0.00021110017889087657, 'epoch': 3.12}                                                                                                      
{'loss': 0.4223, 'learning_rate': 0.00021096601073345255, 'epoch': 3.12}                                                                                                      
{'loss': 0.4135, 'learning_rate': 0.0002108318425760286, 'epoch': 3.13}                                                                                                       
{'loss': 0.6251, 'learning_rate': 0.00021069767441860463, 'epoch': 3.13}                                                                                                      
{'loss': 0.2362, 'learning_rate': 0.00021056350626118067, 'epoch': 3.14}                                                                                                      
{'loss': 0.3334, 'learning_rate': 0.0002104293381037567, 'epoch': 3.14}                                                                                                       
{'loss': 0.4213, 'learning_rate': 0.00021029516994633271, 'epoch': 3.15}                                                                                                      
{'loss': 0.4606, 'learning_rate': 0.00021016100178890875, 'epoch': 3.15}                                                                                                      
 31%|████████████████████████████████████████▎                                                                                       | 7200/22860 [9:54:35<3:10:19,  1.37it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2699543237686157, 'eval_wer': 0.45077399380804956, 'eval_cer': 0.10765486396832796, 'eval_runtime': 404.7098, 'eval_samples_per_second': 23.792, 'eval_steps_per_second': 2.975, 'epoch': 3.15}                                                                                                                                             
{'loss': 0.6009, 'learning_rate': 0.0002100268336314848, 'epoch': 3.15}                                                                                                       
{'loss': 0.3057, 'learning_rate': 0.00020989266547406083, 'epoch': 3.16}                                                                                                      
{'loss': 0.2876, 'learning_rate': 0.0002097584973166368, 'epoch': 3.16}                                                                                                       
{'loss': 0.3965, 'learning_rate': 0.00020962432915921285, 'epoch': 3.17}                                                                                                      
{'loss': 0.5031, 'learning_rate': 0.0002094901610017889, 'epoch': 3.17}                                                                                                       
{'loss': 0.6143, 'learning_rate': 0.00020935599284436493, 'epoch': 3.18}                                                                                                      
{'loss': 0.3156, 'learning_rate': 0.00020922182468694096, 'epoch': 3.18}                                                                                                      
{'loss': 0.3343, 'learning_rate': 0.00020908765652951698, 'epoch': 3.18}                                                                                                      
{'loss': 0.4296, 'learning_rate': 0.000208953488372093, 'epoch': 3.19}                                                                                                        
{'loss': 0.4538, 'learning_rate': 0.00020881932021466905, 'epoch': 3.19}                                                                                                      
 32%|████████████████████████████████████████▌                                                                                      | 7300/22860 [10:03:01<3:04:37,  1.40it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2645549178123474, 'eval_wer': 0.4391998094784472, 'eval_cer': 0.10481397407054595, 'eval_runtime': 407.4094, 'eval_samples_per_second': 23.635, 'eval_steps_per_second': 2.955, 'epoch': 3.19}                                                                                                                                              
{'loss': 0.5688, 'learning_rate': 0.00020868515205724506, 'epoch': 3.2}                                                                                                       
{'loss': 0.2859, 'learning_rate': 0.00020855098389982107, 'epoch': 3.2}                                                                                                       
{'loss': 0.3116, 'learning_rate': 0.0002084168157423971, 'epoch': 3.21}                                                                                                       
{'loss': 0.4222, 'learning_rate': 0.00020828264758497315, 'epoch': 3.21}                                                                                                      
{'loss': 0.4531, 'learning_rate': 0.0002081484794275492, 'epoch': 3.22}                                                                                                       
{'loss': 0.6753, 'learning_rate': 0.0002080143112701252, 'epoch': 3.22}                                                                                                       
{'loss': 0.2569, 'learning_rate': 0.00020788014311270124, 'epoch': 3.22}                                                                                                      
{'loss': 0.3226, 'learning_rate': 0.00020774597495527727, 'epoch': 3.23}                                                                                                      
{'loss': 0.4047, 'learning_rate': 0.00020761180679785329, 'epoch': 3.23}                                                                                                      
{'loss': 0.4707, 'learning_rate': 0.00020747763864042932, 'epoch': 3.24}                                                                                                      
 32%|█████████████████████████████████████████                                                                                      | 7400/22860 [10:11:30<2:59:02,  1.44it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2648372948169708, 'eval_wer': 0.4488806858775899, 'eval_cer': 0.10662964389225561, 'eval_runtime': 405.8773, 'eval_samples_per_second': 23.724, 'eval_steps_per_second': 2.966, 'epoch': 3.24}                                                                                                                                              
{'loss': 0.5576, 'learning_rate': 0.00020734347048300533, 'epoch': 3.24}                                                                                                      
{'loss': 0.2649, 'learning_rate': 0.00020720930232558137, 'epoch': 3.25}                                                                                                      
{'loss': 0.3118, 'learning_rate': 0.0002070751341681574, 'epoch': 3.25}                                                                                                       
{'loss': 0.419, 'learning_rate': 0.00020694096601073345, 'epoch': 3.25}                                                                                                       
{'loss': 0.4888, 'learning_rate': 0.00020680679785330946, 'epoch': 3.26}                                                                                                      
{'loss': 0.5945, 'learning_rate': 0.00020667262969588547, 'epoch': 3.26}                                                                                                      
{'loss': 0.3061, 'learning_rate': 0.0002065384615384615, 'epoch': 3.27}                                                                                                       
{'loss': 0.3711, 'learning_rate': 0.00020640429338103755, 'epoch': 3.27}                                                                                                      
{'loss': 0.4595, 'learning_rate': 0.00020627012522361359, 'epoch': 3.28}                                                                                                      
{'loss': 0.4878, 'learning_rate': 0.0002061359570661896, 'epoch': 3.28}                                                                                                       
 33%|█████████████████████████████████████████▋                                                                                     | 7500/22860 [10:19:56<2:54:27,  1.47it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.26766476035118103, 'eval_wer': 0.4445582281495594, 'eval_cer': 0.10491362478634211, 'eval_runtime': 407.0697, 'eval_samples_per_second': 23.654, 'eval_steps_per_second': 2.958, 'epoch': 3.28}                                                                                                                                             
{'loss': 0.6112, 'learning_rate': 0.00020601520572450802, 'epoch': 3.29}                                                                                                      
{'loss': 0.3315, 'learning_rate': 0.00020588103756708406, 'epoch': 3.29}                                                                                                      
{'loss': 0.3197, 'learning_rate': 0.00020574686940966007, 'epoch': 3.29}                                                                                                      
{'loss': 0.4325, 'learning_rate': 0.0002056127012522361, 'epoch': 3.3}                                                                                                        
{'loss': 0.4463, 'learning_rate': 0.00020547853309481215, 'epoch': 3.3}                                                                                                       
{'loss': 0.5998, 'learning_rate': 0.0002053443649373882, 'epoch': 3.31}                                                                                                       
{'loss': 0.3135, 'learning_rate': 0.00020521019677996423, 'epoch': 3.31}                                                                                                      
{'loss': 0.3266, 'learning_rate': 0.0002050760286225402, 'epoch': 3.32}                                                                                                       
{'loss': 0.4686, 'learning_rate': 0.00020494186046511625, 'epoch': 3.32}                                                                                                      
{'loss': 0.5051, 'learning_rate': 0.00020480769230769229, 'epoch': 3.32}                                                                                                      
 33%|██████████████████████████████████████████▏                                                                                    | 7600/22860 [10:28:23<2:57:52,  1.43it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.274187296628952, 'eval_wer': 0.4485115503691355, 'eval_cer': 0.10704851469763609, 'eval_runtime': 408.0424, 'eval_samples_per_second': 23.598, 'eval_steps_per_second': 2.951, 'epoch': 3.32}                                                                                                                                               
{'loss': 0.6768, 'learning_rate': 0.00020467352415026832, 'epoch': 3.33}                                                                                                      
{'loss': 0.3181, 'learning_rate': 0.00020453935599284434, 'epoch': 3.33}                                                                                                      
{'loss': 0.297, 'learning_rate': 0.00020440518783542037, 'epoch': 3.34}                                                                                                       
{'loss': 0.4098, 'learning_rate': 0.0002042710196779964, 'epoch': 3.34}                                                                                                       
{'loss': 0.5236, 'learning_rate': 0.00020413685152057245, 'epoch': 3.35}                                                                                                      
{'loss': 0.5746, 'learning_rate': 0.0002040026833631485, 'epoch': 3.35}                                                                                                       
{'loss': 0.2902, 'learning_rate': 0.00020386851520572447, 'epoch': 3.36}                                                                                                      
{'loss': 0.2977, 'learning_rate': 0.0002037343470483005, 'epoch': 3.36}                                                                                                       
{'loss': 0.3244, 'learning_rate': 0.00020360017889087655, 'epoch': 3.36}                                                                                                      
{'loss': 0.5014, 'learning_rate': 0.00020346601073345259, 'epoch': 3.37}                                                                                                      
 34%|██████████████████████████████████████████▊                                                                                    | 7700/22860 [10:36:53<2:59:17,  1.41it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.25936466455459595, 'eval_wer': 0.44084305787092165, 'eval_cer': 0.10429883053973531, 'eval_runtime': 403.691, 'eval_samples_per_second': 23.852, 'eval_steps_per_second': 2.982, 'epoch': 3.37}                                                                                                                                             
{'loss': 0.6333, 'learning_rate': 0.0002033318425760286, 'epoch': 3.37}                                                                                                       
{'loss': 0.2976, 'learning_rate': 0.00020319767441860463, 'epoch': 3.38}                                                                                                      
{'loss': 0.3035, 'learning_rate': 0.00020306350626118067, 'epoch': 3.38}                                                                                                      
{'loss': 0.3558, 'learning_rate': 0.0002029293381037567, 'epoch': 3.39}                                                                                                       
{'loss': 0.4539, 'learning_rate': 0.0002027951699463327, 'epoch': 3.39}                                                                                                       
{'loss': 0.5855, 'learning_rate': 0.00020266100178890873, 'epoch': 3.39}                                                                                                      
{'loss': 0.3533, 'learning_rate': 0.00020252683363148477, 'epoch': 3.4}                                                                                                       
{'loss': 0.3381, 'learning_rate': 0.0002023926654740608, 'epoch': 3.4}                                                                                                        
{'loss': 0.3337, 'learning_rate': 0.00020225849731663685, 'epoch': 3.41}                                                                                                      
{'loss': 0.4526, 'learning_rate': 0.00020212432915921286, 'epoch': 3.41}                                                                                                      
 34%|███████████████████████████████████████████▎                                                                                   | 7800/22860 [10:45:20<3:01:29,  1.38it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.264710396528244, 'eval_wer': 0.4463800904977376, 'eval_cer': 0.105518285061851, 'eval_runtime': 406.3904, 'eval_samples_per_second': 23.694, 'eval_steps_per_second': 2.963, 'epoch': 3.41}                                                                                                                                                 
{'loss': 0.5395, 'learning_rate': 0.0002019901610017889, 'epoch': 3.42}                                                                                                       
{'loss': 0.252, 'learning_rate': 0.00020185599284436493, 'epoch': 3.42}                                                                                                       
{'loss': 0.3018, 'learning_rate': 0.00020172182468694094, 'epoch': 3.43}                                                                                                      
{'loss': 0.3371, 'learning_rate': 0.00020158765652951696, 'epoch': 3.43}                                                                                                      
{'loss': 0.4233, 'learning_rate': 0.000201453488372093, 'epoch': 3.43}                                                                                                        
{'loss': 0.5839, 'learning_rate': 0.00020131932021466903, 'epoch': 3.44}                                                                                                      
{'loss': 0.2891, 'learning_rate': 0.00020118515205724507, 'epoch': 3.44}                                                                                                      
{'loss': 0.3327, 'learning_rate': 0.0002010509838998211, 'epoch': 3.45}                                                                                                       
{'loss': 0.346, 'learning_rate': 0.00020091681574239712, 'epoch': 3.45}                                                                                                       
{'loss': 0.5986, 'learning_rate': 0.00020078264758497316, 'epoch': 3.46}                                                                                                      
 35%|███████████████████████████████████████████▉                                                                                   | 7900/22860 [10:53:48<2:49:54,  1.47it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2571469843387604, 'eval_wer': 0.43873541319361753, 'eval_cer': 0.1033276583095185, 'eval_runtime': 405.4312, 'eval_samples_per_second': 23.75, 'eval_steps_per_second': 2.97, 'epoch': 3.46}                                                                                                                                                
{'loss': 0.5825, 'learning_rate': 0.00020064847942754917, 'epoch': 3.46}                                                                                                      
{'loss': 0.2868, 'learning_rate': 0.0002005143112701252, 'epoch': 3.46}                                                                                                       
{'loss': 0.3545, 'learning_rate': 0.00020038014311270122, 'epoch': 3.47}                                                                                                      
{'loss': 0.4315, 'learning_rate': 0.00020024597495527726, 'epoch': 3.47}                                                                                                      
{'loss': 0.4519, 'learning_rate': 0.0002001118067978533, 'epoch': 3.48}                                                                                                       
{'loss': 0.5566, 'learning_rate': 0.00019997763864042933, 'epoch': 3.48}                                                                                                      
{'loss': 0.2662, 'learning_rate': 0.00019984347048300537, 'epoch': 3.49}                                                                                                      
{'loss': 0.3409, 'learning_rate': 0.00019970930232558135, 'epoch': 3.49}                                                                                                      
{'loss': 0.3657, 'learning_rate': 0.0001995751341681574, 'epoch': 3.5}                                                                                                        
{'loss': 0.4749, 'learning_rate': 0.00019944096601073343, 'epoch': 3.5}                                                                                                       
 35%|████████████████████████████████████████████▍                                                                                  | 8000/22860 [11:02:14<2:53:37,  1.43it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.26716822385787964, 'eval_wer': 0.44258156703977136, 'eval_cer': 0.10497105062256362, 'eval_runtime': 403.5801, 'eval_samples_per_second': 23.859, 'eval_steps_per_second': 2.983, 'epoch': 3.5}                                                                                                                                             
{'loss': 0.5446, 'learning_rate': 0.00019930679785330947, 'epoch': 3.5}                                                                                                       
{'loss': 0.2912, 'learning_rate': 0.00019917262969588548, 'epoch': 3.51}                                                                                                      
{'loss': 0.3122, 'learning_rate': 0.00019903846153846152, 'epoch': 3.51}                                                                                                      
{'loss': 0.3546, 'learning_rate': 0.00019890429338103755, 'epoch': 3.52}                                                                                                      
{'loss': 0.4496, 'learning_rate': 0.0001987701252236136, 'epoch': 3.52}                                                                                                       
{'loss': 0.5336, 'learning_rate': 0.00019863595706618963, 'epoch': 3.53}                                                                                                      
{'loss': 0.2951, 'learning_rate': 0.00019850178890876561, 'epoch': 3.53}                                                                                                      
{'loss': 0.3299, 'learning_rate': 0.00019836762075134165, 'epoch': 3.53}                                                                                                      
{'loss': 0.3773, 'learning_rate': 0.0001982334525939177, 'epoch': 3.54}                                                                                                       
{'loss': 0.4488, 'learning_rate': 0.00019809928443649373, 'epoch': 3.54}                                                                                                      
 35%|█████████████████████████████████████████████                                                                                  | 8100/22860 [11:10:39<2:53:08,  1.42it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2603286802768707, 'eval_wer': 0.435413193617528, 'eval_cer': 0.10276860090395022, 'eval_runtime': 405.5784, 'eval_samples_per_second': 23.741, 'eval_steps_per_second': 2.969, 'epoch': 3.54}                                                                                                                                               
{'loss': 0.6269, 'learning_rate': 0.00019796511627906974, 'epoch': 3.55}                                                                                                      
{'loss': 0.2835, 'learning_rate': 0.00019783094812164578, 'epoch': 3.55}                                                                                                      
{'loss': 0.2808, 'learning_rate': 0.00019769677996422182, 'epoch': 3.56}                                                                                                      
{'loss': 0.4264, 'learning_rate': 0.00019756261180679785, 'epoch': 3.56}                                                                                                      
{'loss': 0.4721, 'learning_rate': 0.0001974284436493739, 'epoch': 3.57}                                                                                                       
{'loss': 0.5386, 'learning_rate': 0.00019729427549194988, 'epoch': 3.57}                                                                                                      
{'loss': 0.2377, 'learning_rate': 0.00019716010733452591, 'epoch': 3.57}                                                                                                      
{'loss': 0.3283, 'learning_rate': 0.00019702593917710195, 'epoch': 3.58}                                                                                                      
{'loss': 0.413, 'learning_rate': 0.000196891771019678, 'epoch': 3.58}                                                                                                         
{'loss': 0.4349, 'learning_rate': 0.000196757602862254, 'epoch': 3.59}                                                                                                        
 36%|█████████████████████████████████████████████▌                                                                                 | 8200/22860 [11:19:08<2:50:22,  1.43it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2552206516265869, 'eval_wer': 0.43494879733269826, 'eval_cer': 0.10425660566016065, 'eval_runtime': 407.547, 'eval_samples_per_second': 23.627, 'eval_steps_per_second': 2.954, 'epoch': 3.59}                                                                                                                                              
{'loss': 0.5986, 'learning_rate': 0.00019662343470483004, 'epoch': 3.59}                                                                                                      
{'loss': 0.2493, 'learning_rate': 0.00019648926654740608, 'epoch': 3.6}                                                                                                       
{'loss': 0.2985, 'learning_rate': 0.00019635509838998212, 'epoch': 3.6}                                                                                                       
{'loss': 0.3568, 'learning_rate': 0.00019622093023255813, 'epoch': 3.6}                                                                                                       
{'loss': 0.5264, 'learning_rate': 0.00019608676207513414, 'epoch': 3.61}                                                                                                      
{'loss': 0.6285, 'learning_rate': 0.00019595259391771017, 'epoch': 3.61}                                                                                                      
{'loss': 0.2482, 'learning_rate': 0.0001958184257602862, 'epoch': 3.62}                                                                                                       
{'loss': 0.3034, 'learning_rate': 0.00019568425760286225, 'epoch': 3.62}                                                                                                      
{'loss': 0.3712, 'learning_rate': 0.00019555008944543826, 'epoch': 3.63}                                                                                                      
{'loss': 0.4335, 'learning_rate': 0.0001954159212880143, 'epoch': 3.63}                                                                                                       
 36%|██████████████████████████████████████████████                                                                                 | 8300/22860 [11:27:37<2:55:28,  1.38it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2621898353099823, 'eval_wer': 0.43166230054774946, 'eval_cer': 0.10195957221130006, 'eval_runtime': 404.1722, 'eval_samples_per_second': 23.824, 'eval_steps_per_second': 2.979, 'epoch': 3.63}                                                                                                                                             
{'loss': 0.575, 'learning_rate': 0.0001952817531305903, 'epoch': 3.64}                                                                                                        
{'loss': 0.2838, 'learning_rate': 0.00019514758497316635, 'epoch': 3.64}                                                                                                      
{'loss': 0.3131, 'learning_rate': 0.0001950134168157424, 'epoch': 3.64}                                                                                                       
{'loss': 0.3267, 'learning_rate': 0.0001948792486583184, 'epoch': 3.65}                                                                                                       
{'loss': 0.4938, 'learning_rate': 0.00019474508050089444, 'epoch': 3.65}                                                                                                      
{'loss': 0.606, 'learning_rate': 0.00019461091234347047, 'epoch': 3.66}                                                                                                       
{'loss': 0.3224, 'learning_rate': 0.0001944767441860465, 'epoch': 3.66}                                                                                                       
{'loss': 0.3043, 'learning_rate': 0.0001943425760286225, 'epoch': 3.67}                                                                                                       
{'loss': 0.3569, 'learning_rate': 0.00019420840787119853, 'epoch': 3.67}                                                                                                      
{'loss': 0.48, 'learning_rate': 0.00019407423971377457, 'epoch': 3.67}                                                                                                        
 37%|██████████████████████████████████████████████▋                                                                                | 8400/22860 [11:36:02<2:44:45,  1.46it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.25987109541893005, 'eval_wer': 0.42700643010240535, 'eval_cer': 0.10144949566603836, 'eval_runtime': 405.4443, 'eval_samples_per_second': 23.749, 'eval_steps_per_second': 2.97, 'epoch': 3.67}                                                                                                                                             
{'loss': 0.591, 'learning_rate': 0.0001939400715563506, 'epoch': 3.68}                                                                                                        
{'loss': 0.247, 'learning_rate': 0.00019380590339892665, 'epoch': 3.68}                                                                                                       
{'loss': 0.3112, 'learning_rate': 0.00019367173524150266, 'epoch': 3.69}                                                                                                      
{'loss': 0.3664, 'learning_rate': 0.0001935375670840787, 'epoch': 3.69}                                                                                                       
{'loss': 0.4881, 'learning_rate': 0.00019340339892665474, 'epoch': 3.7}                                                                                                       
{'loss': 0.6195, 'learning_rate': 0.00019326923076923077, 'epoch': 3.7}                                                                                                       
{'loss': 0.2477, 'learning_rate': 0.00019313506261180676, 'epoch': 3.71}                                                                                                      
{'loss': 0.3693, 'learning_rate': 0.0001930008944543828, 'epoch': 3.71}                                                                                                       
{'loss': 0.4417, 'learning_rate': 0.00019286672629695883, 'epoch': 3.71}                                                                                                      
{'loss': 0.4899, 'learning_rate': 0.00019273255813953487, 'epoch': 3.72}                                                                                                      
 37%|███████████████████████████████████████████████▏                                                                               | 8500/22860 [11:44:30<2:48:20,  1.42it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.25413450598716736, 'eval_wer': 0.42470826387235056, 'eval_cer': 0.10088368227973814, 'eval_runtime': 403.0256, 'eval_samples_per_second': 23.892, 'eval_steps_per_second': 2.987, 'epoch': 3.72}                                                                                                                                            
{'loss': 0.6381, 'learning_rate': 0.00019259838998211088, 'epoch': 3.72}                                                                                                      
{'loss': 0.2871, 'learning_rate': 0.00019246422182468692, 'epoch': 3.73}                                                                                                      
{'loss': 0.2929, 'learning_rate': 0.00019233005366726296, 'epoch': 3.73}                                                                                                      
{'loss': 0.4656, 'learning_rate': 0.000192195885509839, 'epoch': 3.74}                                                                                                        
{'loss': 0.4753, 'learning_rate': 0.00019206171735241503, 'epoch': 3.74}                                                                                                      
{'loss': 0.5782, 'learning_rate': 0.00019192754919499102, 'epoch': 3.74}                                                                                                      
{'loss': 0.2696, 'learning_rate': 0.00019179338103756706, 'epoch': 3.75}                                                                                                      
{'loss': 0.3141, 'learning_rate': 0.0001916592128801431, 'epoch': 3.75}                                                                                                       
{'loss': 0.3779, 'learning_rate': 0.00019152504472271913, 'epoch': 3.76}                                                                                                      
{'loss': 0.5352, 'learning_rate': 0.00019139087656529514, 'epoch': 3.76}                                                                                                      
 38%|███████████████████████████████████████████████▊                                                                               | 8600/22860 [11:52:53<2:48:04,  1.41it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.25548022985458374, 'eval_wer': 0.43272207668492496, 'eval_cer': 0.10214705067661146, 'eval_runtime': 401.3781, 'eval_samples_per_second': 23.99, 'eval_steps_per_second': 3.0, 'epoch': 3.76}                                                                                                                                               
{'loss': 0.5472, 'learning_rate': 0.00019125670840787118, 'epoch': 3.77}                                                                                                      
{'loss': 0.2946, 'learning_rate': 0.00019112254025044722, 'epoch': 3.77}                                                                                                      
{'loss': 0.394, 'learning_rate': 0.00019098837209302326, 'epoch': 3.77}                                                                                                       
{'loss': 0.4358, 'learning_rate': 0.00019085420393559927, 'epoch': 3.78}                                                                                                      
{'loss': 0.4094, 'learning_rate': 0.00019072003577817528, 'epoch': 3.78}                                                                                                      
{'loss': 0.5573, 'learning_rate': 0.00019058586762075132, 'epoch': 3.79}                                                                                                      
{'loss': 0.2436, 'learning_rate': 0.00019045169946332736, 'epoch': 3.79}                                                                                                      
{'loss': 0.3716, 'learning_rate': 0.0001903175313059034, 'epoch': 3.8}                                                                                                        
{'loss': 0.3864, 'learning_rate': 0.0001901833631484794, 'epoch': 3.8}                                                                                                        
{'loss': 0.4254, 'learning_rate': 0.00019004919499105544, 'epoch': 3.81}                                                                                                      
 38%|████████████████████████████████████████████████▎                                                                              | 8700/22860 [12:01:15<2:43:08,  1.45it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.258752703666687, 'eval_wer': 0.4294474874970231, 'eval_cer': 0.1007232277373545, 'eval_runtime': 402.5124, 'eval_samples_per_second': 23.922, 'eval_steps_per_second': 2.991, 'epoch': 3.81}                                                                                                                                                
{'loss': 0.5569, 'learning_rate': 0.00018991502683363145, 'epoch': 3.81}                                                                                                      
{'loss': 0.2992, 'learning_rate': 0.0001897808586762075, 'epoch': 3.81}                                                                                                       
{'loss': 0.2942, 'learning_rate': 0.00018964669051878353, 'epoch': 3.82}                                                                                                      
{'loss': 0.4099, 'learning_rate': 0.00018951252236135954, 'epoch': 3.82}                                                                                                      
{'loss': 0.4423, 'learning_rate': 0.00018937835420393558, 'epoch': 3.83}                                                                                                      
{'loss': 0.5492, 'learning_rate': 0.00018924418604651162, 'epoch': 3.83}                                                                                                      
{'loss': 0.2971, 'learning_rate': 0.00018911001788908766, 'epoch': 3.84}                                                                                                      
{'loss': 0.351, 'learning_rate': 0.00018897584973166367, 'epoch': 3.84}                                                                                                       
{'loss': 0.388, 'learning_rate': 0.00018884168157423968, 'epoch': 3.84}                                                                                                       
{'loss': 0.4913, 'learning_rate': 0.00018870751341681572, 'epoch': 3.85}                                                                                                      
 38%|████████████████████████████████████████████████▉                                                                              | 8800/22860 [12:09:38<2:40:03,  1.46it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2490154504776001, 'eval_wer': 0.4281614670159562, 'eval_cer': 0.09978414641561442, 'eval_runtime': 402.8729, 'eval_samples_per_second': 23.901, 'eval_steps_per_second': 2.989, 'epoch': 3.85}                                                                                                                                              
{'loss': 0.6406, 'learning_rate': 0.00018857334525939175, 'epoch': 3.85}                                                                                                      
{'loss': 0.2524, 'learning_rate': 0.0001884391771019678, 'epoch': 3.86}                                                                                                       
{'loss': 0.3463, 'learning_rate': 0.0001883050089445438, 'epoch': 3.86}                                                                                                       
{'loss': 0.3836, 'learning_rate': 0.00018817084078711984, 'epoch': 3.87}                                                                                                      
{'loss': 0.4252, 'learning_rate': 0.00018803667262969588, 'epoch': 3.87}                                                                                                      
{'loss': 0.6144, 'learning_rate': 0.00018790250447227192, 'epoch': 3.88}                                                                                                      
{'loss': 0.2755, 'learning_rate': 0.0001877683363148479, 'epoch': 3.88}                                                                                                       
{'loss': 0.2935, 'learning_rate': 0.00018763416815742394, 'epoch': 3.88}                                                                                                      
{'loss': 0.3721, 'learning_rate': 0.00018749999999999998, 'epoch': 3.89}                                                                                                      
{'loss': 0.4567, 'learning_rate': 0.00018736583184257601, 'epoch': 3.89}                                                                                                      
 39%|█████████████████████████████████████████████████▍                                                                             | 8900/22860 [12:18:03<2:43:16,  1.43it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.25316405296325684, 'eval_wer': 0.4233269826149083, 'eval_cer': 0.09896329475668335, 'eval_runtime': 406.0094, 'eval_samples_per_second': 23.716, 'eval_steps_per_second': 2.965, 'epoch': 3.89}                                                                                                                                             
{'loss': 0.6232, 'learning_rate': 0.00018723166368515205, 'epoch': 3.9}                                                                                                       
{'loss': 0.2677, 'learning_rate': 0.00018709749552772806, 'epoch': 3.9}                                                                                                       
{'loss': 0.336, 'learning_rate': 0.0001869633273703041, 'epoch': 3.91}                                                                                                        
{'loss': 0.3168, 'learning_rate': 0.00018682915921288014, 'epoch': 3.91}                                                                                                      
{'loss': 0.4539, 'learning_rate': 0.00018669499105545618, 'epoch': 3.91}                                                                                                      
{'loss': 0.585, 'learning_rate': 0.00018656082289803216, 'epoch': 3.92}                                                                                                       
{'loss': 0.241, 'learning_rate': 0.0001864266547406082, 'epoch': 3.92}                                                                                                        
{'loss': 0.3285, 'learning_rate': 0.00018629248658318424, 'epoch': 3.93}                                                                                                      
{'loss': 0.3944, 'learning_rate': 0.00018615831842576028, 'epoch': 3.93}                                                                                                      
{'loss': 0.4502, 'learning_rate': 0.00018602415026833631, 'epoch': 3.94}                                                                                                      
 39%|██████████████████████████████████████████████████                                                                             | 9000/22860 [12:26:31<2:47:37,  1.38it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.25118204951286316, 'eval_wer': 0.41789711836151466, 'eval_cer': 0.0982353378328165, 'eval_runtime': 412.5197, 'eval_samples_per_second': 23.342, 'eval_steps_per_second': 2.919, 'epoch': 3.94}                                                                                                                                             
{'loss': 0.6581, 'learning_rate': 0.00018588998211091233, 'epoch': 3.94}                                                                                                      
{'loss': 0.2331, 'learning_rate': 0.00018575581395348836, 'epoch': 3.95}                                                                                                      
{'loss': 0.333, 'learning_rate': 0.0001856216457960644, 'epoch': 3.95}                                                                                                        
{'loss': 0.3701, 'learning_rate': 0.0001854874776386404, 'epoch': 3.95}                                                                                                       
{'loss': 0.4655, 'learning_rate': 0.00018535330948121642, 'epoch': 3.96}                                                                                                      
{'loss': 0.5918, 'learning_rate': 0.00018521914132379246, 'epoch': 3.96}                                                                                                      
{'loss': 0.2619, 'learning_rate': 0.0001850849731663685, 'epoch': 3.97}                                                                                                       
{'loss': 0.2763, 'learning_rate': 0.00018495080500894454, 'epoch': 3.97}                                                                                                      
{'loss': 0.3924, 'learning_rate': 0.00018481663685152058, 'epoch': 3.98}                                                                                                      
{'loss': 0.4458, 'learning_rate': 0.00018468246869409659, 'epoch': 3.98}                                                                                                      
 40%|██████████████████████████████████████████████████▌                                                                            | 9100/22860 [12:35:05<2:37:05,  1.46it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2559325695037842, 'eval_wer': 0.41918313884258157, 'eval_cer': 0.09974867751677172, 'eval_runtime': 404.7265, 'eval_samples_per_second': 23.791, 'eval_steps_per_second': 2.975, 'epoch': 3.98}                                                                                                                                             
{'loss': 0.6175, 'learning_rate': 0.0001845483005366726, 'epoch': 3.98}                                                                                                       
{'loss': 0.2795, 'learning_rate': 0.00018441413237924864, 'epoch': 3.99}                                                                                                      
{'loss': 0.3059, 'learning_rate': 0.00018427996422182467, 'epoch': 3.99}                                                                                                      
{'loss': 0.4238, 'learning_rate': 0.00018414579606440068, 'epoch': 4.0}                                                                                                       
 40%|██████████████████████████████████████████████████▊                                                                            | 9144/22860 [12:42:31<2:11:58,  1.73it/s]Saving model checkpoint to russian_augmented/checkpoint-9144
Configuration saved in russian_augmented/checkpoint-9144/config.json
Model weights saved in russian_augmented/checkpoint-9144/pytorch_model.bin
Feature extractor saved in russian_augmented/checkpoint-9144/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4428, 'learning_rate': 0.00018401162790697672, 'epoch': 4.0}                                                                                                       
{'loss': 0.2746, 'learning_rate': 0.00018387745974955276, 'epoch': 4.01}                                                                                                      
{'loss': 0.2705, 'learning_rate': 0.0001837432915921288, 'epoch': 4.01}                                                                                                       
{'loss': 0.3431, 'learning_rate': 0.00018360912343470484, 'epoch': 4.02}                                                                                                      
{'loss': 0.5119, 'learning_rate': 0.00018347495527728082, 'epoch': 4.02}                                                                                                      
{'loss': 0.4185, 'learning_rate': 0.00018334078711985686, 'epoch': 4.02}                                                                                                      
 40%|███████████████████████████████████████████████████                                                                            | 9200/22860 [12:43:35<5:28:49,  1.44s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.26376014947891235, 'eval_wer': 0.41976661109788044, 'eval_cer': 0.0997047636420141, 'eval_runtime': 410.1366, 'eval_samples_per_second': 23.478, 'eval_steps_per_second': 2.936, 'epoch': 4.02}                                                                                                                                             
{'loss': 0.2392, 'learning_rate': 0.0001832066189624329, 'epoch': 4.03}                                                                                                       
{'loss': 0.2594, 'learning_rate': 0.00018307245080500893, 'epoch': 4.03}                                                                                                      
{'loss': 0.3903, 'learning_rate': 0.00018293828264758495, 'epoch': 4.04}                                                                                                      
{'loss': 0.5008, 'learning_rate': 0.00018280411449016098, 'epoch': 4.04}                                                                                                      
{'loss': 0.4447, 'learning_rate': 0.00018266994633273702, 'epoch': 4.05}                                                                                                      
{'loss': 0.2382, 'learning_rate': 0.00018253577817531306, 'epoch': 4.05}                                                                                                      
{'loss': 0.284, 'learning_rate': 0.0001824016100178891, 'epoch': 4.06}                                                                                                        
{'loss': 0.3505, 'learning_rate': 0.00018226744186046508, 'epoch': 4.06}                                                                                                      
{'loss': 0.4286, 'learning_rate': 0.00018213327370304112, 'epoch': 4.06}                                                                                                      
{'loss': 0.3546, 'learning_rate': 0.00018199910554561716, 'epoch': 4.07}                                                                                                      
 41%|███████████████████████████████████████████████████▋                                                                           | 9300/22860 [12:52:06<5:25:58,  1.44s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2550077736377716, 'eval_wer': 0.413312693498452, 'eval_cer': 0.09916428518345866, 'eval_runtime': 405.8973, 'eval_samples_per_second': 23.723, 'eval_steps_per_second': 2.966, 'epoch': 4.07}                                                                                                                                               
{'loss': 0.2561, 'learning_rate': 0.0001818649373881932, 'epoch': 4.07}                                                                                                       
{'loss': 0.2851, 'learning_rate': 0.0001817307692307692, 'epoch': 4.08}                                                                                                       
{'loss': 0.3619, 'learning_rate': 0.00018159660107334525, 'epoch': 4.08}                                                                                                      
{'loss': 0.382, 'learning_rate': 0.00018146243291592128, 'epoch': 4.09}                                                                                                       
{'loss': 0.4487, 'learning_rate': 0.00018132826475849732, 'epoch': 4.09}                                                                                                      
{'loss': 0.2506, 'learning_rate': 0.0001811940966010733, 'epoch': 4.09}                                                                                                       
{'loss': 0.3132, 'learning_rate': 0.00018105992844364934, 'epoch': 4.1}                                                                                                       
{'loss': 0.3693, 'learning_rate': 0.00018092576028622538, 'epoch': 4.1}                                                                                                       
{'loss': 0.4579, 'learning_rate': 0.00018079159212880142, 'epoch': 4.11}                                                                                                      
{'loss': 0.4314, 'learning_rate': 0.00018065742397137746, 'epoch': 4.11}                                                                                                      
 41%|████████████████████████████████████████████████████▏                                                                          | 9400/22860 [13:00:32<5:14:42,  1.40s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2588697671890259, 'eval_wer': 0.4180161943319838, 'eval_cer': 0.09935683063431903, 'eval_runtime': 406.1551, 'eval_samples_per_second': 23.708, 'eval_steps_per_second': 2.964, 'epoch': 4.11}                                                                                                                                              
{'loss': 0.2366, 'learning_rate': 0.00018052325581395347, 'epoch': 4.12}                                                                                                      
{'loss': 0.2856, 'learning_rate': 0.0001803890876565295, 'epoch': 4.12}                                                                                                       
{'loss': 0.3886, 'learning_rate': 0.00018025491949910554, 'epoch': 4.13}                                                                                                      
{'loss': 0.4779, 'learning_rate': 0.00018012075134168156, 'epoch': 4.13}                                                                                                      
{'loss': 0.4411, 'learning_rate': 0.00017998658318425757, 'epoch': 4.13}                                                                                                      
{'loss': 0.2195, 'learning_rate': 0.0001798524150268336, 'epoch': 4.14}                                                                                                       
{'loss': 0.306, 'learning_rate': 0.00017971824686940964, 'epoch': 4.14}                                                                                                       
{'loss': 0.3929, 'learning_rate': 0.00017958407871198568, 'epoch': 4.15}                                                                                                      
{'loss': 0.4665, 'learning_rate': 0.00017944991055456172, 'epoch': 4.15}                                                                                                      
{'loss': 0.4471, 'learning_rate': 0.00017931574239713773, 'epoch': 4.16}                                                                                                      
 42%|████████████████████████████████████████████████████▊                                                                          | 9500/22860 [13:08:58<5:27:05,  1.47s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.25152626633644104, 'eval_wer': 0.41923076923076924, 'eval_cer': 0.10040400764777019, 'eval_runtime': 406.5659, 'eval_samples_per_second': 23.684, 'eval_steps_per_second': 2.961, 'epoch': 4.16}                                                                                                                                            
{'loss': 0.2348, 'learning_rate': 0.00017918157423971377, 'epoch': 4.16}                                                                                                      
{'loss': 0.2992, 'learning_rate': 0.00017904740608228978, 'epoch': 4.16}                                                                                                      
{'loss': 0.4135, 'learning_rate': 0.00017891323792486582, 'epoch': 4.17}                                                                                                      
{'loss': 0.4328, 'learning_rate': 0.00017877906976744183, 'epoch': 4.17}                                                                                                      
{'loss': 0.4818, 'learning_rate': 0.00017864490161001787, 'epoch': 4.18}                                                                                                      
{'loss': 0.2701, 'learning_rate': 0.0001785107334525939, 'epoch': 4.18}                                                                                                       
{'loss': 0.339, 'learning_rate': 0.00017837656529516994, 'epoch': 4.19}                                                                                                       
{'loss': 0.3828, 'learning_rate': 0.00017824239713774598, 'epoch': 4.19}                                                                                                      
{'loss': 0.3714, 'learning_rate': 0.00017810822898032196, 'epoch': 4.2}                                                                                                       
{'loss': 0.4213, 'learning_rate': 0.000177974060822898, 'epoch': 4.2}                                                                                                         
 42%|█████████████████████████████████████████████████████▎                                                                         | 9600/22860 [13:17:26<5:26:27,  1.48s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.25794878602027893, 'eval_wer': 0.4202429149797571, 'eval_cer': 0.10189707938952958, 'eval_runtime': 405.9222, 'eval_samples_per_second': 23.721, 'eval_steps_per_second': 2.966, 'epoch': 4.2}                                                                                                                                              
{'loss': 0.2292, 'learning_rate': 0.00017783989266547404, 'epoch': 4.2}                                                                                                       
{'loss': 0.307, 'learning_rate': 0.00017770572450805008, 'epoch': 4.21}                                                                                                       
{'loss': 0.4016, 'learning_rate': 0.0001775715563506261, 'epoch': 4.21}                                                                                                       
{'loss': 0.4559, 'learning_rate': 0.00017743738819320213, 'epoch': 4.22}                                                                                                      
{'loss': 0.397, 'learning_rate': 0.00017730322003577817, 'epoch': 4.22}                                                                                                       
{'loss': 0.2401, 'learning_rate': 0.0001771690518783542, 'epoch': 4.23}                                                                                                       
{'loss': 0.2809, 'learning_rate': 0.00017703488372093024, 'epoch': 4.23}                                                                                                      
{'loss': 0.3285, 'learning_rate': 0.00017690071556350623, 'epoch': 4.23}                                                                                                      
{'loss': 0.4658, 'learning_rate': 0.00017676654740608226, 'epoch': 4.24}                                                                                                      
{'loss': 0.4089, 'learning_rate': 0.0001766323792486583, 'epoch': 4.24}                                                                                                       
 42%|█████████████████████████████████████████████████████▉                                                                         | 9700/22860 [13:25:55<5:17:41,  1.45s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8

^CTraceback (most recent call last):██████████████████████████████████████████████████████████████████▍                                    | 875/1204 [05:07<01:45,  3.13it/s]
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 316, in <module>
    trainer.train()
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1501, in train
    return inner_training_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1826, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2089, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2796, in evaluate
    output = eval_loop(
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2974, in evaluation_loop
    loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 3217, in prediction_step
    loss, outputs = self.compute_loss(model, inputs, return_outputs=True)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2540, in compute_loss
    outputs = model(**inputs)
  File "/home/or/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py", line 1693, in forward
    if labels.max() >= self.config.vocab_size:
KeyboardInterrupt
 42%|█████████████████████████████████████████████████████▍                                                                        | 9700/22860 [13:31:03<18:20:22,  5.02s/it]

(base) or@anidjar:~/Desktop/wav2vec2$                                                                                                                                         


