(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-b1d1c4e75dacebb7
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 532.20it/s]
Using custom data configuration default-a5f54108dd45233d
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 927.74it/s]
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-085b05f6c623f3f8.arrow
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0b8f5845c4d29140.arrow
^CTraceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 65, in <module>
    train['audio']
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2343, in __getitem__
    return self._getitem(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2328, in _getitem
    formatted_output = format_table(
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 512, in format_table
    return formatter(pa_table, query_type)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 284, in __call__
    return self.format_column(pa_table)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 319, in format_column
    column = self.python_features_decoder.decode_column(column, pa_table.column_names[0])
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py", line 225, in decode_column
    return self.features.decode_column(column, column_name) if self.features else column
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1811, in decode_column
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1811, in <listcomp>
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/features.py", line 1262, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 145, in decode_example
    array, sampling_rate = self._decode_mp3(file if file else path)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 296, in _decode_mp3
    array, sampling_rate = self._decode_mp3_torchaudio(path_or_file)
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/features/audio.py", line 333, in _decode_mp3_torchaudio
    array = array.mean(axis=0)
  File "/home/or/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py", line 179, in _mean
    ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-b1d1c4e75dacebb7
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 6990.51it/s]
Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2160.90it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 746.98it/s]
Using custom data configuration default-a5f54108dd45233d
Downloading and preparing dataset csv/default to /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...
Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16131.94it/s]
Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3130.08it/s]
Dataset csv downloaded and prepared to /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1107.55it/s]
Casting the dataset:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                       | 2/3 [00:00<00:00, 21.34ba/s]
Casting the dataset:   0%|                                                                                                                              | 0/1 [00:00<?, ?ba/s]
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7f6aa86929d0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22862/22862 [00:00<00:00, 36511.95ex/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9629/9629 [00:00<00:00, 37096.05ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'Ñ': 0, 'ÑŽ': 1, 'f': 2, 'â€“': 3, 'e': 4, 'n': 5, 'h': 6, 'c': 7, 'Ñ': 8, 'l': 9, 'Ñ': 10, 'ÑŠ': 11, 'Ð¹': 12, 'ÑŒ': 13, 'Ñ‰': 14, 'Ð¿': 15, 'Ð¾': 16, 'Â«': 17, 'Ñ‚': 18, 'p': 19, 'â€¦': 20, 'âˆ’': 21, 'â€‘': 22, 'z': 23, 'Ð´': 24, 'Ð±': 25, 'Ñ…': 26, 'Ð²': 27, 'Ð·': 28, 'â€ž': 29, 'Ðµ': 30, 'k': 31, 'Ð½': 32, '(': 33, 'Ð°': 34, 'Ñ‹': 35, "'": 36, 'o': 37, 'Ð»': 38, 'x': 39, 'Ñ„': 40, 'Ðº': 41, 'Ð³': 42, 'Ñ‘': 43, 'Ñ†': 44, 'â€”': 45, ')': 46, 'Ñ‡': 47, 'i': 48, 'a': 49, 'Ð¼': 50, 'Ð¸': 51, 'Ð¶': 52, 'b': 53, 'r': 54, 'Â»': 55, ' ': 56, 'Ñˆ': 57, 't': 58, 'Ñƒ': 59, 'm': 60, 'Ñ€': 61}
Vocab_len: 64
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_ru_26426765.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_26426765.mp3', 'array': array([ 1.07707100e-15,  8.16166796e-14,  8.20455290e-14, ...,
       -2.91893434e-06,  1.16909966e-07,  1.00369357e-06], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_26426765.mp3', 'array': array([ 2.2830750e-14,  7.5313162e-14,  7.7842897e-14, ...,
        9.3801083e-07, -1.4542667e-06, -2.2241443e-06], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                            | 0/5716 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                            | 0/5715 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                    | 1/5715 [00:00<11:52,  8.02ex/s]
  warnings.warn(
#0:   0%|                                                                                                                                    | 1/5716 [00:00<13:14,  7.19ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5716/5716 [06:47<00:00, 14.02ex/s]
#3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5715/5715 [06:50<00:00, 13.93ex/s]
#0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5716/5716 [06:51<00:00, 13.88ex/s]
^CProcess ForkPoolWorker-4:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5645/5715 [06:47<00:03, 21.36ex/s]
Process ForkPoolWorker-5:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5711/5715 [06:50<00:00, 62.58ex/s]
Traceback (most recent call last):
  File "/home/or/Desktop/wav2vec2/main_russian.py", line 165, in <module>
    train = train.map(prepare_dataset, remove_columns=train.column_names, num_proc=4)  # maybe we'll have to reduce to 1
  File "/home/or/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py", line 2685, in map
    transformed_shards[index] = async_result.get()
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 765, in get
    self.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/site-packages/multiprocess/pool.py", line 762, in wait
    self._event.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 581, in wait
    signaled = self._cond.wait(timeout)
  File "/home/or/anaconda3/lib/python3.9/threading.py", line 312, in wait
    waiter.acquire()
KeyboardInterrupt

(base) or@anidjar:~/Desktop/wav2vec2$ clear
(base) or@anidjar:~/Desktop/wav2vec2$ python3 main_russian.py 
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets... -----------------
Using custom data configuration default-b1d1c4e75dacebb7
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 550.43it/s]
Using custom data configuration default-a5f54108dd45233d
Found cached dataset csv (/home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 886.56it/s]
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-b1d1c4e75dacebb7/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-085b05f6c623f3f8.arrow
Loading cached processed dataset at /home/or/.cache/huggingface/datasets/csv/default-a5f54108dd45233d/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0b8f5845c4d29140.arrow
----------------- Loading Datasets complete. -----------------


----------------- Removing special characters... -----------------
Parameter 'function'=<function remove_special_characters at 0x7f717a37cee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22862/22862 [00:00<00:00, 35592.12ex/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9629/9629 [00:00<00:00, 37034.65ex/s]
----------------- Removing special characters complete. -----------------


----------------- Extracting all characters... -----------------
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
  0%|                                                                                                                                                   | 0/1 [00:00<?, ?ba/s]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'Ð²': 0, 'a': 1, 'Ð¶': 2, 'p': 3, 'Ðº': 4, 'n': 5, 'Ð½': 6, 't': 7, 'Ñ‚': 8, 'Ñ': 9, 'z': 10, 'h': 11, 'Ð¾': 12, 'Ð¼': 13, "'": 14, 'Â»': 15, 'Ñ‡': 16, 'Ñ': 17, 'Ñƒ': 18, 'Ð¸': 19, 'Ð°': 20, 'Ñ': 21, 'Ð¹': 22, 'k': 23, 'x': 24, 'ÑŠ': 25, 'Ñ†': 26, 'â€‘': 27, 'Ðµ': 28, 'â€¦': 29, ' ': 30, '(': 31, 'ÑŒ': 32, 'Ñˆ': 33, 'â€“': 34, 'âˆ’': 35, 'm': 36, 'o': 37, 'â€”': 38, 'Ñ‰': 39, 'Ð´': 40, 'e': 41, 'Ð¿': 42, 'Ñ€': 43, 'Ð·': 44, 'Ñ…': 45, 'c': 46, 'Ð±': 47, 'b': 48, 'Â«': 49, 'Ñ‹': 50, 'Ñ‘': 51, 'Ð³': 52, 'Ñ„': 53, 'i': 54, 'Ð»': 55, 'l': 56, 'r': 57, 'â€ž': 58, 'f': 59, ')': 60, 'ÑŽ': 61}
Vocab_len: 64
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


sample path: common_voice_ru_26426765.mp3

Sanity Check sampling rate is 48khz: {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_26426765.mp3', 'array': array([ 1.07707100e-15,  8.16166796e-14,  8.20455290e-14, ...,
       -2.91893434e-06,  1.16909966e-07,  1.00369357e-06], dtype=float32), 'sampling_rate': 48000}

----------------- Resampling to 16khz... -----------------
Making sure the sampling rate changed to 16khz {'path': '/home/or/Desktop/russian_dataset/augmentations/train/common_voice_ru_26426765.mp3', 'array': array([ 2.2830750e-14,  7.5313162e-14,  7.7842897e-14, ...,
        9.3801083e-07, -1.4542667e-06, -2.2241443e-06], dtype=float32), 'sampling_rate': 16000}
----------------- Resampling complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                           | 0/11431 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0:   0%|                                                                                                                                   | 2/11431 [00:00<14:01, 13.58ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11431/11431 [11:20<00:00, 16.80ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11431/11431 [11:22<00:00, 16.75ex/s]
#0:   0%|                                                                                                                                            | 0/4815 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4815/4815 [04:59<00:00, 16.05ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4814/4814 [05:00<00:00, 16.02ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 4811/4814 [05:00<00:00, 23.17ex/s]

----------------- Preparing datasets complete. -----------------


----------------- saving datasets... -----------------
----------------- saving datasets complete. -----------


----------------- Loading Metrics... -----------------
/home/or/Desktop/wav2vec2/main_russian.py:246: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.weight', 'project_hid.weight', 'quantizer.weight_proj.bias', 'project_q.bias', 'project_q.weight', 'project_hid.bias', 'quantizer.codevectors']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 22862
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 16
  Gradient Accumulation steps = 2
  Total optimization steps = 14290
  Number of trainable parameters = 311294144
  0%|                                                                                                                                               | 0/14290 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 12.9956, 'learning_rate': 5.399999999999999e-06, 'epoch': 0.01}                                                                                                      
{'loss': 13.21, 'learning_rate': 1.14e-05, 'epoch': 0.01}                                                                                                                     
{'loss': 14.2027, 'learning_rate': 1.74e-05, 'epoch': 0.02}                                                                                                                   
{'loss': 16.4228, 'learning_rate': 2.28e-05, 'epoch': 0.03}                                                                                                                   
{'loss': 24.1598, 'learning_rate': 2.7599999999999997e-05, 'epoch': 0.03}                                                                                                     
{'loss': 11.9461, 'learning_rate': 3.36e-05, 'epoch': 0.04}                                                                                                                   
{'loss': 10.0068, 'learning_rate': 3.96e-05, 'epoch': 0.05}                                                                                                                   
{'loss': 8.1272, 'learning_rate': 4.56e-05, 'epoch': 0.06}                                                                                                                    
{'loss': 6.845, 'learning_rate': 5.1599999999999994e-05, 'epoch': 0.06}                                                                                                       
{'loss': 7.1165, 'learning_rate': 5.76e-05, 'epoch': 0.07}                                                                                                                    
  1%|â–‰                                                                                                                                  | 100/14290 [01:46<2:13:36,  1.77it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 4.628498077392578, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 396.2521, 'eval_samples_per_second': 24.3, 'eval_steps_per_second': 3.038, 'epoch': 0.07}                                                                                                                                                  
{'loss': 4.4418, 'learning_rate': 6.359999999999999e-05, 'epoch': 0.08}                                                                                                       
{'loss': 3.9354, 'learning_rate': 6.96e-05, 'epoch': 0.08}                                                                                                                    
{'loss': 3.6802, 'learning_rate': 7.56e-05, 'epoch': 0.09}                                                                                                                    
{'loss': 3.6005, 'learning_rate': 8.16e-05, 'epoch': 0.1}                                                                                                                     
{'loss': 3.6328, 'learning_rate': 8.759999999999999e-05, 'epoch': 0.1}                                                                                                        
{'loss': 3.4196, 'learning_rate': 9.36e-05, 'epoch': 0.11}                                                                                                                    
{'loss': 3.2844, 'learning_rate': 9.96e-05, 'epoch': 0.12}                                                                                                                    
{'loss': 3.2785, 'learning_rate': 0.00010559999999999998, 'epoch': 0.13}                                                                                                      
{'loss': 3.2473, 'learning_rate': 0.00011159999999999999, 'epoch': 0.13}                                                                                                      
{'loss': 3.322, 'learning_rate': 0.0001176, 'epoch': 0.14}                                                                                                                    
  1%|â–ˆâ–Š                                                                                                                                 | 200/14290 [10:04<2:11:54,  1.78it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.323927164077759, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 395.2202, 'eval_samples_per_second': 24.364, 'eval_steps_per_second': 3.046, 'epoch': 0.14}                                                                                                                                                
{'loss': 3.3212, 'learning_rate': 0.0001236, 'epoch': 0.15}                                                                                                                   
{'loss': 3.1962, 'learning_rate': 0.00012959999999999998, 'epoch': 0.15}                                                                                                      
{'loss': 3.1902, 'learning_rate': 0.0001356, 'epoch': 0.16}                                                                                                                   
{'loss': 3.2078, 'learning_rate': 0.00014159999999999997, 'epoch': 0.17}                                                                                                      
{'loss': 3.3034, 'learning_rate': 0.00014759999999999998, 'epoch': 0.17}                                                                                                      
{'loss': 3.3574, 'learning_rate': 0.0001536, 'epoch': 0.18}                                                                                                                   
{'loss': 3.2027, 'learning_rate': 0.0001596, 'epoch': 0.19}                                                                                                                   
{'loss': 3.1631, 'learning_rate': 0.0001656, 'epoch': 0.2}                                                                                                                    
{'loss': 3.1581, 'learning_rate': 0.00017159999999999997, 'epoch': 0.2}                                                                                                       
{'loss': 3.2886, 'learning_rate': 0.00017759999999999998, 'epoch': 0.21}                                                                                                      
  2%|â–ˆâ–ˆâ–Š                                                                                                                                | 300/14290 [18:22<2:09:53,  1.80it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.308337450027466, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 394.6017, 'eval_samples_per_second': 24.402, 'eval_steps_per_second': 3.051, 'epoch': 0.21}                                                                                                                                                
{'loss': 3.3236, 'learning_rate': 0.0001836, 'epoch': 0.22}                                                                                                                   
{'loss': 3.1927, 'learning_rate': 0.00018959999999999997, 'epoch': 0.22}                                                                                                      
{'loss': 3.158, 'learning_rate': 0.00019559999999999998, 'epoch': 0.23}                                                                                                       
{'loss': 3.1826, 'learning_rate': 0.0002016, 'epoch': 0.24}                                                                                                                   
{'loss': 3.2643, 'learning_rate': 0.00020759999999999998, 'epoch': 0.24}                                                                                                      
{'loss': 3.3196, 'learning_rate': 0.00021359999999999996, 'epoch': 0.25}                                                                                                      
{'loss': 3.1823, 'learning_rate': 0.00021959999999999997, 'epoch': 0.26}                                                                                                      
{'loss': 3.1989, 'learning_rate': 0.00022559999999999998, 'epoch': 0.27}                                                                                                      
{'loss': 3.1659, 'learning_rate': 0.0002316, 'epoch': 0.27}                                                                                                                   
{'loss': 3.2464, 'learning_rate': 0.0002376, 'epoch': 0.28}                                                                                                                   
  3%|â–ˆâ–ˆâ–ˆâ–‹                                                                                                                               | 400/14290 [26:38<2:09:07,  1.79it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.28967022895813, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 396.8257, 'eval_samples_per_second': 24.265, 'eval_steps_per_second': 3.034, 'epoch': 0.28}                                                                                                                                                 
{'loss': 3.3052, 'learning_rate': 0.00024359999999999999, 'epoch': 0.29}                                                                                                      
{'loss': 3.1787, 'learning_rate': 0.00024959999999999994, 'epoch': 0.29}                                                                                                      
{'loss': 3.1492, 'learning_rate': 0.0002556, 'epoch': 0.3}                                                                                                                    
{'loss': 3.1648, 'learning_rate': 0.00026159999999999996, 'epoch': 0.31}                                                                                                      
{'loss': 3.2239, 'learning_rate': 0.0002676, 'epoch': 0.31}                                                                                                                   
{'loss': 3.3454, 'learning_rate': 0.0002736, 'epoch': 0.32}                                                                                                                   
{'loss': 3.182, 'learning_rate': 0.00027959999999999997, 'epoch': 0.33}                                                                                                       
{'loss': 3.1579, 'learning_rate': 0.00028559999999999995, 'epoch': 0.34}                                                                                                      
{'loss': 3.2044, 'learning_rate': 0.0002916, 'epoch': 0.34}                                                                                                                   
{'loss': 3.2449, 'learning_rate': 0.00029759999999999997, 'epoch': 0.35}                                                                                                      
  3%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                              | 500/14290 [34:58<2:07:23,  1.80it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.302616834640503, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 395.075, 'eval_samples_per_second': 24.373, 'eval_steps_per_second': 3.048, 'epoch': 0.35}                                                                                                                                                 
{'loss': 3.5251, 'learning_rate': 0.0002998694706308919, 'epoch': 0.36}                                                                                                       
{'loss': 3.1467, 'learning_rate': 0.0002996519216823785, 'epoch': 0.36}                                                                                                       
{'loss': 3.1441, 'learning_rate': 0.0002994343727338651, 'epoch': 0.37}                                                                                                       
{'loss': 3.2073, 'learning_rate': 0.00029921682378535166, 'epoch': 0.38}                                                                                                      
{'loss': 3.2499, 'learning_rate': 0.0002989992748368383, 'epoch': 0.38}                                                                                                       
{'loss': 3.3467, 'learning_rate': 0.00029878172588832484, 'epoch': 0.39}                                                                                                      
{'loss': 3.1766, 'learning_rate': 0.0002985641769398114, 'epoch': 0.4}                                                                                                        
{'loss': 3.1742, 'learning_rate': 0.000298346627991298, 'epoch': 0.41}                                                                                                        
{'loss': 3.1475, 'learning_rate': 0.0002981290790427846, 'epoch': 0.41}                                                                                                       
{'loss': 3.2113, 'learning_rate': 0.0002979115300942712, 'epoch': 0.42}                                                                                                       
  4%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                             | 600/14290 [43:16<2:07:33,  1.79it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.345482587814331, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 389.6987, 'eval_samples_per_second': 24.709, 'eval_steps_per_second': 3.09, 'epoch': 0.42}                                                                                                                                                 
{'loss': 3.4262, 'learning_rate': 0.00029769398114575776, 'epoch': 0.43}                                                                                                      
{'loss': 3.1908, 'learning_rate': 0.0002974764321972444, 'epoch': 0.43}                                                                                                       
{'loss': 3.1454, 'learning_rate': 0.00029725888324873094, 'epoch': 0.44}                                                                                                      
{'loss': 3.1263, 'learning_rate': 0.0002970413343002175, 'epoch': 0.45}                                                                                                       
{'loss': 3.1863, 'learning_rate': 0.0002968237853517041, 'epoch': 0.45}                                                                                                       
{'loss': 3.3711, 'learning_rate': 0.0002966062364031907, 'epoch': 0.46}                                                                                                       
{'loss': 3.1804, 'learning_rate': 0.0002963886874546773, 'epoch': 0.47}                                                                                                       
{'loss': 3.1536, 'learning_rate': 0.00029617113850616386, 'epoch': 0.48}                                                                                                      
{'loss': 3.1359, 'learning_rate': 0.0002959535895576504, 'epoch': 0.48}                                                                                                       
{'loss': 3.1783, 'learning_rate': 0.00029573604060913704, 'epoch': 0.49}                                                                                                      
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                            | 700/14290 [51:30<2:07:00,  1.78it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.3291783332824707, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 392.074, 'eval_samples_per_second': 24.559, 'eval_steps_per_second': 3.071, 'epoch': 0.49}                                                                                                                                                
{'loss': 3.421, 'learning_rate': 0.0002955184916606236, 'epoch': 0.5}                                                                                                         
{'loss': 3.2235, 'learning_rate': 0.0002953009427121102, 'epoch': 0.5}                                                                                                        
{'loss': 3.1171, 'learning_rate': 0.0002950833937635968, 'epoch': 0.51}                                                                                                       
{'loss': 3.121, 'learning_rate': 0.00029486584481508334, 'epoch': 0.52}                                                                                                       
{'loss': 3.156, 'learning_rate': 0.00029464829586656996, 'epoch': 0.52}                                                                                                       
{'loss': 3.3507, 'learning_rate': 0.0002944307469180565, 'epoch': 0.53}                                                                                                       
{'loss': 3.1771, 'learning_rate': 0.00029421319796954314, 'epoch': 0.54}                                                                                                      
{'loss': 3.1138, 'learning_rate': 0.0002939956490210297, 'epoch': 0.55}                                                                                                       
{'loss': 3.1139, 'learning_rate': 0.00029377810007251626, 'epoch': 0.55}                                                                                                      
{'loss': 3.2264, 'learning_rate': 0.0002935605511240029, 'epoch': 0.56}                                                                                                       
  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                           | 800/14290 [59:43<2:02:30,  1.84it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.2629711627960205, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 390.691, 'eval_samples_per_second': 24.646, 'eval_steps_per_second': 3.082, 'epoch': 0.56}                                                                                                                                                
{'loss': 3.2946, 'learning_rate': 0.00029334300217548944, 'epoch': 0.57}                                                                                                      
{'loss': 3.1533, 'learning_rate': 0.00029312545322697606, 'epoch': 0.57}                                                                                                      
{'loss': 3.1291, 'learning_rate': 0.0002929079042784626, 'epoch': 0.58}                                                                                                       
{'loss': 3.1176, 'learning_rate': 0.0002926903553299492, 'epoch': 0.59}                                                                                                       
{'loss': 3.1566, 'learning_rate': 0.0002924728063814358, 'epoch': 0.59}                                                                                                       
{'loss': 3.3678, 'learning_rate': 0.00029225525743292236, 'epoch': 0.6}                                                                                                       
{'loss': 3.1623, 'learning_rate': 0.000292037708484409, 'epoch': 0.61}                                                                                                        
{'loss': 3.1323, 'learning_rate': 0.00029182015953589554, 'epoch': 0.62}                                                                                                      
{'loss': 3.1228, 'learning_rate': 0.00029160261058738216, 'epoch': 0.62}                                                                                                      
{'loss': 3.1282, 'learning_rate': 0.0002913850616388687, 'epoch': 0.63}                                                                                                       
  6%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                         | 900/14290 [1:07:56<2:06:42,  1.76it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.227684497833252, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 390.5797, 'eval_samples_per_second': 24.653, 'eval_steps_per_second': 3.083, 'epoch': 0.63}                                                                                                                                                
{'loss': 3.2742, 'learning_rate': 0.0002911675126903553, 'epoch': 0.64}                                                                                                       
{'loss': 3.1422, 'learning_rate': 0.0002909499637418419, 'epoch': 0.64}                                                                                                       
{'loss': 3.1316, 'learning_rate': 0.00029073241479332846, 'epoch': 0.65}                                                                                                      
{'loss': 3.1086, 'learning_rate': 0.0002905148658448151, 'epoch': 0.66}                                                                                                       
{'loss': 3.1185, 'learning_rate': 0.00029029731689630164, 'epoch': 0.66}                                                                                                      
{'loss': 3.2718, 'learning_rate': 0.0002900797679477882, 'epoch': 0.67}                                                                                                       
{'loss': 3.1377, 'learning_rate': 0.0002898622189992748, 'epoch': 0.68}                                                                                                       
{'loss': 3.0902, 'learning_rate': 0.0002896446700507614, 'epoch': 0.69}                                                                                                       
{'loss': 3.1207, 'learning_rate': 0.000289427121102248, 'epoch': 0.69}                                                                                                        
{'loss': 3.0958, 'learning_rate': 0.00028920957215373456, 'epoch': 0.7}                                                                                                       
  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                       | 1000/14290 [1:16:10<2:02:58,  1.80it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.218885898590088, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 392.4677, 'eval_samples_per_second': 24.535, 'eval_steps_per_second': 3.068, 'epoch': 0.7}                                                                                                                                                 
{'loss': 3.2321, 'learning_rate': 0.0002889920232052211, 'epoch': 0.71}                                                                                                       
{'loss': 3.1236, 'learning_rate': 0.00028877447425670774, 'epoch': 0.71}                                                                                                      
{'loss': 3.1062, 'learning_rate': 0.0002885569253081943, 'epoch': 0.72}                                                                                                       
{'loss': 3.0924, 'learning_rate': 0.0002883393763596809, 'epoch': 0.73}                                                                                                       
{'loss': 3.074, 'learning_rate': 0.0002881218274111675, 'epoch': 0.73}                                                                                                        
{'loss': 3.1254, 'learning_rate': 0.00028790427846265404, 'epoch': 0.74}                                                                                                      
{'loss': 3.0915, 'learning_rate': 0.00028768672951414066, 'epoch': 0.75}                                                                                                      
{'loss': 3.0882, 'learning_rate': 0.0002874691805656272, 'epoch': 0.76}                                                                                                       
{'loss': 3.096, 'learning_rate': 0.00028725163161711384, 'epoch': 0.76}                                                                                                       
{'loss': 3.0741, 'learning_rate': 0.0002870340826686004, 'epoch': 0.77}                                                                                                       
  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                      | 1100/14290 [1:24:25<2:01:28,  1.81it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.120669364929199, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 389.0293, 'eval_samples_per_second': 24.751, 'eval_steps_per_second': 3.095, 'epoch': 0.77}                                                                                                                                                
{'loss': 3.1202, 'learning_rate': 0.000286816533720087, 'epoch': 0.78}                                                                                                        
{'loss': 3.081, 'learning_rate': 0.0002865989847715736, 'epoch': 0.78}                                                                                                        
{'loss': 3.0906, 'learning_rate': 0.00028638143582306014, 'epoch': 0.79}                                                                                                      
{'loss': 3.0861, 'learning_rate': 0.00028616388687454676, 'epoch': 0.8}                                                                                                       
{'loss': 3.1033, 'learning_rate': 0.0002859463379260333, 'epoch': 0.8}                                                                                                        
{'loss': 3.1234, 'learning_rate': 0.00028572878897751994, 'epoch': 0.81}                                                                                                      
{'loss': 3.0975, 'learning_rate': 0.0002855112400290065, 'epoch': 0.82}                                                                                                       
{'loss': 3.1013, 'learning_rate': 0.00028529369108049306, 'epoch': 0.83}                                                                                                      
{'loss': 3.0677, 'learning_rate': 0.0002850761421319797, 'epoch': 0.83}                                                                                                       
{'loss': 3.0858, 'learning_rate': 0.00028485859318346624, 'epoch': 0.84}                                                                                                      
  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                     | 1200/14290 [1:32:35<2:03:53,  1.76it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 3.0783140659332275, 'eval_wer': 0.9746130030959752, 'eval_cer': 0.9862718471526919, 'eval_runtime': 390.1732, 'eval_samples_per_second': 24.679, 'eval_steps_per_second': 3.086, 'epoch': 0.84}                                                                                                                                               
{'loss': 3.0865, 'learning_rate': 0.00028464104423495286, 'epoch': 0.85}                                                                                                      
{'loss': 3.0542, 'learning_rate': 0.0002844234952864394, 'epoch': 0.85}                                                                                                       
{'loss': 3.0286, 'learning_rate': 0.000284205946337926, 'epoch': 0.86}                                                                                                        
{'loss': 3.0213, 'learning_rate': 0.0002839883973894126, 'epoch': 0.87}                                                                                                       
{'loss': 2.9681, 'learning_rate': 0.00028377084844089916, 'epoch': 0.87}                                                                                                      
{'loss': 3.0296, 'learning_rate': 0.0002835532994923858, 'epoch': 0.88}                                                                                                       
{'loss': 2.9364, 'learning_rate': 0.00028333575054387234, 'epoch': 0.89}                                                                                                      
{'loss': 2.8274, 'learning_rate': 0.0002831182015953589, 'epoch': 0.9}                                                                                                        
{'loss': 2.7701, 'learning_rate': 0.0002829006526468455, 'epoch': 0.9}                                                                                                        
{'loss': 2.6925, 'learning_rate': 0.0002826831036983321, 'epoch': 0.91}                                                                                                       
  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                    | 1300/14290 [1:40:49<1:58:34,  1.83it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 2.636476755142212, 'eval_wer': 0.9768635389378424, 'eval_cer': 0.9016582554706554, 'eval_runtime': 389.9847, 'eval_samples_per_second': 24.691, 'eval_steps_per_second': 3.087, 'epoch': 0.91}                                                                                                                                                
{'loss': 2.5755, 'learning_rate': 0.0002824655547498187, 'epoch': 0.92}                                                                                                       
{'loss': 2.4069, 'learning_rate': 0.00028224800580130526, 'epoch': 0.92}                                                                                                      
{'loss': 2.2318, 'learning_rate': 0.0002820304568527919, 'epoch': 0.93}                                                                                                       
{'loss': 2.0758, 'learning_rate': 0.00028181290790427844, 'epoch': 0.94}                                                                                                      
{'loss': 1.9954, 'learning_rate': 0.000281595358955765, 'epoch': 0.94}                                                                                                        
{'loss': 1.9103, 'learning_rate': 0.0002813778100072516, 'epoch': 0.95}                                                                                                       
{'loss': 1.791, 'learning_rate': 0.0002811602610587382, 'epoch': 0.96}                                                                                                        
{'loss': 1.7015, 'learning_rate': 0.0002809427121102248, 'epoch': 0.97}                                                                                                       
{'loss': 1.6307, 'learning_rate': 0.00028072516316171136, 'epoch': 0.97}                                                                                                      
{'loss': 1.5932, 'learning_rate': 0.0002805076142131979, 'epoch': 0.98}                                                                                                       
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                   | 1400/14290 [1:49:02<2:04:45,  1.72it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 1.4264476299285889, 'eval_wer': 0.9797809002143367, 'eval_cer': 0.4647422255551727, 'eval_runtime': 391.7819, 'eval_samples_per_second': 24.577, 'eval_steps_per_second': 3.073, 'epoch': 0.98}                                                                                                                                               
{'loss': 1.5693, 'learning_rate': 0.00028029006526468454, 'epoch': 0.99}                                                                                                      
{'loss': 1.4954, 'learning_rate': 0.0002800725163161711, 'epoch': 0.99}                                                                                                       
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                   | 1428/14290 [1:56:03<2:21:44,  1.51it/s]Saving model checkpoint to ./russian_augmented/checkpoint-1428
Configuration saved in ./russian_augmented/checkpoint-1428/config.json
Model weights saved in ./russian_augmented/checkpoint-1428/pytorch_model.bin
Feature extractor saved in ./russian_augmented/checkpoint-1428/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 1.4416, 'learning_rate': 0.0002798549673676577, 'epoch': 1.0}                                                                                                        
{'loss': 1.4602, 'learning_rate': 0.0002796374184191443, 'epoch': 1.01}                                                                                                       
{'loss': 1.4105, 'learning_rate': 0.00027941986947063084, 'epoch': 1.01}                                                                                                      
{'loss': 1.3417, 'learning_rate': 0.00027920232052211746, 'epoch': 1.02}                                                                                                      
{'loss': 1.3472, 'learning_rate': 0.000278984771573604, 'epoch': 1.03}                                                                                                        
{'loss': 1.3157, 'learning_rate': 0.00027876722262509064, 'epoch': 1.04}                                                                                                      
{'loss': 1.2877, 'learning_rate': 0.0002785496736765772, 'epoch': 1.04}                                                                                                       
{'loss': 1.2764, 'learning_rate': 0.00027833212472806376, 'epoch': 1.05}                                                                                                      
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                  | 1500/14290 [1:57:26<3:58:48,  1.12s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 1.0288697481155396, 'eval_wer': 0.9660395332221957, 'eval_cer': 0.355994581703453, 'eval_runtime': 395.8137, 'eval_samples_per_second': 24.327, 'eval_steps_per_second': 3.042, 'epoch': 1.05}                                                                                                                                                
{'loss': 1.28, 'learning_rate': 0.0002781145757795504, 'epoch': 1.06}                                                                                                         
{'loss': 1.2643, 'learning_rate': 0.00027789702683103694, 'epoch': 1.06}                                                                                                      
{'loss': 1.2534, 'learning_rate': 0.00027767947788252356, 'epoch': 1.07}                                                                                                      
{'loss': 1.1966, 'learning_rate': 0.0002774619289340101, 'epoch': 1.08}                                                                                                       
{'loss': 1.1915, 'learning_rate': 0.0002772443799854967, 'epoch': 1.08}                                                                                                       
{'loss': 1.1324, 'learning_rate': 0.0002770268310369833, 'epoch': 1.09}                                                                                                       
{'loss': 1.1865, 'learning_rate': 0.00027680928208846986, 'epoch': 1.1}                                                                                                       
{'loss': 1.1726, 'learning_rate': 0.0002765917331399565, 'epoch': 1.11}                                                                                                       
{'loss': 1.1249, 'learning_rate': 0.00027637418419144304, 'epoch': 1.11}                                                                                                      
{'loss': 1.1259, 'learning_rate': 0.00027615663524292966, 'epoch': 1.12}                                                                                                      
 11%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                 | 1600/14290 [2:05:46<4:03:36,  1.15s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.8923030495643616, 'eval_wer': 0.9398904501071683, 'eval_cer': 0.30547504678516657, 'eval_runtime': 390.6344, 'eval_samples_per_second': 24.65, 'eval_steps_per_second': 3.082, 'epoch': 1.12}                                                                                                                                               
{'loss': 1.0687, 'learning_rate': 0.0002759390862944162, 'epoch': 1.13}                                                                                                       
{'loss': 1.1584, 'learning_rate': 0.0002757215373459028, 'epoch': 1.13}                                                                                                       
{'loss': 1.2261, 'learning_rate': 0.0002755039883973894, 'epoch': 1.14}                                                                                                       
{'loss': 1.099, 'learning_rate': 0.00027528643944887596, 'epoch': 1.15}                                                                                                       
{'loss': 1.0368, 'learning_rate': 0.0002750688905003626, 'epoch': 1.15}                                                                                                       
{'loss': 1.0369, 'learning_rate': 0.00027485134155184914, 'epoch': 1.16}                                                                                                      
{'loss': 1.0237, 'learning_rate': 0.0002746337926033357, 'epoch': 1.17}                                                                                                       
{'loss': 1.1618, 'learning_rate': 0.0002744162436548223, 'epoch': 1.18}                                                                                                       
{'loss': 1.0191, 'learning_rate': 0.0002741986947063089, 'epoch': 1.18}                                                                                                       
{'loss': 1.0294, 'learning_rate': 0.0002739811457577955, 'epoch': 1.19}                                                                                                       
 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                | 1700/14290 [2:13:59<3:52:34,  1.11s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.7913210391998291, 'eval_wer': 0.8982733984281972, 'eval_cer': 0.2791621908294318, 'eval_runtime': 390.1082, 'eval_samples_per_second': 24.683, 'eval_steps_per_second': 3.086, 'epoch': 1.19}                                                                                                                                               
{'loss': 1.0074, 'learning_rate': 0.00027376359680928206, 'epoch': 1.2}                                                                                                       
{'loss': 0.9879, 'learning_rate': 0.0002735460478607686, 'epoch': 1.2}                                                                                                        
{'loss': 1.0964, 'learning_rate': 0.00027332849891225524, 'epoch': 1.21}                                                                                                      
{'loss': 0.9652, 'learning_rate': 0.0002731109499637418, 'epoch': 1.22}                                                                                                       
{'loss': 0.9653, 'learning_rate': 0.0002728934010152284, 'epoch': 1.22}                                                                                                       
{'loss': 0.9869, 'learning_rate': 0.000272675852066715, 'epoch': 1.23}                                                                                                        
{'loss': 0.9936, 'learning_rate': 0.00027245830311820155, 'epoch': 1.24}                                                                                                      
{'loss': 1.0163, 'learning_rate': 0.00027224075416968816, 'epoch': 1.25}                                                                                                      
{'loss': 0.9016, 'learning_rate': 0.0002720232052211747, 'epoch': 1.25}                                                                                                       
{'loss': 0.9304, 'learning_rate': 0.00027180565627266134, 'epoch': 1.26}                                                                                                      
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                                | 1800/14290 [2:22:12<3:59:00,  1.15s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.7301341891288757, 'eval_wer': 0.8689211717075495, 'eval_cer': 0.25350804299506136, 'eval_runtime': 395.1795, 'eval_samples_per_second': 24.366, 'eval_steps_per_second': 3.047, 'epoch': 1.26}                                                                                                                                              
{'loss': 0.9199, 'learning_rate': 0.0002715881073241479, 'epoch': 1.27}                                                                                                       
{'loss': 0.948, 'learning_rate': 0.0002713705583756345, 'epoch': 1.27}                                                                                                        
{'loss': 1.0055, 'learning_rate': 0.0002711530094271211, 'epoch': 1.28}                                                                                                       
{'loss': 0.8863, 'learning_rate': 0.00027093546047860764, 'epoch': 1.29}                                                                                                      
{'loss': 0.8693, 'learning_rate': 0.00027071791153009426, 'epoch': 1.29}                                                                                                      
{'loss': 0.9394, 'learning_rate': 0.0002705003625815808, 'epoch': 1.3}                                                                                                        
{'loss': 1.0003, 'learning_rate': 0.00027028281363306744, 'epoch': 1.31}                                                                                                      
{'loss': 0.9109, 'learning_rate': 0.000270065264684554, 'epoch': 1.32}                                                                                                        
{'loss': 0.8669, 'learning_rate': 0.00026984771573604056, 'epoch': 1.32}                                                                                                      
{'loss': 0.8688, 'learning_rate': 0.0002696301667875272, 'epoch': 1.33}                                                                                                       
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                               | 1900/14290 [2:30:30<3:48:39,  1.11s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.6591372489929199, 'eval_wer': 0.8419147416051441, 'eval_cer': 0.23296817257477181, 'eval_runtime': 391.669, 'eval_samples_per_second': 24.585, 'eval_steps_per_second': 3.074, 'epoch': 1.33}                                                                                                                                               
{'loss': 0.8823, 'learning_rate': 0.00026941261783901374, 'epoch': 1.34}                                                                                                      
{'loss': 0.9744, 'learning_rate': 0.00026919506889050036, 'epoch': 1.34}                                                                                                      
{'loss': 0.9677, 'learning_rate': 0.0002689775199419869, 'epoch': 1.35}                                                                                                       
{'loss': 0.8167, 'learning_rate': 0.0002687599709934735, 'epoch': 1.36}                                                                                                       
{'loss': 0.8224, 'learning_rate': 0.0002685424220449601, 'epoch': 1.36}                                                                                                       
{'loss': 0.857, 'learning_rate': 0.00026832487309644666, 'epoch': 1.37}                                                                                                       
{'loss': 0.9132, 'learning_rate': 0.0002681073241479333, 'epoch': 1.38}                                                                                                       
{'loss': 0.9221, 'learning_rate': 0.00026788977519941984, 'epoch': 1.39}                                                                                                      
{'loss': 0.7778, 'learning_rate': 0.0002676722262509064, 'epoch': 1.39}                                                                                                       
{'loss': 0.8146, 'learning_rate': 0.000267454677302393, 'epoch': 1.4}                                                                                                         
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                              | 2000/14290 [2:38:43<3:48:48,  1.12s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.6396724581718445, 'eval_wer': 0.8237556561085972, 'eval_cer': 0.22388982346622346, 'eval_runtime': 392.7205, 'eval_samples_per_second': 24.519, 'eval_steps_per_second': 3.066, 'epoch': 1.4}                                                                                                                                               
{'loss': 0.8722, 'learning_rate': 0.0002672371283538796, 'epoch': 1.41}                                                                                                       
{'loss': 0.8565, 'learning_rate': 0.0002670195794053662, 'epoch': 1.41}                                                                                                       
{'loss': 0.9125, 'learning_rate': 0.00026680203045685276, 'epoch': 1.42}                                                                                                      
{'loss': 0.7552, 'learning_rate': 0.0002665844815083394, 'epoch': 1.43}                                                                                                       
{'loss': 0.8171, 'learning_rate': 0.00026636693255982594, 'epoch': 1.43}                                                                                                      
{'loss': 0.8552, 'learning_rate': 0.0002661493836113125, 'epoch': 1.44}                                                                                                       
{'loss': 0.8684, 'learning_rate': 0.0002659318346627991, 'epoch': 1.45}                                                                                                       
{'loss': 0.9103, 'learning_rate': 0.0002657142857142857, 'epoch': 1.46}                                                                                                       
{'loss': 0.7437, 'learning_rate': 0.0002654967367657723, 'epoch': 1.46}                                                                                                       
{'loss': 0.7545, 'learning_rate': 0.00026527918781725886, 'epoch': 1.47}                                                                                                      
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                             | 2100/14290 [2:46:59<3:43:13,  1.10s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5893750786781311, 'eval_wer': 0.7844486782567278, 'eval_cer': 0.2060979482086517, 'eval_runtime': 395.5822, 'eval_samples_per_second': 24.341, 'eval_steps_per_second': 3.044, 'epoch': 1.47}                                                                                                                                               
{'loss': 0.7649, 'learning_rate': 0.0002650616388687454, 'epoch': 1.48}                                                                                                       
{'loss': 0.843, 'learning_rate': 0.00026484408992023204, 'epoch': 1.48}                                                                                                       
{'loss': 0.8264, 'learning_rate': 0.0002646265409717186, 'epoch': 1.49}                                                                                                       
{'loss': 0.7247, 'learning_rate': 0.0002644089920232052, 'epoch': 1.5}                                                                                                        
{'loss': 0.742, 'learning_rate': 0.0002641914430746918, 'epoch': 1.5}                                                                                                         
{'loss': 0.7856, 'learning_rate': 0.00026397389412617834, 'epoch': 1.51}                                                                                                      
{'loss': 0.8223, 'learning_rate': 0.00026375634517766496, 'epoch': 1.52}                                                                                                      
{'loss': 0.7803, 'learning_rate': 0.0002635387962291515, 'epoch': 1.53}                                                                                                       
{'loss': 0.7, 'learning_rate': 0.00026332124728063814, 'epoch': 1.53}                                                                                                         
{'loss': 0.7736, 'learning_rate': 0.0002631036983321247, 'epoch': 1.54}                                                                                                       
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                            | 2200/14290 [2:55:17<3:44:33,  1.11s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5575834512710571, 'eval_wer': 0.76162181471779, 'eval_cer': 0.19472087665605978, 'eval_runtime': 396.1291, 'eval_samples_per_second': 24.308, 'eval_steps_per_second': 3.039, 'epoch': 1.54}                                                                                                                                                
{'loss': 0.7921, 'learning_rate': 0.00026288614938361127, 'epoch': 1.55}                                                                                                      
{'loss': 0.8051, 'learning_rate': 0.0002626686004350979, 'epoch': 1.55}                                                                                                       
{'loss': 0.8425, 'learning_rate': 0.00026245105148658444, 'epoch': 1.56}                                                                                                      
{'loss': 0.676, 'learning_rate': 0.00026223350253807106, 'epoch': 1.57}                                                                                                       
{'loss': 0.7147, 'learning_rate': 0.0002620159535895576, 'epoch': 1.57}                                                                                                       
{'loss': 0.7645, 'learning_rate': 0.00026179840464104424, 'epoch': 1.58}                                                                                                      
{'loss': 0.8, 'learning_rate': 0.0002615808556925308, 'epoch': 1.59}                                                                                                          
{'loss': 0.8248, 'learning_rate': 0.00026136330674401736, 'epoch': 1.6}                                                                                                       
{'loss': 0.703, 'learning_rate': 0.000261145757795504, 'epoch': 1.6}                                                                                                          
{'loss': 0.676, 'learning_rate': 0.00026092820884699054, 'epoch': 1.61}                                                                                                       
 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                           | 2300/14290 [3:03:37<3:45:24,  1.13s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5318080186843872, 'eval_wer': 0.7409502262443439, 'eval_cer': 0.18945796766587622, 'eval_runtime': 395.3626, 'eval_samples_per_second': 24.355, 'eval_steps_per_second': 3.045, 'epoch': 1.61}                                                                                                                                              
{'loss': 0.7162, 'learning_rate': 0.00026071065989847716, 'epoch': 1.62}                                                                                                      
{'loss': 0.7392, 'learning_rate': 0.0002604931109499637, 'epoch': 1.62}                                                                                                       
{'loss': 0.7933, 'learning_rate': 0.0002602755620014503, 'epoch': 1.63}                                                                                                       
{'loss': 0.6522, 'learning_rate': 0.0002600580130529369, 'epoch': 1.64}                                                                                                       
{'loss': 0.6606, 'learning_rate': 0.00025984046410442346, 'epoch': 1.64}                                                                                                      
{'loss': 0.695, 'learning_rate': 0.0002596229151559101, 'epoch': 1.65}                                                                                                        
{'loss': 0.7622, 'learning_rate': 0.00025940536620739664, 'epoch': 1.66}                                                                                                      
{'loss': 0.7525, 'learning_rate': 0.0002591878172588832, 'epoch': 1.67}                                                                                                       
{'loss': 0.6855, 'learning_rate': 0.0002589702683103698, 'epoch': 1.67}                                                                                                       
{'loss': 0.6376, 'learning_rate': 0.0002587527193618564, 'epoch': 1.68}                                                                                                       
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                          | 2400/14290 [3:11:55<3:43:36,  1.13s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.5054419040679932, 'eval_wer': 0.7233507978090021, 'eval_cer': 0.18174770465554632, 'eval_runtime': 395.2155, 'eval_samples_per_second': 24.364, 'eval_steps_per_second': 3.046, 'epoch': 1.68}                                                                                                                                              
{'loss': 0.7313, 'learning_rate': 0.000258535170413343, 'epoch': 1.69}                                                                                                        
{'loss': 0.7726, 'learning_rate': 0.00025831762146482956, 'epoch': 1.69}                                                                                                      
{'loss': 0.7716, 'learning_rate': 0.0002581000725163161, 'epoch': 1.7}                                                                                                        
{'loss': 0.6082, 'learning_rate': 0.00025788252356780274, 'epoch': 1.71}                                                                                                      
{'loss': 0.6734, 'learning_rate': 0.0002576649746192893, 'epoch': 1.71}                                                                                                       
{'loss': 0.722, 'learning_rate': 0.0002574474256707759, 'epoch': 1.72}                                                                                                        
{'loss': 0.7125, 'learning_rate': 0.0002572298767222625, 'epoch': 1.73}                                                                                                       
{'loss': 0.8221, 'learning_rate': 0.00025701232777374905, 'epoch': 1.74}                                                                                                      
{'loss': 0.6552, 'learning_rate': 0.00025679477882523566, 'epoch': 1.74}                                                                                                      
{'loss': 0.6098, 'learning_rate': 0.0002565772298767222, 'epoch': 1.75}                                                                                                       
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                         | 2500/14290 [3:20:14<3:40:19,  1.12s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.481427401304245, 'eval_wer': 0.6966896880209573, 'eval_cer': 0.17468601579548296, 'eval_runtime': 396.2656, 'eval_samples_per_second': 24.299, 'eval_steps_per_second': 3.038, 'epoch': 1.75}                                                                                                                                               
{'loss': 0.6411, 'learning_rate': 0.00025635968092820884, 'epoch': 1.76}                                                                                                      
{'loss': 0.7383, 'learning_rate': 0.0002561421319796954, 'epoch': 1.76}                                                                                                       
{'loss': 0.8407, 'learning_rate': 0.000255924583031182, 'epoch': 1.77}                                                                                                        
{'loss': 0.6205, 'learning_rate': 0.0002557070340826686, 'epoch': 1.78}                                                                                                       
{'loss': 0.6342, 'learning_rate': 0.00025548948513415514, 'epoch': 1.78}                                                                                                      
{'loss': 0.7052, 'learning_rate': 0.00025527193618564176, 'epoch': 1.79}                                                                                                      
{'loss': 0.7294, 'learning_rate': 0.0002550543872371283, 'epoch': 1.8}                                                                                                        
{'loss': 0.7759, 'learning_rate': 0.00025483683828861494, 'epoch': 1.81}                                                                                                      
{'loss': 0.6343, 'learning_rate': 0.0002546192893401015, 'epoch': 1.81}                                                                                                       
{'loss': 0.6729, 'learning_rate': 0.00025440174039158806, 'epoch': 1.82}                                                                                                      
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                        | 2600/14290 [3:28:34<3:33:52,  1.10s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.46193966269493103, 'eval_wer': 0.6845082162419623, 'eval_cer': 0.17053277664052102, 'eval_runtime': 396.606, 'eval_samples_per_second': 24.279, 'eval_steps_per_second': 3.036, 'epoch': 1.82}                                                                                                                                              
{'loss': 0.6664, 'learning_rate': 0.0002541841914430747, 'epoch': 1.83}                                                                                                       
{'loss': 0.7035, 'learning_rate': 0.00025396664249456124, 'epoch': 1.83}                                                                                                      
{'loss': 0.6962, 'learning_rate': 0.00025374909354604786, 'epoch': 1.84}                                                                                                      
{'loss': 0.5792, 'learning_rate': 0.0002535315445975344, 'epoch': 1.85}                                                                                                       
{'loss': 0.6515, 'learning_rate': 0.000253313995649021, 'epoch': 1.85}                                                                                                        
{'loss': 0.6699, 'learning_rate': 0.0002530964467005076, 'epoch': 1.86}                                                                                                       
{'loss': 0.668, 'learning_rate': 0.00025287889775199416, 'epoch': 1.87}                                                                                                       
{'loss': 0.7311, 'learning_rate': 0.0002526613488034808, 'epoch': 1.88}                                                                                                       
{'loss': 0.5678, 'learning_rate': 0.00025244379985496734, 'epoch': 1.88}                                                                                                      
{'loss': 0.5962, 'learning_rate': 0.0002522262509064539, 'epoch': 1.89}                                                                                                       
 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                       | 2700/14290 [3:36:55<3:38:15,  1.13s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.4444841146469116, 'eval_wer': 0.6676113360323886, 'eval_cer': 0.1643189633623165, 'eval_runtime': 397.1438, 'eval_samples_per_second': 24.246, 'eval_steps_per_second': 3.032, 'epoch': 1.89}                                                                                                                                               
{'loss': 0.7062, 'learning_rate': 0.0002520087019579405, 'epoch': 1.9}                                                                                                        
{'loss': 0.6983, 'learning_rate': 0.0002517911530094271, 'epoch': 1.9}                                                                                                        
{'loss': 0.8355, 'learning_rate': 0.0002515736040609137, 'epoch': 1.91}                                                                                                       
{'loss': 0.6109, 'learning_rate': 0.00025135605511240026, 'epoch': 1.92}                                                                                                      
{'loss': 0.6129, 'learning_rate': 0.0002511385061638869, 'epoch': 1.92}                                                                                                       
{'loss': 0.6708, 'learning_rate': 0.00025092095721537344, 'epoch': 1.93}                                                                                                      
{'loss': 0.6727, 'learning_rate': 0.00025070340826686, 'epoch': 1.94}                                                                                                         
{'loss': 0.7288, 'learning_rate': 0.0002504858593183466, 'epoch': 1.95}                                                                                                       
{'loss': 0.5647, 'learning_rate': 0.0002502683103698332, 'epoch': 1.95}                                                                                                       
{'loss': 0.6285, 'learning_rate': 0.0002500507614213198, 'epoch': 1.96}                                                                                                       
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                       | 2800/14290 [3:45:14<3:30:27,  1.10s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.42640209197998047, 'eval_wer': 0.6524291497975708, 'eval_cer': 0.15972489646459528, 'eval_runtime': 395.1611, 'eval_samples_per_second': 24.367, 'eval_steps_per_second': 3.047, 'epoch': 1.96}                                                                                                                                             
{'loss': 0.636, 'learning_rate': 0.00024983321247280636, 'epoch': 1.97}                                                                                                       
{'loss': 0.6723, 'learning_rate': 0.0002496156635242929, 'epoch': 1.97}                                                                                                       
{'loss': 0.7047, 'learning_rate': 0.00024939811457577954, 'epoch': 1.98}                                                                                                      
{'loss': 0.607, 'learning_rate': 0.0002491805656272661, 'epoch': 1.99}                                                                                                        
{'loss': 0.5912, 'learning_rate': 0.0002489630166787527, 'epoch': 1.99}                                                                                                       
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                      | 2856/14290 [3:52:40<2:08:06,  1.49it/s]Saving model checkpoint to ./russian_augmented/checkpoint-2856
Configuration saved in ./russian_augmented/checkpoint-2856/config.json
Model weights saved in ./russian_augmented/checkpoint-2856/pytorch_model.bin
Feature extractor saved in ./russian_augmented/checkpoint-2856/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.6871, 'learning_rate': 0.0002487454677302393, 'epoch': 2.0}                                                                                                        
{'loss': 0.5248, 'learning_rate': 0.00024852791878172585, 'epoch': 2.01}                                                                                                      
{'loss': 0.5195, 'learning_rate': 0.00024831036983321246, 'epoch': 2.02}                                                                                                      
{'loss': 0.5992, 'learning_rate': 0.000248092820884699, 'epoch': 2.02}                                                                                                        
{'loss': 0.5963, 'learning_rate': 0.00024787527193618564, 'epoch': 2.03}                                                                                                      
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                      | 2900/14290 [3:53:30<2:11:08,  1.45it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.43782615661621094, 'eval_wer': 0.6550726363419862, 'eval_cer': 0.1606960686948121, 'eval_runtime': 393.936, 'eval_samples_per_second': 24.443, 'eval_steps_per_second': 3.056, 'epoch': 2.03}                                                                                                                                               
{'loss': 0.6287, 'learning_rate': 0.0002476577229876722, 'epoch': 2.04}                                                                                                       
{'loss': 0.4734, 'learning_rate': 0.00024744017403915877, 'epoch': 2.04}                                                                                                      
{'loss': 0.5377, 'learning_rate': 0.0002472226250906454, 'epoch': 2.05}                                                                                                       
{'loss': 0.5645, 'learning_rate': 0.00024700507614213194, 'epoch': 2.06}                                                                                                      
{'loss': 0.6098, 'learning_rate': 0.00024678752719361856, 'epoch': 2.06}                                                                                                      
{'loss': 0.6071, 'learning_rate': 0.0002465699782451051, 'epoch': 2.07}                                                                                                       
{'loss': 0.483, 'learning_rate': 0.00024635242929659174, 'epoch': 2.08}                                                                                                       
{'loss': 0.5321, 'learning_rate': 0.0002461348803480783, 'epoch': 2.09}                                                                                                       
{'loss': 0.5551, 'learning_rate': 0.00024591733139956486, 'epoch': 2.09}                                                                                                      
{'loss': 0.6066, 'learning_rate': 0.0002456997824510515, 'epoch': 2.1}                                                                                                        
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                     | 3000/14290 [4:01:48<2:13:00,  1.41it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.41796088218688965, 'eval_wer': 0.6372588711598, 'eval_cer': 0.1549399731111967, 'eval_runtime': 394.5224, 'eval_samples_per_second': 24.407, 'eval_steps_per_second': 3.052, 'epoch': 2.1}                                                                                                                                                  
{'loss': 0.6502, 'learning_rate': 0.00024548223350253804, 'epoch': 2.11}                                                                                                      
{'loss': 0.5328, 'learning_rate': 0.00024526468455402466, 'epoch': 2.11}                                                                                                      
{'loss': 0.5526, 'learning_rate': 0.0002450471356055112, 'epoch': 2.12}                                                                                                       
{'loss': 0.5292, 'learning_rate': 0.0002448295866569978, 'epoch': 2.13}                                                                                                       
{'loss': 0.5575, 'learning_rate': 0.0002446120377084844, 'epoch': 2.13}                                                                                                       
{'loss': 0.6388, 'learning_rate': 0.00024439448875997096, 'epoch': 2.14}                                                                                                      
{'loss': 0.4638, 'learning_rate': 0.0002441769398114576, 'epoch': 2.15}                                                                                                       
{'loss': 0.4955, 'learning_rate': 0.00024395939086294412, 'epoch': 2.16}                                                                                                      
{'loss': 0.5693, 'learning_rate': 0.00024374184191443073, 'epoch': 2.16}                                                                                                      
{'loss': 0.6379, 'learning_rate': 0.00024352429296591732, 'epoch': 2.17}                                                                                                      
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                    | 3100/14290 [4:10:06<2:11:15,  1.42it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.4112088084220886, 'eval_wer': 0.6257918552036199, 'eval_cer': 0.15254328894653993, 'eval_runtime': 394.0549, 'eval_samples_per_second': 24.436, 'eval_steps_per_second': 3.055, 'epoch': 2.17}                                                                                                                                              
{'loss': 0.5805, 'learning_rate': 0.00024330674401740388, 'epoch': 2.18}                                                                                                      
{'loss': 0.5115, 'learning_rate': 0.00024308919506889047, 'epoch': 2.18}                                                                                                      
{'loss': 0.5252, 'learning_rate': 0.00024287164612037706, 'epoch': 2.19}                                                                                                      
{'loss': 0.5475, 'learning_rate': 0.00024265409717186365, 'epoch': 2.2}                                                                                                       
{'loss': 0.5504, 'learning_rate': 0.00024243654822335024, 'epoch': 2.2}                                                                                                       
{'loss': 0.6035, 'learning_rate': 0.0002422189992748368, 'epoch': 2.21}                                                                                                       
{'loss': 0.4964, 'learning_rate': 0.00024200145032632342, 'epoch': 2.22}                                                                                                      
{'loss': 0.5231, 'learning_rate': 0.00024178390137780998, 'epoch': 2.23}                                                                                                      
{'loss': 0.5541, 'learning_rate': 0.00024156635242929657, 'epoch': 2.23}                                                                                                      
{'loss': 0.6035, 'learning_rate': 0.00024134880348078316, 'epoch': 2.24}                                                                                                      
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                   | 3200/14290 [4:18:24<2:12:43,  1.39it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.4021724760532379, 'eval_wer': 0.6164443915217909, 'eval_cer': 0.15101474830593783, 'eval_runtime': 399.1124, 'eval_samples_per_second': 24.126, 'eval_steps_per_second': 3.017, 'epoch': 2.24}                                                                                                                                              
{'loss': 0.557, 'learning_rate': 0.00024113125453226972, 'epoch': 2.25}                                                                                                       
{'loss': 0.5, 'learning_rate': 0.00024091370558375634, 'epoch': 2.25}                                                                                                         
{'loss': 0.4431, 'learning_rate': 0.0002406961566352429, 'epoch': 2.26}                                                                                                       
{'loss': 0.5147, 'learning_rate': 0.0002404786076867295, 'epoch': 2.27}                                                                                                       
{'loss': 0.5773, 'learning_rate': 0.00024026105873821606, 'epoch': 2.27}                                                                                                      
{'loss': 0.5612, 'learning_rate': 0.00024004350978970267, 'epoch': 2.28}                                                                                                      
{'loss': 0.5119, 'learning_rate': 0.00023982596084118926, 'epoch': 2.29}                                                                                                      
{'loss': 0.4966, 'learning_rate': 0.00023960841189267582, 'epoch': 2.3}                                                                                                       
{'loss': 0.52, 'learning_rate': 0.0002393908629441624, 'epoch': 2.3}                                                                                                          
{'loss': 0.5444, 'learning_rate': 0.00023917331399564898, 'epoch': 2.31}                                                                                                      
 23%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                  | 3300/14290 [4:26:47<2:25:44,  1.26it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.39946863055229187, 'eval_wer': 0.6122648249583235, 'eval_cer': 0.14960612632332773, 'eval_runtime': 396.3478, 'eval_samples_per_second': 24.294, 'eval_steps_per_second': 3.038, 'epoch': 2.31}                                                                                                                                             
{'loss': 0.5331, 'learning_rate': 0.0002389557650471356, 'epoch': 2.32}                                                                                                       
{'loss': 0.5009, 'learning_rate': 0.00023873821609862218, 'epoch': 2.32}                                                                                                      
{'loss': 0.5121, 'learning_rate': 0.00023852066715010874, 'epoch': 2.33}                                                                                                      
{'loss': 0.5305, 'learning_rate': 0.00023830311820159533, 'epoch': 2.34}                                                                                                      
{'loss': 0.5933, 'learning_rate': 0.0002380855692530819, 'epoch': 2.34}                                                                                                       
{'loss': 0.5991, 'learning_rate': 0.0002378680203045685, 'epoch': 2.35}                                                                                                       
{'loss': 0.4121, 'learning_rate': 0.0002376504713560551, 'epoch': 2.36}                                                                                                       
{'loss': 0.4984, 'learning_rate': 0.00023743292240754166, 'epoch': 2.37}                                                                                                      
{'loss': 0.555, 'learning_rate': 0.00023721537345902828, 'epoch': 2.37}                                                                                                       
{'loss': 0.5758, 'learning_rate': 0.00023699782451051484, 'epoch': 2.38}                                                                                                      
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                 | 3400/14290 [4:35:08<2:17:13,  1.32it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.37796124815940857, 'eval_wer': 0.5996308644915456, 'eval_cer': 0.1425140355499706, 'eval_runtime': 395.2268, 'eval_samples_per_second': 24.363, 'eval_steps_per_second': 3.046, 'epoch': 2.38}                                                                                                                                              
{'loss': 0.628, 'learning_rate': 0.00023678027556200143, 'epoch': 2.39}                                                                                                       
{'loss': 0.4205, 'learning_rate': 0.00023656272661348802, 'epoch': 2.39}                                                                                                      
{'loss': 0.4628, 'learning_rate': 0.00023634517766497458, 'epoch': 2.4}                                                                                                       
{'loss': 0.5217, 'learning_rate': 0.0002361276287164612, 'epoch': 2.41}                                                                                                       
{'loss': 0.5611, 'learning_rate': 0.00023591007976794776, 'epoch': 2.41}                                                                                                      
{'loss': 0.5359, 'learning_rate': 0.00023569253081943435, 'epoch': 2.42}                                                                                                      
{'loss': 0.4458, 'learning_rate': 0.00023547498187092092, 'epoch': 2.43}                                                                                                      
{'loss': 0.4921, 'learning_rate': 0.0002352574329224075, 'epoch': 2.44}                                                                                                       
{'loss': 0.5793, 'learning_rate': 0.00023503988397389412, 'epoch': 2.44}                                                                                                      
{'loss': 0.5289, 'learning_rate': 0.00023482233502538068, 'epoch': 2.45}                                                                                                      
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                | 3500/14290 [4:43:26<2:11:38,  1.37it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3921608626842499, 'eval_wer': 0.5919028340080972, 'eval_cer': 0.14452225082254067, 'eval_runtime': 394.312, 'eval_samples_per_second': 24.42, 'eval_steps_per_second': 3.053, 'epoch': 2.45}                                                                                                                                                
{'loss': 0.5951, 'learning_rate': 0.00023460478607686727, 'epoch': 2.46}                                                                                                      
{'loss': 0.4558, 'learning_rate': 0.00023438723712835384, 'epoch': 2.46}                                                                                                      
{'loss': 0.4676, 'learning_rate': 0.00023416968817984045, 'epoch': 2.47}                                                                                                      
{'loss': 0.4849, 'learning_rate': 0.00023395213923132704, 'epoch': 2.48}                                                                                                      
{'loss': 0.5706, 'learning_rate': 0.0002337345902828136, 'epoch': 2.48}                                                                                                       
{'loss': 0.5441, 'learning_rate': 0.0002335170413343002, 'epoch': 2.49}                                                                                                       
{'loss': 0.4339, 'learning_rate': 0.00023329949238578676, 'epoch': 2.5}                                                                                                       
{'loss': 0.4638, 'learning_rate': 0.00023308194343727337, 'epoch': 2.51}                                                                                                      
{'loss': 0.4679, 'learning_rate': 0.00023286439448875996, 'epoch': 2.51}                                                                                                      
{'loss': 0.5324, 'learning_rate': 0.00023264684554024652, 'epoch': 2.52}                                                                                                      
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                               | 3600/14290 [4:51:42<2:07:44,  1.39it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.368081659078598, 'eval_wer': 0.5837818528221005, 'eval_cer': 0.1392475188660762, 'eval_runtime': 397.1313, 'eval_samples_per_second': 24.246, 'eval_steps_per_second': 3.032, 'epoch': 2.52}                                                                                                                                                
{'loss': 0.4963, 'learning_rate': 0.00023242929659173314, 'epoch': 2.53}                                                                                                      
{'loss': 0.4712, 'learning_rate': 0.0002322117476432197, 'epoch': 2.53}                                                                                                       
{'loss': 0.4777, 'learning_rate': 0.0002319941986947063, 'epoch': 2.54}                                                                                                       
{'loss': 0.5275, 'learning_rate': 0.00023177664974619288, 'epoch': 2.55}                                                                                                      
{'loss': 0.4977, 'learning_rate': 0.00023155910079767944, 'epoch': 2.55}                                                                                                      
{'loss': 0.5576, 'learning_rate': 0.00023134155184916606, 'epoch': 2.56}                                                                                                      
{'loss': 0.4288, 'learning_rate': 0.00023112400290065262, 'epoch': 2.57}                                                                                                      
{'loss': 0.4874, 'learning_rate': 0.0002309064539521392, 'epoch': 2.58}                                                                                                       
{'loss': 0.5021, 'learning_rate': 0.00023068890500362578, 'epoch': 2.58}                                                                                                      
{'loss': 0.5757, 'learning_rate': 0.00023047135605511236, 'epoch': 2.59}                                                                                                      
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                              | 3700/14290 [5:00:02<2:06:58,  1.39it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.35869213938713074, 'eval_wer': 0.5770064301024054, 'eval_cer': 0.14011735138531384, 'eval_runtime': 394.6396, 'eval_samples_per_second': 24.399, 'eval_steps_per_second': 3.051, 'epoch': 2.59}                                                                                                                                             
{'loss': 0.5993, 'learning_rate': 0.00023025380710659898, 'epoch': 2.6}                                                                                                       
{'loss': 0.4483, 'learning_rate': 0.00023003625815808554, 'epoch': 2.6}                                                                                                       
{'loss': 0.4628, 'learning_rate': 0.00022981870920957213, 'epoch': 2.61}                                                                                                      
{'loss': 0.5232, 'learning_rate': 0.0002296011602610587, 'epoch': 2.62}                                                                                                       
{'loss': 0.5352, 'learning_rate': 0.0002293836113125453, 'epoch': 2.62}                                                                                                       
{'loss': 0.517, 'learning_rate': 0.0002291660623640319, 'epoch': 2.63}                                                                                                        
{'loss': 0.487, 'learning_rate': 0.00022894851341551846, 'epoch': 2.64}                                                                                                       
{'loss': 0.4483, 'learning_rate': 0.00022873096446700505, 'epoch': 2.65}                                                                                                      
{'loss': 0.4826, 'learning_rate': 0.00022851341551849162, 'epoch': 2.65}                                                                                                      
{'loss': 0.6282, 'learning_rate': 0.00022829586656997823, 'epoch': 2.66}                                                                                                      
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                              | 3800/14290 [5:08:21<2:08:38,  1.36it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.35551780462265015, 'eval_wer': 0.5709454632055251, 'eval_cer': 0.1378743657823088, 'eval_runtime': 396.174, 'eval_samples_per_second': 24.305, 'eval_steps_per_second': 3.039, 'epoch': 2.66}                                                                                                                                               
{'loss': 0.551, 'learning_rate': 0.00022807831762146482, 'epoch': 2.67}                                                                                                       
{'loss': 0.4455, 'learning_rate': 0.00022786076867295138, 'epoch': 2.67}                                                                                                      
{'loss': 0.441, 'learning_rate': 0.00022764321972443797, 'epoch': 2.68}                                                                                                       
{'loss': 0.4653, 'learning_rate': 0.00022742567077592456, 'epoch': 2.69}                                                                                                      
{'loss': 0.4771, 'learning_rate': 0.00022720812182741115, 'epoch': 2.69}                                                                                                      
{'loss': 0.5341, 'learning_rate': 0.00022699057287889774, 'epoch': 2.7}                                                                                                       
{'loss': 0.4043, 'learning_rate': 0.0002267730239303843, 'epoch': 2.71}                                                                                                       
{'loss': 0.4523, 'learning_rate': 0.00022655547498187092, 'epoch': 2.72}                                                                                                      
{'loss': 0.486, 'learning_rate': 0.00022633792603335748, 'epoch': 2.72}                                                                                                       
{'loss': 0.4849, 'learning_rate': 0.00022612037708484407, 'epoch': 2.73}                                                                                                      
 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                             | 3900/14290 [5:16:41<2:07:45,  1.36it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.35488948225975037, 'eval_wer': 0.5657418432960228, 'eval_cer': 0.1355063945357628, 'eval_runtime': 396.6649, 'eval_samples_per_second': 24.275, 'eval_steps_per_second': 3.035, 'epoch': 2.73}                                                                                                                                              
{'loss': 0.5402, 'learning_rate': 0.00022590282813633064, 'epoch': 2.74}                                                                                                      
{'loss': 0.4353, 'learning_rate': 0.00022568527918781722, 'epoch': 2.74}                                                                                                      
{'loss': 0.4566, 'learning_rate': 0.00022546773023930384, 'epoch': 2.75}                                                                                                      
{'loss': 0.504, 'learning_rate': 0.0002252501812907904, 'epoch': 2.76}                                                                                                        
{'loss': 0.5774, 'learning_rate': 0.000225032632342277, 'epoch': 2.76}                                                                                                        
{'loss': 0.5388, 'learning_rate': 0.00022481508339376356, 'epoch': 2.77}                                                                                                      
{'loss': 0.4077, 'learning_rate': 0.00022459753444525017, 'epoch': 2.78}                                                                                                      
{'loss': 0.4063, 'learning_rate': 0.00022437998549673676, 'epoch': 2.79}                                                                                                      
{'loss': 0.4912, 'learning_rate': 0.00022416243654822332, 'epoch': 2.79}                                                                                                      
{'loss': 0.4972, 'learning_rate': 0.0002239448875997099, 'epoch': 2.8}                                                                                                        
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                            | 4000/14290 [5:25:02<2:06:28,  1.36it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.34809964895248413, 'eval_wer': 0.560764467730412, 'eval_cer': 0.1331840261591574, 'eval_runtime': 396.4373, 'eval_samples_per_second': 24.289, 'eval_steps_per_second': 3.037, 'epoch': 2.8}                                                                                                                                                
{'loss': 0.5965, 'learning_rate': 0.00022372733865119648, 'epoch': 2.81}                                                                                                      
{'loss': 0.4518, 'learning_rate': 0.0002235097897026831, 'epoch': 2.81}                                                                                                       
{'loss': 0.4429, 'learning_rate': 0.00022329224075416968, 'epoch': 2.82}                                                                                                      
{'loss': 0.4846, 'learning_rate': 0.00022307469180565624, 'epoch': 2.83}                                                                                                      
{'loss': 0.5161, 'learning_rate': 0.00022285714285714283, 'epoch': 2.83}                                                                                                      
{'loss': 0.5224, 'learning_rate': 0.00022263959390862942, 'epoch': 2.84}                                                                                                      
{'loss': 0.4205, 'learning_rate': 0.000222422044960116, 'epoch': 2.85}                                                                                                        
{'loss': 0.4444, 'learning_rate': 0.0002222044960116026, 'epoch': 2.86}                                                                                                       
{'loss': 0.4884, 'learning_rate': 0.00022198694706308916, 'epoch': 2.86}                                                                                                      
{'loss': 0.5401, 'learning_rate': 0.00022176939811457578, 'epoch': 2.87}                                                                                                      
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                           | 4100/14290 [5:33:24<2:03:45,  1.37it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3405711352825165, 'eval_wer': 0.5587520838294832, 'eval_cer': 0.13342555247032437, 'eval_runtime': 398.9955, 'eval_samples_per_second': 24.133, 'eval_steps_per_second': 3.018, 'epoch': 2.87}                                                                                                                                              
{'loss': 0.5855, 'learning_rate': 0.00022155184916606234, 'epoch': 2.88}                                                                                                      
{'loss': 0.4119, 'learning_rate': 0.00022133430021754893, 'epoch': 2.88}                                                                                                      
{'loss': 0.4517, 'learning_rate': 0.0002211167512690355, 'epoch': 2.89}                                                                                                       
{'loss': 0.4596, 'learning_rate': 0.00022089920232052208, 'epoch': 2.9}                                                                                                       
{'loss': 0.5405, 'learning_rate': 0.0002206816533720087, 'epoch': 2.9}                                                                                                        
{'loss': 0.5064, 'learning_rate': 0.00022046410442349526, 'epoch': 2.91}                                                                                                      
{'loss': 0.4189, 'learning_rate': 0.00022024655547498185, 'epoch': 2.92}                                                                                                      
{'loss': 0.4249, 'learning_rate': 0.00022002900652646842, 'epoch': 2.93}                                                                                                      
{'loss': 0.4984, 'learning_rate': 0.00021981145757795503, 'epoch': 2.93}                                                                                                      
{'loss': 0.4865, 'learning_rate': 0.00021959390862944162, 'epoch': 2.94}                                                                                                      
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                          | 4200/14290 [5:41:47<2:07:23,  1.32it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.339950829744339, 'eval_wer': 0.5529411764705883, 'eval_cer': 0.13229054770735793, 'eval_runtime': 396.5195, 'eval_samples_per_second': 24.284, 'eval_steps_per_second': 3.036, 'epoch': 2.94}                                                                                                                                               
{'loss': 0.4965, 'learning_rate': 0.00021937635968092818, 'epoch': 2.95}                                                                                                      
{'loss': 0.4175, 'learning_rate': 0.00021915881073241477, 'epoch': 2.95}                                                                                                      
{'loss': 0.4413, 'learning_rate': 0.00021894126178390134, 'epoch': 2.96}                                                                                                      
{'loss': 0.4913, 'learning_rate': 0.00021872371283538795, 'epoch': 2.97}                                                                                                      
{'loss': 0.4974, 'learning_rate': 0.00021850616388687454, 'epoch': 2.97}                                                                                                      
{'loss': 0.5473, 'learning_rate': 0.0002182886149383611, 'epoch': 2.98}                                                                                                       
{'loss': 0.4442, 'learning_rate': 0.0002180710659898477, 'epoch': 2.99}                                                                                                       
{'loss': 0.4773, 'learning_rate': 0.00021785351704133426, 'epoch': 3.0}                                                                                                       
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                         | 4284/14290 [5:49:47<1:59:45,  1.39it/s]Saving model checkpoint to ./russian_augmented/checkpoint-4284
Configuration saved in ./russian_augmented/checkpoint-4284/config.json
Model weights saved in ./russian_augmented/checkpoint-4284/pytorch_model.bin
Feature extractor saved in ./russian_augmented/checkpoint-4284/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.5475, 'learning_rate': 0.00021763596809282087, 'epoch': 3.0}                                                                                                       
{'loss': 0.3847, 'learning_rate': 0.00021741841914430746, 'epoch': 3.01}                                                                                                      
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                         | 4300/14290 [5:50:10<3:42:24,  1.34s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.33966049551963806, 'eval_wer': 0.5375446534889259, 'eval_cer': 0.12734854780194166, 'eval_runtime': 396.5979, 'eval_samples_per_second': 24.279, 'eval_steps_per_second': 3.036, 'epoch': 3.01}                                                                                                                                             
{'loss': 0.3852, 'learning_rate': 0.00021720087019579402, 'epoch': 3.02}                                                                                                      
{'loss': 0.4115, 'learning_rate': 0.00021698332124728064, 'epoch': 3.02}                                                                                                      
{'loss': 0.4356, 'learning_rate': 0.0002167657722987672, 'epoch': 3.03}                                                                                                       
{'loss': 0.4453, 'learning_rate': 0.0002165482233502538, 'epoch': 3.04}                                                                                                       
{'loss': 0.4258, 'learning_rate': 0.00021633067440174038, 'epoch': 3.04}                                                                                                      
{'loss': 0.3631, 'learning_rate': 0.00021611312545322694, 'epoch': 3.05}                                                                                                      
{'loss': 0.4117, 'learning_rate': 0.00021589557650471356, 'epoch': 3.06}                                                                                                      
{'loss': 0.4528, 'learning_rate': 0.00021567802755620012, 'epoch': 3.07}                                                                                                      
{'loss': 0.4673, 'learning_rate': 0.0002154604786076867, 'epoch': 3.07}                                                                                                       
{'loss': 0.3683, 'learning_rate': 0.00021524292965917328, 'epoch': 3.08}                                                                                                      
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                        | 4400/14290 [5:58:31<3:33:17,  1.29s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3341304063796997, 'eval_wer': 0.5303881876637294, 'eval_cer': 0.1256038157779174, 'eval_runtime': 398.8912, 'eval_samples_per_second': 24.139, 'eval_steps_per_second': 3.018, 'epoch': 3.08}                                                                                                                                               
{'loss': 0.4036, 'learning_rate': 0.00021502538071065987, 'epoch': 3.09}                                                                                                      
{'loss': 0.3937, 'learning_rate': 0.00021480783176214648, 'epoch': 3.09}                                                                                                      
{'loss': 0.4869, 'learning_rate': 0.00021459028281363304, 'epoch': 3.1}                                                                                                       
{'loss': 0.4923, 'learning_rate': 0.00021437273386511963, 'epoch': 3.11}                                                                                                      
{'loss': 0.3529, 'learning_rate': 0.0002141551849166062, 'epoch': 3.11}                                                                                                       
{'loss': 0.3765, 'learning_rate': 0.0002139376359680928, 'epoch': 3.12}                                                                                                       
{'loss': 0.445, 'learning_rate': 0.0002137200870195794, 'epoch': 3.13}                                                                                                        
{'loss': 0.4571, 'learning_rate': 0.00021350253807106596, 'epoch': 3.14}                                                                                                      
{'loss': 0.3875, 'learning_rate': 0.00021328498912255255, 'epoch': 3.14}                                                                                                      
{'loss': 0.3875, 'learning_rate': 0.00021306744017403912, 'epoch': 3.15}                                                                                                      
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                       | 4500/14290 [6:06:53<3:35:13,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.32749706506729126, 'eval_wer': 0.5320076208621101, 'eval_cer': 0.12660707891661094, 'eval_runtime': 399.6645, 'eval_samples_per_second': 24.093, 'eval_steps_per_second': 3.013, 'epoch': 3.15}                                                                                                                                             
{'loss': 0.3756, 'learning_rate': 0.00021284989122552573, 'epoch': 3.16}                                                                                                      
{'loss': 0.392, 'learning_rate': 0.00021263234227701232, 'epoch': 3.16}                                                                                                       
{'loss': 0.3994, 'learning_rate': 0.00021241479332849888, 'epoch': 3.17}                                                                                                      
{'loss': 0.4184, 'learning_rate': 0.00021219724437998547, 'epoch': 3.18}                                                                                                      
{'loss': 0.3254, 'learning_rate': 0.00021197969543147206, 'epoch': 3.18}                                                                                                      
{'loss': 0.3701, 'learning_rate': 0.00021176214648295865, 'epoch': 3.19}                                                                                                      
{'loss': 0.4091, 'learning_rate': 0.00021154459753444524, 'epoch': 3.2}                                                                                                       
{'loss': 0.509, 'learning_rate': 0.0002113270485859318, 'epoch': 3.21}                                                                                                        
{'loss': 0.4214, 'learning_rate': 0.00021110949963741842, 'epoch': 3.21}                                                                                                      
{'loss': 0.3661, 'learning_rate': 0.00021089195068890498, 'epoch': 3.22}                                                                                                      
 32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                      | 4600/14290 [6:15:19<3:33:47,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.31698235869407654, 'eval_wer': 0.5150512026673018, 'eval_cer': 0.12172588283778214, 'eval_runtime': 396.1122, 'eval_samples_per_second': 24.309, 'eval_steps_per_second': 3.04, 'epoch': 3.22}                                                                                                                                              
{'loss': 0.3812, 'learning_rate': 0.00021067440174039157, 'epoch': 3.23}                                                                                                      
{'loss': 0.3973, 'learning_rate': 0.00021045685279187814, 'epoch': 3.23}                                                                                                      
{'loss': 0.4079, 'learning_rate': 0.00021023930384336473, 'epoch': 3.24}                                                                                                      
{'loss': 0.4278, 'learning_rate': 0.00021002175489485134, 'epoch': 3.25}                                                                                                      
{'loss': 0.3653, 'learning_rate': 0.0002098042059463379, 'epoch': 3.25}                                                                                                       
{'loss': 0.3616, 'learning_rate': 0.0002095866569978245, 'epoch': 3.26}                                                                                                       
{'loss': 0.4288, 'learning_rate': 0.00020936910804931106, 'epoch': 3.27}                                                                                                      
{'loss': 0.4277, 'learning_rate': 0.00020915155910079767, 'epoch': 3.28}                                                                                                      
{'loss': 0.4423, 'learning_rate': 0.00020893401015228426, 'epoch': 3.28}                                                                                                      
{'loss': 0.3537, 'learning_rate': 0.00020871646120377082, 'epoch': 3.29}                                                                                                      
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                      | 4700/14290 [6:23:39<3:21:45,  1.26s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.32368138432502747, 'eval_wer': 0.5190521552750655, 'eval_cer': 0.12556496888870872, 'eval_runtime': 396.7378, 'eval_samples_per_second': 24.27, 'eval_steps_per_second': 3.035, 'epoch': 3.29}                                                                                                                                              
{'loss': 0.3697, 'learning_rate': 0.00020849891225525741, 'epoch': 3.3}                                                                                                       
{'loss': 0.3626, 'learning_rate': 0.00020828136330674398, 'epoch': 3.3}                                                                                                       
{'loss': 0.4517, 'learning_rate': 0.0002080638143582306, 'epoch': 3.31}                                                                                                       
{'loss': 0.4673, 'learning_rate': 0.00020784626540971718, 'epoch': 3.32}                                                                                                      
{'loss': 0.371, 'learning_rate': 0.00020762871646120374, 'epoch': 3.32}                                                                                                       
{'loss': 0.3924, 'learning_rate': 0.00020741116751269033, 'epoch': 3.33}                                                                                                      
{'loss': 0.4141, 'learning_rate': 0.00020719361856417692, 'epoch': 3.34}                                                                                                      
{'loss': 0.4487, 'learning_rate': 0.0002069760696156635, 'epoch': 3.34}                                                                                                       
{'loss': 0.4245, 'learning_rate': 0.0002067585206671501, 'epoch': 3.35}                                                                                                       
{'loss': 0.3611, 'learning_rate': 0.00020654097171863666, 'epoch': 3.36}                                                                                                      
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                     | 4800/14290 [6:31:58<3:28:08,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3151925802230835, 'eval_wer': 0.5159561800428674, 'eval_cer': 0.1268232703000331, 'eval_runtime': 399.1366, 'eval_samples_per_second': 24.125, 'eval_steps_per_second': 3.017, 'epoch': 3.36}                                                                                                                                               
{'loss': 0.4121, 'learning_rate': 0.00020632342277012328, 'epoch': 3.37}                                                                                                      
{'loss': 0.4192, 'learning_rate': 0.00020610587382160984, 'epoch': 3.37}                                                                                                      
{'loss': 0.4337, 'learning_rate': 0.00020588832487309643, 'epoch': 3.38}                                                                                                      
{'loss': 0.4584, 'learning_rate': 0.000205670775924583, 'epoch': 3.39}                                                                                                        
{'loss': 0.3621, 'learning_rate': 0.00020545322697606959, 'epoch': 3.39}                                                                                                      
{'loss': 0.3959, 'learning_rate': 0.0002052356780275562, 'epoch': 3.4}                                                                                                        
{'loss': 0.4312, 'learning_rate': 0.00020501812907904276, 'epoch': 3.41}                                                                                                      
{'loss': 0.437, 'learning_rate': 0.00020480058013052935, 'epoch': 3.41}                                                                                                       
{'loss': 0.4597, 'learning_rate': 0.00020458303118201592, 'epoch': 3.42}                                                                                                      
{'loss': 0.3815, 'learning_rate': 0.00020436548223350253, 'epoch': 3.43}                                                                                                      
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                    | 4900/14290 [6:40:20<3:28:26,  1.33s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3189263641834259, 'eval_wer': 0.5187782805429865, 'eval_cer': 0.12425093063634582, 'eval_runtime': 398.7583, 'eval_samples_per_second': 24.147, 'eval_steps_per_second': 3.019, 'epoch': 3.43}                                                                                                                                              
{'loss': 0.3622, 'learning_rate': 0.00020414793328498912, 'epoch': 3.44}                                                                                                      
{'loss': 0.4069, 'learning_rate': 0.00020393038433647568, 'epoch': 3.44}                                                                                                      
{'loss': 0.4489, 'learning_rate': 0.00020371283538796227, 'epoch': 3.45}                                                                                                      
{'loss': 0.4058, 'learning_rate': 0.00020349528643944884, 'epoch': 3.46}                                                                                                      
{'loss': 0.3432, 'learning_rate': 0.00020327773749093545, 'epoch': 3.46}                                                                                                      
{'loss': 0.4039, 'learning_rate': 0.00020306018854242204, 'epoch': 3.47}                                                                                                      
{'loss': 0.3959, 'learning_rate': 0.0002028426395939086, 'epoch': 3.48}                                                                                                       
{'loss': 0.4888, 'learning_rate': 0.0002026250906453952, 'epoch': 3.48}                                                                                                       
{'loss': 0.4673, 'learning_rate': 0.00020240754169688176, 'epoch': 3.49}                                                                                                      
{'loss': 0.3335, 'learning_rate': 0.00020218999274836837, 'epoch': 3.5}                                                                                                       
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                   | 5000/14290 [6:48:42<3:23:31,  1.31s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.31477293372154236, 'eval_wer': 0.5159680876399143, 'eval_cer': 0.12119216035995865, 'eval_runtime': 398.7769, 'eval_samples_per_second': 24.146, 'eval_steps_per_second': 3.019, 'epoch': 3.5}                                                                                                                                              
{'loss': 0.381, 'learning_rate': 0.00020197244379985496, 'epoch': 3.51}                                                                                                       
{'loss': 0.4081, 'learning_rate': 0.00020175489485134152, 'epoch': 3.51}                                                                                                      
{'loss': 0.4163, 'learning_rate': 0.00020153734590282814, 'epoch': 3.52}                                                                                                      
{'loss': 0.4565, 'learning_rate': 0.0002013197969543147, 'epoch': 3.53}                                                                                                       
{'loss': 0.3764, 'learning_rate': 0.0002011022480058013, 'epoch': 3.53}                                                                                                       
{'loss': 0.3971, 'learning_rate': 0.00020088469905728786, 'epoch': 3.54}                                                                                                      
{'loss': 0.4263, 'learning_rate': 0.00020066715010877445, 'epoch': 3.55}                                                                                                      
{'loss': 0.4639, 'learning_rate': 0.00020044960116026106, 'epoch': 3.55}                                                                                                      
{'loss': 0.4247, 'learning_rate': 0.00020023205221174762, 'epoch': 3.56}                                                                                                      
{'loss': 0.3615, 'learning_rate': 0.0002000145032632342, 'epoch': 3.57}                                                                                                       
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                  | 5100/14290 [6:57:05<3:25:20,  1.34s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3039921224117279, 'eval_wer': 0.49930935937127885, 'eval_cer': 0.1192329259476952, 'eval_runtime': 397.1414, 'eval_samples_per_second': 24.246, 'eval_steps_per_second': 3.032, 'epoch': 3.57}                                                                                                                                              
{'loss': 0.394, 'learning_rate': 0.00019979695431472078, 'epoch': 3.58}                                                                                                       
{'loss': 0.3884, 'learning_rate': 0.0001995794053662074, 'epoch': 3.58}                                                                                                       
{'loss': 0.3967, 'learning_rate': 0.00019936185641769398, 'epoch': 3.59}                                                                                                      
{'loss': 0.4034, 'learning_rate': 0.00019914430746918054, 'epoch': 3.6}                                                                                                       
{'loss': 0.3471, 'learning_rate': 0.00019892675852066713, 'epoch': 3.6}                                                                                                       
{'loss': 0.3967, 'learning_rate': 0.0001987092095721537, 'epoch': 3.61}                                                                                                       
{'loss': 0.4357, 'learning_rate': 0.0001984916606236403, 'epoch': 3.62}                                                                                                       
{'loss': 0.3781, 'learning_rate': 0.0001982741116751269, 'epoch': 3.62}                                                                                                       
{'loss': 0.4152, 'learning_rate': 0.00019805656272661346, 'epoch': 3.63}                                                                                                      
{'loss': 0.3502, 'learning_rate': 0.00019783901377810005, 'epoch': 3.64}                                                                                                      
 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                 | 5200/14290 [7:05:26<3:22:25,  1.34s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3029046952724457, 'eval_wer': 0.5017623243629435, 'eval_cer': 0.1189829546606133, 'eval_runtime': 399.8416, 'eval_samples_per_second': 24.082, 'eval_steps_per_second': 3.011, 'epoch': 3.64}                                                                                                                                               
{'loss': 0.3654, 'learning_rate': 0.00019762146482958662, 'epoch': 3.65}                                                                                                      
{'loss': 0.4211, 'learning_rate': 0.00019740391588107323, 'epoch': 3.65}                                                                                                      
{'loss': 0.4227, 'learning_rate': 0.00019718636693255982, 'epoch': 3.66}                                                                                                      
{'loss': 0.4227, 'learning_rate': 0.00019696881798404638, 'epoch': 3.67}                                                                                                      
{'loss': 0.3855, 'learning_rate': 0.000196751269035533, 'epoch': 3.67}                                                                                                        
{'loss': 0.3456, 'learning_rate': 0.00019653372008701956, 'epoch': 3.68}                                                                                                      
{'loss': 0.3865, 'learning_rate': 0.00019631617113850615, 'epoch': 3.69}                                                                                                      
{'loss': 0.3918, 'learning_rate': 0.00019609862218999272, 'epoch': 3.69}                                                                                                      
{'loss': 0.4574, 'learning_rate': 0.0001958810732414793, 'epoch': 3.7}                                                                                                        
{'loss': 0.338, 'learning_rate': 0.00019566352429296592, 'epoch': 3.71}                                                                                                       
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                | 5300/14290 [7:13:50<3:16:05,  1.31s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29886311292648315, 'eval_wer': 0.4945463205525125, 'eval_cer': 0.1204642034360918, 'eval_runtime': 400.1973, 'eval_samples_per_second': 24.061, 'eval_steps_per_second': 3.009, 'epoch': 3.71}                                                                                                                                              
{'loss': 0.3412, 'learning_rate': 0.00019544597534445248, 'epoch': 3.72}                                                                                                      
{'loss': 0.3821, 'learning_rate': 0.00019522842639593907, 'epoch': 3.72}                                                                                                      
{'loss': 0.4579, 'learning_rate': 0.00019501087744742564, 'epoch': 3.73}                                                                                                      
{'loss': 0.5218, 'learning_rate': 0.00019479332849891223, 'epoch': 3.74}                                                                                                      
{'loss': 0.2972, 'learning_rate': 0.00019457577955039884, 'epoch': 3.74}                                                                                                      
{'loss': 0.3621, 'learning_rate': 0.0001943582306018854, 'epoch': 3.75}                                                                                                       
{'loss': 0.39, 'learning_rate': 0.000194140681653372, 'epoch': 3.76}                                                                                                          
{'loss': 0.4402, 'learning_rate': 0.00019392313270485856, 'epoch': 3.76}                                                                                                      
{'loss': 0.3992, 'learning_rate': 0.00019370558375634517, 'epoch': 3.77}                                                                                                      
{'loss': 0.3359, 'learning_rate': 0.00019348803480783176, 'epoch': 3.78}                                                                                                      
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                               | 5400/14290 [7:22:15<3:17:15,  1.33s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29843828082084656, 'eval_wer': 0.49158132888783046, 'eval_cer': 0.12056723214225393, 'eval_runtime': 399.7433, 'eval_samples_per_second': 24.088, 'eval_steps_per_second': 3.012, 'epoch': 3.78}                                                                                                                                            
{'loss': 0.3398, 'learning_rate': 0.00019327048585931832, 'epoch': 3.79}                                                                                                      
{'loss': 0.3587, 'learning_rate': 0.00019305293691080491, 'epoch': 3.79}                                                                                                      
{'loss': 0.383, 'learning_rate': 0.00019283538796229148, 'epoch': 3.8}                                                                                                        
{'loss': 0.505, 'learning_rate': 0.0001926178390137781, 'epoch': 3.81}                                                                                                        
{'loss': 0.3177, 'learning_rate': 0.00019240029006526468, 'epoch': 3.81}                                                                                                      
{'loss': 0.3558, 'learning_rate': 0.00019218274111675124, 'epoch': 3.82}                                                                                                      
{'loss': 0.4106, 'learning_rate': 0.00019196519216823783, 'epoch': 3.83}                                                                                                      
{'loss': 0.398, 'learning_rate': 0.00019174764321972442, 'epoch': 3.83}                                                                                                       
{'loss': 0.4702, 'learning_rate': 0.000191530094271211, 'epoch': 3.84}                                                                                                        
{'loss': 0.3563, 'learning_rate': 0.00019131254532269758, 'epoch': 3.85}                                                                                                      
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                              | 5500/14290 [7:30:39<3:13:21,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29739269614219666, 'eval_wer': 0.4979161705167897, 'eval_cer': 0.11742232311153449, 'eval_runtime': 400.138, 'eval_samples_per_second': 24.064, 'eval_steps_per_second': 3.009, 'epoch': 3.85}                                                                                                                                              
{'loss': 0.3533, 'learning_rate': 0.00019109499637418417, 'epoch': 3.86}                                                                                                      
{'loss': 0.3921, 'learning_rate': 0.00019087744742567078, 'epoch': 3.86}                                                                                                      
{'loss': 0.4277, 'learning_rate': 0.00019065989847715734, 'epoch': 3.87}                                                                                                      
{'loss': 0.4726, 'learning_rate': 0.00019044234952864393, 'epoch': 3.88}                                                                                                      
{'loss': 0.3333, 'learning_rate': 0.0001902248005801305, 'epoch': 3.88}                                                                                                       
{'loss': 0.3645, 'learning_rate': 0.00019000725163161709, 'epoch': 3.89}                                                                                                      
{'loss': 0.4122, 'learning_rate': 0.0001897897026831037, 'epoch': 3.9}                                                                                                        
{'loss': 0.4129, 'learning_rate': 0.00018957215373459026, 'epoch': 3.9}                                                                                                       
{'loss': 0.3935, 'learning_rate': 0.00018935460478607685, 'epoch': 3.91}                                                                                                      
{'loss': 0.3652, 'learning_rate': 0.00018913705583756342, 'epoch': 3.92}                                                                                                      
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                             | 5600/14290 [7:39:02<3:11:18,  1.32s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29310864210128784, 'eval_wer': 0.493343653250774, 'eval_cer': 0.11885121303634041, 'eval_runtime': 400.0851, 'eval_samples_per_second': 24.067, 'eval_steps_per_second': 3.009, 'epoch': 3.92}                                                                                                                                              
{'loss': 0.3406, 'learning_rate': 0.00018891950688905003, 'epoch': 3.93}                                                                                                      
{'loss': 0.4018, 'learning_rate': 0.00018870195794053662, 'epoch': 3.93}                                                                                                      
{'loss': 0.3857, 'learning_rate': 0.00018848440899202318, 'epoch': 3.94}                                                                                                      
{'loss': 0.427, 'learning_rate': 0.00018826686004350977, 'epoch': 3.95}                                                                                                       
{'loss': 0.3242, 'learning_rate': 0.00018804931109499634, 'epoch': 3.95}                                                                                                      
{'loss': 0.332, 'learning_rate': 0.00018783176214648295, 'epoch': 3.96}                                                                                                       
{'loss': 0.403, 'learning_rate': 0.00018761421319796954, 'epoch': 3.97}                                                                                                       
{'loss': 0.45, 'learning_rate': 0.0001873966642494561, 'epoch': 3.97}                                                                                                         
{'loss': 0.4045, 'learning_rate': 0.0001871791153009427, 'epoch': 3.98}                                                                                                       
{'loss': 0.3281, 'learning_rate': 0.00018696156635242928, 'epoch': 3.99}                                                                                                      
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                             | 5700/14290 [7:47:25<2:41:33,  1.13s/it]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.29166722297668457, 'eval_wer': 0.48335317932841154, 'eval_cer': 0.11633461021369167, 'eval_runtime': 400.7292, 'eval_samples_per_second': 24.029, 'eval_steps_per_second': 3.005, 'epoch': 3.99}                                                                                                                                            
{'loss': 0.3929, 'learning_rate': 0.00018674401740391587, 'epoch': 4.0}                                                                                                       
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                            | 5712/14290 [7:54:16<7:22:26,  3.09s/it]Saving model checkpoint to ./russian_augmented/checkpoint-5712
Configuration saved in ./russian_augmented/checkpoint-5712/config.json
Model weights saved in ./russian_augmented/checkpoint-5712/pytorch_model.bin
Feature extractor saved in ./russian_augmented/checkpoint-5712/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4033, 'learning_rate': 0.00018652646845540244, 'epoch': 4.0}                                                                                                       
{'loss': 0.2959, 'learning_rate': 0.00018630891950688903, 'epoch': 4.01}                                                                                                      
{'loss': 0.284, 'learning_rate': 0.00018609137055837564, 'epoch': 4.02}                                                                                                       
{'loss': 0.3192, 'learning_rate': 0.0001858738216098622, 'epoch': 4.02}                                                                                                       
{'loss': 0.3903, 'learning_rate': 0.0001856562726613488, 'epoch': 4.03}                                                                                                       
{'loss': 0.3185, 'learning_rate': 0.00018543872371283536, 'epoch': 4.04}                                                                                                      
{'loss': 0.2878, 'learning_rate': 0.00018522117476432195, 'epoch': 4.04}                                                                                                      
{'loss': 0.3006, 'learning_rate': 0.00018500362581580856, 'epoch': 4.05}                                                                                                      
{'loss': 0.3622, 'learning_rate': 0.00018478607686729512, 'epoch': 4.06}                                                                                                      
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                            | 5800/14290 [7:55:54<2:05:35,  1.13it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2906414270401001, 'eval_wer': 0.47949511788521076, 'eval_cer': 0.11353932318585028, 'eval_runtime': 400.0606, 'eval_samples_per_second': 24.069, 'eval_steps_per_second': 3.01, 'epoch': 4.06}                                                                                                                                              
{'loss': 0.3523, 'learning_rate': 0.00018456852791878171, 'epoch': 4.07}                                                                                                      
{'loss': 0.4122, 'learning_rate': 0.00018435097897026828, 'epoch': 4.07}                                                                                                      
{'loss': 0.3026, 'learning_rate': 0.0001841334300217549, 'epoch': 4.08}                                                                                                       
{'loss': 0.3077, 'learning_rate': 0.00018391588107324148, 'epoch': 4.09}                                                                                                      
{'loss': 0.3513, 'learning_rate': 0.00018369833212472804, 'epoch': 4.09}                                                                                                      
{'loss': 0.3718, 'learning_rate': 0.00018348078317621463, 'epoch': 4.1}                                                                                                       
{'loss': 0.3563, 'learning_rate': 0.0001832632342277012, 'epoch': 4.11}                                                                                                       
{'loss': 0.3086, 'learning_rate': 0.0001830456852791878, 'epoch': 4.11}                                                                                                       
{'loss': 0.2986, 'learning_rate': 0.0001828281363306744, 'epoch': 4.12}                                                                                                       
{'loss': 0.3731, 'learning_rate': 0.00018261058738216096, 'epoch': 4.13}                                                                                                      
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                           | 5900/14290 [8:04:18<2:05:03,  1.12it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.3005143404006958, 'eval_wer': 0.47635151226482497, 'eval_cer': 0.11435172986886641, 'eval_runtime': 408.2733, 'eval_samples_per_second': 23.585, 'eval_steps_per_second': 2.949, 'epoch': 4.13}                                                                                                                                             
{'loss': 0.3734, 'learning_rate': 0.00018239303843364755, 'epoch': 4.14}                                                                                                      
{'loss': 0.3671, 'learning_rate': 0.00018217548948513412, 'epoch': 4.14}                                                                                                      
{'loss': 0.3012, 'learning_rate': 0.00018195794053662073, 'epoch': 4.15}                                                                                                      
{'loss': 0.3382, 'learning_rate': 0.0001817403915881073, 'epoch': 4.16}                                                                                                       
{'loss': 0.3703, 'learning_rate': 0.00018152284263959389, 'epoch': 4.16}                                                                                                      
{'loss': 0.3758, 'learning_rate': 0.0001813052936910805, 'epoch': 4.17}                                                                                                       
{'loss': 0.3396, 'learning_rate': 0.00018108774474256706, 'epoch': 4.18}                                                                                                      
{'loss': 0.3011, 'learning_rate': 0.00018087019579405365, 'epoch': 4.18}                                                                                                      
{'loss': 0.3143, 'learning_rate': 0.00018065264684554022, 'epoch': 4.19}                                                                                                      
{'loss': 0.3501, 'learning_rate': 0.0001804350978970268, 'epoch': 4.2}                                                                                                        
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                          | 6000/14290 [8:12:53<2:05:19,  1.10it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.286941260099411, 'eval_wer': 0.47213622291021673, 'eval_cer': 0.11239756244215192, 'eval_runtime': 409.0152, 'eval_samples_per_second': 23.542, 'eval_steps_per_second': 2.944, 'epoch': 4.2}                                                                                                                                               
{'loss': 0.4152, 'learning_rate': 0.00018021754894851342, 'epoch': 4.21}                                                                                                      
{'loss': 0.3751, 'learning_rate': 0.00017999999999999998, 'epoch': 4.21}                                                                                                      
{'loss': 0.3239, 'learning_rate': 0.00017978245105148657, 'epoch': 4.22}                                                                                                      
{'loss': 0.3503, 'learning_rate': 0.00017956490210297314, 'epoch': 4.23}                                                                                                      
{'loss': 0.3324, 'learning_rate': 0.00017934735315445973, 'epoch': 4.23}                                                                                                      
{'loss': 0.3961, 'learning_rate': 0.00017912980420594634, 'epoch': 4.24}                                                                                                      
{'loss': 0.3257, 'learning_rate': 0.0001789122552574329, 'epoch': 4.25}                                                                                                       
{'loss': 0.2854, 'learning_rate': 0.0001786947063089195, 'epoch': 4.25}                                                                                                       
{'loss': 0.3531, 'learning_rate': 0.00017847715736040606, 'epoch': 4.26}                                                                                                      
{'loss': 0.3198, 'learning_rate': 0.00017825960841189267, 'epoch': 4.27}                                                                                                      
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                         | 6100/14290 [8:21:27<2:02:55,  1.11it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2991798222064972, 'eval_wer': 0.47432722076684924, 'eval_cer': 0.11147030408669274, 'eval_runtime': 410.2454, 'eval_samples_per_second': 23.471, 'eval_steps_per_second': 2.935, 'epoch': 4.27}                                                                                                                                             
{'loss': 0.3656, 'learning_rate': 0.00017804205946337926, 'epoch': 4.28}                                                                                                      
{'loss': 0.3478, 'learning_rate': 0.00017782451051486582, 'epoch': 4.28}                                                                                                      
{'loss': 0.2957, 'learning_rate': 0.00017760696156635241, 'epoch': 4.29}                                                                                                      
{'loss': 0.3146, 'learning_rate': 0.00017738941261783898, 'epoch': 4.3}                                                                                                       
{'loss': 0.3115, 'learning_rate': 0.0001771718636693256, 'epoch': 4.3}                                                                                                        
{'loss': 0.3719, 'learning_rate': 0.00017695431472081216, 'epoch': 4.31}                                                                                                      
{'loss': 0.3314, 'learning_rate': 0.00017673676577229875, 'epoch': 4.32}                                                                                                      
{'loss': 0.2907, 'learning_rate': 0.00017651921682378533, 'epoch': 4.32}                                                                                                      
{'loss': 0.296, 'learning_rate': 0.00017630166787527192, 'epoch': 4.33}                                                                                                       
{'loss': 0.3625, 'learning_rate': 0.0001760841189267585, 'epoch': 4.34}                                                                                                       
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                        | 6200/14290 [8:30:05<2:06:36,  1.06it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.28357309103012085, 'eval_wer': 0.4651940938318647, 'eval_cer': 0.11057851463007627, 'eval_runtime': 412.3063, 'eval_samples_per_second': 23.354, 'eval_steps_per_second': 2.92, 'epoch': 4.34}                                                                                                                                              
{'loss': 0.3464, 'learning_rate': 0.00017586656997824508, 'epoch': 4.35}                                                                                                      
{'loss': 0.4507, 'learning_rate': 0.00017564902102973167, 'epoch': 4.35}                                                                                                      
{'loss': 0.3045, 'learning_rate': 0.00017543147208121828, 'epoch': 4.36}                                                                                                      
{'loss': 0.343, 'learning_rate': 0.00017521392313270484, 'epoch': 4.37}                                                                                                       
{'loss': 0.3737, 'learning_rate': 0.00017499637418419143, 'epoch': 4.37}                                                                                                      
{'loss': 0.3485, 'learning_rate': 0.000174778825235678, 'epoch': 4.38}                                                                                                        
{'loss': 0.4254, 'learning_rate': 0.00017456127628716459, 'epoch': 4.39}                                                                                                      
{'loss': 0.306, 'learning_rate': 0.0001743437273386512, 'epoch': 4.39}                                                                                                        
{'loss': 0.3352, 'learning_rate': 0.00017412617839013776, 'epoch': 4.4}                                                                                                       
{'loss': 0.337, 'learning_rate': 0.00017390862944162435, 'epoch': 4.41}                                                                                                       
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                       | 6300/14290 [8:38:42<2:02:41,  1.09it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2898269593715668, 'eval_wer': 0.47281495594189094, 'eval_cer': 0.1105160218083058, 'eval_runtime': 412.1161, 'eval_samples_per_second': 23.365, 'eval_steps_per_second': 2.922, 'epoch': 4.41}                                                                                                                                              
{'loss': 0.3429, 'learning_rate': 0.00017369108049311092, 'epoch': 4.42}                                                                                                      
{'loss': 0.4206, 'learning_rate': 0.00017347353154459753, 'epoch': 4.42}                                                                                                      
{'loss': 0.2995, 'learning_rate': 0.00017325598259608412, 'epoch': 4.43}                                                                                                      
{'loss': 0.301, 'learning_rate': 0.00017303843364757068, 'epoch': 4.44}                                                                                                       
{'loss': 0.3387, 'learning_rate': 0.00017282088469905727, 'epoch': 4.44}                                                                                                      
{'loss': 0.3223, 'learning_rate': 0.00017260333575054384, 'epoch': 4.45}                                                                                                      
{'loss': 0.3786, 'learning_rate': 0.00017238578680203045, 'epoch': 4.46}                                                                                                      
{'loss': 0.271, 'learning_rate': 0.00017216823785351702, 'epoch': 4.46}                                                                                                       
{'loss': 0.2837, 'learning_rate': 0.0001719506889050036, 'epoch': 4.47}                                                                                                       
{'loss': 0.3302, 'learning_rate': 0.0001717331399564902, 'epoch': 4.48}                                                                                                       
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                      | 6400/14290 [8:47:21<2:00:35,  1.09it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2894989848136902, 'eval_wer': 0.46624196237199333, 'eval_cer': 0.11032516535262842, 'eval_runtime': 408.4728, 'eval_samples_per_second': 23.573, 'eval_steps_per_second': 2.948, 'epoch': 4.48}                                                                                                                                             
{'loss': 0.3348, 'learning_rate': 0.00017151559100797678, 'epoch': 4.49}                                                                                                      
{'loss': 0.3904, 'learning_rate': 0.00017129804205946337, 'epoch': 4.49}                                                                                                      
{'loss': 0.3035, 'learning_rate': 0.00017108049311094994, 'epoch': 4.5}                                                                                                       
{'loss': 0.3183, 'learning_rate': 0.00017086294416243653, 'epoch': 4.51}                                                                                                      
{'loss': 0.3194, 'learning_rate': 0.00017064539521392314, 'epoch': 4.51}                                                                                                      
{'loss': 0.3742, 'learning_rate': 0.0001704278462654097, 'epoch': 4.52}                                                                                                       
{'loss': 0.3437, 'learning_rate': 0.0001702102973168963, 'epoch': 4.53}                                                                                                       
{'loss': 0.2803, 'learning_rate': 0.00016999274836838286, 'epoch': 4.53}                                                                                                      
{'loss': 0.3079, 'learning_rate': 0.00016977519941986945, 'epoch': 4.54}                                                                                                      
{'loss': 0.3581, 'learning_rate': 0.00016955765047135606, 'epoch': 4.55}                                                                                                      
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                     | 6500/14290 [8:55:55<1:59:23,  1.09it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.28143301606178284, 'eval_wer': 0.46234817813765183, 'eval_cer': 0.11046366295763324, 'eval_runtime': 412.5161, 'eval_samples_per_second': 23.342, 'eval_steps_per_second': 2.919, 'epoch': 4.55}                                                                                                                                            
{'loss': 0.3797, 'learning_rate': 0.00016934010152284262, 'epoch': 4.56}                                                                                                      
{'loss': 0.3613, 'learning_rate': 0.00016912255257432921, 'epoch': 4.56}                                                                                                      
{'loss': 0.3006, 'learning_rate': 0.00016890500362581578, 'epoch': 4.57}                                                                                                      
{'loss': 0.3395, 'learning_rate': 0.0001686874546773024, 'epoch': 4.58}                                                                                                       
{'loss': 0.3156, 'learning_rate': 0.00016846990572878898, 'epoch': 4.58}                                                                                                      
{'loss': 0.4216, 'learning_rate': 0.00016825235678027554, 'epoch': 4.59}                                                                                                      
{'loss': 0.323, 'learning_rate': 0.00016803480783176213, 'epoch': 4.6}                                                                                                        
{'loss': 0.2799, 'learning_rate': 0.0001678172588832487, 'epoch': 4.6}                                                                                                        
{'loss': 0.3188, 'learning_rate': 0.0001675997099347353, 'epoch': 4.61}                                                                                                       
{'loss': 0.3293, 'learning_rate': 0.00016738216098622188, 'epoch': 4.62}                                                                                                      
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                     | 6600/14290 [9:04:34<1:56:30,  1.10it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2824387848377228, 'eval_wer': 0.46245534651107406, 'eval_cer': 0.11066634237959154, 'eval_runtime': 410.3707, 'eval_samples_per_second': 23.464, 'eval_steps_per_second': 2.934, 'epoch': 4.62}                                                                                                                                             
{'loss': 0.3537, 'learning_rate': 0.00016716461203770847, 'epoch': 4.63}                                                                                                      
{'loss': 0.3794, 'learning_rate': 0.00016694706308919505, 'epoch': 4.63}                                                                                                      
{'loss': 0.297, 'learning_rate': 0.00016672951414068162, 'epoch': 4.64}                                                                                                       
{'loss': 0.3202, 'learning_rate': 0.00016651196519216823, 'epoch': 4.65}                                                                                                      
{'loss': 0.3494, 'learning_rate': 0.0001662944162436548, 'epoch': 4.65}                                                                                                       
{'loss': 0.35, 'learning_rate': 0.00016607686729514139, 'epoch': 4.66}                                                                                                        
{'loss': 0.3295, 'learning_rate': 0.000165859318346628, 'epoch': 4.67}                                                                                                        
{'loss': 0.3051, 'learning_rate': 0.00016564176939811456, 'epoch': 4.67}                                                                                                      
{'loss': 0.3302, 'learning_rate': 0.00016542422044960115, 'epoch': 4.68}                                                                                                      
{'loss': 0.3324, 'learning_rate': 0.00016520667150108772, 'epoch': 4.69}                                                                                                      
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                    | 6700/14290 [9:13:10<1:55:55,  1.09it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8
{'eval_loss': 0.2778180241584778, 'eval_wer': 0.4587639914265301, 'eval_cer': 0.11117641892485322, 'eval_runtime': 415.2591, 'eval_samples_per_second': 23.188, 'eval_steps_per_second': 2.899, 'epoch': 4.69}                                                                                                                                              
{'loss': 0.3471, 'learning_rate': 0.0001649891225525743, 'epoch': 4.7}                                                                                                        
{'loss': 0.3324, 'learning_rate': 0.00016477157360406092, 'epoch': 4.7}                                                                                                       
{'loss': 0.3063, 'learning_rate': 0.00016455402465554748, 'epoch': 4.71}                                                                                                      
{'loss': 0.3204, 'learning_rate': 0.00016433647570703407, 'epoch': 4.72}                                                                                                      
{'loss': 0.3037, 'learning_rate': 0.00016411892675852064, 'epoch': 4.72}                                                                                                      
{'loss': 0.3959, 'learning_rate': 0.00016390137781000725, 'epoch': 4.73}                                                                                                      
{'loss': 0.3485, 'learning_rate': 0.00016368382886149384, 'epoch': 4.74}                                                                                                      
{'loss': 0.2905, 'learning_rate': 0.0001634662799129804, 'epoch': 4.74}                                                                                                       
{'loss': 0.3232, 'learning_rate': 0.000163248730964467, 'epoch': 4.75}                                                                                                        
{'loss': 0.3092, 'learning_rate': 0.00016303118201595356, 'epoch': 4.76}                                                                                                      
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                   | 6800/14290 [9:21:52<1:56:35,  1.07it/s]***** Running Evaluation *****
  Num examples = 9629
  Batch size = 8

Killedâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                 | 760/1204 [04:32<02:46,  2.66it/s]
(base) or@anidjar:~/Desktop/wav2vec2$ 


